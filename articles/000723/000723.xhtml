<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>[PREVIEW] DHQ: Digital Humanities Quarterly: </title>
      <link href="../../common/css/dhq.css" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_screen.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_print.css" media="print" type="text/css" rel="stylesheet" />
      <style type="text/css">
        #mainContent {
          float: none;
          padding-top: 2em;
          padding-left: 4em;
          padding-right: 4em;
          margin-left: 225px;
           
        }</style>
   </head>
   <body>
      <div id="mainContent">
         <div class="DHQarticle">
            <div id="pubInfo">Preview<br />Volume  Number </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            
            <div class="DHQheader">
               
               
               
               <h1 class="articleTitle lang en">Problems of Authorship Classification: Recognising the Author Style or a Book?</h1>
               
               <div class="author"><span style="color: grey">František Válek</span> &lt;<a href="mailto:frantisek_dot_valek_at_upce_dot_cz" onclick="javascript:window.location.href='mailto:'+deobfuscate('frantisek_dot_valek_at_upce_dot_cz'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('frantisek_dot_valek_at_upce_dot_cz'); return false;">frantisek_dot_valek_at_upce_dot_cz</a>&gt;, National Library of the Czech Republic; Department of Philosophy and Religious Studies,
                  University of 
                  Pardubice; Institute of Ancient Near Eastern Studies, Charles University</div>
               
               <div class="author"><span style="color: grey">Jan Hajič, Jr.</span> &lt;<a href="mailto:hajicj_at_ufal_dot_mff_dot_cuni_dot_cz" onclick="javascript:window.location.href='mailto:'+deobfuscate('hajicj_at_ufal_dot_mff_dot_cuni_dot_cz'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('hajicj_at_ufal_dot_mff_dot_cuni_dot_cz'); return false;">hajicj_at_ufal_dot_mff_dot_cuni_dot_cz</a>&gt;, National Library of the Czech Republic; Masaryk Institute and Archive, 
                  Czech Academy of Sciences; Institute of Formal and Applied Linguistics, Charles University</div>
               
               
               
               
               
               
               
               <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Problems%20of%20Authorship%20Classification%3A%20Recognising%20the%20Author%20Style%20or%20a%20Book%3F&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=&amp;rft.volume=&amp;rft.issue=&amp;rft.aulast=Válek&amp;rft.aufirst=František&amp;rft.au=František%20Válek&amp;rft.au=Jan%20Hajič"> </span></div>
            
            <div id="DHQtext">
               
               
               <div id="abstract">
                  <h2>Abstract</h2>
                  
                  <p>The presented article proposes that one of the problems regarding authorship attribution
                     tasks is the attribution of a 
                     specific book rather than the author. This often leads to overestimated reported performance.
                     This problem is in general 
                     connected to the dataset construction and more specifically to the train-test data
                     split. Using a heavily delexicalized 
                     and diverse dataset of Czech authors and basic LinearSVC classifiers, we designed
                     a three-step experiment setting to 
                     explore book versus author attribution effects. First, the authorship attribution
                     task is performed on a dataset split 
                     to train and test data segments across books. Second, the same task is performed on
                     a dataset where individual books 
                     are used wholly either for training or testing. Expectedly, this leads to poorer results.
                     In the third step, we do not 
                     attribute book segments to authors but to books themselves. This step reveals that
                     there is a general tendency towards 
                     attributing to a specific book rather than to different books of the same author.
                     The results indicate that authors 
                     who show a higher inner confusion among their works tend to perform better in the
                     task of attribution of an unseen book.</p>
                  </div>
               
               
               
               
               <div class="div div0">
                  
                  <h1 class="head">Introduction</h1>
                  
                  <div class="counter"><a href="#p1">1</a></div>
                  <div class="ptext" id="p1">Authorship attribution using machine learning is a fertile area of digital literary
                     scholarship<a class="noteRef" href="#d4e199">[1]</a> 
                     to such an extent that it has its own software package within the R programming language
                     ecosystem.<a class="noteRef" href="#d4e240">[2]</a> Feature design is the most interesting 
                     sub-problem in terms of classification performance; very recently, Robert Gorman has achieved impressive results with 
                     morphosyntactic instead of lexical features, also for very short segments [<a class="ref" href="#gorman2022">Gorman 2022</a>]. However, we explore 
                     a different aspect of the problem: that of experiment design and, by implication,
                     dataset design. Issues of dataset imbalance, 
                     genre consistency and dataset sizes (both in terms of the total number of tokens and
                     texts, as well as the number of authors) 
                     have been discussed, for instance, in the works of Efstathios Stamatatos and Kim Luyckx, but what 
                     has received comparatively little attention is stylistic variation among the works
                     of a single author 
                     [<a class="ref" href="#stamatatos2009">Stamatatos 2009</a>] [<a class="ref" href="#luyckx2011">Luyckx 2011</a>].
                     </div>
                  
                  <div class="counter"><a href="#p2">2</a></div>
                  <div class="ptext" id="p2">In this article, we show that in the domain of long-form literary works, stylistic
                     variation between individual works 
                     of the same author is a significant factor that should be reflected in the dataset
                     and experiment design. Assuming that we 
                     are interested in capturing features of authorial styles that transcend the boundaries
                     of their known works (especially 
                     to attribute texts with unclear authorship, such as in the seminal study of <cite class="title italic">The Federalist Papers</cite> 
                     by Frederick Mosteller and David L. Wallace), a test set that includes different segments of 
                     works that have been previously used during training will significantly overestimate
                     the system's accuracy for unseen texts 
                     and therefore overestimate the system's ability to characterise authorial style, as
                     opposed to the styles of individual works 
                     [<a class="ref" href="#mosteller_wallace1964">Mosteller and Wallace 1964</a>]. The extent of this overestimation differs significantly among individual authors;
                     
                     some have a more consistent style than others.
                     </div>
                  
                  <div class="counter"><a href="#p3">3</a></div>
                  <div class="ptext" id="p3">Our findings are applicable when we are interested in attributing texts to authors
                     <em class="emph">despite</em> their stylistic 
                     inconsistencies. This may not always be the case – an authorship attribution system
                     might be used for other purposes, such 
                     as to find which observable linguistic features are responsible for stylistic distinctions,
                     where the classification task 
                     is merely a proxy for the true goal (which would then be achieved through feature
                     selection). Note also that our findings 
                     only apply to classifying texts that are long enough to be processed by segments.
                     This is often the case with
                     applications in the study of literature, less so in attributing authorship of short
                     texts such as emails or tweets.
                     </div>
                  
                  <div class="counter"><a href="#p4">4</a></div>
                  <div class="ptext" id="p4">The contribution of our article can be summarised thus: the stylistic variation between
                     individual books of an author 
                     is significant enough to affect state-of-the-art authorship classification system
                     performance. Thus, to credibly
                     claim a certain level of ability to classify the style of an <em class="emph">author</em> as opposed to the style of 
                     individual <em class="emph">books</em>, the evaluation set should contain whole books not seen during training. We believe
                     these 
                     findings are useful, first of all, to authorship attribution system designers, as
                     we quantify the extent to which stylistic
                     variation among books matters to the classifier. Thus, we provide a guideline for
                     evaluation design so that system 
                     performance is not overestimated. Second, we believe our findings are useful to the
                     literary scholar selecting a
                     classification system to inform judgments about the authorship of unattributed texts,
                     as our findings show that 
                     systems that do not test on unseen books cannot be trusted to perform as well as their
                     evaluation results indicate.
                     </div>
                  
                  <div class="counter"><a href="#p5">5</a></div>
                  <div class="ptext" id="p5">It should be noted that we did <em class="emph">not</em> aim to maximise the classification accuracy beyond a reasonable fraction 
                     of the state-of-the-art [<a class="ref" href="#tyo_dhingra_lipton2022">Tyo, Dhingra, and Lipton 2022</a>]. We used the standard, state-of-the-art Support Vector 
                     Machine (SVM) classifier and performed a brief hyperparameter search over possible
                     settings.
                     </div>
                  
                  <div class="counter"><a href="#p6">6</a></div>
                  <div class="ptext" id="p6">Crucially, as in [<a class="ref" href="#gorman2022">Gorman 2022</a>], we perform <em class="term">delexicalisation</em>. This is a step that replaces words 
                     (primarily autosemantic words, such as nouns, adjectives, verbs, and adverbs) with
                     just their morphosyntactic properties 
                     so that the topics and contents of individual books do not artificially inflate the
                     stylistic differences between 
                     individual books. Imagine that the same author wrote one novel from a 19th-century
                     farm environment and one from a 
                     Great War factory. While the style in terms of linguistic choices in both books may
                     be very similar, the vastly different 
                     content and, therefore, vocabulary would make it difficult to identify the factory
                     book as being written by the same 
                     author as the farm book. The process of delexicalisation filters out such content-related
                     confounding factors when 
                     focusing on author style detection: names of characters and places, characteristic
                     objects (such as the presence of 
                     automobiles or wireless communication), genres (such as realist or anarchist perspectives
                     on social conditions vs. 
                     detective stories or gothic fiction), and environments (urban vs. rural, wartime vs.
                     peacetime conditions) and helps 
                     to avoid confusion of authors dealing with the same topics or writing about the same
                     geographical areas. On the 
                     other hand, one must be aware that delexicalisation implicitly restricts the definition
                     of “authorial style” by 
                     excluding vocabulary choices (of autosemantic words) and some elements of register
                     (such as informality expressed in 
                     Czech by orthography of word endings). Some aspects of the author style are therefore
                     lost in delexicalisation. However, 
                     we consider it more important to remove confounding factors that can identify specific
                     books (and therefore authors), 
                     which can hardly be considered elements of author style. Given that we are attempting
                     to explore the extent to which 
                     author style varies between books, we want to avoid leveraging trivial sources of
                     this variation.
                     </div>
                  
                  <div class="counter"><a href="#p7">7</a></div>
                  <div class="ptext" id="p7">It should be noted that the use of non-lexical features is by no means rare in computational
                     stylometry 
                     [<a class="ref" href="#swain_mishra_sindhu2017">Swain, Mishra, and Sindhu 2017</a>]. We use the UDPipe morphosyntactic feature extractor to extract morphological 
                     features [<a class="ref" href="#nivre2015">Nivre 2015</a>]. (Notably, while [<a class="ref" href="#gorman2022">Gorman 2022</a>] uses UDpipe features as well, they
                     combine them in a more sophisticated manner and achieve better absolute accuracies,
                     especially for shorter segments.)
                     </div>
                  
                  <div class="counter"><a href="#p8">8</a></div>
                  <div class="ptext" id="p8">In the rest of the article, we first introduce our dataset and specify pre-processing
                     and hyperparameter search procedures 
                     and results. Then, we demonstrate our findings in three experimental steps. First,
                     we establish the baseline accuracies for 
                     a system that does not distinguish between training and test books. Next, we show
                     how results change once specific books 
                     are set aside for testing. Finally, we show how the tension between author and book
                     style is distributed across the dataset.
                     </div>
                  
                  <div class="counter"><a href="#p9">9</a></div>
                  <div class="ptext" id="p9">The following visualisation summarises our findings. The columns show results for
                     different segmentation lengths 
                     (in tokens, see below). The first part shows the results of our classifiers when each
                     of the books is split into train 
                     and test segments. Here, a different selection of test segments does not significantly
                     influence the performance. The 
                     following rows show the results when the train-test split is not done across all books,
                     but one book for each author is
                     left out of training and used for testing. With a random selection, five runs were
                     performed. The performance correlates 
                     significantly with segment lengths and is also greatly influenced by the test-book
                     selection.
                     </div>
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row label">
                           
                           <td valign="top" class="cell label" colspan="6" rowspan="1"><span class="hi italic">Train and Test Across All Books of the Dataset</span> (Experiments: Step 1)</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"><span class="hi italic">Segment Length</span></td> 
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-1000</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-500</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-200</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-100</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-50</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Full Dataset</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.73</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.58</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.42</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Validation</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.91</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.74</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.58</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.42</td>
                           </tr>
                        <tr class="row label">
                           
                           <td valign="top" class="cell label" colspan="6" rowspan="1"><span class="hi italic">Train Books vs. Test Books</span> (Experiments: Step 2)</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Set 1</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.80</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.62</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.44</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.29</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Set 2</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.78</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.58</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.38</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.23</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Set 3</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.82</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.63</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.42</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.26</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Set 4</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.77</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.69</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.51</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.35</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.23</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Set 5</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.92</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.85</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.66</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.47</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.33</td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 1. </div>Summary Table of Results</div>
                  </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Dataset</h1>
                  
                  <div class="counter"><a href="#p10">10</a></div>
                  <div class="ptext" id="p10">Our dataset consists of 210 books (written in Czech) by 23 authors (for a full overview,
                     see the table in the appendix). 
                     The authors were chosen from the late 19th and early 20th centuries to avoid differences
                     in the written form of the Czech 
                     language due to chronological development in standardisation. This limited timeframe
                     reduces differences in style stemming
                     from the varied periods of origin. The dataset is far from being balanced: for each
                     author, we have chosen a different 
                     number of books (ranging from 4 books by Č. Slepánek to 18 books by K. Čapek) of varying lengths 
                     (the shortest book consists of only 6,004 tokens while the longest contains 300,021
                     tokens). In addition, even though novels 
                     dominantly prevail, the genres vary across the dataset. See the appendix for a detailed
                     overview of the dataset.
                     </div>
                  
                  <div class="counter"><a href="#p11">11</a></div>
                  <div class="ptext" id="p11">Such a diverse and unbalanced nature dataset may not be ideal for machine learning
                     (ML) experiments, but it reflects the 
                     reality of library collections and the issues with authorship attribution. There are
                     several features of our dataset that can be
                     contrasted with the dataset of [<a class="ref" href="#gorman2022">Gorman 2022</a>] and show that what Gorman presents as a difficult problem must be 
                     problematised even further.<a class="noteRef" href="#d4e531">[3]</a>
                     </div>
                  
                  <div class="counter"><a href="#p12">12</a></div>
                  <div class="ptext" id="p12">First, we have included several books by each of the authors. Therefore, our dataset
                     has the potential to demonstrate 
                     whether different authors change their style across their works. As is discussed below,
                     our experiments have shown that
                     some authors are more consistent across their work, allowing us to accurately attribute
                     to them a book which has never 
                     been seen within the training process, while other authors vary their style to such
                     an extent that attributing an unseen book 
                     to them is almost impossible. In these cases, when trained and tested across the dataset,
                     we are actually attributing 
                     individual books and not the author.
                     </div>
                  
                  <div class="counter"><a href="#p13">13</a></div>
                  <div class="ptext" id="p13">Second, the books we have chosen vary greatly in length. [<a class="ref" href="#gorman2022">Gorman 2022</a>] has chosen works that include at 
                     least 20,000 tokens. In our dataset, we have 17 books that do not reach this limit,
                     but we compensate for this by 
                     including more books for each of the authors, so there are significantly more than
                     20,000 tokens for each author, ranging 
                     from 174,115 tokens for Č. Slepánek) to 1,512,167 tokens for A. Jirásek.
                     </div>
                  
                  <div class="counter"><a href="#p14">14</a></div>
                  <div class="ptext" id="p14">Finally, our dataset includes mainly prose (mostly literary, but also journalistic
                     and scholarly), a few works of drama, 
                     and one item of poetry. This further complicates the problem mentioned in the previous
                     paragraph. While 
                     [<a class="ref" href="#gorman2022">Gorman 2022</a>] is right that varying genres may lead to the confounding of genres with author styles,
                     we 
                     believe that we can learn something interesting from including such data. In the end,
                     our experiments have shown that 
                     author style remains partially preserved across genres. Expanding the dataset with
                     works of drama and poetry may be fruitful in 
                     the future, but this must be done hand-in-hand with an expansion of author selection
                     (as the selected authors are 
                     predominantly novelists).
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Data Preparation</h1>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Data Cleaning</h2>
                     
                     <div class="counter"><a href="#p15">15</a></div>
                     <div class="ptext" id="p15">The raw data we have at our disposal are scanned books that have been processed with
                        optical character recognition 
                        (OCR).<a class="noteRef" href="#d4e572">[4]</a>Therefore, some cleaning was necessary. Basic automatised data cleaning was performed<a class="noteRef" href="#d4e580">[5]</a>, followed by a manual clearing of junk data such as 
                        imprints, tables of contents, forewords, afterwords, and endnotes. Finally, hyphenated
                        words were restored across 
                        line boundaries and page boundaries. For the sake of keeping the pipeline simple,
                        we did not fix OCR errors; they 
                        could, however, be mitigated using, for example, the LINDAT Korektor service.<a class="noteRef" href="#d4e582">[6]</a>
                        </div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Segments and Train-Test Split</h2>
                     
                     <div class="counter"><a href="#p16">16</a></div>
                     <div class="ptext" id="p16">For training and testing authorship detection, we must split the books into shorter
                        segments. For testing, we 
                        need a sufficient number of test samples to provide meaningful accuracy estimates.
                        For training, this is necessary to
                        provide a sufficient number of data points while keeping the segments long enough
                        to provide meaningful estimates of 
                        the relationship between feature distributions and segment authors.
                        </div>
                     
                     <div class="counter"><a href="#p17">17</a></div>
                     <div class="ptext" id="p17">We split the dataset into segments of 1000, 500, 200, 100, and 50 tokens as data points
                        for classification 
                        experiments, denoted s-1000, s-500, and so on. Because we want the dataset to allow
                        us to investigate how authorial 
                        style is expressed through other than lexical choices, including potentially syntactic
                        features (although we do not 
                        use those in this work), we decided only to draw segment boundaries at the sentence
                        level. Thus, these segment
                        lengths represent the <em class="emph">average</em> segment lengths because sentences occur in lengths that do not sum 
                        exactly to the desired multiple of 50. We discarded end-of-book segments if they were
                        shorter than half the target 
                        segment length. To maintain a consistent training and test set so that results are
                        directly comparable between 
                        segment lengths, we first built the s-1000 segmentation, assigned these segments to
                        training and test sets, and then 
                        obtained the shorter segmentations by splitting the s-1000 segments, rather than re-segmenting
                        the entire books. This 
                        ensures that each test segment in the shorter segmentations is a subset of a test
                        segment in s-1000, and each training 
                        segment in shorter segmentations is a subset of a training segment in s-1000, maintaining
                        the same content of the
                        test and training sets across different segment lengths. (Note that this is a dataset
                        design choice, not an experiment 
                        design, with the primary aim of enabling a direct comparison to the results presented
                        in Experiment and Results, Step 1.)
                        </div>
                     
                     <div class="counter"><a href="#p18">18</a></div>
                     <div class="ptext" id="p18">Specifically, we have pre-split the data into “train” (60%), “development” (20%), and “test” (20%) segments 
                        in order to make future direct comparisons to our results with this dataset straightforward.<a class="noteRef" href="#d4e610">[7]</a> 
                        However, as we have not made any attempts at optimising the classifiers and instead
                        used their default settings (see below), 
                        unless stated otherwise, the “training” set for all our experiments consists of both the “train” and 
                        “development” subsets of the dataset.
                        </div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Delexicalisation</h2>
                     
                     <div class="counter"><a href="#p19">19</a></div>
                     <div class="ptext" id="p19">As stated above, we have delexicalised the dataset using the publicly available Application
                        Programming Interface (API) 
                        of UDPipe at LINDAT/CLARIAH.<a class="noteRef" href="#d4e627">[8]</a> The
                        UDPipe service performs canonical tokenisation and outputs a set of extracted features
                        for each token. For the purpose 
                        of this article, we have applied delexicalisation that replaces all of the autosemantic
                        words<a class="noteRef" href="#d4e635">[9]</a> by their part-of-speech tag<a class="noteRef" href="#d4e637">[10]</a> and all other words by 
                        their lemmas.
                        </div>
                     
                     <div class="counter"><a href="#p20">20</a></div>
                     <div class="ptext" id="p20">In contrast, [<a class="ref" href="#gorman2022">Gorman 2022</a>] has provided a more nuanced and sophisticated approach to delexicalisation 
                        that indeed seems much more fruitful. In the future, combining the variety of experiments
                        presented in this paper and 
                        enhanced classifiers using more sophisticated forms of delexicalisation may yield
                        more significant results. Nonetheless, 
                        while not being the state-of-the-art approach, using POS and lemmatisation is well
                        established in the authorship 
                        attribution field [<a class="ref" href="#swain_mishra_sindhu2017">Swain, Mishra, and Sindhu 2017</a>].
                        </div>
                     
                     <div class="counter"><a href="#p21">21</a></div>
                     <div class="ptext" id="p21">In addition to using the above mentioned form of delexicalisation, we have performed
                        a variety of delexicalizations 
                        for a smaller subset of 6 authors (30 books) to explore the effects of different levels
                        of delexicalization on the 
                        performance of various classifiers (see below). Still, these forms of delexicalisation
                        do not reach the complexity of 
                        the approach utilized by [<a class="ref" href="#gorman2022">Gorman 2022</a>].</div>
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Hyperparameter Search: Authorship Classification at Varying Levels of Delexicalisation</h1>
                  
                  <div class="counter"><a href="#p22">22</a></div>
                  <div class="ptext" id="p22">To set reasonable parameters for the pipeline, we conducted a series of experiments,
                     working as a kind of grid search, 
                     to explore the results of different classifiers in relation to different levels of
                     delexicalisation. This is a
                     “lightweight” hyperparameter search that helps us find a model and pre-processing settings such
                     that we do not work 
                     with an unnecessarily underperforming setup, rather than finding an optimal setup
                     for the dataset.
                     </div>
                  
                  <div class="counter"><a href="#p23">23</a></div>
                  <div class="ptext" id="p23">Because these experiments are essentially a grid search, we have selected only a subset
                     of our data, consisting of 
                     six authors (5 books per each, 30 in total): A. Stašek, J. Neruda, J. Arbes, 
                     K. Klostermann, F. X. Šalda, and T. G. Masaryk.<a class="noteRef" href="#d4e682">[11]</a>
                     </div>
                  
                  <div class="counter"><a href="#p24">24</a></div>
                  <div class="ptext" id="p24">For these experiments, we chose one of 10 different levels of delexicalisation. All
                     of these pre-processings have 
                     been segmented in the same way as the larger dataset used for the rest of the experiments
                     (1000, 500, 200, 100, and 50 tokens). 
                     </div>
                  
                  <div class="counter"><a href="#p25">25</a></div>
                  <div class="ptext" id="p25">The different modes of delexicalisation were abbreviated as “r-codes”, from r-04 to r-13.<a class="noteRef" href="#d4e692">[12]</a> The baseline where no 
                     delexicalisation was applied is r-04. Delexicalisations based on UDPipe are applied
                     in r-05 through r-09.<a class="noteRef" href="#d4e694">[13]</a> We also applied NameTag 2 [<a class="ref" href="#strakova_straka_hajic2019">Straková, Straka, and Hajič 2019</a>]to replace named entities 
                     with tags specifying only the type of the named entity in r-10 through r-13.<a class="noteRef" href="#d4e702">[14]</a> The full list of 
                     delexicalisation settings we explored is as follows:
                     
                     <ul class="list">
                        <li class="item">r-04: No delexicalisation (baseline) — original word forms are used</li>
                        <li class="item">r-05: Lemmatisation — lemmas used instead of word forms</li>
                        <li class="item">r-06: Part-of-speech tags for all words</li>
                        <li class="item">r-07: Morphological tags for all words </li>
                        <li class="item">r-08: Part-of-speech tags for autosemantic words, others lemmatised</li>
                        <li class="item">r-09: Morphological tags for autosemantic words, others lemmatised</li>
                        <li class="item">r-10: NameTag tags for recognised named entities, others with original word forms</li>
                        <li class="item">r-11: NameTag tags for recognised named entities, others lemmatised</li>
                        <li class="item">r-12: NameTag tags for recognised named entities, part-of-speech tags for autosemantic
                           words, others lemmatised</li>
                        <li class="item">r-13 NameTag tags for recognised named entities, morphological tags for autosemantic
                           words, others lemmatised</li>
                     </ul>
                     </div>
                  
                  <div class="counter"><a href="#p26">26</a></div>
                  <div class="ptext" id="p26">We then conducted a series of experiments across all of these levels of delexicalisation
                     as well as across different 
                     segmentations. We have trained the following standard classifiers used in authorship
                     classification 
                     [<a class="ref" href="#savoy2020">Savoy 2020</a>, chap. 6], using the default implementations and hyperparameter settings in the 
                     scikit-learn library (https://scikit-learn.org/) [<a class="ref" href="#pedregosa_et_al2011">Pedregosa et al. 2011</a>]:
                     
                     <ul class="list">
                        <li class="item">Naive Bayes (sklearn.naive_bayes.MultinomialNB)</li>
                        <li class="item">C-Support Vector Classification (sklearn.svm.SVC)</li>
                        <li class="item">Linear Support Vector Classification (sklearn.svm.LinearSVC)</li>
                        <li class="item">K-Nearest Neighbours (sklearn.neighbors.KNeighborsClassifier)</li>
                        <li class="item">Stochastic Gradient Descent (sklearn.linear_model.SGDClassifier)</li>
                        <li class="item">Decision Tree (sklearn.tree.DecisionTreeClassifier)</li>
                     </ul>
                     </div>
                  
                  <div class="counter"><a href="#p27">27</a></div>
                  <div class="ptext" id="p27">We used the same feature extraction settings for each. The only adjusted setting was
                     word n-gram size, set to unigrams, 
                     bigrams, and trigrams. The training was performed using only the “train” passages, and the evaluation using only 
                     the “test” passages. Because we used the default settings, the “devel” passages were unnecessarily ignored 
                     during this phase. We performed multiple runs of trainings and evaluations across
                     the classifiers and pre-processing.
                     </div>
                  
                  <div class="counter"><a href="#p28">28</a></div>
                  <div class="ptext" id="p28">As an example, we provide here a table of results representing the accuracy scores
                     of the LinearSVC classifier run 
                     across all books with different pre-processing.
                     </div>
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"><span class="hi italic">Segment Length</span></td> 
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-1000</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-500</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-200</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-100</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">s-50</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-04</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.94</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.87</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-05</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.94</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.87</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-06</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.95</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.91</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.79</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.69</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.60</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-07</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.83</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.71</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-08</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.95</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.77</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.62</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-09</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.89</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.82</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.70</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-10</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.93</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-11</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.93</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-12</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.95</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.88</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.78</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.64</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">r-13</td> 
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.95</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.89</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.83</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.71</td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 2. </div>Table of results using varying levels of delexicalization. The higher the number,
                        the better the classification performance.</div>
                  </div>
                  
                  <div class="counter"><a href="#p29">29</a></div>
                  <div class="ptext" id="p29">These initial experiments have shown a performance dependency on different levels
                     of delexicalisation. In addition, it 
                     has became clear that different classifiers react differently across varying levels
                     of delexicalisation. This also shows us
                     that we are not recognising the author style <em class="emph">per se</em>, but rather that we are constantly flattening the 
                     problem to how the author style is reflected in specific conditions using specific
                     features. Quite unsurprisingly, the
                     performance is highly dependent on segment lengths.
                     </div>
                  
                  <div class="counter"><a href="#p30">30</a></div>
                  <div class="ptext" id="p30">Of all the classifiers we experimented with, support vector machines worked best.
                     Therefore, we have decided to use 
                     LinearSVC for the rest of the experiments, using the pre-processing r-08. Even though
                     the pre-processing r-08 did not lead to
                     the best performance, it represents a simple and straightforward yet very strong level
                     of delexicalisation that significantly 
                     reduces the number of features and conceals content.
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Experiments and Results</h1>
                  
                  <div class="counter"><a href="#p31">31</a></div>
                  <div class="ptext" id="p31">Using the pre-processing/classification pipeline described above, we performed three
                     experimental steps to illustrate 
                     the relationship between author and book style in authorship classification:
                     
                     <ol class="list">
                        <li class="item">The full dataset (see above; 23 authors, 210 books) was used for a task of authorship
                           attribution with 
                           <em class="emph">each book</em> divided into “train” (80%) and “test” (20%) passages. We reported performance 
                           across different lengths of passages. This is an “easy” setting for the classifier.
                           </li>
                        <li class="item">Next, we performed the experiment with the same settings, but this time we built the
                           “test” set by 
                           choosing <em class="emph">one book from each author</em> and adding <em class="emph">all its segments</em> into the test set. All 
                           other books of each author were used in their entirety for training. In this “harder” setting, performance 
                           dropped significantly, which is the main point of this paper. Furthermore, classification
                           performance seemed 
                           to depend on the selection of the testing books.
                           </li>
                        <li class="item">Finally, we performed the same experiment as outlined in #1, but instead of classifying
                           by author, we classified 
                           segments into individual books. With this experiment, it is possible to discuss further
                           why the test-book 
                           selection in Experiment #2 is so influential, as well as to show that some authors
                           are more consistent in their 
                           style (as expressed by the selected features) than others.
                           </li>
                     </ol>
                     </div>
                  
                  <div class="counter"><a href="#p32">32</a></div>
                  <div class="ptext" id="p32">We again emphasise that our purpose here is not to reach the best possible classification
                     accuracy but rather to explore the 
                     influence of authorial style variation between individual works on the classification
                     accuracy of a “decent” pipeline. 
                     Our pre-processing steps, classification models, and final scores are not the focus
                     of our findings. Rather, we are interested 
                     in exploring how classification metrics change across different experiments.
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Step 1. Train and Test Across All Books of the dataset</h2>
                     
                     <div class="counter"><a href="#p33">33</a></div>
                     <div class="ptext" id="p33">Having selected the pre-processing and classification pipeline (delexicalisation r-08,
                        using part-of-speech tags instead 
                        of autosemantic words and lemmas for functional words, and the LinearSVC classifier),
                        we measured the baseline results 
                        when “train” and “test” sets were drawn randomly from all books of each author.
                        </div>
                     
                     <div class="counter"><a href="#p34">34</a></div>
                     <div class="ptext" id="p34">In addition to measuring performance on the “train+devel versus test” split, we also tried an alternative 
                        “train+test vs. devel” split (which, because we never used the development set for model selection, is essentially
                        just a 
                        different partition for cross-validation). The results were almost identical, so we
                        did not consider it necessary to carry 
                        out full cross-validation.
                        </div>
                     
                     <div class="counter"><a href="#p35">35</a></div>
                     <div class="ptext" id="p35">The following table shows the accuracies of the two experiment runs in comparison
                        with the same setting on a smaller dataset.
                        </div>
                     
                     <div class="table">
                        <table class="table">
                           <tr class="row label">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1"><span class="hi italic">Across Books</span></td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-1000</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-500</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-200</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-100</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-50</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Full dataset</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.74</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.58</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.42</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Full Dataset, Validation</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.9</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.73</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.58</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.42</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Small Dataset (5 Authors)</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.95</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.77</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.62</td>
                              </tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 3. </div>Step 1 Results Table</div>
                     </div>
                     
                     <div class="counter"><a href="#p36">36</a></div>
                     <div class="ptext" id="p36">The selection of individual segments as testing seems to have only limited influence
                        on the results. The best results 
                        were achieved, predictably, using the longest segments of 1000 tokens (96.1/96.4%).
                        Shorter segments significantly lowered 
                        the performance.<a class="noteRef" href="#d4e1186">[15]</a>
                        </div>
                     
                     <div class="counter"><a href="#p37">37</a></div>
                     <div class="ptext" id="p37">Interestingly, when using the segments of 1000 tokens, the accuracy of the classifier
                        was consistently around the same 
                        96% for both the small, five author dataset used for hyperparameter selection and
                        for the full dataset of 23 authors. 
                        However, when shortening the segments, the performance on the larger dataset radically
                        dropped.<a class="noteRef" href="#d4e1194">[16]</a>
                        </div>
                     
                     <div class="counter"><a href="#p38">38</a></div>
                     <div class="ptext" id="p38">The results of this first experiment serve as a baseline for the second, where we
                        show how setting aside specific 
                        books changes the results.
                        </div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Step 2. “Train” Books Versus “Test” Books</h2>
                     
                     <div class="counter"><a href="#p39">39</a></div>
                     <div class="ptext" id="p39">We believe that the above-mentioned experiments are relatively simple ML-based author
                        attribution tasks. In our opinion, 
                        the experimental settings that use the same books for training and testing, such as
                        [<a class="ref" href="#gorman2022">Gorman 2022</a>] or 
                        [<a class="ref" href="#benotto2021">Benotto 2021</a>], are biased in their reported performance. After all, the capability to recognise
                        the author 
                        of an unseen and unattributed text is one of the main research objectives within the
                        field of authorship attribution 
                        (while certainly not being the only goal [<a class="ref" href="#swain_mishra_sindhu2017">Swain, Mishra, and Sindhu 2017</a>]).
                        </div>
                     
                     <div class="counter"><a href="#p40">40</a></div>
                     <div class="ptext" id="p40">Therefore, we have further expanded the experimental scenario to address real-life
                        problem: recognising a book (or rather 
                        its parts) that has never been seen in the system building process (see the appendix
                        for detailed information). The 
                        experiments discussed below reveal that selecting a test book from the available corpus
                        heavily influences the reported 
                        performance of the classifier.
                        </div>
                     
                     <div class="counter"><a href="#p41">41</a></div>
                     <div class="ptext" id="p41">We randomly selected five sets of testing books such that each set contained one book
                        from each author and no book was in 
                        two testing sets, except for <cite class="title italic">Svědomí Lidových novin, čili, Jak bylo po léta v českém tisku štváno 
                           lživě proti mně</cite> (a-08.b-03) in sets 1 and 5, because the dataset contains only four books by Č. Slepánek. We ran 
                        the same classification experiment and reported results across segment sizes. The
                        results are reported in the following table.
                        </div>
                     
                     <div class="table">
                        <table class="table">
                           <tr class="row label">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1"><span class="hi italic">Book-Based</span></td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-1000</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-500</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-200</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-100</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">s-50</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 1</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.80</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.62</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.44</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.29</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 2</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.78</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.58</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.38</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.22</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 3</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.82</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.63</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.42</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.26</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 4</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.77</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.69</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.51</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.35</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.23</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 5</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.92</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.85</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.66</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.47</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.22</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Average</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.79</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.60</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.41</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.24</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1"><span class="hi italic">Cf. Step 1 (Across Books)</span></td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.74</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.58</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.42</td>
                              </tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 4. </div>Step 2 Results Table</div>
                     </div>
                     
                     <div class="counter"><a href="#p42">42</a></div>
                     <div class="ptext" id="p42">The results show a drop of 0.04 to 0.23, with 0.10 being the average deterioration
                        of classification accuracy. In the 
                        case of the easiest s-1000 and s-500 settings, this means more than a three-fold increase
                        in error. Furthermore, Set 4 
                        shows that a random selection of testing books can make this difference much larger.
                        </div>
                     
                     <div class="counter"><a href="#p43">43</a></div>
                     <div class="ptext" id="p43">We note that performing five-fold, cross-validation with 23-book test sets rather
                        than 210-fold, leave-one-out, 
                        cross-validation on individual books had little bearing on these results while being
                        significantly more expedient 
                        despite the classifier performance on each testing book being further influenced by
                        the choice of the other 22 testing 
                        books in each fold. We chose the five worst performing outliers and five high-performing
                        books and performed leave-one-out 
                        experiments with these. We found that the leave-one-out results were, in fact, worse
                        by 0.5% on average 
                        (when disregarding 3 books that had their authors classified perfectly in the 5-fold
                        and leave-one-out settings both), 
                        with the leave-one-out accuracy ranging from 7.6% higher (a-03 test book from Set
                        4) to 7% lower (a-15 test book from 
                        Set 1).
                        </div>
                     
                     <div class="counter"><a href="#p44">44</a></div>
                     <div class="ptext" id="p44">Compared to the leave-one-out setting, the effect of removing books potentially helpful
                        for identifying an author from the
                        training set was roughly cancelled out by the effect of introducing potentially confounding
                        books to the training set. As a
                        result, while the estimates for individual books did likely have a somewhat higher
                        variance, our main finding that accuracy 
                        dropped significantly overall in this setting was not affected. Furthermore, the accuracies
                        of items of the highest 
                        significance for further analysis — outliers in both directions — seem to have been
                        affected by less than 10%, which does 
                        not materially affect the selection of books that are significantly harder or easier
                        to classify by author than the average. 
                        Thus, our analytical attention is directed to the same items that a leave-one-out
                        experiment design would point towards.
                        <a class="noteRef" href="#d4e1426">[17]</a>
                        </div>
                     
                     <div class="counter"><a href="#p45">45</a></div>
                     <div class="ptext" id="p45">These experiments show that there is little to be gained by performing the remaining
                        199 leave-one-out experiments over 
                        the 5-fold scheme. We attribute this consistency between the lower-variance, leave-one-out
                        setting and the 5-fold setting 
                        to the size of the dataset: at these scales, leave-one-out cross-validation schemes
                        no longer provide a less biased 
                        estimate of aggregate statistics, and the effect of inclusion of individual items
                        into the training set is not as pronounced. 
                        Note also that although in our 5-fold cross-validation the folds differed by 46/210
                        books, the results for each book 
                        within a fold were computed on a perfectly identical training set and thus are perfectly
                        comparable, while in the 
                        leave-one-out setting, no two training sets are the same.
                        </div>
                     
                     <div class="counter"><a href="#p46">46</a></div>
                     <div class="ptext" id="p46">A possible systematic confounding factor for the drop in average performance could
                        be the irregularity of training set 
                        sizes introduced by setting aside random entire books for testing, as book lengths
                        vary greatly. As opposed to the 
                        “Across Books” setting from Step 1, here we do not have the same “train”:“test” token ratio. The obvious 
                        question then arises: is the model performance dependent on the “train”:“test” ratio, “test” or 
                        “train” token absolute count, both, or neither? The following table shows data from experiments
                        (for s-1000 segments). 
                        The indicated “test ratio” is the ratio of “test” tokens to all tokens. Asterisks indicate the experiments where 
                        drama or poetry were used as the test book (* = drama; ** = poetry).
                        </div>
                     
                     <div class="table">
                        <table class="table">
                           <tr class="row label">
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">All Tokens</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 1<br />Rest Ratio<br />Accuracy</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 2</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 3</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 4</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 5</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-01</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1,044,186</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">7.76%<br />0.97</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">13.50%<br />0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">6.38%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">8.81%<br />0.97</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">8.79%<br />0.82</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-02</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">364,582</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">4.05%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">17.00%<br />0.53</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">21.00%<br />0.94</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">24.43%<br />0.88</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">33.51%<br />0.83</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-03</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1,197,470</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">6.10%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">3.34%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">7.43%<br />0.93</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">13.62%<br />0.20</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">10.44%<br />0.99</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-04</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">371,909</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">25.74%<br />0.83</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">27.00%<br />0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">23.46%<br />0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">4.94%<br />0.67</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">18.86%<br />0.97</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-05</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">285,386</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">22.12%<br />0.95</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">39.89%<br />0.81</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">28.83%<br />0.85</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">3.55%<br />0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">5.90%<br />0.94</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-06</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">299,530</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">63.53%<br />0.64</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">8.56%<br />0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">3.89%<br />0.83</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">2.93%<br />0.78</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">21.09%<br />0.83</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-07</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1,512,167</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">14.22%<br />0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">4.96%<br />0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.79%<br />0.70</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">11.90%<br />0.99</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">9.66%<br />0.99</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-08</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">174,115</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">3.45%<br />0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">63.19%<br />0.13</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">10.37%<br />0.67</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">22.99%<br />0.10</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">3.45%<br />0.00</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-09</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">374,104</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">10.69%<br />0.45</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">*3.21%<br />*0.42</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">12.57%<br />0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">19.79%<br />0.24</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">24.06%<br />0.80</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-10</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">514,131</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">19.26%<br />0.97</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">14.20%<br />0.79</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">13.42%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">3.70%<br />0.53</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">13.81%<br />0.93</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-11</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">715,093</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">11.33%<br />0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">5.73%<br />0.78</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">6.43%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">16.36%<br />0.74</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">9.93%<br />0.93</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-12</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">241,111</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">14.52%<br />0.66</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">*8.71%<br />*0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">*6.23%<br />*0.53</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">*14.53%<br />*0.89</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">10.39%<br />0.32</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-13</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">417,080</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">8.16%<br />0.62</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">16.78%<br />0.89</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">14.15%<br />0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">16.54%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">14.39%<br />0.92</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-14</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">731,207</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">5.88%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">4.10%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">12.45%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">15.73%<br />0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">7.80%<br />1.00</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-15</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">785,198</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">5.35%<br />0.24</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">*3.06%<br />*0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">10.57%<br />0.84</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">*2.93%<br />*0.83</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">*3.18%<br />*0.84</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-16</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1,099,103</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">12.46%<br />0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">27.30%<br />0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">7.01%<br />0.99</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">4.00%<br />0.93</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">11.46%<br />0.95</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">614,032</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">4.40%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">23.45%<br />0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">37.46%<br />0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">*3.26%<br />*0.75</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">17.43%<br />1.00</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-18</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">819,145</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">10.74%<br />0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">5.98%<br />0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">15.14%<br />0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">7.33%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">15.63%<br />0.95</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-19</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">765,197</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">2.75%<br />0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">12.81%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">9.42%<br />0.99</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">9.15%<br />0.89</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">8.49%<br />0.97</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-20</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1,137,133</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">3.52%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">6.16%<br />0.84</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">4.13%<br />0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">2.11%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">15.04%<br />0.99</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-21</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">703,121</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">5.41%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">12.38%<br />0.93</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">24.18%<br />0.55</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">**2.42%<br />**0.65</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">8.25%<br />0.98</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-22</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">618,089</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">6.15%<br />0.79</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">5.50%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">5.34%<br />0.94</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">2.91%<br />0.56</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">17.64%<br />0.88</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-23</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">683,108</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">9.66%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">25.92%<br />0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">9.37%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">16.84%<br />1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">9.08%<br />0.98</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Average (Per Author)</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">672,443</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">12.05%<br />0.81</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">15.32%<br />0.84</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">12.65%<br />0.89</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">10.03%<br />0.76</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">12.97%<br />0.86</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1"><span class="hi italic">Full Performance</span></td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">672,443</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.77</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.92</td>
                              </tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 5. </div>Step 2 results table for individual authors, showing test ratio and accuracy across
                           the five test book sets. 
                           * = drama; ** = poetry.</div>
                     </div>
                     
                     <div class="counter"><a href="#p47">47</a></div>
                     <div class="ptext" id="p47">The following table shows the correlation coefficients of the authors' accuracies
                        to the “train”:“test” 
                        ratio, full token count, “test” token count, and “train” token count:
                        </div>
                     
                     <div class="table">
                        <table class="table">
                           <tr class="row label">
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 1</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 2</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 3</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 4</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 5</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Train Ratio</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.19474</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.01766</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.01495</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.18115</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.176758</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Full Token Count</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.356384</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.390591</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.234502</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.259228</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.502111</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Test Token Count </td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.091817</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.217205</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.126774</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.099459</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.510302</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Train Token Count</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.358298</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.361026</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.217488</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.268124</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.477041</td>
                              </tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 6. </div>Correlation coefficients of the authors' accuracies to the “train”:“test” ration, full token count, 
                           “test” token count, and “train” token count.</div>
                     </div>
                     
                     <div class="counter"><a href="#p48">48</a></div>
                     <div class="ptext" id="p48">These data show that while there are some tendencies in the correlations, in general,
                        these correlations are unstable, 
                        and the most significant feature that influences classification accuracy is the selection
                        of the test books. At the same 
                        time, there does seem to be a minimum number of tokens necessary in order for the
                        model to perform well. This is visible 
                        with Č. Slepánek (a-08). He has the lowest number of tokens, as well as books, and usually performs
                        the worst, 
                        except for set 3, where two other authors (a-12 and a-21) perform worse. There is
                        likely not enough data to be trained on, 
                        and at the same time, there are only a few test passages (only 3 in the case of sets
                        1 and 5), so the model has few chances 
                        to accurately predict his authorship of a segment, further increasing the variance
                        of the result.
                        </div>
                     
                     <div class="counter"><a href="#p49">49</a></div>
                     <div class="ptext" id="p49">On the other end of the data size spectrum, K. Sabina (a-07), who has the highest number of tokens, performs 
                        very well but not the best, and his worst performing test book is the shortest of
                        the five — the one with the smallest 
                        impact on training data size. A high number of training tokens by itself apparently
                        does not ensure stable performance. 
                        Another example may be given in Set 4, a-03 (J. Arbes). Even though the token count is very high, the 
                        performance is only 0.20. This deviation is, however, easily explained once the test
                        book is consulted and compared to 
                        the rest of his works. In this case, a-03.b-04 (<cite class="title italic">Persekuce lidu českého v letech 1869-1873</cite>) 
                        has been used for testing. In contrast to Arbes' more typical short novels, this book is a work of his 
                        journalism career. A similar influence may be observed in the case of V. Hálek (a-21) in Set 3, as the work
                        used for testing (<cite class="title italic">Fejetony</cite>) is also journalistic.
                        </div>
                     
                     <div class="counter"><a href="#p50">50</a></div>
                     <div class="ptext" id="p50">This further opens the question of the influence of genres on the performance of the
                        models. In general, there are 
                        journalistic works counted among the prose, and we may also point to several cases
                        of drama or poetry. The works 
                        of drama were used for testing in the case of four authors on eight instances<a class="noteRef" href="#d4e2521">[18]</a> and a work of poetry in one case<a class="noteRef" href="#d4e2531">[19]</a>. The influence of genre is not that significant for K. Čapek (a-15, sets 2, 
                        4, 5) or J. Vrchlický (a-12, sets 2, 3, 4), likely because, in their cases, there are several books of
                        drama 
                        that provide a sufficient base for testing.
                        </div>
                     
                     <div class="counter"><a href="#p51">51</a></div>
                     <div class="ptext" id="p51">On the other hand, for V. Hálek (a-21, Set 4) and K. Sabina (a-17, Set 4), the deviance in genre 
                        resulted in a significant drop in performance, probably because there is no training
                        data for support. However, even though 
                        the performance significantly dropped in these cases, it was still much higher than
                        a random baseline. Furthermore, other 
                        authors who write consistently in one genre performed much worse.
                        </div>
                     
                     <div class="counter"><a href="#p52">52</a></div>
                     <div class="ptext" id="p52">There are several other cases where the influence of the selected test book can be
                        well explained. For example, 
                        V. Hálek (a-21) shows a 1.00 accuracy in Set 1. A simple look at the dataset does not explain
                        such a success. 
                        However, the work <cite class="title italic">Na statku a v chaloupce</cite> (a-21.b-09) is a short story that is also included 
                        in <cite class="title italic">Kresby křídou i tuší</cite> (a-21.b-10), which was used for training. Such overlaps in 
                        datasets are easily created when based on real-life library scenarios.
                        </div>
                     
                     <div class="counter"><a href="#p53">53</a></div>
                     <div class="ptext" id="p53">We believe that the data and discussion presented here clearly illustrate the problem
                        and influence of the test-book 
                        selection. In addition, we can see that reporting the overall statistics of authorship
                        classification performance can cover 
                        up significant specific high-variance issues that come up in more detailed analysis.
                        </div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Step 3. Books as Targets</h2>
                     
                     <div class="counter"><a href="#p54">54</a></div>
                     <div class="ptext" id="p54">Our third experiment aimed to discover the structure of stylistic similarity within
                        individual authors. As hinted by the 
                        large differences between cross-validation runs, the stylistic differences among individual
                        books of an author vary 
                        significantly. We are interested in the characteristics of these dissimilarities.
                        </div>
                     
                     <div class="counter"><a href="#p55">55</a></div>
                     <div class="ptext" id="p55">To expose these characteristics, we ran the classification pipeline with the 210 individual
                        books (instead of the 23 authors) 
                        as output classes and observed misclassification patterns. If an author's style is
                        highly consistent, we would expect 
                        (thanks to delexicalisation) that segments from one of their books would be easily
                        misclassified as segments from their other 
                        books, especially in the “easy” s-1000 segmentation setting where the confusion between authors was minimal. More
                        
                        generally, we have three kinds of possible results for the classification of a segment:
                        (a) the correct book, (b) a wrong 
                        book by the correct author, or (c) a book by a different author. If we assume that
                        misclassification is a good proxy for 
                        similarity (which we examine later), then we can define the following:
                        
                        <ul class="list">
                           <li class="item">The greater the ratio of b / (a + b), the more consistent an author's style is.</li>
                           <li class="item">The greater the ratio of a / (b + c), the more inconsistent an author's style.</li>
                           <li class="item">The greater the ratio of (a + b) / (a + b + c), the more distinctive an author is.</li>
                        </ul>
                        </div>
                     
                     <div class="counter"><a href="#p56">56</a></div>
                     <div class="ptext" id="p56">We have split each book into 80% of training and 20% of test segments (see above).
                        In this step, two sets of experiments 
                        were run. In the first, only books with over 20,000 tokens were used to ensure decent
                        model training (see, for example,  
                        [<a class="ref" href="#gorman2022">Gorman 2022</a>]). In the second, we included all of the books. Here, we report and discuss only the
                        results 
                        of s-1000 segments. The following charts show general results for individual authors.
                        The numbers stated are the numbers of 
                        segments which have been attributed to the correct book (blue), other books of the
                        same author (yellow), and books of a 
                        different author (red).
                        </div>
                     
                     <div class="figure">
                        
                        
                        <div class="ptext"><a href="resources/fig01.png" rel="external"><img src="resources/fig01.png" style="" alt="" /></a></div>
                        
                        <div class="caption">
                           <div class="label">Figure 1. </div>Results of classification of books by individual authors, in numbers of segments attributed
                           to the correct book 
                           (blue), other books of the same author (yellow), and books of a different author (red);
                           created using Flourish 
                           (<a href="https://flourish.studio/" onclick="window.open('https://flourish.studio/'); return false" class="ref">https://flourish.studio/</a>)</div>
                     </div>
                     
                     <div class="counter"><a href="#p57">57</a></div>
                     <div class="ptext" id="p57">These results may be compared with the experiments performed in Step 2. The author
                        a-20 (S. K. Neumann) can 
                        be taken as an author whose style seems consistent across books, whereas author a-06
                        (T. G. Masaryk) is one 
                        whose style seems more book related. In Step 2, a-20 performed better than average,
                        except for Set 2, where the results 
                        were slightly below-average (0.84). In that case, the test book was a-20.b-14. This
                        book consists of 70 passages, meaning 
                        it has 14 test passages. Ten passages were attributed to the same book, two to other
                        books of the same author, and two to 
                        incorrect authors. Author a-06 seems to be more consistent within individual books,
                        but these are only rarely confused with 
                        each other. In the experiments of Step 2, a-06 performed best in Set 2 (0.96). The
                        test book selected for this set 
                        (a-06.b-05) is the only one that gets confused with the author's other books. Even
                        though there are only 5 test passages in 
                        this short work, the results of steps 2 and 3 seem to correlate. The following chart
                        shows the heatmaps of confusion 
                        matrices of a-20 and a-06. These show the confusion within the works of the selected
                        author.
                        </div>
                     
                     <div class="figure">
                        
                        
                        <div class="ptext"><a href="resources/fig02.png" rel="external"><img src="resources/fig02.png" style="" alt="" /></a></div>
                        
                        <div class="caption">
                           <div class="label">Figure 2. </div>Heatmaps of intra-author classification for a-20 and a-06; created using Flourish
                           
                           (<a href="https://flourish.studio/" onclick="window.open('https://flourish.studio/'); return false" class="ref">https://flourish.studio/</a>)</div>
                     </div>
                     
                     <div class="counter"><a href="#p58">58</a></div>
                     <div class="ptext" id="p58">These experiments show that, albeit delexicalised, most books tend to be recognised
                        as themselves, meaning that most 
                        authors do write individual books differently, even when the differences in the lexicon
                        are suppressed. At the same time, 
                        the results of Step 2 conclusively demonstrate that most authors are still recognisable
                        when tested on an unseen book.
                        </div>
                     
                     <div class="counter"><a href="#p59">59</a></div>
                     <div class="ptext" id="p59">Some interesting phenomena revealed by this experiment may be noted. The results show
                        that accuracy scores are not strongly 
                        dependent on the books' lengths (the correlation coefficient is ca. 0.27). However,
                        the books under 20,000 tokens (17 books 
                        in our dataset) lead to poorer results on average. The accuracy score was only 0.54
                        (21 of 39 test segments attributed 
                        correctly), and six of these books were not recognised at all. In comparison, the
                        accuracy scores of the full model were 
                        0.65 (all books) and 0.66 (only books over 20,000 tokens). At the same time, even
                        some of the longer books performed very 
                        badly. For example, of 20 test segments from a-23.b-04, only one was attributed correctly.
                        However, this book scored very 
                        well (0.9) in attribution to the correct author (including the one correctly attributed
                        segment) in both experiments. The 
                        explanation for this may become clear when the nature of the book is considered —
                        it is a collection of short stories.
                        </div>
                     
                     <div class="counter"><a href="#p60">60</a></div>
                     <div class="ptext" id="p60">From this, one may assume that collections of short stories are good candidates for
                        high levels of intra-author confusion. 
                        However, some examples contradict this assumption. For example, a-15.b-02, 03, 04,
                        and 06 are collections of short stories 
                        by K. Čapek. In contrast to a-23.b-04, these perform quite well in the correct book attribution
                        (0.56 for the 
                        experiment with all books, 0.61 for the experiment with over 20,000 token books).
                        But the performance for correct author 
                        attribution was not especially high (0.71 in both experiments). Further exploration
                        of features and their weights may 
                        help us to understand these differences better.
                        </div>
                     
                     <div class="counter"><a href="#p61">61</a></div>
                     <div class="ptext" id="p61">Another interesting example is a high level of confusion among books a-20.b-06, 07,
                        and 08 (see the image above). These 
                        three books form a trilogy together (<cite class="title italic">Francouzská revoluce</cite>), and confusion was, therefore, to 
                        be expected.
                        </div>
                     
                     <div class="counter"><a href="#p62">62</a></div>
                     <div class="ptext" id="p62">Comparison of steps 2 and 3 may help us to further explore the deviations in the performances
                        of different authors. The 
                        following table shows correlations of authors' accuracy scores from Step 2 (using
                        all books irrespective of their 
                        token length) to different data obtained from Step 3 related to the authors' test
                        books: (a) proportion of segments 
                        attributed to the same book, (b) proportion of segments attributed to other books
                        by the same author, (c) proportion of 
                        segments attributed to other authors, and (d) proportion of segments attributed to
                        the correct author (both correct and 
                        incorrect books).
                        </div>
                     
                     <div class="table">
                        <table class="table">
                           <tr class="row label">
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 1</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 2</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 3</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 4</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 5</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Attribution to Correct Book</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.183381</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.23135</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.51682</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.26735</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.523796</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">To Correct Author // Incorrect Book</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.486218</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.443661</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.441649</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.416486</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.413774</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">To Incorrect Author</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.87451</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.15772</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.286852</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.27283</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.88701</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">To Correct Author</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.872354</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.154229</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">-0.293</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.270222</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.885652</td>
                              </tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 7. </div>Correlation coefficients of authors' accuracy scores (Step 2) to different results
                           of experiments from Step 3 of the
                           test books attribution.</div>
                     </div>
                     
                     <div class="counter"><a href="#p63">63</a></div>
                     <div class="ptext" id="p63">The correlations shown in this table seem to support our initial assumption that misclassification
                        is a good proxy for 
                        similarity. The following table presents the data for a detailed exploration of these
                        correlations. Variations among 
                        individual authors are still significant. Other criteria must always be considered.
                        </div>
                     
                     <div class="table">
                        <table class="table">
                           <tr class="row label">
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                              
                              <td valign="top" class="cell label" colspan="5" rowspan="1">Proportion of the Test Book Segments Attributed<br />to the Correct Author but an Incorrect Book (Step 3)</td>
                              
                              <td valign="top" class="cell label" colspan="5" rowspan="1">Author's Performance (Step 2)</td>
                              </tr>
                           <tr class="row label">
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 1</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 2</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 3</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 4</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 5</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 1</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 2</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 3</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 4</td>
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">Set 5</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-01</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.54</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.03</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.82</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-02</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.50</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.33</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.33</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.05</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.53</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.94</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.88</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.83</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-03</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.06</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.27</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.93</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.20</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-04</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.38</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.14</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.89</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.25</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.47</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.83</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.67</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-05</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.16</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.14</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.50</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.38</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.95</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.81</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.85</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.94</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-06</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.12</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.44</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.08</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.67</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.36</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.64</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.83</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.78</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.83</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-07</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.80</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.11</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.02</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.50</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.10</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.70</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-08</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.15</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.10</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.47</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.25</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.32</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.13</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.67</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.10</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-09</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.12</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.25</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.40</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.45</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.42</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.91</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.24</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.80</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-10</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.25</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0,33</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0,33</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0,00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0,09</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0,97</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0,79</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1,00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0,53</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0,93</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-11</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.21</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.18</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.23</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.50</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.78</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.74</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.93</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-12</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.43</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.25</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.66</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.53</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.89</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.32</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-13</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.31</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.38</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.64</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.62</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.89</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.92</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-14</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.16</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.21</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.08</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-15</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.11</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.24</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.84</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.83</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.84</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-16</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.33</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.90</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.93</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.95</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.23</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.26</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.47</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.51</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.75</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-18</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.40</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.96</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.95</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-19</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.06</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.33</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.86</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.89</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.97</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-20</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.11</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.05</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.06</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.14</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.84</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.99</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-21</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.43</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.63</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.53</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.06</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.12</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.93</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.55</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.65</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-22</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.08</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.33</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.06</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.79</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.94</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.56</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.88</td>
                              </tr>
                           <tr class="row">
                              
                              <td valign="top" class="cell label" colspan="1" rowspan="1">a-23</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.13</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.21</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.69</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.67</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.17</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">1.00</td>
                              
                              <td valign="top" class="cell" colspan="1" rowspan="1">0.98</td>
                              </tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 8. </div>Correct author // incorrect book attribution of test books (Step 3) and authors' performance.</div>
                     </div>
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Conclusion</h1>
                  
                  <div class="counter"><a href="#p64">64</a></div>
                  <div class="ptext" id="p64">We do not claim to have studied the issue of book versus authorial style exhaustively.
                     What we have done is build a pipeline 
                     to show that this issue is worth taking into account in developing and evaluating
                     authorship classification systems. It is 
                     clear that the performance drops significantly when an unseen book is used for testing
                     instead of unseen segments of books 
                     seen during the training process. On the one hand, this is not a catastrophic problem,
                     as performances only drop by 10-20% 
                     on average. On the other hand, however, this makes an important difference for applications
                     since it results in a significant 
                     rise in the number of errors.
                     </div>
                  
                  <div class="counter"><a href="#p65">65</a></div>
                  <div class="ptext" id="p65">The results of our experiments focused on attributing individual books instead of
                     authors have revealed that models 
                     trained and tested on the segments from the same book perform well despite a relatively
                     high level of delexicalisation. These 
                     experiments have also shown that misclassification of a book but correct classification
                     of an author is a good proxy for 
                     similarity in author style. Thus, we may recommend such an experiment in the classifiers'
                     development stage. Further 
                     research might also focus on measuring this effect across languages.
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Acknowledgements</h1>
                  
                  <div class="counter"><a href="#p66">66</a></div>
                  <div class="ptext" id="p66">Realised with the support of institutional research of the National Library of the Czech Republic, 
                     funded by the Ministry of Culture of the Czech Republic as part of the framework of long-term conception 
                     developement of scientific organisation.
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Appendix</h1>
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row label">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Author</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Title</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Genre</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Book ID in Dataset</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Token Count</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Set in Which Used<br />as Test Book<br />(Experiment Step 2)</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">Nedokončený obraz</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-01</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">91,746</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Set 5</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">Otřelá kolečka</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-02</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">83,978</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">Vzpomínky</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-03</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">155,266</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">Bohatství</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-04</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">54,474</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">Bratři</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-05</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">66,637</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Set 3</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">Blouznivci našich hor</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-07</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">141,011</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Set 2</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">O ševci Matoušovi a jeho přátelích</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-08</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">83,005</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">Na rozhraní</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-09</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">106,018</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">V temných vírech (1)</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-11</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">89,013</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">V temných vírech (3)</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-12</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92,030</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Set 4</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A. Stašek</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><cite class="title italic">Stíny minulosti</cite></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Prose</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">a-01.b-13</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">81,008</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Set 1</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="6" rowspan="1">A. Stašek Full Tokens Count: 1,044,186</td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 9. </div>List of Works in Dataset</div>
                  </div>
                  </div>
               
               
               
               
               </div>
            
            <div id="notes">
               <h2>Notes</h2>
               <div class="endnote" id="d4e199"><span class="noteRef lang en">[1] See, for example, 
                     [<a class="ref" href="#savoy2020">Savoy 2020</a>], [<a class="ref" href="#swain_mishra_sindhu2017">Swain, Mishra, and Sindhu 2017</a>], [<a class="ref" href="#grzybek2014">Grzybek 2014</a>], 
                     [<a class="ref" href="#grieve2005">Grieve 2005</a>], and [<a class="ref" href="#holmes1998">Holmes 1998</a>] for general studies following the development of the area. 
                     For literary oriented studies that cover a more or less random selection of works
                     we have consulted during our research, 
                     see [<a class="ref" href="#zhao_zobel2007">Zhao and Zobel 2007</a>], [<a class="ref" href="#kusakci2012">Kusakci 2012</a>], [<a class="ref" href="#segarra_eisen_ribeiro2013">Segarra, Eisen, and Ribeiro 2013</a>], 
                     [<a class="ref" href="#ramezani_sheydaei_kahani2013">Ramezani, Sheydaei, and Kahani 2013</a>], [<a class="ref" href="#pinho_pratas_ferreira2016">Pinho, Pratas, and Ferreira 2016</a>], [<a class="ref" href="#nutanong_et_al2016">Nutanong et al.</a>],
                     [<a class="ref" href="#marinho_hirst_amancio2016">Marinho, Hirst, and Amancio 2016</a>], [<a class="ref" href="#benotto2021">Benotto 2021</a>], and [<a class="ref" href="#gorman2022">Gorman 2022</a>]. We also 
                     organized a workshop, “Authorial style, its analysis, and limits of automatic recognition”,
                     at the National Library of the Czech Republic in 2022, which brought together research approaching the topic 
                     from diverse perspectives, demonstrating the rich and complex problematics of authorial
                     style detection. See
                     <a href="https://digilab.nkp.cz/?page_id=55" onclick="window.open('https://digilab.nkp.cz/?page_id=55'); return false" class="ref">https://digilab.nkp.cz/?page_id=55</a> (accessed 5 April 2023).</span></div>
               <div class="endnote" id="d4e240"><span class="noteRef lang en">[2] Stylo: 
                     Stylometric Multivariate Analyses, available at <a href="https://cran.r-project.org/package=stylo" onclick="window.open('https://cran.r-project.org/package=stylo'); return false" class="ref">
                        https://cran.r-project.org/package=stylo</a> (accessed 5 April 2023).</span></div>
               <div class="endnote" id="d4e531"><span class="noteRef lang en">[3] Compare also with [<a class="ref" href="#luyckx_daelemans2011">Luyckx and Daelemans 2011</a>], who focus on the effect of author set 
                     size and data size in authorship attribution, taking into consideration a variety
                     of genres and topics. Luyckx and 
                     Daelemans' use cases focus on much shorter texts than this article does or Gorman, thus posing
                     a different issue.</span></div>
               <div class="endnote" id="d4e572"><span class="noteRef lang en">[4] We have used the digital collections of the National Library of the Czech Republic 
                     (<a href="https://ndk.cz/" onclick="window.open('https://ndk.cz/'); return false" class="ref">https://ndk.cz/</a>, accessed April 5, 2023) as the source of our data. 
                     Unfortunately, these data are not publicly accessible, which creates issues regarding
                     the repeatability of our 
                     experiments.</span></div>
               <div class="endnote" id="d4e580"><span class="noteRef lang en">[5] The raw 
                     data consisted of individual pages as .txt files with inconsistent encoding. Firstly,
                     the encoding was unified to 
                     UTF-8. From these files we attempted to remove non-content data such as headers, page
                     numbers, footnotes, etc. 
                     This process was automatized and therefore may include some imperfections. After this
                     initial cleaning, we merged 
                     the individual pages into a single .txt file per book.</span></div>
               <div class="endnote" id="d4e582"><span class="noteRef lang en">[6] Available at:  
                     <a href="http://lindat.mff.cuni.cz/services/korektor/" onclick="window.open('http://lindat.mff.cuni.cz/services/korektor/'); return false" class="ref">http://lindat.mff.cuni.cz/services/korektor/</a>.</span></div>
               <div class="endnote" id="d4e610"><span class="noteRef lang en">[7] In machine learning 
                     experiments, the development set is used to evaluate different hyperparameter settings
                     (such as regularization strength 
                     or internal dimension of the model) and models in order to select the best model and
                     its setting. Once all these 
                     choices are fixed, the selected model is trained on a combination of the training
                     and development sets, and the test 
                     set is used to estimate the expected system performance on unseen data. If one used
                     the test set rather than the 
                     development set for hyperparameter optimization, the final evaluation result would
                     be artificially inflated by 
                     information leakage from the test set into the hyperparameter design — hence the use
                     of a development set.</span></div>
               <div class="endnote" id="d4e627"><span class="noteRef lang en">[8] Available at: 
                     <a href="https://lindat.mff.cuni.cz/services/udpipe/api-reference.php" onclick="window.open('https://lindat.mff.cuni.cz/services/udpipe/api-reference.php'); return false" class="ref">
                        https://lindat.mff.cuni.cz/services/udpipe/api-reference.php</a>; see [<a class="ref" href="#straka2018">Straka 2018</a>].</span></div>
               <div class="endnote" id="d4e635"><span class="noteRef lang en">[9] Autosemantic words, 
                     as recognized by UDPipe, are: nouns (NOUN), proper nouns (PROPN), adjectives (ADJ),
                     verbs (VERB), adverbs (ADV), 
                     and numbers (NUM).</span></div>
               <div class="endnote" id="d4e637"><span class="noteRef lang en">[10]  See 
                     <a href="http://universaldependencies.org/docs/u/pos/index.html" onclick="window.open('http://universaldependencies.org/docs/u/pos/index.html'); return false" class="ref">
                        http://universaldependencies.org/docs/u/pos/index.html</a>, accessed April 5, 2023.</span></div>
               <div class="endnote" id="d4e682"><span class="noteRef lang en">[11] These are the books 
                     designated as b-01 to b-05 for each of the authors in the list of works in the appendix.</span></div>
               <div class="endnote" id="d4e692"><span class="noteRef lang en">[12] Codes r-01, r-02, and 
                     r-03 were used in preparation for further delexicalization; therefore, we start with
                     r-04.</span></div>
               <div class="endnote" id="d4e694"><span class="noteRef lang en">[13] Aside from 
                     the word form for non-delexicalised baselines, we have used the lemma, the full morphological
                     tag according to the Universal 
                     Dependencies specification, and at the coarsest level of granuality, the universal
                     part-of-speech tag. See 
                     <a href="http://universaldependencies.org/docs/u/pos/index.html" onclick="window.open('http://universaldependencies.org/docs/u/pos/index.html'); return false" class="ref">http://universaldependencies.org/docs/u/pos/index.html</a>, 
                     accessed April 5, 2023.</span></div>
               <div class="endnote" id="d4e702"><span class="noteRef lang en">[14] The types of named entities are persons 
                     (first names and surnames), locations, organizations (including brands), and miscellaneous
                     named entities such as 
                     religions, sports leagues, and wars. For a detailed list, see 
                     <a href="https://www.cnts.ua.ac.be/conll2003/ner/annotation.txt" onclick="window.open('https://www.cnts.ua.ac.be/conll2003/ner/annotation.txt'); return false" class="ref">
                        https://www.cnts.ua.ac.be/conll2003/ner/annotation.txt</a>, accessed September 15, 2023.</span></div>
               <div class="endnote" id="d4e1186"><span class="noteRef lang en">[15] There is clearly space for improving classification accuracy here; the features in
                     
                     [<a class="ref" href="#gorman2022">Gorman 2022</a>] reported little such decrease in a comparable experiment. While 42/42.3% accuracy
                     with 
                     segments of approximately 50 tokens is still above the 23-class baseline (4.35%),
                     in order to provide useful results 
                     outside of long-form texts, the classification pipeline would need significant improvement.
                     Again, we emphasize we are not 
                     trying to reach the highest possible accuracy. Rather, we use classification experiments
                     to illustrate variation within 
                     an author's style.</span></div>
               <div class="endnote" id="d4e1194"><span class="noteRef lang en">[16] For the effect of 
                     author set size and data size in authorship attribution, see [<a class="ref" href="#luyckx_daelemans2011">Luyckx and Daelemans 2011</a>].</span></div>
               <div class="endnote" id="d4e1426"><span class="noteRef lang en">[17] Specifically, the 11 test books where we compared the 5-fold and leave-one-out accuracies
                     were: a-03 Set 4, with a 
                     change from 0.20 to 0.276 (+7.6%); a-15 Set 1: 0.24 → 0.214 (-2.6%); a-02 Set 2: 0.53→0.516
                     (-1.4%); a-07 Set 3: 0.7→0.63 
                     (-7.0%); a-17 Set 4 (drama): 0.75→0.75 (0.0%); a-08 Set 3: 0.67→0.667% (-0.3%); a-09
                     Set 3: 0.91→0.85 (-6.0%); 
                     a-13 Set 4: 1.0→1.0 (0.0%); a-22 Set 2: 1.0→1.0 (0.0%); a-11 Set 3: 1.0→1.0 (0.0%);
                     a-21 Set 4 (poetry): 0.65→0.706 (+5.6%). 
                     The average difference when discarding the three books with perfect accuracies was
                     that in the leave-one-out setting, 
                     classification was 0.3% worse. Without these three books taken into account (because
                     they may be so easy to classify 
                     that even a very flawed methodology pipeline would obtain perfect accuracy), leave-one-out
                     classification performed 0.5% 
                     worse than the five-fold setting. (We give the books here as author-set pairs rather
                     than author-books, so that their 
                     “outlier-ness” is easy to find in the tables in this section. To find which book these are, refer
                     to Appendix: 
                     List of Works in the Dataset.)</span></div>
               <div class="endnote" id="d4e2521"><span class="noteRef lang en">[18] E. Krásnohorská (a-09) 
                     in Set 2; J. Vrchlický (a-12) in sets 2, 3, 4; K. Čapek (a-15) in sets 2, 4, 5; 
                     K. Sabina (a-17) in Set 4; see appendix.</span></div>
               <div class="endnote" id="d4e2531"><span class="noteRef lang en">[19] V. Hálek 
                     (a-21) in Set 4; see appendix.</span></div>
            </div>
            <div id="worksCited">
               <h2>Works Cited</h2>
               <div class="bibl"><span class="ref" id="benotto2021"><!-- close -->Benotto 2021</span> Benotto, G. (2021) “Can an author style be unveiled through 
                  word distribution?”, <cite class="title italic">Digital Humanities Quarterly</cite>, 15(1). 
                  <a href="http://digitalhumanities.org:8081/dhq/vol/15/1/000539/000539.html" onclick="window.open('http://digitalhumanities.org:8081/dhq/vol/15/1/000539/000539.html'); return false" class="ref">
                     http://digitalhumanities.org:8081/dhq/vol/15/1/000539/000539.html</a>
                  </div>
               <div class="bibl"><span class="ref" id="gorman2022"><!-- close -->Gorman 2022</span> Gorman, R. (2022) “Universal dependencies and author 
                  attribution of short texts with syntax alone”, <cite class="title italic">Digital Humanities Quarterly</cite>, 
                  16(2). <a href="http://digitalhumanities.org:8081/dhq/vol/16/2/000606/000606.html" onclick="window.open('http://digitalhumanities.org:8081/dhq/vol/16/2/000606/000606.html'); return false" class="ref">
                     http://digitalhumanities.org:8081/dhq/vol/16/2/000606/000606.html</a>
                  </div>
               <div class="bibl"><span class="ref" id="grieve2005"><!-- close -->Grieve 2005</span> Grieve, J. (2005) <cite class="title italic">Quantitative authorship attribution: 
                     A history and an evaluation of techniques</cite>. MA thesis. Simon Fraser University. 
                  Available at: <a href="https://summit.sfu.ca/item/8840" onclick="window.open('https://summit.sfu.ca/item/8840'); return false" class="ref">https://summit.sfu.ca/item/8840</a>.
                  </div>
               <div class="bibl"><span class="ref" id="grzybek2014"><!-- close -->Grzybek 2014</span> Grzybek, P. (2014) “The emergence of stylometry: 
                  Prolegomena to the history of term and concept”, in Kroó, K. and Torop, P. (eds.) <cite class="title italic">Text 
                     within text: Culture within Culture</cite>. Paris: L’Harmattan, pp. 58–75.
                  </div>
               <div class="bibl"><span class="ref" id="holmes1998"><!-- close -->Holmes 1998</span> Holmes, D.I. (1998) “The evolution of stylometry in 
                  humanities scholarship”, <cite class="title italic">Literary and Linguistic Computing</cite>, 13(3), pp. 111–117.
                  </div>
               <div class="bibl"><span class="ref" id="kusakci2012"><!-- close -->Kusakci 2012</span> Kusakci, A.O. (2012) “Authorship attribution using 
                  committee machines with k-nearest neighbors rated voting”, <cite class="title italic">Proceedings of the 11th symposium 
                     on neural network applications in electrical engineering, IEEE, 2012</cite>. Belgrade, Serbia, 20–22 September. pp. 161–166.
                  Available at: <a href="https://ieeexplore.ieee.org/document/6419997" onclick="window.open('https://ieeexplore.ieee.org/document/6419997'); return false" class="ref">https://ieeexplore.ieee.org/document/6419997</a>.
                  </div>
               <div class="bibl"><span class="ref" id="luyckx2011"><!-- close -->Luyckx 2011</span> Luyckx, K. (2011) <cite class="title italic">Scalability issues in authorship 
                     attribution</cite>. Brussels, Belgium: University Press Antwerp.
                  </div>
               <div class="bibl"><span class="ref" id="luyckx_daelemans2011"><!-- close -->Luyckx and Daelemans 2011</span> Luyckx, K., and Daelemans, W. (2011) 
                  “The effect of author set size and data size in authorship attribution”, 
                  <cite class="title italic">Literary and Linguistic Computing</cite>, 26(1), pp. 35–55.
                  </div>
               <div class="bibl"><span class="ref" id="marinho_hirst_amancio2016"><!-- close -->Marinho, Hirst, and Amancio 2016</span> Marino, V.Q., Hirst, G., and Amancio, D.R. 
                  “Authorship attribution via network motifs identification”, <cite class="title italic">Proceedings
                     of the 5th Brazilian conference of intelligent systems, IEEE, 2016</cite>. Recife, Brazil, 9–12 October. pp. 355–360.
                  <a href="https://doi.org/10.48550/arXiv.1607.06961" onclick="window.open('https://doi.org/10.48550/arXiv.1607.06961'); return false" class="ref">https://doi.org/10.48550/arXiv.1607.06961</a>.
                  </div>
               <div class="bibl"><span class="ref" id="mosteller_wallace1964"><!-- close -->Mosteller and Wallace 1964</span> Mosteller, F., and Wallace, D. (1964) 
                  <cite class="title italic">Inference and disputed authorship: The Federalist</cite>. Reading, MA: Addison-Wesley.
                  </div>
               <div class="bibl"><span class="ref" id="nivre2015"><!-- close -->Nivre 2015</span> Nivre, J. (2015) “Towards a universal grammar for
                  natural language processing”, <cite class="title italic">Proceedings of the international conference on intelligent
                     text processing and computational linguistics, CICLing, 2016</cite>. Konya, Turkey, 3–9 April.
                  <a href="https://doi.org/10.1007/978-3-319-18111-0_1" onclick="window.open('https://doi.org/10.1007/978-3-319-18111-0_1'); return false" class="ref">https://doi.org/10.1007/978-3-319-18111-0_1</a>.
                  </div>
               <div class="bibl"><span class="ref" id="nutanong_et_al2016"><!-- close -->Nutanong et al.</span> Nutanong, S. et al. “A scalable framework
                  for stylometric analysis query processing”, <cite class="title italic">Proceedings of the 16th international
                     conference on data mining, IEEE, 2016</cite>. Barcelona, Spain, 12–15 December. pp. 1125–1130.
                  <a href="https://doi.org/10.1109/ICDM.2016.0147" onclick="window.open('https://doi.org/10.1109/ICDM.2016.0147'); return false" class="ref">https://doi.org/10.1109/ICDM.2016.0147</a>.
                  </div>
               <div class="bibl"><span class="ref" id="pedregosa_et_al2011"><!-- close -->Pedregosa et al. 2011</span> Pedregosa, F. et al. (2011) “Scikit-learn:
                  Machine learning in Python”, <cite class="title italic">Journal of Machine Learning Research</cite>, 12, pp. 2825–2830.
                  Available at: <a href="https://jmlr.csail.mit.edu/papers/volume12/pedregosa11a/pedregosa11a.pdf" onclick="window.open('https://jmlr.csail.mit.edu/papers/volume12/pedregosa11a/pedregosa11a.pdf'); return false" class="ref">
                     https://jmlr.csail.mit.edu/papers/volume12/pedregosa11a/pedregosa11a.pdf</a>.
                  </div>
               <div class="bibl"><span class="ref" id="pinho_pratas_ferreira2016"><!-- close -->Pinho, Pratas, and Ferreira 2016</span> Pinho, A.J., Pratas, D., and Ferreira, P.J.S.G.
                  “Authorship attribution using relative compression”, <cite class="title italic">Proceedings of the
                     data compression conference, IEEE, 2016</cite>. Snowbird, UT, 30 March–1 April. pp. 329–338.
                  <a href="https://doi.org/10.1109/DCC.2016.53" onclick="window.open('https://doi.org/10.1109/DCC.2016.53'); return false" class="ref">https://doi.org/10.1109/DCC.2016.53</a>.
                  </div>
               <div class="bibl"><span class="ref" id="ramezani_sheydaei_kahani2013"><!-- close -->Ramezani, Sheydaei, and Kahani 2013</span> Ramezani, R., Sheydaei, N., and Kahani, M. (2013)
                  “Evaluating the effects of textual features on authorship attribution accuracy”,
                  <cite class="title italic">Proceedings of the international econference on computer and knowledge engineering,
                     IEEE, 
                     2016</cite>. Mashhad, Iran, 31 October–1 November. pp. 108–113.
                  <a href="https://doi.org/10.1109/ICCKE.2013.6682828" onclick="window.open('https://doi.org/10.1109/ICCKE.2013.6682828'); return false" class="ref">https://doi.org/10.1109/ICCKE.2013.6682828</a>
                  </div>
               <div class="bibl"><span class="ref" id="savoy2020"><!-- close -->Savoy 2020</span> Savoy, J. (2020) <cite class="title italic">Machine learning methods for
                     stylometry: Authorship attribution and author profiling</cite>. New York: Springer Publishing.
                  </div>
               <div class="bibl"><span class="ref" id="segarra_eisen_ribeiro2013"><!-- close -->Segarra, Eisen, and Ribeiro 2013</span> Segarra, S., Eisein, M., and Ribeiro, A. (2013)
                  “Authorship attribution using function words adjaceny networks”, 
                  <cite class="title italic">Proceedings of the international conference on acoustics, speech and signal processing,
                     IEEE, 2013
                     </cite>. Vancouver, Canada, 26–31 May. <a href="https://doi.org/10.1109/ICASSP.2013.6638728" onclick="window.open('https://doi.org/10.1109/ICASSP.2013.6638728'); return false" class="ref">
                     https://doi.org/10.1109/ICASSP.2013.6638728</a>.
                  </div>
               <div class="bibl"><span class="ref" id="stamatatos2009"><!-- close -->Stamatatos 2009</span> Stamatatos, E. (2009) “A survey of modern
                  authorship attribution methods”, <cite class="title italic">Journal of the American Society for Information 
                     Science and Technology</cite>, 60(3), pp. 538–556. <a href="https://doi.org/10.1002/asi.21001" onclick="window.open('https://doi.org/10.1002/asi.21001'); return false" class="ref">
                     https://doi.org/10.1002/asi.21001</a>.
                  </div>
               <div class="bibl"><span class="ref" id="straka2018"><!-- close -->Straka 2018</span> Straka, M. (2018) “UDPipe 2.0 prototype at CoNLL 2018 
                  UD shared task”, <cite class="title italic">Proceedings of the CoNLL 2018 shared task: Multilingual parsing from raw
                     text to universal dependencies, ACL, 2018</cite>, pp. 197–207. 
                  <a href="https://doi.org/10.18653/v1/K18-2020" onclick="window.open('https://doi.org/10.18653/v1/K18-2020'); return false" class="ref">https://doi.org/10.18653/v1/K18-2020</a>.
                  </div>
               <div class="bibl"><span class="ref" id="strakova_straka_hajic2019"><!-- close -->Straková, Straka, and Hajič 2019</span> Straková, J., Straka, M., and Hajič, J. (2019)
                  “Neural architectures for nested NER through linearization”, <cite class="title italic">Proceedings
                     of the 57th annual meeting of the association for computational linguistics, ACL,
                     2019</cite>. Florence, Italy, 
                  28 July–2 August. pp. 5326–5331. Available at: 
                  <a href="https://aclanthology.org/P19-1527.pdf" onclick="window.open('https://aclanthology.org/P19-1527.pdf'); return false" class="ref">https://aclanthology.org/P19-1527.pdf</a>.
                  </div>
               <div class="bibl"><span class="ref" id="swain_mishra_sindhu2017"><!-- close -->Swain, Mishra, and Sindhu 2017</span> Swain, S., Mishra, G., and Sinhu, C. (2017)
                  “Recent approaches on authorship attribution techniques: An overview”, 
                  <cite class="title italic">Proceedings of the international conference of electronics, commmunication, and aerospace
                     technology, ICECA, 2017</cite>. Coimbatore, India, 20–22 April. pp. 557–566.
                  <a href="https://doi.org/10.1109/ICECA.2017.8203599" onclick="window.open('https://doi.org/10.1109/ICECA.2017.8203599'); return false" class="ref">https://doi.org/10.1109/ICECA.2017.8203599</a>
                  </div>
               <div class="bibl"><span class="ref" id="tyo_dhingra_lipton2022"><!-- close -->Tyo, Dhingra, and Lipton 2022</span> Tyo, J., Dhingra, B., and Lipton, Z.C. (2022)
                  “On the state of the art in authorship attribution and authorship verification”,
                  <cite class="title italic">arXiv</cite>. <a href="https://doi.org/10.48550/arXiv.2209.06869" onclick="window.open('https://doi.org/10.48550/arXiv.2209.06869'); return false" class="ref">
                     https://doi.org/10.48550/arXiv.2209.06869</a>.
                  </div>
               <div class="bibl"><span class="ref" id="zhao_zobel2007"><!-- close -->Zhao and Zobel 2007</span> Zhao, Y, and Zobel, J. (2007)
                  “Searching with style: Authorship attribution in classic literature”,
                  <cite class="title italic">Proceedings of the 30th Australasian computer science conference, ACSC, 2007</cite>.
                  Ballarat, Australia, 30 January–2 February. pp. 59–68. Available at:
                  <a href="https://www.researchgate.net/publication/221574042_Searching_With_Style_Authorship_Attribution_in_Classic_Literature" onclick="window.open('https://www.researchgate.net/publication/221574042_Searching_With_Style_Authorship_Attribution_in_Classic_Literature'); return false" class="ref">
                     https://www.researchgate.net/publication/221574042_Searching_With_Style_Authorship_Attribution_in_Classic_Literature</a>.
                  </div>
            </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            <div class="license"><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
               </div>
         </div>
      </div>
   </body>
</html>