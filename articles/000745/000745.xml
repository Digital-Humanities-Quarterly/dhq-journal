<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xmlns:cc="http://web.resource.org/cc/"
     xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
     xmlns:mml="http://www.w3.org/1998/Math/MathML"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <teiHeader>
      <fileDesc>
         <titleStmt><!--Author should supply the title and personal information-->
            <title type="article" xml:lang="en"><!--article title in English--></title>
            <!--Add a <title> with appropriate @xml:lang for articles in languages other than English-->
            <dhq:authorInfo><!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>first name(s) <dhq:family>family name</dhq:family>
               </dhq:author_name>
               <idno type="ORCID"><!--if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000--></idno>
               <dhq:affiliation/>
               <email/>
               <dhq:bio>
                  <p/>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <!--This information will be completed at publication-->
            <idno type="DHQarticle-id">000745<!--including leading zeroes: e.g. 000110--></idno>
            <idno type="volume"><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006--></idno>
            <idno type="issue"><!--issue number, without leading zeroes: e.g. 2--></idno>
            <date><!--include @when with ISO date and also content in the form 23 February 2024--></date>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND"><!--If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default):        
                  CC-BY:    
                  CC0:  -->
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
            <taxonomy xml:id="project_keywords">
               <bibl>DHQ project registry; full list available at <ref target="http://www.digitalhumanities.org/dhq/projects.xml">http://www.digitalhumanities.org/dhq/projects.xml</ref>
               </bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
            <!--add <language> with appropriate @ident for any additional languages-->
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords"><!--Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors--><!--Enter keywords below preceeded by a "#". Create a new term element for each-->
               <term corresp=""/>
            </keywords>
            <keywords scheme="#authorial_keywords"><!--Authors may include one or more keywords of their choice-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#project_keywords">
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc><!-- Replace "NNNNNN" in the @target of ref below with the appropriate DHQarticle-id value. -->
         <change>The version history for this file can be found on <ref target="https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/main/articles/NNNNNN/NNNNNN.xml">GitHub
                   </ref>
         </change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract><!--Include a brief abstract of the article-->
            <p/>
         </dhq:abstract>
         <dhq:teaser><!--Include a brief teaser, no more than a phrase or a single sentence-->
            <p/>
         </dhq:teaser>
      </front>
      <front>
         <titlePage>
            <docTitle>
               <titlePart type="Title">LemonizeTBX: Design and Implementation of a New Converter from TBX to OntoLex-Lemon </titlePart>
            </docTitle>
         </titlePage>
         <p>Andrea Bellandi1, Giorgio Maria Di Nunzio2, Silvia Piccini1, Federica Vezzani3</p>
         <p>1Institute for Computational Linguistics “A. Zampolli” CNR, Via Moruzzi 1, 56124, Pisa - Italy</p>
         <p>{name.surname}@ilc.cnr.it</p>
         <p>2Department of Information Engineering, University of Padova, Via Gradenigo 6/b, 35131 Padova, Italy</p>
         <p>{giorgiomaria.dinunzio}@unipd.it</p>
         <p>3Department of Linguistic and Literary Studies, University of Padova, Via Elisabetta Vendramini, 13 35137 Padova, Italy</p>
         <p>{federica.vezzani}@unipd.it</p>
      </front>
      <body>
         <div>
            <head>Abstract</head>
            <p>In this paper, we introduce LemonizeTBX, a converter that enhances interoperability between terminological and lexicographical frameworks, acknowledging their divergent data modelling approaches. First, we present the theoretical implications of a conversion from the TermBase eXchange (TBX) concept-oriented framework to the OntoLex-Lemon sense-centred standpoint within Semantic Web technologies. Then, we illustrate the prototype version of the converter, designed as an interactive tool engaging terminologists in the conversion process.</p>
            <p>keywords: terminography, lexicography, TermBase eXchange, OntoLex-Lemon, data serialisation.</p>
         </div>
         <div>
            <head>1. Introduction </head>
            <p>In recent years, Linked Data (LD) has emerged as a highly promising approach to effectively integrate, interconnect, and semantically enrich different datasets, thus promoting interoperability and accessibility across the web (Frey and Hellmann 2021). Terminologists therefore increasingly recognise the importance of publishing resources as LD to overcome siloed information management, and facilitate the reuse of terminological datasets in accordance with the FAIR principles (Wilkinson et al. 2016). In response to this paradigm shift, alongside the well-established ISO standard 30042:2019 about the TermBase eXchange implementation format (TBX),<note> https://www.iso.org/standard/62510.html</note> the OntoLex-Lemon data model has gained increasing importance within the terminology community, being widely recognized as the de facto standard for constructing RDF lexical resources (inter al. see Bosque-Gil et al. (2015); Rodriguez-Doncel et al. (2018); Vellutino et al. (2016)).<note> Another data model widely used in the world of semantic web for sharing and publishing lexical information as LD is the Simple Knowledge Organization System (SKOS). The latter features the same concept-centric structure as TBX (for a comparison between TBX and SKOS see Reineke and Romary (2019). </note> TBX is an XML-based family of terminology exchange formats characterised by a hierarchical structure based on the Terminological Markup Framework (TMF - ISO 16642:2017).<note> https://www.iso.org/standard/56063.html</note> Specifically, a terminological data collection (TDC) is constituted by a set of concept entries (CEs), each describing a concept within a specialised domain. Each concept entry includes one or more language sections (LSs) that, in turn, include one or more term sections (TSs) containing the term designating the concept in that specific language, as well as a set of additional information describing the term itself. In Figure 1, we show an example of a TBX file that contains two CE; the first CE identified with the code “1” has three LSs: English, Spanish, and Italian. The English LS contains two designations for this concept, the same for Spanish, while the Italian LS contains only one designation.</p>
            <figure>
               <head/>
               <graphic url="media/image1.png"/>
            </figure>
            <p>Figure 1. Example of a TBX file containing a CE with three LSs.</p>
            <p>The OntoLex-Lemon model, on the other hand, is characterised by a modular architecture that allows for a detailed and articulated description of the linguistic characteristics of a term. Figure 2 depicts the core elements of the model. Each lexical entry – be it an affix, a word or a multiword expression – is an instance of the class Lexical Entry and is associated to its morphological realisations (class Form) through the relation <hi rend="italic">ontolex:lexicalForm</hi> as well as to its sense(s) (class Lexical Sense) by means of the <hi rend="italic">ontolex:sense</hi> property. Lexical sense, conceived as the reification of the <hi rend="italic">ontolex:denotes</hi> property linking the lexical entry and the concept, can be provided with additional information, such as usage context (<hi rend="italic">ontolex:usage</hi>), and its semantic relations expressed by means of a particular linguistic vocabulary, e.g., LexInfo<note> LexInfo is an ontology that provides data categories for the OntoLex-Lemon model.</note>.<figure>
                  <head/>
                  <graphic url="media/image2.png"/>
               </figure>
            </p>
            <p>Figure 2. The architecture of the OntoLex-Lemon module.</p>
            <p>The concept, viewed as an extra-linguistic entity, can be formally described either in an external domain ontology (already existing or created from scratch) according to the principle known as “semantics by reference” (Buitelaar 2010), or as an instance of the Lexical concept class (see Figure 1), which represents “a mental abstraction, concept or unit of thought that can be lexicalized by a given collection of senses”. In addition to the Ontolex core, other modules have been developed, such as the Decomposition module; the Variation and Translation module; the Syntax and Semantics module; the Linguistic Metadata module.<note> For a description of the above-mentioned modules see: https://www.w3.org/2016/05/ontolex/ </note>
            </p>
            <p>To ensure interoperability between these two distinct approaches to data modelling – on one side, the ISO TMF and TBX standards, and on the other side, OntoLex-Lemon and the Semantic Web technologies – we found it necessary to develop a new converter, named LemonizeTBX, which will be the focus of this paper. Although a similar tool was already developed by Cimiano et al. (2015), the new converter differs in two fundamental aspects. It is interactive, allowing the terminologist to play an active role in the conversion process. As highlighted by Piccini et al. (2023), indeed, moving from a TBX format to an LD structure goes beyond a simple shift from an XML-based to an RDF-based data format. The conversion process involves a shift in perspective: a strictly terminological concept-oriented framework (TBX) is converted into a lexicographical sense-centred standpoint (OntoLex-Lemon). Moreover, as discussed by Bellandi et al. (2023b), TBX primarily focuses on facilitating the exchange and administration of terminological resources to maintain coherence and compatibility among terminologists and language experts. Conversely, Ontolex-Lemon is specifically designed to encode lexical data, with the goal of capturing intricate linguistic details and facilitating semantic integration with other RDF datasets.</p>
            <p>In addition, the new converter will handle input and output files in the latest versions of TBX and OntoLex-Lemon, as both have undergone revisions over time. In 2019, the TBX version 3.0 was released and published as ISO 30042: 2019, replacing the previous TBX version 2.0 published in 2008 (ISO 30042: 2008). Similarly, the OntoLex-Lemon model, born within the European Monnet project as a result of the integration of the three pre-existing models LingInfo (Buitelaar et al. 2006), LexOnto (Cimiano et al. 2007), LIR (Montiel-Ponsoda et al. 2011), was later extended into the OntoLex-Lemon model by the Ontology-Lexicon Community Group. </p>
            <p>This paper is structured as follows. In Section 2, we provide an overview of the main works that address the issue of transforming a terminological resource serialised in a TBX format into a Linguistic Linked Data (LLD) resource serialised in an RDF OntoLex-Lemon format. In Section 3, we define the key requirements for the development of the new converter LemonizeTBX. Section 4 describes the initial prototype of the converter, and finally, in Section 5, conclusions will be drawn, and future work will be outlined. </p>
         </div>
         <div>
            <head>2. State of the Art </head>
            <p>This section provides an overview of previous efforts in transforming a TBX terminological resource into a LLD resource using the OntoLex-Lemon model. We categorised these approaches into two sections: Section 2.1 focuses on the TBX2RDF tool specifically designed for this purpose, and Section 2.2 delves into alternative approaches, discussing the theoretical implications of such transformation.</p>
            <div>
               <head>2.1 An Overview of TBX2RDF Approaches</head>
               <p>The application of LD principles to terminological datasets was discussed by Cimiano et al. (2015); Siemoneit et al. (2015). In their seminal work, the authors present a process involving the mapping of TBX elements and structures into the OntoLex-Lemon ontology, which provides a semantic framework for describing lexical and linguistic information in RDF.<note> https://www.w3.org/2015/09/bpmlod-reports/multilingual-terminologies/</note> The proposed methodology is implemented as an online service named TBX2RDF that enables the representation of terminological data in a linked and machine-readable format, facilitating their integration with other semantic web resources and applications. In fact, by converting XML data into RDF, it becomes possible to semantically enrich the data, enabling more effective querying, linking, and reasoning across heterogeneous sources on the web. This transformation enhances the accessibility, reusability, and comprehensibility of data, ultimately contributing to the realisation of the Semantic Web's vision of a more interconnected and meaningful web of data. In addition, as the manual creation of links between datasets is costly and therefore not scalable, the authors propose a preliminary attempt to explore approaches for automatic linking between different datasets.</p>
               <p>The best practices to model LLD were identified in the masterwork by Cimiano et al. (2020ab) devoted to the principles behind the idea of semantic web and, in particular, to the issues of reusability of dictionaries and interoperability of resources. However, the treatment of transforming a terminological resource into a LD format often remains confined to a surface-level mapping of elements, lacking deeper consideration for the theoretical implications inherent in these mapping choices.</p>
               <p>The design and implementation of TBX2RDF have certainly influenced the research in this area and has given the possibility to create important linguistic linked resources. For example, in Rodriguez-Doncel et al. (2018), the authors describe a terminology created in a half-automated process, where terms and natural language definitions have been extracted and integrated from different lexical sources and mapped in a supervised process. In particular, the paper analyses the process and the methodologies adopted in the automatic conversion into TBX of linguistic resources together with their semantic enrichment.</p>
               <p>A similar, but somewhat inverse process, was described by Speranza et al. (2020) who propose a proof-of-concept for an automated methodology to convert linguistic resources into TBX resources using the Italian Linguistic Resource for the Archaeological domain. A conversion tool is designed and implemented to support the creation of ontology-aware terminologies, enhancing interoperability and facilitating the sharing of language technologies and datasets. By ontology-aware terminologies, the authors intend the approach that relies on a precise conceptual mapping of linguistic and semantic information to TBX elements and the enrichment of these elements by means of semantic information, which may be useful in several applications to create a cloud of interoperable and interconnected terminologies, directly linked to both already existing ontologies and new developed ones.</p>
               <p>In Declerck et al. (2020); di Buono et al. (2020), the authors discuss the Prêt-à-LLOD project<note> https://cordis.europa.eu/project/id/825182</note> which aims at increasing the uptake of language technologies by exploiting the combination of LD and language technologies to create ready-to-use multilingual data. In particular, they present a new approach called Terme-à-LLOD devoted to simplifying the task of converting a TBX terminological resource into a LLD one.</p>
               <p>Another example of the organisation of terminological data concerning the domain of raw material and mining was presented by Kitanovic et al. (2021). The authors introduce the development of a termbase for the field of mining engineering, the transformation from a custom scheme into the TBX, and then a further analysis aiming at compatibility with the LD approach.</p>
               <p>In Chozas and Declerck (2022), the authors explore the use of the OntoLex-Lemon model and suggest some extensions, for achieving a declarative encoding of relations between multilingual expressions contained in terminologies. In particular, the authors link their proposal to the previous LIDER project<note> https://www.multilingualweb.eu/projects/lider</note> that was already concerned with mapping TBX to RDF, with the goal of transforming and publishing terminologies as LD.</p>
               <p>All the previous works have set an important base for the development of future tools. Nevertheless, there are at least two issues that were overlooked: first, the lack of a theoretical analysis about the implications of such a transformation – can we really use a lexicographic model for representing a terminological resource and vice versa? – second, the fact that none of the most recent works have implemented the tools on the latest TBX standard (ISO 30042: 2019).</p>
               <p>In the following Section, we present the papers that have raised these questions together with alternative approaches to the mapping of TBX files into other formats.</p>
            </div>
            <div>
               <head>2.2 Open Issues and Other Approaches</head>
               <p>Reineke and Romary (2019) were among the pioneers in questioning the theoretical soundness of converting a terminological resource from TBX to RDF. In their article, the authors discuss the limitations of the outcomes generated by TBX2RDF due essentially to the fact that a semasiological (word-to-sense) model such as OntoLex cannot be naturally mapped onto the concept-to-term model of TBX. Consequently, they present a comparison between SKOS and TBX, which, conversely, in their view, prove to be more interoperable given their shared foundation in a concept-oriented perspective. As discussed in detail by Bellandi et al. (2023b), the choice of whether and how to represent senses from a data model that does not inherently incorporate senses is indeed one of the most important issues in these data serialisation procedures. We will return to this point in section 3.1 to illustrate different approaches to addressing this challenge.</p>
               <p>A multilevel contrastive analysis between TBX and OntoLex-Lemon was presented by Bellandi et al. (2023a); Piccini et al. (2023), taking into account the technological, theoretical, methodological dimensions, as well as the user perspective and application of the two data models. The authors provide a detailed discussion about the issues of the already available tools for this type of conversion, and the need for a deeper understanding of both models and the ability to reconcile the differences in their structures and semantics during the conversion process.</p>
               <p>Some other researchers provide a different perspective on the possibility of employing alternative serialisations and representations. For example, Suchowolec et al. (2019) discuss the limitations of TBX in terms of the three levels (concept, language, and term) and the use of SKOS as a potential format to describe the amount of available relation types. A different point of view is given by Di Nunzio and Vezzani (2021) who put forward the hypothesis that, if terminological data are appropriately modelled at an abstract level, they can be exported or exposed in any format, while preserving both the linguistic dimension and its relationship to the conceptual dimension.</p>
            </div>
         </div>
         <div>
            <head>3. Analysis of Requirements </head>
            <p>Before delving into the core content of the paper, we define the main requirements underpinning the design and the implementation of the converter here proposed.</p>
            <div>
               <head>3.1 Theoretical Flexibility</head>
               <p>The terminology community encompasses a range of heterogeneous theoretical and methodological perspectives.<note> For a complete and recent overview of the different theoretical perspectives on terminology science, see Faber and L’Homme (2022).</note> In a nutshell, three main theoretical approaches can be distinguished: </p>
               <list rend="numbered">
                  <item>The concept has priority over the term that is a linguistic designation with the function of naming the concepts. This would be the view of classical terminology that would relegate the contextual interpretation of the sense of the term to a secondary role. </item>
                  <item>The concept designated by the term is flattened on the sense of the term itself, and no difference is made between the linguistic and conceptual dimensions of the terminological analysis.<note> As underlined by Rastier: “le concept est le signifié d’un mot dont on décide de négliger la dimension linguistique" (Rastier 1995, 55).</note>
                  </item>
                  <item>The concept and the sense are two distinct entities that both need to be taken into consideration, in order not to turn terminology into specialised lexicography. Terminology, indeed, is considered as a “twofold science” characterised by two complementary and necessary dimensions of analysis, namely the conceptual and the linguistic (Costa 2013; Santos and Costa 2015). </item>
               </list>
               <p>The flexibility of the OntoLex-Lemon model makes it possible to satisfy all these three main theoretical approaches. Consequently, as we shall see in more detail in Section 4, the converter will make it possible to:</p>
               <list rend="bulleted">
                  <item>bypass the Lexical Sense class and directly link the lexical entry to the concept it designates;</item>
                  <item>omit the conceptual dimension and limit itself to the description of the sense via the Lexical Sense class;</item>
                  <item>describe both dimensions. As far as the conceptual dimension is concerned, the converter is agnostic with respect to the specific ontology language used for representing concepts. It is up to the terminologist to decide if using SKOS, OWL, or mapping the concepts to a given ontology.</item>
               </list>
            </div>
            <div>
               <head>3.2 Reusability</head>
               <p>The LD paradigm strongly advocates for the reuse of existing vocabularies. In line with this principle, the new converter will provide terminologists with the flexibility to choose the data categories they deem more suitable, thus facilitating:</p>
               <list rend="bulleted">
                  <item>Interoperability: Terminologists might feel the need to align their resources with widely accepted standards and ontologies.</item>
                  <item>Flexibility for domain-specific needs: Terminologists may find it necessary to effectively address the specific requirements and nuances for data categorization set by their specialised domain.</item>
                  <item>Adaptability for evolving standards: Terminological needs and standards can evolve over time. Adaptability in this sense is ensured by the active involvement of the users in the conversion process. They can decide the latest standards in terminology to conform with or the new best practices emerged within the LD community.</item>
               </list>
            </div>
            <div>
               <head>3.3 Knowledge Extraction</head>
               <p>When employing TBX to describe terminological data, researchers may encounter constraints dictated by their chosen TBX dialect.<note> The TBX format can be implemented via both public and private dialects. The public dialects are: 1) TBX-Core, 2) TBX-Min, and 3) TBX-Basic. For a detailed description of these dialects, see: https://www.tbxinfo.net/tbx-dialects/</note> Each dialect has its own unique set of data categories designed to describe the entries, and the richness of this set directly influences the granularity of the description of each entry. Despite the availability of a large shared set of categories, challenges arise when terminographers lack a specific data category to describe a specific information. Let us suppose that terminographers need to add information about the etymology of a term. In such cases, they have no choice but to use the <hi rend="italic">&lt;note&gt;</hi> field to store this information. Notably, the strategy adopted by TBX2RDF is to use annotation properties, such as <hi rend="italic">rdfs:comment</hi>, <hi rend="italic">rdfs:label</hi>, and so on.<note> Please see <ref target="https://www.w3.org/TR/rdf-schema/#ch_properties">https://www.w3.org/TR/rdf-schema/#ch_properti</ref>es for a complete list.</note> Nevertheless, our perspective underscores the importance of employing automatic methods to i) analyse these unstructured text sources, ii) identify structured semantic information embedded within the text, and subsequently iii) organise, and store it by means of the appropriate relations within OntoLex-Lemon. Returning to our example regarding etymology, OntoLex-Lemon provides the LemonEty<note> Please, see Khan (2018).</note> module specifically designed to accurately represent such information.  This proactive strategy ensures that valuable semantic information, initially confined to notes, is systematically integrated into the structured ontology, thus fostering a more comprehensive and enriched representation of terminological knowledge.</p>
            </div>
            <div>
               <head>3.4 Data Enrichment</head>
               <p>This requirement involves the explication of information that is (a) implicitly conveyed by the hierarchical structure of TBX itself, and (b) explicitly written in unstructured content such as note fields of a concept entry in TBX.</p>
               <div>
                  <head>3.4.1 Deductive Rules Exploitation</head>
                  <p>The hierarchical structure of TBX implies relationships that can be lost in the conversion from TBX to OntoLex-Lemon, if not properly managed. These relationships mainly include synonymy and equivalence. In the first case, terms described within the same LS belonging to the same concept entry are assumed to be synonymous without the necessity of adding an explicit synonymy relationship among them. Likely, in TBX, terms in different LSs, grouped within the same concept entry, are equivalents. By employing deductive rules, our converter LemonizeTBX enables the terminographer to explicitly define these relations in the new resource, suggesting the appropriate links (e.g. <hi rend="italic">lexinfo:synonym</hi> for synonymy and <hi rend="italic">vartrans:translatableAs</hi> or <hi rend="italic">lexinfo:translation</hi> for linguistic equivalence among terms).</p>
               </div>
               <div>
                  <head>3.4.2 TBX Data Enrichment</head>
                  <p>If the extraction of knowledge from unstructured notes proves successful (see Section 3.3), an additional step may involve enhancing the original TBX by incorporating the newfound information, in a sort of hermeneutic circle. This process goes beyond a naive addition of data, as it aims to complement the relationships stored within the TBX file, whether implicit or explicit. </p>
                  <p>While this proposition stands as a theoretically sound alternative, practical implementation considerations arise when modifying the TBX structure within the framework of the latest ISO standard. The pipeline of this process becomes easier by leveraging pre-established data categories available in DatCatInfo.<note> https://datcatinfo.termweb.eu/</note> This resource is a data category repository collecting data categories specifically developed for terminology work. The strategic use of these existing categories facilitates seamless integration and compliance to standard specifications. Conversely, should there be a need to introduce a novel data category, a more elaborate solution is required to document and comply with the requirements of the ISO standards. This expanded documentation process ensures that any additions align seamlessly with the established standards, maintaining the integrity and compatibility of the enriched TBX structure.</p>
               </div>
            </div>
         </div>
         <div>
            <head>4. LemonizeTBX: Towards a TBX to OntoLex-Lemon Converter Requirements </head>
            <p>In this Section, we present the design and the current development of LemonizeTBX, the prototype for converting resources from TBX into OntoLex-Lemon. Following the considerations mentioned above, we started to develop an interactive and highly customizable converter designed to accommodate the theoretical framework of the user conducting the conversion, be they terminologists, translators, or lexicographers. Given the dynamic nature of the converter, it also became crucial to develop a user interface that enables the coordination and monitoring of the conversion process. From a technological standpoint, we designed a software architecture based on the back-ends-for-front-ends pattern: a server-side component implementing the logic of conversion processes, and a client-side application representing the interface through which a user interacts and manages these processes.</p>
            <p>In the following, Section 4.1 is devoted to providing the implementation details of the server component (referred to as back-end from here on), while Section 4.2 describes the user interface through an example of conversion. Finally, Section 4.3 illustrates the current limitations of our prototype, and provides some general considerations.</p>
            <figure>
               <head/>
               <graphic url="media/image3.png"/>
            </figure>
            <p>Figure 2. The architecture of LemonizeTBX converter: (a) the front-end discussed in Section 4.2. (b) the back-end discussed in Section 4.1.</p>
            <div>
               <head>4.1 The Back-end Architecture</head>
               <p>The architecture, namely an Online Compiler, translates a TBX source into RDF triples according to the OntoLex-Lemon model, going interactively through three main phases: 1) analysis, 2) filtering, and 3) assemblage, as depicted in Figure 2. Through a Web client (described in the next section), a user can upload a TBX resource that is ingested by the Online Compiler that starts the process:</p>
               <list rend="bulleted">
                  <item>In the first phase, analysis, the Online Compiler routes the TBX file to the TBX parser component, which is in charge of analysing the XML input – potentially written in different TBX dialects (min, basic, core) – and processing the resource in order to get an intermediate representation (IR) of the information contained. IR is designed to fulfil two objectives: i) perform a partial conversion of entities (lexicons, concepts, terms, and senses) into their RDF-equivalent series of triples; ii) convey the resource's metadata information (such as the number of languages and terms) in JSON format. This format facilitates user interaction during the filtering and assemblage phases. Please note that the conversion at this stage is not considered final, as the ultimate coalescing phase will necessitate additional input from the user. During this phase, the resource is converted without making any assumptions about the final output.</item>
                  <item>The second phase, filtering, enables the user to query and inspect the resource, allowing them to define a personalised filter for selecting and potentially enriching the data. All interactions with the client are conducted by the Metadata Merger, which queries the database and returns a JSON response to the web client.</item>
                  <item>Subsequently, the assemblage phase, starting from the filtered data, constructs the OntoLex-Lemon lexica. This process involves processing languages, concepts, and terms, and serialising them as RDF triples in accordance with the OntoLex-Lemon data model.  </item>
               </list>
               <figure>
                  <head/>
                  <graphic url="media/image4.png"/>
               </figure>
               <p>Figure 3. The hierarchical structure of a TBX entry (tag &lt;conceptEntry&gt;). It has a set of language sections (tag &lt;langSec&gt;), and for each of them, a set of terms that designate the concept for that language (tag &lt;termSec&gt;). The example is about the concept of a “neighborhood electric vehicle” (c1), that is designed by the English terms “neighborhood electric vehicle”, and “NEV”.</p>
            </div>
            <div>
               <head>4.2 The Front-end Prototype</head>
               <p>Throughout the design and development of the converter, we endeavoured to envision the interaction between the user and the converter, guided by the requirements and considerations outlined in Section 3. In this section, we will illustrate the user interface using a brief example of TBX (basic). For simplicity, our focus will be on the concept of “neighborhood electric vehicle.” Figure 3 displays the XML code related to the English language section of this concept. Specifically, the fragment presents a concept identified as “c1” within the e-mobility field, along with an English language section containing the definition for that concept. Within the English language section, there are two terms associated with “c1”: the preferred full form 'neighborhood car vehicle' and the accepted acronym “NEV.” Each term includes specific information, such as morphology, usage contexts, and external references. Subsequently, we will explore incrementally how each part of the TBX input is converted into RDF triples according to the OntoLex-Lemon model.</p>
               <figure>
                  <head/>
                  <graphic url="media/image5.png"/>
               </figure>
               <p>Figure 4. Representation of a quantitative summary of the imported TBX resource.</p>
               <p>The interface divides the conversion process into five key phases:</p>
               <list rend="bulleted">
                  <item>Data ingestion: makes it possible to upload the TBX file to be converted, and verifies that it is written in one of the three TBX dialects (basic, min, core); validate it according to the three dialects (basic, min, core);</item>
                  <item>Data filtering: allows users to specify the data they wish to convert;</item>
                  <item>Concept mapping: permits users to define how filtered concepts should be converted;</item>
                  <item>Term mapping: lets users specify the conversion approach for terms associated with filtered concepts;</item>
                  <item>Data conversion: displays the converted data by querying the triple store containing the conversion.</item>
               </list>
               <p>Figure 4 illustrates the initial phase of the conversion process. Users can upload a TBX file, and the system parses the data, constructing an internal intermediate representation (IR) as outlined in Section 4.1. It is important to note that the input TBX file is assumed to be valid and well-formed; otherwise, the system will generate an error, a topic we will delve into further in the subsequent section. The system provides the user with a summary of the ingested data, presenting information such as file size, the public TBX dialect used, the count of concepts, and the number of terms per concept and language. This summary proves valuable for obtaining a quantitative overview of the file slated for conversion.</p>
               <figure>
                  <head/>
                  <graphic url="media/image6.png"/>
               </figure>
               <p>Figure 5. TBX data filtering interface.</p>
               <p>At this point, the user has the option to either proceed with an automatic file conversion using a default mapping or interactively determine the conversion of terminological entities on a case-by-case basis, as illustrated in Figure 5. The system presents TBX data in a table featuring a column for concepts and additional columns for each language in the TBX file. Each column includes all the terms designating the respective concepts, along with their parts of speech. Rows in the table, such as the one for concept c1 in Figure 5, can be expanded to reveal the definition of the concept in natural language across different languages. This capability stems from the TBX example used, where concept definitions are provided at the language level (see the <hi rend="italic">&lt;descripGrp/&gt;</hi> tag in Figure 3). In instances where the definition is specified at the concept level, the system directly presents it in the concept column. The table results can be filtered based on two parameters, which can also be used in combination: concepts created on specific dates (concept date filter) and concepts associated with particular topics (subject field filter). Additionally, users can opt to convert terms only in certain languages using the language filter. Subsequently, users can select the concepts they wish to convert by checking the checkbox in the corresponding column.</p>
               <figure>
                  <head/>
                  <graphic url="media/image7.png"/>
               </figure>
               <p>Figure 6. TBX concepts mapping interface.</p>
               <p>After selecting the concepts, users can determine how to convert them, as depicted in Figure 6. It is also an option to convert only the language part, i.e., the terms designating the selected concepts. There are four conversion possibilities:</p>
               <list rend="numbered">
                  <item>
                     <hi rend="italic">URL</hi>: the concepts are not created as ontological entities, but they are defined by URLs specified by the user;</item>
                  <item>
                     <hi rend="italic">Lexical Concept</hi>: the system maps concepts to the class 'Lexical Concept,' representing a mental abstraction, concept, or unit of thought lexicalized by a collection of terms;</item>
                  <item>
                     <hi rend="italic">SKOS Concept</hi> (default choice for automatic conversion): concepts are converted into SKOS classes. A detailed example will be presented below;</item>
                  <item>
                     <hi rend="italic">OWL Concept</hi>: the system generates as many OWL classes as selected concepts.</item>
               </list>
               <p>Additionally, users can specify whether, in relation to a concept “C” already defined in another ontology, that class represents it exactly (<hi rend="italic">owl:sameAs</hi>) or is related in some way (<hi rend="italic">rdfs:seeAlso</hi>). Concerning the SKOS choice, the concepts (<hi rend="italic">&lt;conceptEntry&gt;</hi>}, are converted by means of the SKOS ontology, according to Reineke and Romary (2019). Subject fields correspond to SKOS concept schemes, while concepts are mapped to SKOS concepts. The membership of concepts to their subject fields is formalised through the SKOS \textit{inScheme} relationship. The SKOS <hi rend="italic">definition</hi> property of a concept represents the definition of that concept provided by the TBX resource, whether the definition is given at the concept level or at the language level. </p>
               <p>In the following, an example of RDF Turtle serialisation produced by the tool is provided:</p>
               <p>:c1 a skos:Concept ;</p>
               <p>   skos:prefLabel “c1”@en ;</p>
               <p>   skos:inScheme :sbjf_1 ;</p>
               <p>   skos:definition “A battery-electric car that is capable of traveling at </p>
               <p>   a maximum speed of 25 miles per hour (mph) and has a maximum loaded </p>
               <p>   weight of 3,000 lbs.”@en ;</p>
               <p>   skos:definition “éhicule à deux places, activé par un moteur électrique  </p>
               <p>   à courant continue alimenté par des batteries au plomb rechargeables à </p>
               <p>   partir d'une prise de courant résidentielle de 110 volts.”@fr . </p>
               <p>:sbjf_1 a skos:ConceptScheme ;</p>
               <p>   skos:prefLabel “e-mobility”@en .</p>
               <p>Concerning the <hi rend="italic">&lt;langSec&gt;</hi> entity, the related OntoLex-Lemon lexica are created. Referring to the example in Figure 3, English, French, and Italian lexica are defined, and the terms are created as entries of the suitable lexicon. The Turtle serialisation produced by the tool is provided:</p>
               <p>:enLex a lime:Lexicon ;</p>
               <p>   lime:language “en” ;</p>
               <p>   lime:entry :t1, :t2 .</p>
               <p>:frLex a lime:Lexicon ;</p>
               <p>   lime:language “fr” ;</p>
               <p>   lime:entry :t3 .</p>
               <p>:itLex a lime:Lexicon ;</p>
               <p>   lime:language “it” ;</p>
               <p>   lime:entry :t4, :t5 .</p>
               <figure>
                  <head/>
                  <graphic url="media/image8.png"/>
               </figure>
               <p>Figure 7. TBX terms mapping interface.</p>
               <p>Finally, users have to determine how to convert the terms. The interface depicted in Figure 7 makes it possible to establish: </p>
               <list rend="numbered">
                  <item>whether lexical senses of the terms should be created; </item>
                  <item>what semantic relations among terms need to be represented;</item>
                  <item>how to handle terms with the same character sequence but different meanings.</item>
               </list>
               <p>For point one, the terms within the <hi rend="italic">&lt;termSec&gt;</hi> entity are represented as lexical entries in the OntoLex-Lemon model. Each term is mapped to the Lexical Entry class, without specifying its particular type (word or multi-word), and it is represented as a canonical form, typically a lemma, of that lexical entry. Following the “<hi rend="italic">semantics by reference</hi>” paradigm of OntoLex-Lemon, the meaning of a lexical entry is specified by referring to the created SKOS concept that represents its meaning. </p>
               <p>The default conversion process generates a lexical sense for each lexical entry and links it to the suitable concept by means of the <hi rend="italic">ontolex:reference</hi> property.  In the event the user opts not to represent the lexical sense of lexical entries (option shown in Figure 7), the converter links the term directly to the concept by means of the <hi rend="italic">denote</hi> property. Given that the model lacks a comprehensive set of linguistic categories, it relies on Lexinfo vocabulary.<note> LexInfo is an ontology that provides data categories for the \textit{lemon} model. Please, see https://lexinfo.net/</note> Consequently, morphological information, such as part of speech, and other morphological traits is associated with the forms, while usage context, term type, and administrative status are associated with the senses, according to the Lexinfo schema. If the definition in the <hi rend="italic">&lt;langSec&gt;</hi> has a source or/and an external reference, the reification mechanism<note> The reification is a mechanism allowing us to write RDF triples about RDF triples. In our case, we could specify both the source and the link of concept definitions.</note> would be employed in order to represent the source and the reference of the concept definition, using Dublin core <hi rend="italic">source</hi>, and RDF <hi rend="italic">seeAlso</hi> properties, respectively. Similarly, this mechanism can be applied to represent examples of term usage with the <hi rend="italic">usage</hi> property. Below is an example of the conversion related to the term “neighborhood electric vehicle”:</p>
               <p>:t1 rdf:type ontolex:LexicalEntry ; </p>
               <p>    lexinfo:partOfSpeech lexinfo:noun ; </p>
               <p>    lexinfo:normativeAuthorization lexinfo:preferredTerm ; </p>
               <p>    lexinfo:termType lexinfo:fullForm ; </p>
               <p>    ontolex:canonicalForm :t1_cf ;</p>
               <p>    ontolex:sense :t1_sense .</p>
               <p>:t1_cf rdf:type ontolex:Form ; </p>
               <p>    ontolex:writtenRep "neighborhood electric vehicle"@en .</p>
               <p>:t1_sense rdf:type ontolex:LexicalSense ; </p>
               <p>    skos:definition [ </p>
               <p>        rdf:value "A battery-electric ..." ;</p>
               <p>        dct:source "TechTarget" ;</p>
               <p>        rdfs:seeAlso &lt;https://www.techtarget.com/whatis/definition/neighborhood-</p>
               <p>        -electric-vehicle-NEV&gt; ] ;</p>
               <p>    ontolex:usage [ </p>
               <p>        rdf:value "A Neighborhood Electric Vehicle is a U.S. category for ..." ;</p>
               <p>        dct:source "Wikipedia" ;</p>
               <p>        rdfs:seeAlso &lt;https://en.wikipedia.org/wiki/Neighborhood_Electric</p>
               <p>        _Vehicle&gt; ] .</p>
               <p>Concerning point two, the semantic relations among terms, synonymy and translation can be identified and represented in OntoLex-Lemon. In particular, if the appropriate checkboxes in Figure 7 are selected, the system retrieves all the terms in different languages belonging to the same <hi rend="italic">&lt;conceptEntry&gt;</hi> element and creates suitable translation relations among them<note> For example, referring to Figure 6, all the terms referring to concept c1 are in a translation relationship with each other.</note>. Similarly, the system retrieves the terms of each language that share the same meaning (i.e., design the same concept) and converts them as synonyms. It is important to note that this is only feasible if the user opts to create lexical senses, as the Lexinfo synonymy relationship links senses together. The default behaviour in the case of automatic conversion is to refrain from representing any semantic relation.</p>
               <p>Finally, as for terms with the same character sequence but different meanings (see point three), all terms designating more than one concept are listed in a table. The user can choose which terms to represent as polysemic entries (multiple lexical senses are created for each term), and which terms to represent as homonyms (multiple distinct lexical entries are created). The default behaviour in the case of automatic conversion is the latter.</p>
            </div>
            <div>
               <head>4.3 Considerations</head>
               <p>The development of the converter is still in its early stages, and currently, only the default behaviour, outlined in the preceding sections, has been implemented. In this Section, we briefly address the limitations of the current implementation and how they manifest in the converted data. </p>
               <p>The converter presupposes that the TBX file slated for conversion is both syntactically and semantically valid. This implies that the file must be well-formed and the textual values within the XML tags should align semantically with the intended representation of the tags. Specifically, it assumes accurate reporting of data category values to ensure proper mapping with the Lexinfo vocabulary. Currently, only public TBX dialects are handled<note> For efficiency reasons, the converter still does not handle TBX files that are too large, such as IATE exports.</note>, and incorporating a private dialect would necessitate adjustments to the converter code, particularly in updating the parser and IR generator depicted in Figure 2. Introducing specific data categories might also require modifications to the user interface code. A pivotal aspect of the conversion process is the decision on whether or not to represent lexical sense. As emphasised in Section 3, the importance of sense may vary, and it could either not play a central role or be flattened onto the concept. However, in the OntoLex-Lemon model, the sense is deemed central, with semantic relations formally defined as links between lexical senses.<note> In the terminology model described in ISO 30042:2019, the entity <hi rend="italic">lexical sense</hi> is not defined.</note> Choosing not to represent lexical sense limits the converter's ability to explicitly define semantic relations, as illustrated by the interface in Figure 7.</p>
               <p>An alternative approach could involve mapping semantic relations (such as, for example, hypernymy, meronymy, etc.) with relations between the concepts (such as isA, partOf, etc.) designated by the terms to which the appropriate senses would correspond. This aligns with perspectives that do not distinguish between sense and concept, but deviates from the theoretical viewpoint where senses and concepts are considered distinct entities, albeit intimately related. </p>
            </div>
         </div>
         <div>
            <head>5. Conclusions </head>
            <p>The paper introduces LemonizeTBX, a prototype software to enhance interoperability between the ISO TBX standard, used for representing terminological resources and the OntoLex-Lemon model, adopted to represent lexicographic resources. The converter aims to bridge the gap between terminological and lexicographical frameworks, emphasising a shift from a concept-oriented to a sense-centred standpoint. This change in perspective underscores the need for an interactive tool to engage terminologists in the conversion process. The interactivity concerns choices that users need to make when there is no direct mapping from TBX to OntoLex-Lemon. For instance, deciding whether and how to link lexical entries directly to concepts or how to add missing data categories. The converter is designed to support an advanced process to enrich the data by extracting implicit and explicit information from unstructured content in TBX entries.</p>
            <p>The implementation of LemonizeTBX is currently in its early stages, featuring some default behaviour. For instance, it assumes syntactic and semantic validity in the input TBX files, it primarily focuses on representing lexical senses, leaving room for potential alternative approaches, such as mapping semantic relations to concept relations.</p>
            <p>However, as discussed in the preceding Section 4.3, the work conducted thus far has revealed that the challenges posed by the conversion process are fundamentally theoretical, raising questions that deserve discussion within the community. This discussion is crucial to provide a solid foundation for the development of a customised OntoLex-Lemon module for terminology science tailored to the specificities of this discipline.<note> At the time of writing this article, the W3C OntoLex group is discussing the possibility of introducing such a module https://www.w3.org/community/ontolex/wiki/Terminology\#Use_Cases</note>
            </p>
         </div>
         <div>
            <head>References</head>
            <p>Bellandi, Andrea, Di Nunzio, Giorgio Maria, Piccini, Silvia, and Vezzani, Federica. (2023a) 'From TBX to Ontolex Lemon: Issues and Desiderata' in Proceedings of the 2nd International Conference on Multilingual Digital Terminology Today (MDTT 2023), Volume 3427 of CEUR Workshop Proceedings, Lisbon, Portugal. CEUR. ISSN: 1613-0073. </p>
            <p>Available at: https://ceur-ws.org/Vol-3427/paper4.pdf (Accessed: 09 April 2024). </p>
            <p>Bellandi, Andrea, Di Nunzio, Giorgio Maria, Piccini, Silvia, and Vezzani, Federica. (2023b) ‘The Importance of Being Interoperable: Theoretical and Practical Implications in Converting TBX to OntoLex-Lemon’ in Proceedings of the 4th Conference on Language, Data and Knowledge, pages 646–651, Vienna, Austria. NOVA CLUNL, Portugal.</p>
            <p>Available at: https://aclanthology.org/2023.ldk-1.70 (Accessed: 09 April 2024). </p>
            <p>Bosque-Gil, Julia, Gracia, Jorge, Aguado-de Cea, Guadalupe, and Montiel-Ponsoda, Elena. (2015) ‘Applying the OntoLex Model to a Multilingual Terminological Resource’ in The Semantic Web: ESWC 2015 Satellite Events, Lecture Notes in Computer Science, Cham, pp. 283–294. Springer International Publishing. </p>
            <p>Available at: https://doi.org/10.1007/978-3-319-25639-9_43 (Accessed: 09 April 2024). </p>
            <p>Buitelaar, Paul. (2010) ‘Ontology-based semantic lexicons: mapping between terms and object descriptions’ In A. Gangemi, A. Lenci, A. Oltramari, C.-r. Huang, L. Prevot, and N. Calzolari (Eds.) Ontology and the Lexicon: A Natural Language Processing Perspective, Studies in Natural Language Processing, pp. 212–223. Cambridge: Cambridge University Press. </p>
            <p>Available at: https://doi.org/10.1017/CBO9780511676536.013 (Accessed: 09 April 2024).</p>
            <p>Buitelaar, Paul, Declerck, Thierry, Anette Frank, Racioppa, Stefania, Kiesel, Malte, Sintek, Michael, Engel, Ralf, Romanelli, Massimo, Sonntag, Daniel, Loos, Berenike, Micelli, Vanessa, Porzel, Robert, and Cimiano, Philipp. (2006) ‘LingInfo: Design and Applications of a Model for the Integration of Linguistic Information in Ontologies’ in Proceedings of the OntoLex Workshop at LREC 2006.</p>
            <p>Available at: https://www.aifb.kit.edu/images/9/9f/2006_1233_Buitelaar_LingInfo_Desig_1.pdf (Accessed: 09 April 2024).</p>
            <p>Chozas, Patricia Martin and Declerck, Thierry. (2022) ‘Representing Multilingual Terminologies with OntoLex-Lemon (short paper)’ in Proceedings of the 1st International Conference on Multilingual Digital Terminology Today (MDTT 2022), Volume 3161 of CEUR Workshop Proceedings, Padua, Italy. CEUR. ISSN: 1613-0073.</p>
            <p>Available at: https://ceur-ws.org/Vol-3161/short1.pdf (Accessed: 09 April 2024).</p>
            <p>Cimiano, Philipp, Chiarcos, Christian, McCrae, John P., and Gracia Jorge. (2020a) ‘Converting Language Resources into Linked Data’ in Linguistic Linked Data, pp. 163–180. Cham: Springer International Publishing.</p>
            <p>Available at: https://doi.org/10.1007/978-3-030-30225-2_9 (Accessed: 09 April 2024).</p>
            <p>Cimiano, Philipp, Chiarcos, Christian, McCrae, John P., and Gracia, Jorge. (2020b)</p>
            <p>Linguistic Linked Data: Representation, Generation and Applications. Cham: Springer International Publishing.</p>
            <p>Available at: https://doi.org/10.1007/978-3-030-30225-2 (Accessed: 09 April 2024).</p>
            <p>Cimiano, Philipp, Haase, Peter, Herold, Matthias, Mantel, Matthias, and Buitelaar, Paul. (2007) ‘Lexonto: A model for ontology lexicons for ontology-based nlp’ in Proceedings of the OntoLex07 Workshop held in conjunction with ISWC’07.</p>
            <p>Available at: https://www.aifb.kit.edu/web/Inproceedings1584 (Accessed: 09 April 2024).</p>
            <p>Cimiano, Philipp, McCrae, John P., Rodríguez-Doncel, Víctor, Gornostay, Tatiana, Gómez-Pérez, Asunción, Siemoneit, Benjamin and Lagzdins, Andis. (2015) ‘Linked terminologies: applying linked data principles to terminological resources’ in Proceedings of the eLex 2015 Conference, pp. 504–517.</p>
            <p>Available at: https://elex.link/elex2015/proceedings/eLex_2015_34_Cimiano+etal.pdf (Accessed: 09 April 2024).</p>
            <p>Costa, Rute. (2013) ‘Terminology and Specialised Lexicography: two complementary domains’. Lexicographica 29 (2013), pp. 29–42. De Gruyter.</p>
            <p>Available at: https://doi.org/10.1515/lexi-2013-0004 (Accessed: 09 April 2024).</p>
            <p>Declerck, Thierry, McCrae, John Philip, Hartung, Matthias, Gracia, Jorge, Chiarcos, Christian, Montiel-Ponsoda, Elena, Cimiano, Philipp, Revenko, Artem, Saurí, Roser, Lee, Deirdre, Racioppa, Stefania, Abdul Nasir, Jamal, Orlikowsk, Matthias, Lanau-Coronas, Marta, Fäth, Christian, Rico, Mariano, Fazleh Elahi, Mohammad, Khvalchik, Maria, Gonzalez, Meritxell, and Cooney, Katharine. (2020) ‘Recent developments for the linguistic linked open data infrastructure’ in Proceedings of the Twelfth Language Resources and Evaluation Conference, pp. 5660–5667, Marseille, France. European Language Resources Association.</p>
            <p>Available at: https://aclanthology.org/2020.lrec-1.695.pdf (Accessed: 09 April 2024).</p>
            <p>di Buono, Maria Pia, Cimiano, Philipp, Fazleh Elahi, Mohammad, and Grimm, Frank. (2020) ‘Terme-à-LLOD: Simplifying theConversion and Hosting of Terminological Resources as Linked Data’ in Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020), Marseille, France, pp.28–35. European Language Resources Association.</p>
            <p>Available at: https://aclanthology.org/2020.ldl-1.5.pdf (Accessed: 09 April 2024).</p>
            <p>Di Nunzio, Giorgio Maria and Vezzani, Federica. (2021) ‘One Size Fits All: A Conceptual Data Model for Any Approach to Terminology’. arXiv:2112.06562 [cs].</p>
            <p>Available at: https://arxiv.org/pdf/2112.06562.pdf (Accessed: 09 April 2024).</p>
            <p>Faber, Pamela and L’Homme, Marie-Claude. (2022) Theoretical Perspectives on Terminology. John Benjamins Publishing Company.</p>
            <p>Frey, Johannes and Hellmann, Sebastian. (2021) ‘FAIR Linked Data - Towards a Linked Data Backbone for Users and Machines’ in Companion Proceedings of the Web Conference 2021. New York, NY, USA, pp. 431–435. Association for Computing Machinery. </p>
            <p>Available at: https://doi.org/10.1145/3442442.3451364 (Accessed: 09 April 2024).</p>
            <p>Kitanović, Olivera, Stanković, Ranka, Tomašević, Aleksandra, Škorić, Mihailo, Babić, Ivan, and Kolonja, Ljiljana. (2021) ‘A Data Driven Approach for Raw Material Terminology’, Applied Sciences, 11 (7), 2892. Publisher: MDPI.</p>
            <p>Available at: https://www.mdpi.com/2076-3417/11/7/2892 (Accessed: 09 April 2024).</p>
            <p>Montiel-Ponsoda, Elena, Aguado De Cea, Guadalupe Gómez-Pérez, Asunción, and Peters, Wim. (2011) ‘Enriching ontologies with multilingual information’, Natural language engineering, 17(3), pp. 283–309.</p>
            <p>Available at: https://doi.org/10.1017/S1351324910000082 (Accessed: 09 April 2024).</p>
            <p>Piccini, Silvia, Vezzani, Federica, and Bellandi, Andrea. (2023) ‘TBX and ‘Lemon’: What perspectives in terminology?’ Digital Scholarship in the Humanities, 38 (Supplement_1), pp. i61–i72. </p>
            <p>Available at: https://doi.org/10.1093/llc/fqad025 (Accessed: 09 April 2024).</p>
            <p>Rastier, Francois. (1995) ‘Le terme : entre ontologie et linguistique’. La banque de mots 7, pp. 35–65.</p>
            <p>Reineke, Detlef and Romary, Laurent. (2019) ‘Bridging the gap between SKOS and TBX’. Die Fachzeitschrift für Terminologie 19(2).</p>
            <p>Available at: https://inria.hal.science/hal-02398820 (Accessed: 09 April 2024).</p>
            <p>Rodriguez-Doncel, Víctor, Santos, Cristiana, Casanovas, Pompeu, Gómez-Pérez, Asunción, and Gracia, Jorge. (2018) ‘A Linked Data Terminology for Copyright Based on Ontolex-Lemon’. in AI Approaches to the Complexity of Legal Systems, Lecture Notes in Computer Science, Cham, pp. 410–423. Springer International Publishing. </p>
            <p>Available at: https://doi.org/10.1007/978-3-030-00178-0_28 (Accessed: 09 April 2024)</p>
            <p>Santos, Claudia and Costa, Rute. (2015) ‘Semasiological and onomasiological knowledge representation: Domain specificity’. in Handbook of Terminology: Volume 1, Handbook of Terminology, pp. 153–179. John Benjamins Publishing Company. </p>
            <p>Available at: https://doi.org/10.1075/hot.1.dom1 (Accessed: 09 April 2024)</p>
            <p>Siemoneit, Benjamin, McCrae, John Philip, and Cimiano, Philipp. (2015) ‘Linking four heterogeneous language resources as linked data’ in Proceedings of the 4th Workshop on Linked Data in Linguistics: Resources and Applications, pp. 59–63, Beijing, China. Association for Computational Linguistics.</p>
            <p>Available at: https://aclanthology.org/W15-4207.pdf (Accessed: 09 April 2024)</p>
            <p>Speranza, Giulia, Di Buono, Maria Pia, Sangati, Federico, and Monti, Johanna. (2020) ‘From linguistic resources to ontology-aware terminologies: Minding the representation gap’ in Proceedings of The 12th Language Resources and Evaluation Conference, pp. 2503–2510. European Language Resources Association.</p>
            <p>Available at: https://aclanthology.org/2020.lrec-1.305.pdf (Accessed: 09 April 2024)</p>
            <p>Suchowolec, Karolina, Lang, Christian, and Schneider, Roman. (2019) ‘An empirically validated, onomasiologically structured, and linguistically motivated online terminology: Re-designing scientific resources on German grammar’. International Journal on Digital Libraries. 20(3), pp. 253–268. </p>
            <p>Available at: https://doi.org/10.1007/s00799-018-0254-x (Accessed: 09 April 2024)</p>
            <p>Vellutino, Daniela, Maslias, Rodolfo, Rossi, Francesco, Mangiacapre, Carmina, and Montoro, Maria Pia. (2016) ‘Verso l’interoperabilità semantica di IATE. Studio preliminare sul lessico dei Fondi strutturali e d’Investimento Europei (Fondi SIE)’, Diacronia XIII (1), 187.</p>
            <p>Available at: https://www.diacronia.ro/en/indexing/details/A23887/pdf (Accessed: 09 April 2024)</p>
            <p>Wilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. (2016) ‘The FAIR Guiding Principles for Scientific Data Management and Stewardship’. Scientific Data, 3 (1): 160018.</p>
            <p>Available at: https://doi.org/10.1038/sdata.2016.18 (Accessed: 09 April 2024)</p>
            <p>— — ORCID</p>
            <p>Andrea Bellandi</p>
            <p>0000-0002-1900-5616</p>
            <p>Giorgio Maria Di nunzio</p>
            <p>0000-0001-9709-6392</p>
            <p>Silvia Piccini</p>
            <p>0000-0002-2584-0191</p>
            <p>Federica Vezzani</p>
            <p>0000-0003-2240-6127</p>
            <p>— — Keywords</p>
            <p>Linguistics</p>
            <p>Markup Languages</p>
            <p>Semantic Web Technologies</p>
            <p>Biographies</p>
            <p>Andrea Bellandi (Institute for Computational Linguistics "A. Zampolli" (CNR) in Pisa, andrea.bellandi@ilc.cnr.it) is a researcher in Computational Linguistics. He has a PhD in Computer Science in the field of knowledge representation and reasoning. He currently contributes to the development of formal models and tools of computational lexicography and terminology. He has been working also on the<ref target="https://www.talmud.it/?lang=en" xml:space="preserve"> </ref>
               <ref target="https://www.talmud.it/?lang=en">Babylonian Talmud Translation Project</ref>, contributing to the development of <hi rend="italic">Traduco</hi>, an innovative software for completing the first ever translation into Italian of the Talmud, the fundamental Jewish text written in Ancient Aramaic.</p>
            <p>Giorgio Maria Di Nunzio (University of Padua, Italy, <ref target="mailto:giorgiomaria.dinunzio@unipd.it">giorgiomaria.dinunzio@unipd.it</ref>) is Associate Professor of Computer Engineering. His main research interests are: Technology Assisted Review systems, Interactive Information Retrieval, Computational Terminology and Open Data Science. He’s the principal investigator and coordinator of the Centre of Studies of Computational Terminology (CENTRICO) at the University of Padova, and Open Data advisor and member of the Open Science Committee of the University of Padova. He is co-editor in chief of the journal Umanistica Digitale and was appointed as the Secretary of the Associazione per l’Informatica Umanistica e la Cultura Digitale (AIUCD) from 2018 until 2020.</p>
            <p>Silvia Piccini (Institute for Computational Linguistics "A. Zampolli" (CNR) in Pisa, <ref target="mailto:silvia.piccini@ilc.cnr.it">silvia.piccini@ilc.cnr.it</ref>) is a researcher in Computational Lexicography and Terminology. She has contributed to the development of terminological resources in multiple languages and for various specialised domains. Her research interests primarily focus on the formal representation of terminological variation, with a keen focus on both the diachronic axis and cultural dimensions. She has been working also on aspects related to Baltic studies and general linguistics, particularly focusing on the thought and work of Ferdinand de Saussure. Since June 2018, she has been a member of the Cercle Ferdinand de Saussure.</p>
            <p>Federica Vezzani (University of Padua, Italy, <ref target="mailto:federica.vezzani@uipd.it">federica.vezzani@uipd.it</ref>) is Tenure-track Assistant Professor in Terminology and Specialized Translation. She is a member of the ISO/TC 37 "Language and Terminology" and of the Portuguese mirror committee "CT 221 – Terminologia, Língua e Linguagens" at the Portuguese Institute for Quality. Her main research interests are terminology, specialised translation, and technical communication. In particular, she focuses on the management of multilingual terminology according to ISO standards, and she has developed the FAIR terminology paradigm for the optimal organisation of findable, accessible, interoperable, and reusable terminological data.</p>
         </div>
      </body>
      <back>
         <listBibl>
            <bibl/>
         </listBibl>
      </back>
   </text>
</TEI>
