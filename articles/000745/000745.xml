<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
	xmlns:dhq="http://www.digitalhumanities.org/ns/dhq" xmlns:mml="http://www.w3.org/1998/Math/MathML"
	xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
	<teiHeader>
		<fileDesc>
			<titleStmt>
				<!--Author should supply the title and personal information-->
				<title type="article" xml:lang="en">LemonizeTBX: Design and Implementation of a New Converter from TBX to
					OntoLex-Lemon<!--article title in English--></title>
				<!--Add a <title> with appropriate @xml:lang for articles in languages other than English-->
				<dhq:authorInfo>
					<dhq:author_name>Andrea <dhq:family>Bellandi</dhq:family>
					</dhq:author_name>
					<idno type="ORCID">https://orcid.org/0000-0002-1900-5616</idno>
					<dhq:affiliation>Institute for Computational Linguistics "A. Zampolli" CNR, Via Moruzzi 1, 56124, Pisa -
						Italy</dhq:affiliation>
					<email>andrea.bellandi@ilc.cnr.it</email>
					<dhq:bio>
						<p>Andrea Bellandi is a researcher in Computational Linguistics. He has a PhD in Computer Science in the field of
							knowledge representation and reasoning. He currently contributes to the development of formal models and tools
							of computational lexicography and terminology. He has been working also on the Babylonian Talmud Translation
							Project, contributing to the development of <title rend="italic">Traduco</title>, an innovative software for
							completing the first ever translation into Italian of the Talmud, the fundamental Jewish text written in
							Ancient Aramaic.</p>
					</dhq:bio>
				</dhq:authorInfo>
				<dhq:authorInfo>
					<dhq:author_name>Giorgio Maria <dhq:family>Di Nunzio</dhq:family></dhq:author_name>
					<idno type="ORCID">https://orcid.org/0000-0001-9709-6392</idno>
					<dhq:affiliation>Department of Information Engineering, University of Padova, Via Gradenigo 6/b, 35131 Padova,
						Italy</dhq:affiliation>
					<email>giorgiomaria.dinunzio@unipd.it</email>
					<dhq:bio>
						<p>Giorgio Maria Di Nunzio is Associate Professor of Computer Engineering. His main research interests are:
							Technology Assisted Review systems, Interactive Information Retrieval, Computational Terminology and Open Data
							Science. He is the principal investigator and coordinator of the Centre of Studies of Computational Terminology
							(CENTRICO) at the University of Padova, and Open Data advisor and member of the Open Science Committee of the
							University of Padova. He is co-editor in chief of the journal <title rend="italic" xml:lang="it">Umanistica
								Digitale</title> and was appointed as the Secretary of the <title rend="none" xml:lang="it">Associazione per
								l’Informatica Umanistica e la Cultura Digitale</title> (AIUCD) from 2018 until 2020.</p>
					</dhq:bio>
				</dhq:authorInfo>
				<dhq:authorInfo>
					<dhq:author_name>Silvia <dhq:family>Piccini</dhq:family></dhq:author_name>
					<idno type="ORCID">https://orcid.org/0000-0002-2584-0191</idno>
					<dhq:affiliation>Institute for Computational Linguistics "A. Zampolli" CNR, Via Moruzzi 1, 56124, Pisa -
						Italy</dhq:affiliation>
					<email>silvia.piccini@ilc.cnr.it</email>
					<dhq:bio>
						<p>Silvia Piccini is a researcher in Computational Lexicography and Terminology. She has contributed to the
							development of terminological resources in multiple languages and for various specialised domains. Her research
							interests primarily focus on the formal representation of terminological variation, with a keen focus on both
							the diachronic axis and cultural dimensions. She has been working also on aspects related to Baltic studies and
							general linguistics, particularly focusing on the thought and work of Ferdinand de Saussure. Since June 2018,
							she has been a member of the Cercle Ferdinand de Saussure.</p>
					</dhq:bio>
				</dhq:authorInfo>
				<dhq:authorInfo>
					<dhq:author_name>Federica <dhq:family>Vezzani</dhq:family></dhq:author_name>
					<idno type="ORCID">https://orcid.org/0000-0003-2240-6127</idno>
					<dhq:affiliation>Department of Linguistic and Literary Studies, University of Padova, Via Elisabetta Vendramini, 13
						35137 Padova, Italy</dhq:affiliation>
					<email>federica.vezzani@unipd.it</email>
					<dhq:bio>
						<p>Frederica Vezzani is Tenure-track Assistant Professor in Terminology and Specialized Translation. She is a
							member of the ISO/TC 37 <q>Language and Terminology</q> and of the Portuguese mirror committee <q xml:lang="pt"
								>CT 221 – Terminologia, Língua e Linguagens</q> at the Portuguese Institute for Quality. Her main research
							interests are terminology, specialised translation, and technical communication. In particular, she focuses on
							the management of multilingual terminology according to ISO standards, and she has developed the FAIR
							terminology paradigm for the optimal organisation of findable, accessible, interoperable, and reusable
							terminological data.</p>
					</dhq:bio>
				</dhq:authorInfo>
			</titleStmt>
			<publicationStmt>
				<publisher>Alliance of Digital Humanities Organizations</publisher>
				<publisher>Association for Computers and the Humanities</publisher>
				<!--This information will be completed at publication-->
				<idno type="DHQarticle-id">000745<!--including leading zeroes: e.g. 000110--></idno>
				<idno type="volume"><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006--></idno>
				<idno type="issue"><!--issue number, without leading zeroes: e.g. 2--></idno>
				<date><!--include @when with ISO date and also content in the form 23 February 2024--></date>
				<dhq:articleType>article</dhq:articleType>
				<availability status="CC-BY-ND">
					<!--If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default):        
                  CC-BY:    
                  CC0:  -->
					<cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
				</availability>
			</publicationStmt>
			<sourceDesc>
				<p>This is the source</p>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<classDecl>
				<taxonomy xml:id="dhq_keywords">
					<bibl>DHQ classification scheme; full list available at <ref
							target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
							>http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
					</bibl>
				</taxonomy>
				<taxonomy xml:id="authorial_keywords">
					<bibl>Keywords supplied by author; no controlled vocabulary</bibl>
				</taxonomy>
				<taxonomy xml:id="project_keywords">
					<bibl>DHQ project registry; full list available at <ref target="http://www.digitalhumanities.org/dhq/projects.xml"
							>http://www.digitalhumanities.org/dhq/projects.xml</ref>
					</bibl>
				</taxonomy>
			</classDecl>
		</encodingDesc>
		<profileDesc>
			<langUsage>
				<language ident="en" extent="original"/>
				<!--add <language> with appropriate @ident for any additional languages-->
			</langUsage>
			<textClass>
				<keywords scheme="#dhq_keywords">
					<!--Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors-->
					<!--Enter keywords below preceeded by a "#". Create a new term element for each-->
					<term corresp=""/>
				</keywords>
				<keywords scheme="#authorial_keywords">
					<!--Authors may include one or more keywords of their choice-->
					<list type="simple">
						<item/>
					</list>
				</keywords>
				<keywords scheme="#project_keywords">
					<list type="simple">
						<item/>
					</list>
				</keywords>
			</textClass>
		</profileDesc>
		<revisionDesc>
			<!-- Replace "NNNNNN" in the @target of ref below with the appropriate DHQarticle-id value. -->
			<change>The version history for this file can be found on <ref
					target="https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/main/articles/000745/000745.xml">GitHub
				</ref>
			</change>
		</revisionDesc>
	</teiHeader>
	<text xml:lang="en" type="original">
		<front>
			<dhq:abstract>
				<!--Include a brief abstract of the article-->
				<p>In this paper, we introduce LemonizeTBX, a converter that enhances interoperability between terminological and
					lexicographical frameworks, acknowledging their divergent data modelling approaches. First, we present the
					theoretical implications of a conversion from the TermBase eXchange (TBX) concept-oriented framework to the
					OntoLex-Lemon sense-centred standpoint within Semantic Web technologies. Then, we illustrate the prototype version
					of the converter, designed as an interactive tool engaging terminologists in the conversion process.</p>
			</dhq:abstract>
			<dhq:teaser>
				<!--Include a brief teaser, no more than a phrase or a single sentence-->
				<p/>
			</dhq:teaser>
		</front>
		<body>
			<div>
				<head>1. Introduction </head>
				<p>In recent years, Linked Data (LD) has emerged as a highly promising approach to effectively integrate,
					interconnect, and semantically enrich different datasets, thus promoting interoperability and accessibility across
					the web <ptr target="#frey_etal2021"/>. Terminologists therefore increasingly recognise the importance of
					publishing resources as LD to overcome siloed information management, and facilitate the reuse of terminological
					datasets in accordance with the FAIR principles <ptr target="#wilkinson_etal2016"/>. In response to this paradigm
					shift, alongside the well-established ISO standard 30042:2019 about the TermBase eXchange implementation format
						(TBX),<note> https://www.iso.org/standard/62510.html</note> the OntoLex-Lemon data model has gained increasing
					importance within the terminology community, being widely recognized as the de facto standard for constructing RDF
					lexical resources (inter al. see <ptr target="#bosquegil_etal2015"/>; <ptr target="#rodriguezdoncel_etal2018"/>;
						<ptr target="#vellutino_etal2016"/>).<note> Another data model widely used in the world of semantic web for
						sharing and publishing lexical information as LD is the Simple Knowledge Organization System (SKOS). The latter
						features the same concept-centric structure as TBX (for a comparison between TBX and SKOS see Reineke and Romary
							(<ref target="#reineke_etal2019">2019</ref>). </note> TBX is an XML-based family of terminology exchange
					formats characterised by a hierarchical structure based on the Terminological Markup Framework (TMF - ISO
						16642:2017).<note> https://www.iso.org/standard/56063.html</note> Specifically, a terminological data collection
					(TDC) is constituted by a set of concept entries (CEs), each describing a concept within a specialised domain. Each
					concept entry includes one or more language sections (LSs) that, in turn, include one or more term sections (TSs)
					containing the term designating the concept in that specific language, as well as a set of additional information
					describing the term itself. In Figure 1, we show an example of a TBX file that contains two CE; the first CE
					identified with the code “1” has three LSs: English, Spanish, and Italian. The English LS contains two designations
					for this concept, the same for Spanish, while the Italian LS contains only one designation.</p>
				<figure xml:id="figure01">
					<head>Example of a TBX file containing a CE with three LSs.</head>
					<graphic url="resources/images/figure01.png"/>
				</figure>
				<p>The OntoLex-Lemon model, on the other hand, is characterised by a modular architecture that allows for a detailed
					and articulated description of the linguistic characteristics of a term. Figure 2 depicts the core elements of the
					model. Each lexical entry – be it an affix, a word or a multiword expression – is an instance of the class Lexical
					Entry and is associated to its morphological realisations (class Form) through the relation <hi rend="italic"
						>ontolex:lexicalForm</hi> as well as to its sense(s) (class Lexical Sense) by means of the <hi rend="italic"
						>ontolex:sense</hi> property. Lexical sense, conceived as the reification of the <hi rend="italic"
						>ontolex:denotes</hi> property linking the lexical entry and the concept, can be provided with additional
					information, such as usage context (<hi rend="italic">ontolex:usage</hi>), and its semantic relations expressed by
					means of a particular linguistic vocabulary, e.g., LexInfo.<note> LexInfo is an ontology that provides data
						categories for the OntoLex-Lemon model.</note></p>
				<figure xml:id="figure02">
					<head>The architecture of the OntoLex-Lemon module.</head>
					<graphic url="resources/images/figure02.png"/>
				</figure>
				<p>The concept, viewed as an extra-linguistic entity, can be formally described either in an external domain ontology
					(already existing or created from scratch) according to the principle known as “semantics by reference” <ptr
						target="#buitelaar2010"/>, or as an instance of the Lexical concept class (<ref target="#figure01">see Figure
						1</ref>), which represents “a mental abstraction, concept or unit of thought that can be lexicalized by a given
					collection of senses”. In addition to the Ontolex core, other modules have been developed, such as the
					Decomposition module; the Variation and Translation module; the Syntax and Semantics module; the Linguistic
					Metadata module.<note> For a description of the above-mentioned modules see: https://www.w3.org/2016/05/ontolex/
					</note>
				</p>
				<p>To ensure interoperability between these two distinct approaches to data modelling – on one side, the ISO TMF and
					TBX standards, and on the other side, OntoLex-Lemon and the Semantic Web technologies – we found it necessary to
					develop a new converter, named LemonizeTBX, which will be the focus of this paper. Although a similar tool was
					already developed by Cimiano et al (<ref target="#cimiano_etal2015">2015</ref>), the new converter differs in two
					fundamental aspects. It is interactive, allowing the terminologist to play an active role in the conversion
					process. As highlighted by Piccini et al (<ref target="#piccini_etal2023">2023</ref>), indeed, moving from a TBX
					format to an LD structure goes beyond a simple shift from an XML-based to an RDF-based data format. The conversion
					process involves a shift in perspective: a strictly terminological concept-oriented framework (TBX) is converted
					into a lexicographical sense-centred standpoint (OntoLex-Lemon). Moreover, as discussed by Bellandi et al (2023b),
					TBX primarily focuses on facilitating the exchange and administration of terminological resources to maintain
					coherence and compatibility among terminologists and language experts. Conversely, Ontolex-Lemon is specifically
					designed to encode lexical data, with the goal of capturing intricate linguistic details and facilitating semantic
					integration with other RDF datasets.</p>
				<p>In addition, the new converter will handle input and output files in the latest versions of TBX and OntoLex-Lemon,
					as both have undergone revisions over time. In 2019, the TBX version 3.0 was released and published as ISO 30042:
					2019, replacing the previous TBX version 2.0 published in 2008 (ISO 30042: 2008). Similarly, the OntoLex-Lemon
					model, born within the European Monnet project as a result of the integration of the three pre-existing models
					LingInfo <ptr target="#buitelaar_etal2006"/>, LexOnto <ptr target="#cimiano_etal2007"/>, LIR <ptr
						target="#montielponsoda_etal2011"/>, was later extended into the OntoLex-Lemon model by the Ontology-Lexicon
					Community Group. </p>
				<p>This paper is structured as follows. In Section 2, we provide an overview of the main works that address the issue
					of transforming a terminological resource serialised in a TBX format into a Linguistic Linked Data (LLD) resource
					serialised in an RDF OntoLex-Lemon format. In Section 3, we define the key requirements for the development of the
					new converter LemonizeTBX. Section 4 describes the initial prototype of the converter, and finally, in Section 5,
					conclusions will be drawn, and future work will be outlined. </p>
			</div>
			<div>
				<head>2. State of the Art </head>
				<p>This section provides an overview of previous efforts in transforming a TBX terminological resource into a LLD
					resource using the OntoLex-Lemon model. We categorised these approaches into two sections: Section 2.1 focuses on
					the TBX2RDF tool specifically designed for this purpose, and Section 2.2 delves into alternative approaches,
					discussing the theoretical implications of such transformation.</p>
				<div>
					<head>2.1 An Overview of TBX2RDF Approaches</head>
					<p>The application of LD principles to terminological datasets was discussed by Cimiano et al (<ref
							target="#cimiano_etal2015">2015</ref>); Siemoneit et al (<ref target="#siemoneit_etal2015">2015</ref>). In
						their seminal work, the authors present a process involving the mapping of TBX elements and structures into the
						OntoLex-Lemon ontology, which provides a semantic framework for describing lexical and linguistic information in
							RDF.<note> https://www.w3.org/2015/09/bpmlod-reports/multilingual-terminologies/</note> The proposed
						methodology is implemented as an online service named TBX2RDF that enables the representation of terminological
						data in a linked and machine-readable format, facilitating their integration with other semantic web resources
						and applications. In fact, by converting XML data into RDF, it becomes possible to semantically enrich the data,
						enabling more effective querying, linking, and reasoning across heterogeneous sources on the web. This
						transformation enhances the accessibility, reusability, and comprehensibility of data, ultimately contributing to
						the realisation of the Semantic Web's vision of a more interconnected and meaningful web of data. In addition, as
						the manual creation of links between datasets is costly and therefore not scalable, the authors propose a
						preliminary attempt to explore approaches for automatic linking between different datasets.</p>
					<p>The best practices to model LLD were identified in the masterwork by Cimiano et al (<ref
							target="#cimiano_etal2020b">2020b</ref>) devoted to the principles behind the idea of semantic web and, in
						particular, to the issues of reusability of dictionaries and interoperability of resources. However, the
						treatment of transforming a terminological resource into a LD format often remains confined to a surface-level
						mapping of elements, lacking deeper consideration for the theoretical implications inherent in these mapping
						choices.</p>
					<p>The design and implementation of TBX2RDF have certainly influenced the research in this area and has given the
						possibility to create important linguistic linked resources. For example, in Rodriguez-Doncel et al (<ref
							target="#rodriguezdoncel_etal2018">2018</ref>), the authors describe a terminology created in a half-automated
						process, where terms and natural language definitions have been extracted and integrated from different lexical
						sources and mapped in a supervised process. In particular, the paper analyses the process and the methodologies
						adopted in the automatic conversion into TBX of linguistic resources together with their semantic enrichment.</p>
					<p>A similar, but somewhat inverse process, was described by Speranza et al (<ref target="#speranza_etal2020"
							>2020</ref>) who propose a proof-of-concept for an automated methodology to convert linguistic resources into
						TBX resources using the Italian Linguistic Resource for the Archaeological domain. A conversion tool is designed
						and implemented to support the creation of ontology-aware terminologies, enhancing interoperability and
						facilitating the sharing of language technologies and datasets. By ontology-aware terminologies, the authors
						intend the approach that relies on a precise conceptual mapping of linguistic and semantic information to TBX
						elements and the enrichment of these elements by means of semantic information, which may be useful in several
						applications to create a cloud of interoperable and interconnected terminologies, directly linked to both already
						existing ontologies and new developed ones.</p>
					<p>In Declerck et al (<ref target="#declerck_etal2020">2020</ref>); di Buono et al (<ref target="#dibuono_etal2020"
							>2020</ref>), the authors discuss the Prêt-à-LLOD project<note>
							https://cordis.europa.eu/project/id/825182</note> which aims at increasing the uptake of language technologies
						by exploiting the combination of LD and language technologies to create ready-to-use multilingual data. In
						particular, they present a new approach called Terme-à-LLOD devoted to simplifying the task of converting a TBX
						terminological resource into a LLD one.</p>
					<p>Another example of the organisation of terminological data concerning the domain of raw material and mining was
						presented by Kitanovic et al (<ref target="#kitanovic_etal2021">2021</ref>). The authors introduce the
						development of a termbase for the field of mining engineering, the transformation from a custom scheme into the
						TBX, and then a further analysis aiming at compatibility with the LD approach.</p>
					<p>In Chozas and Declerck (<ref target="#chozas_etal2022">2022</ref>), the authors explore the use of the
						OntoLex-Lemon model and suggest some extensions, for achieving a declarative encoding of relations between
						multilingual expressions contained in terminologies. In particular, the authors link their proposal to the
						previous LIDER project<note> https://www.multilingualweb.eu/projects/lider</note> that was already concerned with
						mapping TBX to RDF, with the goal of transforming and publishing terminologies as LD.</p>
					<p>All the previous works have set an important base for the development of future tools. Nevertheless, there are
						at least two issues that were overlooked: first, the lack of a theoretical analysis about the implications of
						such a transformation – can we really use a lexicographic model for representing a terminological resource and
						vice versa? – second, the fact that none of the most recent works have implemented the tools on the latest TBX
						standard (ISO 30042: 2019).</p>
					<p>In the following Section, we present the papers that have raised these questions together with alternative
						approaches to the mapping of TBX files into other formats.</p>
				</div>
				<div>
					<head>2.2 Open Issues and Other Approaches</head>
					<p>Reineke and Romary (<ref target="#reineke_etal2019">2019</ref>) were among the pioneers in questioning the
						theoretical soundness of converting a terminological resource from TBX to RDF. In their article, the authors
						discuss the limitations of the outcomes generated by TBX2RDF due essentially to the fact that a semasiological
						(word-to-sense) model such as OntoLex cannot be naturally mapped onto the concept-to-term model of TBX.
						Consequently, they present a comparison between SKOS and TBX, which, conversely, in their view, prove to be more
						interoperable given their shared foundation in a concept-oriented perspective. As discussed in detail by Bellandi
						et al (2023b), the choice of whether and how to represent senses from a data model that does not inherently
						incorporate senses is indeed one of the most important issues in these data serialisation procedures. We will
						return to this point in section 3.1 to illustrate different approaches to addressing this challenge.</p>
					<p>A multilevel contrastive analysis between TBX and OntoLex-Lemon was presented by Bellandi et al (<ref
							target="#bellandi_etal2023a">2023a</ref>); Piccini et al (<ref target="#piccini_etal2023">2023</ref>), taking
						into account the technological, theoretical, methodological dimensions, as well as the user perspective and
						application of the two data models. The authors provide a detailed discussion about the issues of the already
						available tools for this type of conversion, and the need for a deeper understanding of both models and the
						ability to reconcile the differences in their structures and semantics during the conversion process.</p>
					<p>Some other researchers provide a different perspective on the possibility of employing alternative
						serialisations and representations. For example, Suchowolec et al (<ref target="#suchowolec_etal2019">2019</ref>)
						discuss the limitations of TBX in terms of the three levels (concept, language, and term) and the use of SKOS as
						a potential format to describe the amount of available relation types. A different point of view is given by Di
						Nunzio and Vezzani (<ref target="#dinunzio_etal2021">2021</ref>) who put forward the hypothesis that, if
						terminological data are appropriately modelled at an abstract level, they can be exported or exposed in any
						format, while preserving both the linguistic dimension and its relationship to the conceptual dimension.</p>
				</div>
			</div>
			<div>
				<head>3. Analysis of Requirements </head>
				<p>Before delving into the core content of the paper, we define the main requirements underpinning the design and the
					implementation of the converter here proposed.</p>
				<div>
					<head>3.1 Theoretical Flexibility</head>
					<p>The terminology community encompasses a range of heterogeneous theoretical and methodological
							perspectives.<note> For a complete and recent overview of the different theoretical perspectives on terminology
							science, see Faber and L’Homme (<ref target="#faber_etal2022">2022</ref>).</note> In a nutshell, three main
						theoretical approaches can be distinguished: </p>
					<list rend="numbered">
						<item>The concept has priority over the term that is a linguistic designation with the function of naming the
							concepts. This would be the view of classical terminology that would relegate the contextual interpretation of
							the sense of the term to a secondary role. </item>
						<item>The concept designated by the term is flattened on the sense of the term itself, and no difference is made
							between the linguistic and conceptual dimensions of the terminological analysis.<note> As underlined by
								Rastier: “le concept est le signifié d’un mot dont on décide de négliger la dimension linguistique" <ptr
									target="#rastier1995" loc="55"/>.</note>
						</item>
						<item>The concept and the sense are two distinct entities that both need to be taken into consideration, in order
							not to turn terminology into specialised lexicography. Terminology, indeed, is considered as a “twofold
							science” characterised by two complementary and necessary dimensions of analysis, namely the conceptual and the
							linguistic (Costa 2013; Santos and Costa 2015). </item>
					</list>
					<p>The flexibility of the OntoLex-Lemon model makes it possible to satisfy all these three main theoretical
						approaches. Consequently, as we shall see in more detail in Section 4, the converter will make it possible
						to:</p>
					<list rend="bulleted">
						<item>bypass the Lexical Sense class and directly link the lexical entry to the concept it designates;</item>
						<item>omit the conceptual dimension and limit itself to the description of the sense via the Lexical Sense
							class;</item>
						<item>describe both dimensions. As far as the conceptual dimension is concerned, the converter is agnostic with
							respect to the specific ontology language used for representing concepts. It is up to the terminologist to
							decide if using SKOS, OWL, or mapping the concepts to a given ontology.</item>
					</list>
				</div>
				<div>
					<head>3.2 Reusability</head>
					<p>The LD paradigm strongly advocates for the reuse of existing vocabularies. In line with this principle, the new
						converter will provide terminologists with the flexibility to choose the data categories they deem more suitable,
						thus facilitating:</p>
					<list rend="bulleted">
						<item>Interoperability: Terminologists might feel the need to align their resources with widely accepted
							standards and ontologies.</item>
						<item>Flexibility for domain-specific needs: Terminologists may find it necessary to effectively address the
							specific requirements and nuances for data categorization set by their specialised domain.</item>
						<item>Adaptability for evolving standards: Terminological needs and standards can evolve over time. Adaptability
							in this sense is ensured by the active involvement of the users in the conversion process. They can decide the
							latest standards in terminology to conform with or the new best practices emerged within the LD
							community.</item>
					</list>
				</div>
				<div xml:id="section03.3">
					<head>3.3 Knowledge Extraction</head>
					<p>When employing TBX to describe terminological data, researchers may encounter constraints dictated by their
						chosen TBX dialect.<note> The TBX format can be implemented via both public and private dialects. The public
							dialects are: 1) TBX-Core, 2) TBX-Min, and 3) TBX-Basic. For a detailed description of these dialects, see:
							https://www.tbxinfo.net/tbx-dialects/</note> Each dialect has its own unique set of data categories designed to
						describe the entries, and the richness of this set directly influences the granularity of the description of each
						entry. Despite the availability of a large shared set of categories, challenges arise when terminographers lack a
						specific data category to describe a specific information. Let us suppose that terminographers need to add
						information about the etymology of a term. In such cases, they have no choice but to use the <hi rend="italic"
							><gi>note</gi></hi> field to store this information. Notably, the strategy adopted by TBX2RDF is to use
						annotation properties, such as <hi rend="italic">rdfs:comment</hi>, <hi rend="italic">rdfs:label</hi>, and so
							on.<note> Please see <ref target="https://www.w3.org/TR/rdf-schema/#ch_properties"
								>https://www.w3.org/TR/rdf-schema/#ch_properti</ref>es for a complete list.</note> Nevertheless, our
						perspective underscores the importance of employing automatic methods to i) analyse these unstructured text
						sources, ii) identify structured semantic information embedded within the text, and subsequently iii) organise,
						and store it by means of the appropriate relations within OntoLex-Lemon. Returning to our example regarding
						etymology, OntoLex-Lemon provides the LemonEty<note> Please, see Khan (<ref target="#khan2018"
							>2018</ref>).</note> module specifically designed to accurately represent such information. This proactive
						strategy ensures that valuable semantic information, initially confined to notes, is systematically integrated
						into the structured ontology, thus fostering a more comprehensive and enriched representation of terminological
						knowledge.</p>
				</div>
				<div>
					<head>3.4 Data Enrichment</head>
					<p>This requirement involves the explication of information that is (a) implicitly conveyed by the hierarchical
						structure of TBX itself, and (b) explicitly written in unstructured content such as note fields of a concept
						entry in TBX.</p>
					<div>
						<head>3.4.1 Deductive Rules Exploitation</head>
						<p>The hierarchical structure of TBX implies relationships that can be lost in the conversion from TBX to
							OntoLex-Lemon, if not properly managed. These relationships mainly include synonymy and equivalence. In the
							first case, terms described within the same LS belonging to the same concept entry are assumed to be synonymous
							without the necessity of adding an explicit synonymy relationship among them. Likely, in TBX, terms in
							different LSs, grouped within the same concept entry, are equivalents. By employing deductive rules, our
							converter LemonizeTBX enables the terminographer to explicitly define these relations in the new resource,
							suggesting the appropriate links (e.g. <hi rend="italic">lexinfo:synonym</hi> for synonymy and <hi
								rend="italic">vartrans:translatableAs</hi> or <hi rend="italic">lexinfo:translation</hi> for linguistic
							equivalence among terms).</p>
					</div>
					<div>
						<head>3.4.2 TBX Data Enrichment</head>
						<p>If the extraction of knowledge from unstructured notes proves successful (<ref target="#section03.3">see
								Section 3.3</ref>), an additional step may involve enhancing the original TBX by incorporating the newfound
							information, in a sort of hermeneutic circle. This process goes beyond a naive addition of data, as it aims to
							complement the relationships stored within the TBX file, whether implicit or explicit. </p>
						<p>While this proposition stands as a theoretically sound alternative, practical implementation considerations
							arise when modifying the TBX structure within the framework of the latest ISO standard. The pipeline of this
							process becomes easier by leveraging pre-established data categories available in DatCatInfo.<note>
								https://datcatinfo.termweb.eu/</note> This resource is a data category repository collecting data categories
							specifically developed for terminology work. The strategic use of these existing categories facilitates
							seamless integration and compliance to standard specifications. Conversely, should there be a need to introduce
							a novel data category, a more elaborate solution is required to document and comply with the requirements of
							the ISO standards. This expanded documentation process ensures that any additions align seamlessly with the
							established standards, maintaining the integrity and compatibility of the enriched TBX structure.</p>
					</div>
				</div>
			</div>
			<div>
				<head>4. LemonizeTBX: Towards a TBX to OntoLex-Lemon Converter Requirements </head>
				<p>In this Section, we present the design and the current development of LemonizeTBX, the prototype for converting
					resources from TBX into OntoLex-Lemon. Following the considerations mentioned above, we started to develop an
					interactive and highly customizable converter designed to accommodate the theoretical framework of the user
					conducting the conversion, be they terminologists, translators, or lexicographers. Given the dynamic nature of the
					converter, it also became crucial to develop a user interface that enables the coordination and monitoring of the
					conversion process. From a technological standpoint, we designed a software architecture based on the
					back-ends-for-front-ends pattern: a server-side component implementing the logic of conversion processes, and a
					client-side application representing the interface through which a user interacts and manages these processes.</p>
				<p>In the following, Section 4.1 is devoted to providing the implementation details of the server component (referred
					to as back-end from here on), while Section 4.2 describes the user interface through an example of conversion.
					Finally, Section 4.3 illustrates the current limitations of our prototype, and provides some general
					considerations.</p>
				<figure xml:id="figure03">
					<head>The architecture of LemonizeTBX converter: (a) the front-end discussed in Section 4.2. (b) the back-end
						discussed in Section 4.1.</head>
					<graphic url="resources/images/figure03.png"/>
				</figure>
				<div>
					<head>4.1 The Back-end Architecture</head>
					<p>The architecture, namely an Online Compiler, translates a TBX source into RDF triples according to the
						OntoLex-Lemon model, going interactively through three main phases: 1) analysis, 2) filtering, and 3) assemblage,
						as depicted in Figure 2. Through a Web client (described in the next section), a user can upload a TBX resource
						that is ingested by the Online Compiler that starts the process:</p>
					<list rend="bulleted">
						<item>In the first phase, analysis, the Online Compiler routes the TBX file to the TBX parser component, which is
							in charge of analysing the XML input – potentially written in different TBX dialects (min, basic, core) – and
							processing the resource in order to get an intermediate representation (IR) of the information contained. IR is
							designed to fulfil two objectives: i) perform a partial conversion of entities (lexicons, concepts, terms, and
							senses) into their RDF-equivalent series of triples; ii) convey the resource's metadata information (such as
							the number of languages and terms) in JSON format. This format facilitates user interaction during the
							filtering and assemblage phases. Please note that the conversion at this stage is not considered final, as the
							ultimate coalescing phase will necessitate additional input from the user. During this phase, the resource is
							converted without making any assumptions about the final output.</item>
						<item>The second phase, filtering, enables the user to query and inspect the resource, allowing them to define a
							personalised filter for selecting and potentially enriching the data. All interactions with the client are
							conducted by the Metadata Merger, which queries the database and returns a JSON response to the web
							client.</item>
						<item>Subsequently, the assemblage phase, starting from the filtered data, constructs the OntoLex-Lemon lexica.
							This process involves processing languages, concepts, and terms, and serialising them as RDF triples in
							accordance with the OntoLex-Lemon data model. </item>
					</list>
					<figure xml:id="figure04">
						<head>The hierarchical structure of a TBX entry (tag <gi>conceptEntry</gi>). It has a set of language sections
							(tag <gi>langSec</gi>), and for each of them, a set of terms that designate the concept for that language (tag
							<gi>termSec</gi>). The example is about the concept of a “neighborhood electric vehicle” (c1), that is designed
							by the English terms “neighborhood electric vehicle”, and “NEV”.</head>
						<graphic url="resources/images/figure04.png"/>
					</figure>
				</div>
				<div>
					<head>4.2 The Front-end Prototype</head>
					<p>Throughout the design and development of the converter, we endeavoured to envision the interaction between the
						user and the converter, guided by the requirements and considerations outlined in Section 3. In this section, we
						will illustrate the user interface using a brief example of TBX (basic). For simplicity, our focus will be on the
						concept of “neighborhood electric vehicle.” <ref target="#figure03">Figure 4</ref> displays the XML code related to the English language
						section of this concept. Specifically, the fragment presents a concept identified as “c1” within the e-mobility
						field, along with an English language section containing the definition for that concept. Within the English
						language section, there are two terms associated with “c1”: the preferred full form 'neighborhood car vehicle'
						and the accepted acronym “NEV.” Each term includes specific information, such as morphology, usage contexts, and
						external references. Subsequently, we will explore incrementally how each part of the TBX input is converted into
						RDF triples according to the OntoLex-Lemon model.</p>
					<figure xml:id="figure05">
						<head>Representation of a quantitative summary of the imported TBX resource.</head>
						<graphic url="resources/images/figure05.png"/>
					</figure>
					<p>The interface divides the conversion process into five key phases:</p>
					<list rend="bulleted">
						<item>Data ingestion: makes it possible to upload the TBX file to be converted, and verifies that it is written
							in one of the three TBX dialects (basic, min, core); validate it according to the three dialects (basic, min,
							core);</item>
						<item>Data filtering: allows users to specify the data they wish to convert;</item>
						<item>Concept mapping: permits users to define how filtered concepts should be converted;</item>
						<item>Term mapping: lets users specify the conversion approach for terms associated with filtered
							concepts;</item>
						<item>Data conversion: displays the converted data by querying the triple store containing the conversion.</item>
					</list>
					<p><ref target="#figure05">Figure 5</ref> illustrates the initial phase of the conversion process. Users can upload a TBX file, and the system
						parses the data, constructing an internal intermediate representation (IR) as outlined in Section 4.1. It is
						important to note that the input TBX file is assumed to be valid and well-formed; otherwise, the system will
						generate an error, a topic we will delve into further in the subsequent section. The system provides the user
						with a summary of the ingested data, presenting information such as file size, the public TBX dialect used, the
						count of concepts, and the number of terms per concept and language. This summary proves valuable for obtaining a
						quantitative overview of the file slated for conversion.</p>
					<figure xml:id="figure06">
						<head>TBX data filtering interface.</head>
						<graphic url="resources/images/figure06.png"/>
					</figure>
					<p>At this point, the user has the option to either proceed with an automatic file conversion using a default
						mapping or interactively determine the conversion of terminological entities on a case-by-case basis, as
						illustrated in <ref target="#figure06">Figure 6</ref>. The system presents TBX data in a table featuring a column for concepts and additional
						columns for each language in the TBX file. Each column includes all the terms designating the respective
						concepts, along with their parts of speech. Rows in the table, such as the one for concept c1 in Figure 6, can be
						expanded to reveal the definition of the concept in natural language across different languages. This capability
						stems from the TBX example used, where concept definitions are provided at the language level (see the <hi
							rend="italic"><gi>descripGrp/</gi></hi> tag in Figure 4). In instances where the definition is specified at the
						concept level, the system directly presents it in the concept column. The table results can be filtered based on
						two parameters, which can also be used in combination: concepts created on specific dates (concept date filter)
						and concepts associated with particular topics (subject field filter). Additionally, users can opt to convert
						terms only in certain languages using the language filter. Subsequently, users can select the concepts they wish
						to convert by checking the checkbox in the corresponding column.</p>
					<figure xml:id="figure07">
						<head>TBX concepts mapping interface.</head>
						<graphic url="resources/images/figure07.png"/>
					</figure>
					<p>After selecting the concepts, users can determine how to convert them, as depicted in Figure 7. It is also an
						option to convert only the language part, i.e., the terms designating the selected concepts. There are four
						conversion possibilities:</p>
					<list rend="numbered">
						<item>
							<hi rend="italic">URL</hi>: the concepts are not created as ontological entities, but they are defined by URLs
							specified by the user;</item>
						<item>
							<hi rend="italic">Lexical Concept</hi>: the system maps concepts to the class 'Lexical Concept,' representing a
							mental abstraction, concept, or unit of thought lexicalized by a collection of terms;</item>
						<item>
							<hi rend="italic">SKOS Concept</hi> (default choice for automatic conversion): concepts are converted into SKOS
							classes. A detailed example will be presented below;</item>
						<item>
							<hi rend="italic">OWL Concept</hi>: the system generates as many OWL classes as selected concepts.</item>
					</list>
					<p>Additionally, users can specify whether, in relation to a concept “C” already defined in another ontology, that
						class represents it exactly (<hi rend="italic">owl:sameAs</hi>) or is related in some way (<hi rend="italic"
							>rdfs:seeAlso</hi>). Concerning the SKOS choice, the concepts (<hi rend="italic"><gi>conceptEntry</gi></hi>},
						are converted by means of the SKOS ontology, according to Reineke and Romary (<ref target="#reineke_etal2019">2019</ref>).
						Subject fields correspond to SKOS concept schemes, while concepts are mapped to SKOS concepts. The membership of
						concepts to their subject fields is formalised through the SKOS \textit{inScheme} relationship. The SKOS <hi
							rend="italic">definition</hi> property of a concept represents the definition of that concept provided by the
						TBX resource, whether the definition is given at the concept level or at the language level. </p>
					<p>In the following, an example of RDF Turtle serialisation produced by the tool is provided:</p>
					<p>:c1 a skos:Concept ;</p>
					<p> skos:prefLabel “c1”@en ;</p>
					<p> skos:inScheme :sbjf_1 ;</p>
					<p> skos:definition “A battery-electric car that is capable of traveling at </p>
					<p> a maximum speed of 25 miles per hour (mph) and has a maximum loaded </p>
					<p> weight of 3,000 lbs.”@en ;</p>
					<p> skos:definition “éhicule à deux places, activé par un moteur électrique </p>
					<p> à courant continue alimenté par des batteries au plomb rechargeables à </p>
					<p> partir d'une prise de courant résidentielle de 110 volts.”@fr . </p>
					<p>:sbjf_1 a skos:ConceptScheme ;</p>
					<p> skos:prefLabel “e-mobility”@en .</p>
					<p>Concerning the <hi rend="italic"><gi>langSec</gi></hi> entity, the related OntoLex-Lemon lexica are created.
						Referring to the example in Figure 4, English, French, and Italian lexica are defined, and the terms are created
						as entries of the suitable lexicon. The Turtle serialisation produced by the tool is provided:</p>
					<p>:enLex a lime:Lexicon ;</p>
					<p> lime:language “en” ;</p>
					<p> lime:entry :t1, :t2 .</p>
					<p>:frLex a lime:Lexicon ;</p>
					<p> lime:language “fr” ;</p>
					<p> lime:entry :t3 .</p>
					<p>:itLex a lime:Lexicon ;</p>
					<p> lime:language “it” ;</p>
					<p> lime:entry :t4, :t5 .</p>
					<figure xml:id="figure08">
						<head>TBX terms mapping interface.</head>
						<graphic url="resources/images/figure08.png"/>
					</figure>
					<p>Finally, users have to determine how to convert the terms. The interface depicted in Figure 8 makes it possible
						to establish: </p>
					<list rend="numbered">
						<item>whether lexical senses of the terms should be created; </item>
						<item>what semantic relations among terms need to be represented;</item>
						<item>how to handle terms with the same character sequence but different meanings.</item>
					</list>
					<p>For point one, the terms within the <hi rend="italic"><gi>termSec</gi></hi> entity are represented as lexical
						entries in the OntoLex-Lemon model. Each term is mapped to the Lexical Entry class, without specifying its
						particular type (word or multi-word), and it is represented as a canonical form, typically a lemma, of that
						lexical entry. Following the “<hi rend="italic">semantics by reference</hi>” paradigm of OntoLex-Lemon, the
						meaning of a lexical entry is specified by referring to the created SKOS concept that represents its meaning. </p>
					<p>The default conversion process generates a lexical sense for each lexical entry and links it to the suitable
						concept by means of the <hi rend="italic">ontolex:reference</hi> property. In the event the user opts not to
						represent the lexical sense of lexical entries (<ref target="#figure08">option shown in Figure 8</ref>), the
						converter links the term directly to the concept by means of the <hi rend="italic">denote</hi> property. Given
						that the model lacks a comprehensive set of linguistic categories, it relies on Lexinfo vocabulary.<note> LexInfo
							is an ontology that provides data categories for the \textit{lemon} model. Please, see
							https://lexinfo.net/</note> Consequently, morphological information, such as part of speech, and other
						morphological traits is associated with the forms, while usage context, term type, and administrative status are
						associated with the senses, according to the Lexinfo schema. If the definition in the <hi rend="italic"
							><gi>langSec</gi></hi> has a source or/and an external reference, the reification mechanism<note> The
							reification is a mechanism allowing us to write RDF triples about RDF triples. In our case, we could specify
							both the source and the link of concept definitions.</note> would be employed in order to represent the source
						and the reference of the concept definition, using Dublin core <hi rend="italic">source</hi>, and RDF <hi
							rend="italic">seeAlso</hi> properties, respectively. Similarly, this mechanism can be applied to represent
						examples of term usage with the <hi rend="italic">usage</hi> property. Below is an example of the conversion
						related to the term “neighborhood electric vehicle”:</p>
					<p>:t1 rdf:type ontolex:LexicalEntry ; </p>
					<p> lexinfo:partOfSpeech lexinfo:noun ; </p>
					<p> lexinfo:normativeAuthorization lexinfo:preferredTerm ; </p>
					<p> lexinfo:termType lexinfo:fullForm ; </p>
					<p> ontolex:canonicalForm :t1_cf ;</p>
					<p> ontolex:sense :t1_sense .</p>
					<p>:t1_cf rdf:type ontolex:Form ; </p>
					<p> ontolex:writtenRep "neighborhood electric vehicle"@en .</p>
					<p>:t1_sense rdf:type ontolex:LexicalSense ; </p>
					<p> skos:definition [ </p>
					<p> rdf:value "A battery-electric ..." ;</p>
					<p> dct:source "TechTarget" ;</p>
					<p> rdfs:seeAlso &lt;https://www.techtarget.com/whatis/definition/neighborhood-</p>
					<p> -electric-vehicle-NEV&gt; ] ;</p>
					<p> ontolex:usage [ </p>
					<p> rdf:value "A Neighborhood Electric Vehicle is a U.S. category for ..." ;</p>
					<p> dct:source "Wikipedia" ;</p>
					<p> rdfs:seeAlso &lt;https://en.wikipedia.org/wiki/Neighborhood_Electric</p>
					<p> _Vehicle&gt; ] .</p>
					<p>Concerning point two, the semantic relations among terms, synonymy and translation can be identified and
						represented in OntoLex-Lemon. In particular, if the appropriate checkboxes in Figure 8 are selected, the system
						retrieves all the terms in different languages belonging to the same <hi rend="italic"><gi>conceptEntry</gi></hi>
						element and creates suitable translation relations among them<note> For example, referring to Figure 7, all the
							terms referring to concept c1 are in a translation relationship with each other.</note>. Similarly, the system
						retrieves the terms of each language that share the same meaning (i.e., design the same concept) and converts
						them as synonyms. It is important to note that this is only feasible if the user opts to create lexical senses,
						as the Lexinfo synonymy relationship links senses together. The default behaviour in the case of automatic
						conversion is to refrain from representing any semantic relation.</p>
					<p>Finally, as for terms with the same character sequence but different meanings (see point three), all terms
						designating more than one concept are listed in a table. The user can choose which terms to represent as
						polysemic entries (multiple lexical senses are created for each term), and which terms to represent as homonyms
						(multiple distinct lexical entries are created). The default behaviour in the case of automatic conversion is the
						latter.</p>
				</div>
				<div>
					<head>4.3 Considerations</head>
					<p>The development of the converter is still in its early stages, and currently, only the default behaviour,
						outlined in the preceding sections, has been implemented. In this Section, we briefly address the limitations of
						the current implementation and how they manifest in the converted data. </p>
					<p>The converter presupposes that the TBX file slated for conversion is both syntactically and semantically valid.
						This implies that the file must be well-formed and the textual values within the XML tags should align
						semantically with the intended representation of the tags. Specifically, it assumes accurate reporting of data
						category values to ensure proper mapping with the Lexinfo vocabulary. Currently, only public TBX dialects are
							handled<note> For efficiency reasons, the converter still does not handle TBX files that are too large, such as
							IATE exports.</note>, and incorporating a private dialect would necessitate adjustments to the converter code,
						particularly in updating the parser and IR generator depicted in Figure 3. Introducing specific data categories
						might also require modifications to the user interface code. A pivotal aspect of the conversion process is the
						decision on whether or not to represent lexical sense. As emphasised in Section 3, the importance of sense may
						vary, and it could either not play a central role or be flattened onto the concept. However, in the OntoLex-Lemon
						model, the sense is deemed central, with semantic relations formally defined as links between lexical
							senses.<note> In the terminology model described in ISO 30042:2019, the entity <hi rend="italic">lexical
								sense</hi> is not defined.</note> Choosing not to represent lexical sense limits the converter's ability to
						explicitly define semantic relations, as illustrated by the interface in Figure 8.</p>
					<p>An alternative approach could involve mapping semantic relations (such as, for example, hypernymy, meronymy,
						etc.) with relations between the concepts (such as isA, partOf, etc.) designated by the terms to which the
						appropriate senses would correspond. This aligns with perspectives that do not distinguish between sense and
						concept, but deviates from the theoretical viewpoint where senses and concepts are considered distinct entities,
						albeit intimately related. </p>
				</div>
			</div>
			<div>
				<head>5. Conclusions </head>
				<p>The paper introduces LemonizeTBX, a prototype software to enhance interoperability between the ISO TBX standard,
					used for representing terminological resources and the OntoLex-Lemon model, adopted to represent lexicographic
					resources. The converter aims to bridge the gap between terminological and lexicographical frameworks, emphasising
					a shift from a concept-oriented to a sense-centred standpoint. This change in perspective underscores the need for
					an interactive tool to engage terminologists in the conversion process. The interactivity concerns choices that
					users need to make when there is no direct mapping from TBX to OntoLex-Lemon. For instance, deciding whether and
					how to link lexical entries directly to concepts or how to add missing data categories. The converter is designed
					to support an advanced process to enrich the data by extracting implicit and explicit information from unstructured
					content in TBX entries.</p>
				<p>The implementation of LemonizeTBX is currently in its early stages, featuring some default behaviour. For
					instance, it assumes syntactic and semantic validity in the input TBX files, it primarily focuses on representing
					lexical senses, leaving room for potential alternative approaches, such as mapping semantic relations to concept
					relations.</p>
				<p>However, as discussed in the preceding Section 4.3, the work conducted thus far has revealed that the challenges
					posed by the conversion process are fundamentally theoretical, raising questions that deserve discussion within the
					community. This discussion is crucial to provide a solid foundation for the development of a customised
					OntoLex-Lemon module for terminology science tailored to the specificities of this discipline.<note> At the time of
						writing this article, the W3C OntoLex group is discussing the possibility of introducing such a module
						https://www.w3.org/community/ontolex/wiki/Terminology\#Use_Cases</note>
				</p>
			</div>
		</body>
		<back>
			<listBibl>
				<bibl xml:id="bellandi_etal2023a" label="Bellandi et al 2023a">Bellandi, Andrea, Di Nunzio, Giorgio Maria, Piccini,
					Silvia, and Vezzani, Federica. (2023a) <title rend="quotes">From TBX to Ontolex Lemon: Issues and
						Desiderata</title> in <title rend="italic">Proceedings of the 2nd International Conference on Multilingual
						Digital Terminology Today</title> (MDTT 2023), Volume 3427 of <title rend="italic">CEUR Workshop
						Proceedings</title>, Lisbon, Portugal. CEUR. ISSN: 1613-0073. Available at: <ref
						target="https://ceur-ws.org/Vol-3427/paper4.pdf">https://ceur-ws.org/Vol-3427/paper4.pdf</ref> (Accessed: 09
					April 2024).</bibl>
				<bibl xml:id="bellandi_etal2023b" label="Bellandi et al 2023b">Bellandi, Andrea, Di Nunzio, Giorgio Maria, Piccini,
					Silvia, and Vezzani, Federica. (2023b) <title rend="quotes">The Importance of Being Interoperable: Theoretical and
						Practical Implications in Converting TBX to OntoLex-Lemon</title> in <title rend="italic">Proceedings of the 4th
						Conference on Language, Data and Knowledge</title>, pages 646–651, Vienna, Austria. NOVA CLUNL, Portugal.
					Available at: <ref target="https://aclanthology.org/2023.ldk-1.70">https://aclanthology.org/2023.ldk-1.70</ref>
					(Accessed: 09 April 2024).</bibl>
				<bibl xml:id="bosquegil_etal2015" label="Bosque-Gil et al 2015">Bosque-Gil, Julia, Gracia, Jorge, Aguado-de Cea,
					Guadalupe, and Montiel-Ponsoda, Elena. (2015) <title rend="quotes">Applying the OntoLex Model to a Multilingual
						Terminological Resource</title> in <title rend="italic">The Semantic Web: ESWC 2015 Satellite Events, Lecture
						Notes in Computer Science</title>, Cham, pp. 283–294. Springer International Publishing. Available at: <ref
						target="https://doi.org/10.1007/978-3-319-25639-9_43">https://doi.org/10.1007/978-3-319-25639-9_43</ref>
					(Accessed: 09 April 2024).</bibl>
				<bibl xml:id="buitelaar2010" label="Buitelaar 2010">Buitelaar, Paul. (2010) <title rend="quotes">Ontology-based
						semantic lexicons: mapping between terms and object descriptions</title> In A. Gangemi, A. Lenci, A. Oltramari,
					C.-r. Huang, L. Prevot, and N. Calzolari (Eds.) <title rend="italic">Ontology and the Lexicon: A Natural Language
						Processing Perspective, Studies in Natural Language Processing</title>, pp. 212–223. Cambridge: Cambridge
					University Press. Available at: <ref target="https://doi.org/10.1017/CBO9780511676536.013"
						>https://doi.org/10.1017/CBO9780511676536.013</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="buitelaar_etal2006" label="Buitelaar et al 2006">Buitelaar, Paul, Declerck, Thierry, Anette Frank,
					Racioppa, Stefania, Kiesel, Malte, Sintek, Michael, Engel, Ralf, Romanelli, Massimo, Sonntag, Daniel, Loos,
					Berenike, Micelli, Vanessa, Porzel, Robert, and Cimiano, Philipp. (2006) <title rend="quotes">LingInfo: Design and
						Applications of a Model for the Integration of Linguistic Information in Ontologies</title> in <title
						rend="italic">Proceedings of the OntoLex Workshop at LREC 2006</title>. Available at: <ref
						target="https://www.aifb.kit.edu/images/9/9f/2006_1233_Buitelaar_LingInfo_Desig_1.pdf"
						>https://www.aifb.kit.edu/images/9/9f/2006_1233_Buitelaar_LingInfo_Desig_1.pdf</ref> (Accessed: 09 April
					2024).</bibl>
				<bibl xml:id="chozas_etal2022" label="Chozas and Declerck 2022">Chozas, Patricia Martin and Declerck, Thierry. (2022)
						<title rend="quotes">Representing Multilingual Terminologies with OntoLex-Lemon (short paper)</title> in <title
						rend="italic">Proceedings of the 1st International Conference on Multilingual Digital Terminology Today</title>
					(MDTT 2022), Volume 3161 of <title rend="italic">CEUR Workshop Proceedings</title>, Padua, Italy. CEUR. ISSN:
					1613-0073. Available at: <ref target="https://ceur-ws.org/Vol-3161/short1.pdf"
						>https://ceur-ws.org/Vol-3161/short1.pdf</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="cimiano_etal2020a" label="Cimiano et al 2020a">Cimiano, Philipp, Chiarcos, Christian, McCrae, John P.,
					and Gracia Jorge. (2020a) <title rend="quotes">Converting Language Resources into Linked Data</title> in <title
						rend="italic">Linguistic Linked Data</title>, pp. 163–180. Cham: Springer International Publishing. Available at:
						<ref target="https://doi.org/10.1007/978-3-030-30225-2_9">https://doi.org/10.1007/978-3-030-30225-2_9</ref>
					(Accessed: 09 April 2024).</bibl>
				<bibl xml:id="cimiano_etal2020b" label="Cimiano et al 2020b">Cimiano, Philipp, Chiarcos, Christian, McCrae, John P.,
					and Gracia, Jorge. (2020b) <title rend="italic">Linguistic Linked Data: Representation, Generation and
						Applications</title>. Cham: Springer International Publishing. Available at: <ref
						target="https://doi.org/10.1007/978-3-030-30225-2">https://doi.org/10.1007/978-3-030-30225-2</ref> (Accessed: 09
					April 2024).</bibl>
				<bibl xml:id="cimiano_etal2007" label="Cimiano et al 2007">Cimiano, Philipp, Haase, Peter, Herold, Matthias, Mantel,
					Matthias, and Buitelaar, Paul. (2007) <title rend="quotes">Lexonto: A model for ontology lexicons for
						ontology-based nlp</title> in <title rend="italic">Proceedings of the OntoLex07 Workshop held in conjunction with
						ISWC’07</title>. Available at: <ref target="https://www.aifb.kit.edu/web/Inproceedings1584"
						>https://www.aifb.kit.edu/web/Inproceedings1584</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="cimiano_etal2015" label="Cimiano et al 2015">Cimiano, Philipp, McCrae, John P., Rodríguez-Doncel,
					Víctor, Gornostay, Tatiana, Gómez-Pérez, Asunción, Siemoneit, Benjamin and Lagzdins, Andis. (2015) <title
						rend="quotes">Linked terminologies: applying linked data principles to terminological resources</title> in <title
						rend="italic">Proceedings of the eLex 2015 Conference</title>, pp. 504–517. Available at: <ref
						target="https://elex.link/elex2015/proceedings/eLex_2015_34_Cimiano+etal.pdf"
						>https://elex.link/elex2015/proceedings/eLex_2015_34_Cimiano+etal.pdf</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="costa2013" label="Costa 2013">Costa, Rute. (2013) <title rend="quotes">Terminology and Specialised
						Lexicography: two complementary domains</title>. <title rend="italic">Lexicographica</title> 29 (2013), pp.
					29–42. De Gruyter. Available at: <ref target="https://doi.org/10.1515/lexi-2013-0004"
						>https://doi.org/10.1515/lexi-2013-0004</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="declerck_etal2020" label="Declerck et al 2020">Declerck, Thierry, McCrae, John Philip, Hartung,
					Matthias, Gracia, Jorge, Chiarcos, Christian, Montiel-Ponsoda, Elena, Cimiano, Philipp, Revenko, Artem, Saurí,
					Roser, Lee, Deirdre, Racioppa, Stefania, Abdul Nasir, Jamal, Orlikowsk, Matthias, Lanau-Coronas, Marta, Fäth,
					Christian, Rico, Mariano, Fazleh Elahi, Mohammad, Khvalchik, Maria, Gonzalez, Meritxell, and Cooney, Katharine.
					(2020) <title rend="quotes">Recent developments for the linguistic linked open data infrastructure</title> in
						<title rend="italic">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>, pp.
					5660–5667, Marseille, France. European Language Resources Association. Available at: <ref
						target="https://aclanthology.org/2020.lrec-1.695.pdf">https://aclanthology.org/2020.lrec-1.695.pdf</ref>
					(Accessed: 09 April 2024).</bibl>
				<bibl xml:id="dibuono_etal2020" label="di Buono et all 2020" sortKey="Dibuono">di Buono, Maria Pia, Cimiano, Philipp,
					Fazleh Elahi, Mohammad, and Grimm, Frank. (2020) <title rend="quotes">Terme-à-LLOD: Simplifying theConversion and
						Hosting of Terminological Resources as Linked Data</title> in <title rend="italic">Proceedings of the 7th
						Workshop on Linked Data in Linguistics</title> (LDL-2020), Marseille, France, pp.28–35. European Language
					Resources Association. Available at: <ref target="https://aclanthology.org/2020.ldl-1.5.pdf"
						>https://aclanthology.org/2020.ldl-1.5.pdf</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="dinunzio_etal2021" label="Di Nunzio and Vezzani 2021" sortKey="Dinunzio">Di Nunzio, Giorgio Maria and
					Vezzani, Federica. (2021) <title rend="quotes">One Size Fits All: A Conceptual Data Model for Any Approach to
						Terminology</title>. <title rend="italic">arXiv</title>:2112.06562 [cs]. Available at: <ref
						target="https://arxiv.org/pdf/2112.06562.pdf">https://arxiv.org/pdf/2112.06562.pdf</ref> (Accessed: 09 April
					2024).</bibl>
				<bibl xml:id="faber_etal2022" label="Faber and L’Homme 2022">Faber, Pamela and L’Homme, Marie-Claude. (2022) <title
						rend="italic">Theoretical Perspectives on Terminology</title>. John Benjamins Publishing Company.</bibl>
				<bibl xml:id="frey_etal2021" label="Frey and Hellmann 2021">Frey, Johannes and Hellmann, Sebastian. (2021) <title
						rend="quotes">FAIR Linked Data - Towards a Linked Data Backbone for Users and Machines</title> in <title
						rend="italic">Companion Proceedings of the Web Conference 2021</title>. New York, NY, USA, pp. 431–435.
					Association for Computing Machinery. Available at: <ref target="https://doi.org/10.1145/3442442.3451364"
						>https://doi.org/10.1145/3442442.3451364</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="kitanovic_etal2021" label="Kitanović et al 2021">Kitanović, Olivera, Stanković, Ranka, Tomašević,
					Aleksandra, Škorić, Mihailo, Babić, Ivan, and Kolonja, Ljiljana. (2021) <title rend="quotes">A Data Driven Approach
						for Raw Material Terminology</title>, <title rend="italic">Applied Sciences</title>, 11 (7), 2892. Available at:
						<ref target="https://www.mdpi.com/2076-3417/11/7/2892">https://www.mdpi.com/2076-3417/11/7/2892</ref> (Accessed:
					09 April 2024).</bibl>
				<bibl xml:id="montielponsoda_etal2011" label="Montiel-Ponsoda et al 2011">Montiel-Ponsoda, Elena, Aguado De Cea,
					Guadalupe Gómez-Pérez, Asunción, and Peters, Wim. (2011) <title rend="quotes">Enriching ontologies with
						multilingual information</title>, <title rend="italic">Natural language engineering</title>, 17(3), pp. 283–309.
					Available at: <ref target="https://doi.org/10.1017/S1351324910000082"
						>https://doi.org/10.1017/S1351324910000082</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="piccini_etal2023" label="Piccini, Vezzani, and Bellandi 2023">Piccini, Silvia, Vezzani, Federica, and
					Bellandi, Andrea. (2023) <title rend="quotes">TBX and <q>Lemon</q>: What perspectives in terminology?</title>
					<title rend="italic">Digital Scholarship in the Humanities</title>, 38 (Supplement_1), pp. i61–i72. Available at:
						<ref target="https://doi.org/10.1093/llc/fqad025">https://doi.org/10.1093/llc/fqad025</ref> (Accessed: 09 April
					2024).</bibl>
				<bibl xml:id="rastier1995" label="Rastier 1995">Rastier, Francois. (1995) <title rend="quotes">Le terme : entre
						ontologie et linguistique</title>. <title rend="italic">La banque de mots</title> 7, pp. 35–65.</bibl>
				<bibl xml:id="reineke_etal2019" label="Reineke and Romary 2019">Reineke, Detlef and Romary, Laurent. (2019) <title
						rend="quotes">Bridging the gap between SKOS and TBX</title>. <title rend="italic">Die Fachzeitschrift für
						Terminologie</title> 19(2). Available at: <ref target="https://inria.hal.science/hal-02398820"
						>https://inria.hal.science/hal-02398820</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="rodriguezdoncel_etal2018" label="Rodriguez-Doncel et al 2018">Rodriguez-Doncel, Víctor, Santos,
					Cristiana, Casanovas, Pompeu, Gómez-Pérez, Asunción, and Gracia, Jorge. (2018) <title rend="quotes">A Linked Data
						Terminology for Copyright Based on Ontolex-Lemon</title>. in <title rend="italic">AI Approaches to the Complexity
						of Legal Systems, Lecture Notes in Computer Science</title>, Cham, pp. 410–423. Springer International
					Publishing. Available at: <ref target="https://doi.org/10.1007/978-3-030-00178-0_28"
						>https://doi.org/10.1007/978-3-030-00178-0_28</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="santos_etal2015" label="Santos and Costa 2015">Santos, Claudia and Costa, Rute. (2015) <title
						rend="quotes">Semasiological and onomasiological knowledge representation: Domain specificity</title>. in <title
						rend="italic">Handbook of Terminology: Volume 1, Handbook of Terminology</title>, pp. 153–179. John Benjamins
					Publishing Company. Available at: <ref target="https://doi.org/10.1075/hot.1.dom1"
						>https://doi.org/10.1075/hot.1.dom1</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="siemoneit_etal2015" label="Siemoneit, McCrae, and Cimiano 2015">Siemoneit, Benjamin, McCrae, John
					Philip, and Cimiano, Philipp. (2015) <title rend="quotes">Linking four heterogeneous language resources as linked
						data</title> in <title rend="italic">Proceedings of the 4th Workshop on Linked Data in Linguistics: Resources and
						Applications</title>, pp. 59–63, Beijing, China. Association for Computational Linguistics. Available at: <ref
						target="https://aclanthology.org/W15-4207.pdf">https://aclanthology.org/W15-4207.pdf</ref> (Accessed: 09 April
					2024).</bibl>
				<bibl xml:id="speranza_etal2020" label="Speranza et al 2020">Speranza, Giulia, Di Buono, Maria Pia, Sangati,
					Federico, and Monti, Johanna. (2020) <title rend="quotes">From linguistic resources to ontology-aware
						terminologies: Minding the representation gap</title> in <title rend="italic">Proceedings of The 12th Language
						Resources and Evaluation Conference</title>, pp. 2503–2510. European Language Resources Association. Available
					at: <ref target="https://aclanthology.org/2020.lrec-1.305.pdf">https://aclanthology.org/2020.lrec-1.305.pdf</ref>
					(Accessed: 09 April 2024).</bibl>
				<bibl xml:id="suchowolec_etal2019" label="Suchowolec Lang, and Schneider 2019">Suchowolec, Karolina, Lang, Christian,
					and Schneider, Roman. (2019) <title rend="quotes">An empirically validated, onomasiologically structured, and
						linguistically motivated online terminology: Re-designing scientific resources on German grammar</title>. <title
						rend="italic">International Journal on Digital Libraries</title>. 20(3), pp. 253–268. Available at: <ref
						target="https://doi.org/10.1007/s00799-018-0254-x">https://doi.org/10.1007/s00799-018-0254-x</ref> (Accessed: 09
					April 2024).</bibl>
				<bibl xml:id="vellutino_etal2016" label="Vellutino et al 2016">Vellutino, Daniela, Maslias, Rodolfo, Rossi,
					Francesco, Mangiacapre, Carmina, and Montoro, Maria Pia. (2016) <title rend="quotes">Verso l'interoperabilità
						semantica di IATE. Studio preliminare sul lessico dei Fondi strutturali e d’Investimento Europei (Fondi
						SIE)</title>, <title rend="italic">Diacronia XIII</title> (1), 187. Available at: <ref
						target="https://www.diacronia.ro/en/indexing/details/A23887/pdf"
						>https://www.diacronia.ro/en/indexing/details/A23887/pdf</ref> (Accessed: 09 April 2024).</bibl>
				<bibl xml:id="wilkinson_etal2016" label="Wilkinson et al 2016">Wilkinson, Mark D., Michel Dumontier, IJsbrand Jan
					Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al (2016) <title rend="quotes">The
						FAIR Guiding Principles for Scientific Data Management and Stewardship</title>. <title rend="italic">Scientific
						Data</title>, 3 (1): 160018. Available at: <ref target="https://doi.org/10.1038/sdata.2016.18"
						>https://doi.org/10.1038/sdata.2016.18</ref> (Accessed: 09 April 2024).</bibl>
			</listBibl>
		</back>
	</text>
</TEI>
