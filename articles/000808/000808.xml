<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xmlns:cc="http://web.resource.org/cc/"
     xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
     xmlns:mml="http://www.w3.org/1998/Math/MathML"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <teiHeader>
      <fileDesc>
         <titleStmt><!--Author should supply the title and personal information-->
            <title type="article" xml:lang="en"><!--article title in English--></title>
            <!--Add a <title> with appropriate @xml:lang for articles in languages other than English-->
            <dhq:authorInfo><!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>first name(s) <dhq:family>family name</dhq:family>
               </dhq:author_name>
               <idno type="ORCID"><!--if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000--></idno>
               <dhq:affiliation/>
               <email/>
               <dhq:bio>
                  <p/>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <!--This information will be completed at publication-->
            <idno type="DHQarticle-id"><!--including leading zeroes: e.g. 000110--></idno>
            <idno type="volume"><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006--></idno>
            <idno type="issue"><!--issue number, without leading zeroes: e.g. 2--></idno>
            <date><!--include @when with ISO date and also content in the form 23 February 2024--></date>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND"><!--If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default):        
                  CC-BY:    
                  CC0:  -->
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
            <taxonomy xml:id="project_keywords">
               <bibl>DHQ project registry; full list available at <ref target="http://www.digitalhumanities.org/dhq/projects.xml">http://www.digitalhumanities.org/dhq/projects.xml</ref>
               </bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
            <!--add <language> with appropriate @ident for any additional languages-->
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords"><!--Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors--><!--Enter keywords below preceeded by a "#". Create a new term element for each-->
               <term corresp=""/>
            </keywords>
            <keywords scheme="#authorial_keywords"><!--Authors may include one or more keywords of their choice-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#project_keywords">
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc><!-- Replace "NNNNNN" in the @target of ref below with the appropriate DHQarticle-id value. -->
         <change>The version history for this file can be found on <ref target="https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/main/articles/NNNNNN/NNNNNN.xml">GitHub
                   </ref>
         </change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract><!--Include a brief abstract of the article-->
            <p/>
         </dhq:abstract>
         <dhq:teaser><!--Include a brief teaser, no more than a phrase or a single sentence-->
            <p/>
         </dhq:teaser>
      </front>
      <body>
         <div>
            <div>
               <head>Contextual Semantic Text and Image Annotation in the MARKUS Environment<note>* This research is part of a project that has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (Grant agreement No. 101019509) and the NWO (Dutch Research Council) (Grant agreement No. 406.20.HW.006).</note>*</head>
               <p>Hilde De Weerdt, Brent Ho, Rainer Simon, Lee Sunkyu, Sander Molenaar, Xi Wangzhi, Dawn Zhuang, Iva Stojević, Tu Hsieh-Chang, Taylor Zaneri, Lin Nung-yao, Meret Meister</p>
               <div>
                  <head>Introduction</head>
                  <p>	Historians and humanities scholars more generally care deeply about context. Context is a vague and malleable concept but essentially constitutes the site or assemblage of sites within which the interpretation of objects or problems of interest takes place. For digital humanists who create or work with data in various forms, the contextualization of data and digital operations and facilitating contextual interpretation of data and operations ought to be critical concerns in the design of services and platforms. In what follows we discuss the rationale behind the design of COMARKUS and IMMARKUS, two browser-based annotation services for the creation and analysis of complex semantic text- and image annotations, in the form of both individual entities or tags with properties <hi rend="italic">and</hi> clusters of entities or tags also with their own set of properties. </p>
                  <p>In the introduction we briefly discuss the challenges we faced with existing text and image annotation platforms, using as our case a longue-durée social history of Chinese material infrastructures including city walls, roads, and bridges. Here we explain how methodological design and redesign constituted an urgent need issuing from both theoretical and empirical findings. In the other two sections we set out how COMARKUS (section two) and IMMARKUS (section three) were designed to address those challenges and facilitate an event- or cluster-based cross-media history of infrastructures. Throughout we also aim to illustrate the more general use of COMARKUS and IMMARKUS annotation methods beyond the specifics of the research project for which they were designed. </p>
                  <p>In each of the two central sections we first discuss the importance of modelling sources and source ecologies (De Weerdt under review, De Weerdt et al. under review, De Weerdt and Molenaar under review, Molenaar under review a) and the ways in which annotation models can be designed, shared, and modified in MARKUS services. We propose that data models be developed on the basis of specific research questions and theoretical frameworks as well as a modeling of how specific text and image genres present and narrate information. This is a critical first step in the way we conceive of contextual annotation. </p>
                  <p>Next, we give an overview of how annotations and data clusters can be created and what they can include. Third, we illustrate how complex text and image annotations and their various properties can be read and analyzed in knowledge graphs, exported as tabular data, and mapped and visualized in allied MARKUS services (X-MARKUS and MUNDa) and other data analytical programs. MARKUS services were specifically designed to preserve the specific location in text and image sources for each datapoint (annotations, properties, and any external authorities used as properties) and allow for moving between datapoints in infographic displays and the text or image sources used in annotation. This is a second critical component in contextual annotation. </p>
                  <p>Finally, we demonstrate how layered metadata can be added to text and image sources (in the case of IIIF images in IMMARKUS automatically) and how normalized annotations linked to external authorities can be used to populate metadata fields. In this way, source images and texts can also be examined together based on the place, time, authorship, or subject of the piece annotated and the higher-level sources of which they formed part. The use of metadata in the exploration and visualization of annotations and properties thus constitutes a third critical aspect of contextual annotation. In the conclusion we evaluate to what extent contextualization can be pursued in this way and return to the question of the ways in which contextualization can be further expanded and refined in digital environments.</p>
                  <div>
                     <head>The Problem</head>
                     <p>The need for a methodology that allows for the grouping of entities into a hierarchical or contextual data cluster arose in a research project on the social history of Chinese material infrastructures (De Weerdt, Stojević, and Ho 2022). We felt an urgent need to refocus Chinese infrastructural history on events for both theoretical and source-related reasons. </p>
                     <p>The infrastructural turn in humanities and social science scholarship has resulted in productive new theoretical and methodological frameworks for understanding infrastructures as spaces, networks, and interfaces within which social relations are expressed and reshaped (Addie, Glass, and Nelles 2020, Bridges 2023, Easterling 2014, Edwards et al. 2009, Graham and Marvin 2001, Hansen and Schultze 2021, Laak 2023, Larkin 2013, Rippa and Oakes 2023, Wilkinson 2018). The focus on modern infrastructures and the assumption that infrastructures define modernity, however, have led to mistaken assumptions about the pre-nineteenth century history of infrastructures and foreclosed a productive dialogue about the longue-durée social and political history of individual infrastructures and infrastructural assemblages (De Weerdt forthcoming). Our aims as medieval and early modern historians were quite similar to those of anthropologists, sociologists, and modern historians. We aimed to interpret the history not so much of infrastructural objects themselves, but of their planning, construction, destruction, uses, repair, and failure to materialize at different scales and across time. </p>
                     <p>Sources to write a cross-regional comparative history of infrastructural development, contraction, and exclusion exist in abundance. We opted to start with the thousands of inscriptions commemorating infrastructural construction and renovation. Such inscriptions have, in the Chinese case, been carved onto rock surfaces and stone stelae, often oblong slabs of stone but also existing in various shapes since early imperial times. From the Song Dynasty (960-1276) onwards texts inscribed on such stone monuments were regularly but selectively transcribed and/or abstracted into local gazetteers. Local gazetteers (Chen et al. 2020; Dennis 2020; De Weerdt 2003) have evolved over time and continue to evolve into the present, but at a basic level report about a locality’s geographic and astronomical location, administrative organization and history, important public works including schools and religious sites, registered households, regional products, taxation, notable residents such as examination degree holders and officials in and from the area, well-known sites and texts. Around 10,000 are extant and a large number (over 6,000) are available in digital format, in facsimile as well as in full text. Because they were compiled and recompiled across generations, and, at least from the Ming Dynasty (1368-1644) onwards, exist for many places and at various levels of the administrative hierarchy, they are an often-used source among social and economic historians. </p>
                     <p>Local gazetteers have in the past century been mined by historians and anthropologists to study infrastructures. For example, information about city walls was used to study the origins of urban settlements or their size and spatial distribution over time, as well as shifts in the use of materials (e.g., increased use of brick) (Li 1928, Xue et al. 2019 and 2021). These studies are based on datasets with a limited set of entities (e.g., object name, time and place of construction, size, and sometimes material), extracted from summary information in union gazetteers and encyclopedias that abstracted information from lower-level gazetteers into empire-wide digests. As we have shown elsewhere, in these analog and digital datasets, infrastructural events are typically dated inaccurately or absent, and data is listed without clear source references (De Weerdt under review). In the case of roads, normative administrative texts have been used to construct static GIS datasets of national or empire-wide “road networks” that are presented as having had stable lives that coincide with those of entire dynasties (Berman and Zhang 2017 and Academia Sinica 2002, n.d. a and n.d. b). </p>
                     <p> Instead, we aimed to rewrite the history of infrastructures from the lower levels up, investigating the actors and social groups involved in the initiation, planning, financing, building, managing, and use of infrastructural objects, information about the causes that led to different types of actions, project cost and labor, the dimensions, materials, and features of infrastructural objects, etc. We therefore set out to collect all relevant remaining inscriptions commemorating infrastructural events, restricting ourselves in the first instance to inscriptions on the construction and repair of city walls in the county-level gazetteers of three Ming-Dynasty provinces (De Weerdt, Xiong, and Liu 2020). In this pilot project, the information listed above was annotated in all collected inscriptions according to a basic set of entities and tag categories. We concluded, however, that digital text annotation methods based on entity annotation and, even relational markup between individual entities, did not yield data with the level of precision required for the accurate interpretation of events of construction, destruction, renovation, expansion, and project failure (De Weerdt, Xiong, and Liu 2020). As we will illustrate in greater detail in section two, epigraphic texts and their transcriptions in historical sources such as local gazetteers often do not commemorate a single event; they narrate multiple events. Each of these events has some unique features and others that are shared with other events. In order to map out the social and political actors, costs, causes, or the dimensions and material features of infrastructures during each of these events, entities that are related have to be grouped together and structured. In the pilot study of inscriptions on city wall construction in three early modern Chinese provinces we showed how, otherwise, multiple and different events become indistinguishable and lead to mistaken conclusions about wall features at different points in time and, more broadly, the longue-durée history of the presence, use, repair, and meanings of walls.<note> Earlier quantitative studies of city wall construction were based on summaries of such inscriptions in encyclopedic texts that similarly reduced complex content, leaving out dates of expansions or destruction, and thus also dating features that were introduced later to earlier time periods. Such early and more recent studies include Li 1928 and Xue et al. 2021.</note>
                     </p>
                     <p>Similarly, existing image annotation services could not accommodate a data-rich semantic annotation of images. Our inquiries led us to include historical maps of infrastructures in gazetteers, modern photographs of infrastructural stelae (whose inscribed texts may or may not have been available to us) and of other material objects (e.g. modern photographs of city walls, bridges, and road sections), manuscript maps and archival documents such as infrastructural construction plans submitted to and still preserved in Qing- Dynasty (1644-1912) archives, and archeological diagrams. Such research materials are available to us in the form of digital images, but existing image annotation services do not provide for the kind of deep semantic annotation we envisioned: the use of hierarchically organized entity or tag classes each with a range of properties and of relationships between entities or tags. They also do not facilitate the integration of external authorities in entity or tag properties. Finally, existing services also do not allow for the integration of annotation data from text- and image-based sources for cross-media discovery, analysis, and reading.</p>
                  </div>
                  <div>
                     <head>On Annotation</head>
                     <p>To conclude the introduction, we offer some fundamental observations about annotation and digital annotation. Why invest time in annotation or designing annotation services at this point in time and for humanities fields like history that tend to favor the particular case over the aggregation of data? The practice of annotating texts, graphic and other objects is attested across human history and fundamental in scholarly practices across space and time. It is, in John Unsworth’s famous phrasing, a “scholarly primitive” (Unsworth 2000). Unstructured and structured annotations are essential aides in research and interpretation; there is at a very fundamental level need for digital annotation methods that can facilitate the tracing and analysis of annotations. It is, therefore, no surprise that considerable effort has been devoted to text encoding (and to a lesser extent to image or audiovisual encoding) since the early days of humanities computing.</p>
                     <p>However, the needs and research practices within the humanities differ significantly. To us as historians it is above all the semantic annotation of various types of primary research materials that matters; this implies that we are usually less concerned with a complete annotation of the linguistic aspects of a text or corpus of texts (e.g., parts of speech tagging) or less interested in a systematic annotation of the layout and structural features of text and image in various editions and different media than literary or cultural studies scholars. We prioritize information about the who, what, where, when, why in the interpretation of events as may have been reported in different accounts in different identifiable sources. And so, we value traceable information about a range of entities in traceable sources across genres and across media. From the start, therefore, annotation standards and tools designed for and by linguists and literary scholars have been less practical and attractive to historians. This includes the widely influential TEI guidelines and associated software and platforms. For our own and other research in Chinese and Korean history, we designed MARKUS to deliver an attractive annotation and reading platform, offering a range of annotation and reading options and taking full advantage of external authorities in annotation and historical analysis. This design was later incorporated in other East Asian digital humanities projects (e.g., Chineseall.com’s <ref target="https://inindex.com/">Inindex</ref> platform and Tu Hsieh-Chang's <ref target="https://docusky.org.tw/DocuSky/home/v4/?l=en">Docusky</ref> tagging service) and in large-scale textual databases (e.g., Donald Sturgeon’s <ref target="https://ctext.org/">Chinese Text Project</ref> and Academia Sinica’s <ref target="https://dh.ascdc.sinica.edu.tw/member/index_en.html">DASH platform</ref>). Nevertheless, MARKUS also allowed for output in TEI-XML of annotated files (De Weerdt 2020). The latter has been mostly used by MARKUS users in cases where full text editions were produced with annotations. Other output options (XLSX, CSV, or JSON) allow for a wide range of data analytics on various platforms and have in our experience been used more frequently by historians.</p>
                     <p>Annotation is thus not only a scholarly primitive, the design of annotation standards, structures, and topologies are also always acts of interpretation. This implies furthermore that annotations typically do not stand alone but are situated within multiple contexts. Maximizing the preservation of context and access to user-desired contexts ought in our view to be a central design principle in digital annotation services. Contextualization in various dimensions remains a considerable challenge (De Weerdt under review) and has become if anything more important as the enormous potential of generative AI makes data evaluation more critical than ever. As indicated in the introduction above, here we only discuss contextualization in relation to the semantic modeling of image and text sources, the traceability of image regions and textual entity and data cluster locations in data analytics, and the uses of piece and source metadata. We consider these aspects to inhere in the ontological concept of annotation.</p>
                     <p>First, annotations are related to one or multiple parts of a text, image, or object and thus have to be analyzed and understood in relation to those parts and the larger wholes of which they form part. We consider both individual entity annotations or simple tags and composite arguments consisting of entity or tag clusters data in the sense of attributed values or abstractions on whose basis further computation can take place. Attributions are interpretive interventions and therefore debatable; they are not transparent reflections of empirical realities — the concept “data” was etymologically not defined as “givens” from empirical reality and has historically not been exclusively used in a positivist sense (Lavin 2021). Second, at an empirical level, annotations are part of sets of annotations, including, for example, the set of annotations on a text or object, on an entire corpus, or the set of annotations attributed to a particular annotator. Annotations are in addition situated within practices of modelling. And so, third, annotations sit within an annotation structure which can be either implicit or explicit, shared and standardized or idiosyncratic, simple or highly differentiated and complex. In our discussion below we have reversed the order and start with modeling and then explain what context data created in IMMARKUS and COMARKUS include and how context can be preserved and activated in the analysis thereof.  </p>
                  </div>
               </div>
               <div>
                  <head>From named entities to structured events and data clusters in semantic digital text annotation</head>
                  <p>Entity markup or the labeling of named entities defined as specific real world objects and concepts has been used in the full range of humanities disciplines for a variety of goals, including linguistic analysis, the preparation of digital editions, the development of more intelligent search functionality in discipline-specific databases, the organisation and exploration of private research materials, and, as in our case, for the spatial, network, or quantitative analysis of semantic annotations embedded in primary sources that have been normalized and linked to external authorities (Nantke and Schlupkothen 2020). As discussed in an earlier essay on the rationale and functionality of the MARKUS entity annotation service we developed from 2014 onwards, semantic entity annotation in MARKUS, now expanded and renamed ENTMARKUS, offers a few advantages over regular text editors and annotation services (De Weerdt 2020). It offers basic automated structural markup and automated markup for a range of default entities (e.g., place, time, person names, offices, book titles) using authoritative scholarly datasets in Chinese, Taiwanese, Korean, and Buddhist studies and linking tagged content to those datasets through their associated ids. It also offers a range of keyword-, KWIC, and regular expression-based annotation methods, the annotation of text comparison results in files compared, and all methods can be applied in batch across all or select files in a corpus. Annotations of entities and other content in ENTMARKUS can be exported along with the full text to HTML and XML-TEI, and data can be extracted and downloaded in several formats (CSV, XLSX, HTML). More importantly, MARKUS annotations and (to a large extent) the data to which they link can be visualized and analyzed directly from the ENTMARKUS interface to three open access platforms: DOCUSKY (Tu and Hsiang 2018, Tu et al. 2020) and DOCUGIS (Lin 2018), PALLADIO (Humanities + Research Design Lab 2014) and PLATIN (Max-Planck-Institute for the History of Science n.d.). This annotation and analysis process has been adopted in a wide array of research projects ranging from the history of medical plants (Stanley-Baker and Ho 2015), correspondence and friendship networks (Chu 2016a-b), the comparison of art collections and collectors (Hsu 2017 and 2018), political factionalism (De Weerdt et al. 2020), modern legal texts, commentarial practices (De Weerdt forthcoming), settings in novels (Wan 2017), the networks of Korean envoys (Hu 2023), citation networks (Beijeren 2017), the spatial distribution of stone monuments (Liu 2024), the preparation of indexes and online editions (De Weerdt, Gelein, and Beijeren 2020), the intellectual historical analysis of notebooks and governance manuals (De Weerdt 2016), the enrichment of biographical databases (Wang and Tsui 2016), etc. </p>
                  <p>	Entity-based semantic annotation comes, like other infrastructures material and virtual, with a disposition: it steers research in some directions, foreclosing or impeding other approaches (Easterling 2014, Rettberg 2020). For example, the availability of extensive authority databases on administrative place names in the Chinese case easily leads to the aggregation of data at the county or higher-level administrative units. Likewise, the bias of digitally available historical sources towards the writing, the careers and networks of office- and examination-degree holders and the correspondingly rich information on these topics in biographical databases have foregrounded the role of elite men and state actors in digital historical projects. As we show elsewhere, inscriptions recount the involvement of a wide range of social actors. To capture their social history more fully, the standard set of named entities needs to be expanded to include within our purview the names of social entities (e.g., shop or business names) and the range of terms used for social categories of all kinds which can then in turn be normalized and categorized (De Weerdt et al. under review). Equally important to the use of semantic entity annotation in historical research, entity-based data models are suboptimal in capturing historical data accurately and may lead to analyses that misrepresent the context and therefore the meaning of the tagged content. For example, analyses of entities in encoded texts tend to aggregate them at the level of a structural division in the text (the entire document or a subdivision of it). This may be a good short-hand for some types of analysis and some texts, but when relations among entities are complex and information is not presented in a linear or tabular fashion but rather in recursive or nested structures the semantic structures of the text need to be modeled further. </p>
                  <div>
                     <head>Modeling Events in Texts</head>
                     <p>As briefly discussed in the introduction, historians have access to a large arsenal of epigraphic texts to write the social and regional history of infrastructural development and contraction — this is the case in East Asian history but “the epigraphic habit” also went hand in hand with infrastructural construction, destruction, renovation, and failed projects in other parts of the world (Gates-Foster 2012, MacMullen 1982). Inscriptions commemorating the construction and repair of walls, bridges, roads, and other types of infrastructure complexes or their parts exhibit a layered event-based semantic structure. As shown in Figure 1 authors may have opted for a predictable chronological pattern, moving from the first known construction project through a history of demolitions, renovations, expansions, etc. They may, however, have started with the latest moment that the authors wished to commemorate, other events that immediately preceded it, and only then move on to a brief chronological overview of the earliest events that they have selected to include in the commemoration.  </p>
                    
                     <p>Moreover, information about event causes, infrastructure features and dimensions, their uses and meanings, the actors involved, etc. is also not necessarily organized in chronological order or neatly clustered together. Within individual events, information is sometimes implied or inferred from earlier events (e.g., “was restored <hi rend="italic">to its original state</hi>” or “<hi rend="italic">thirty years later</hi> X was expanded”) (Figure 2). The authors of infrastructural inscriptions also jump back and forth between events. In Figure 2 we present a more detailed chronological model of events that shows how elements that belong to one event (object parts, dimensions, actors or groups involved in any aspect of an event, or time and place) have to be inferred from events mentioned earlier. The challenge in writing a fuller and more complete history of infrastructural events as commemorated in inscriptions therefore lies in deciding which elements apply to each of the events remembered, based on the interpretation of explicit and implicit information in the text.</p>
                    
                     <p>We first developed a basic text model and a list of entity classes and additional labels for dimensions and other features based on expert domain knowledge. On this basis we created a data model linking entity classes, additional labels, and their data types to event categories, specifying which entity classes fit within which event categories. An event in this second-tier model consists at a minimum of a place, time, event type (construction, renovation, destruction, expansion, failure), and main object (bridge, city wall, or road, for example). Place, time, and main object in the second-tier model admit corresponding entities and an action tag (e.g. “to construct,” “to complete,” “to renovate,” “to repair,” “to expand,” “to plan,” “to destroy”) can be used to create an event type. Optional categories such as actor roles in the event (initiator, sponsor, beneficiary) or event properties such as cost, labor, cause, and object dimensions and materials, are also each linked to relevant entities and tags such as person names, social categories, labor, cost, length, width, depth, height, material, action cause, etc. </p>
                     <p>This model, represented ontologically in Figure 3A, formed the basis of the default data model included in COMARKUS. To better visualize and formalize how information from different domains interrelates within the data model, we translated it into an ontological framework. This ontology builds on established semantic web standards: CIDOC CRM (Doerr 2003) for representing cultural heritage concepts and events; Dublin Core Terms (DCTERMS) (DCMI Usage Board 2020) for documenting metadata such as authorship and publication; and the W3C Time Ontology (Cox and Little 2017) for expressing temporal intervals and instants. These standards enable semantic extensibility and interoperability with existing ontologies and our data model. Where existing ontologies did not provide adequate coverage, we have introduced our own domain-specific vocabulary. Each vocabulary source is clearly identified by a prefix — such as “crm,” “dcterms,” “time,” or our custom namespace “reginfra” — to indicate its origin and maintain clarity in integration.</p>
                     <p>In this model, an event instance (reginfra:event) forms the core of the event annotation domain. Each event includes its defined type, the main object involved, and the time and place of occurrence. Additionally, the model can capture various roles associated with the event — such as initiator (reginfra:initiator), sponsor (reginfra:sponsor), and beneficiary (reginfra:beneficiary) — which may involve individuals, state actors, or social groups. These participants can be linked to identifiers from external authority databases. Annotations may also record other aspects of the event, including causes, costs, and labor. The model also connects events to physical features of material infrastructure (reginfra:object_main), detailing components (reginfra:object_part), materials, quantities, and dimensions. Conceptual associations — such as linked deities or symbolic meanings — are also recorded. Furthermore, events are tied to metadata at the piece and source level, enabling contextual linkage between the event and its documentary origins.</p>
                     <p>Figure 3B shows how this model is used in the annotation of a commemorative inscription from the <hi rend="italic">Gazetteer of Yangzhou Prefecture </hi>(Akedang’a and Yao 1810). Here, the event instance (“build”) represents an expansion of the Yangzhou city wall (“yangzhou_cheng”). The expansion involved a range of actors — initiator, sponsor, and beneficiary — including individuals (e.g., Yang Shoucheng, CBDB id 409577, a provincial graduate) and social groups (e.g., the sponsor “salt_merchant” and the beneficiary “resident”). The event began in November 1556 and ended in March 1556, lasting nine months. The causes for it were identified in the text as “rebel” and "silted_river." Cost and physical details of the object parts are recorded in data properties, including “has_cost,” “has_quant,” and “has_length.” At the top of the diagram, the event is linked to its textual source, “Yangzhou xincheng ji,” appearing in the <hi rend="italic">Gazetteer of Yangzhou Prefecture</hi>, as well as related authorship and publication metadata.  </p>
                     <p>Together, Figures 3A and 3B illustrate how the contextual modeling of historical infrastructure events can be operationalized in COMARKUS through structured annotations that draw on the text of historical sources, standardized vocabularies, and linked data.  </p>
                     
                     <p>The default COMARKUS data model can be modified for other types of contextual markup, for example, to group entities related to other types of historical or fictional events, to memories associated with places and objects in travel diaries, or to arguments in discussions involving different persons, groups, concepts, and texts (De Weerdt and Molenaar 2024). The default data model also allows for nesting data clusters within the larger data model to ensure that shared attributes can be linked to the appropriate entity; in the default model, for example, different object parts such as moats, gates, or towers can thus each have their appropriate quantities and dimensions. </p>
                     <p>In addition to the data model, a metadata model can be specified that can also be populated by tagged entities, thus ensuring that authors, places of publication or coverage, year or period of publication, genre and their associated attributes can be used in faceted browsing and data analysis and visualization alongside the entity and event annotations. COMARKUS comes with a default metadata schema which includes fields for the title, author, time, and place of the piece text as well as the title, author, time, and place of the text’s source (De Weerdt and Molenaar 2024).</p>
                  </div>
                  <div>
                     <head>Creating Events and Data Clusters in COMARKUS</head>
                     <p>Once the data model has been specified, folders with text files annotated in ENTMARKUS can be loaded into COMARKUS for the further organization of entities or custom-tags into events or data clusters. COMARKUS has been designed to allow for revisions and additions, including the annotation of entities and the addition of entity ids, but at this stage it is still recommended that the original ENTMARKUS platform is used as it offers a broader range of options for the annotation of entities and tagging including batch annotation of larger numbers of files. </p>
                     <p>Figures 4 A-B illustrate what data clusters include in the case of infrastructural inscriptions. These figures show one document in the middle with a range of basic entity and other annotations (the other documents in the folder can be accessed from the folder icon on the top left). The tag types include personal names (in red), time references (in green), place names (in blue), bureaucratic titles (in light blue), actions related to infrastructural events (in orange), action causes (in amber), bibliographic titles (in brown), main (infrastructural) objects (in dark slate blue), object parts (in purple), main object and part dimensions such as length (in vivid sky blue) and width (in light sky blue), social categories (in slate blue), etc. Most entities and tags in this case come with ids, in the form of either an id that links to external databases for normalization and extra information in the case of place and personal names, or a normalization or conversion in the case of social categories, actions, event causes, time references, or object dimensions. Tags and ids can be shown or hidden from view from the second set of icons from the top in the left menu. The red arrow in Figure 4A suggests how a tag (in this case the tagged text is a time reference) can be dragged into the data model fields on the right. This specific time reference is selected from among the many time references to create a date for a renovation event; the underlying JSON file will include the id of the time tag and so add the year or specific date in arabic numbers. In this example, the data model allows for both beginning and end dates and the duration of infrastructural projects and events. The other fields can be similarly populated by the relevant tags and ids. All event information can also be edited from the underlying event file which can be accessed from the calendar icon, situated just below the data model editor in the third set of icons on the left menu. All events are saved along with their attributes and associated ids in JSON files in the original folder from which the user loaded the files to be annotated.</p>
                    
                     <p>In this way the sequence and causes for specific infrastructural events, the different roles played by specific persons and organizations as well as those by anonymous persons grouped into social classes by the inscriptions’ authors, their cooperation as well as their conflicts, the changing features and materiality of infrastructural objects and their parts, and the ability and interest of state and other agents to invest in the construction and above all the maintenance and renovation of different types of public works can be set out. These aspects can be investigated at the level of the series of events commemorated in individual inscriptions, but equally as we will show further below, by extending the same methodology to a larger corpus of inscriptions, in the contexts of other infrastructural projects in the same place, and those of other places and other times.</p>
                     <p>Figure 4B shows how metadata can be added in COMARKUS; this ensures that the source text and text edition for each event can be checked and that such bibliographic information can be used to filter content or for other data analytical purposes. The red arrow indicates how the author of a work (whose ID is linked to the <ref target="https://projects.iq.harvard.edu/cbdb">China Biographical Database</ref>) is dragged to the piece author field in the metadata model. The metadata tab can be activated by clicking the raster icon located next to the event tab on the right. This particular example also shows how other publication fields can be populated with annotated data from the document. Metadata added in this way becomes visible at the top of the document in the middle of the screen as shown by the blue arrow in Figure 4B. Metadata fields in the default metadata schema can be edited, added, or deleted and, like event data, all metadata is automatically saved to the folder from which the user selected the files to be annotated.</p>
                    
                     <p>This fine-grained and flexible way of adding metadata to data clusters addresses one of the problems of the traceability of tabular data extracted from primary sources or reference materials: instead of generic source references users can add the piece, source, source section, and edition used for each individual event, and the encoding method used allows for the specific location of the event attributes (the entities and tags) to be identified in the electronic rendering of the text. This design also offers a first step in the direction of a better modeling of source ecologies: as we have set out elsewhere, infrastructural inscriptions have been and still are situated in multi-dimensional source ecologies. It will require further work to bring into view their transformations over time, across media, and their changing location in textual assemblages (De Weerdt under review). </p>
                  </div>
                  <div>
                     <head>Processing and Analyzing Hierarchically Clustered Data</head>
                     <p>All data created in COMARKUS can be examined in a variety of data analytical environments. We conclude this section with a few examples of the quantitative and spatial analysis of infrastructural events as commemorated in inscriptions and an overview of the ways in which events and their attributes can also be used as filters in custom textual databases (Molenaar under review b). Both are important to historical research. The examples are drawn from custom-designed notebooks that require some programming skills in Python and also from the X-MARKUS and MUNDa platforms we have designed for the reading and analysis of entity and event data created in the MARKUS environment. Here we focus on COMARKUS data only; we will return to the integration of text and image data in X-MARKUS below.</p>
                     <p>COMARKUS data is saved as JSON files, allowing for their use in various data analytical environments and for the creation of custom visualizations. Because the structure of the data created in COMARKUS is complex, a significant amount of pre-processing may be required to ensure that the hierarchical data can be flattened into data tables without losing any of the data complexity and accuracy. In Figures 5A-B we provide an illustration of the basic workflow we have adopted to convert the event data into tables that allows us to examine all data categories in relation to each other and to link them with the authority databases used for additional external data. From this, a variety of quantitative analyses and visualizations can be readily produced; the resulting data tables can also be used for further statistical analysis. In Google Notebooks, for example, we created a shared notebook to pre-process COMARKUS and ENTMARKUS files and from there selected event or entity categories of interest for analysis; Figure 5B provides an example of a faceted timeline showing event causes for different types of bridge infrastructural events in Fujian in 50-year slots from the 11th through the 20th centuries. </p>
                    
                     <p>Because all events have time and place coordinates, we can with this data create a more fine-grained timemap of infrastructural development and contraction, allowing the researcher to investigate the appearance, disappearance, transformation, and failure of infrastructural projects, their social makeup, material features, their environmental, military and political embeddedness, and regional patterns therein. The data tables created in our shared notebook can also be used for GIS analysis. Figure 6A provides one example of how the data exported from COMARKUS can be used to trace and interpret spatiotemporal patterns of human-infrastructure activities, such as the renovation and expansion of city walls in the Shanxi area. We can investigate areas with dense clusters, and changes therein over time. Figure 6A reveals different responses in northern and southern Shanxi to escalating security crises––from local banditry to Mongol incursions––during the first and second halves of the sixteenth century. We can deepen our understanding of these patterns and the behaviours they suggest by mapping and examining the causes that were attributed to actions such as the repair or destruction of infrastructures – for example, walls that needed to be repaired due to an episode of violence or bridges that were destroyed by a flood. In this way, we can not only trace the lives of infrastructures, but also investigate how these objects figured in networks of human and environmental interactions. It is also possible to link individuals, social classes and/or groups to infrastructures in both place and time. This provides insight into how actors manipulated infrastructures for their own ends, and defined, contested, or obscured sociopolitical boundaries. Moreover, this methodology allows us to correlate infrastructural information with other spatial data sources, such as environmental events, demographic changes, taxation data, and the presence of wars and conflicts, as shown in the comparison of our own data about violence as a cause for infrastructural events in the Shanxi region with the findings of others (Dinecco and Wang 2018) in Figure 6B. This provides a deeper and more nuanced understanding of how such factors may relate to the life cycles of infrastructures in the longue durée, and conversely and more importantly, we can use the occurrence and recurrence of infrastructural events and projects (rather than the presumed dimensions of city walls over time) as a factor in the explanation of socio-economic and environmental history.</p>
                    
                     <p>With this approach we can thus tabulate and map and so interpret the still traceable course of material infrastructures’ lives and offer an alternative to the tendency in larger-scale quantitative work to select moments of construction in the history of material infrastructures, presuming those moments to have been durable and lasting. This latter tendency is not only the result of source selection but is equally part of early modern and modern theoretical frameworks within which infrastructures are considered to have been naturally endowed with attributes of durability and continuity (De Weerdt forthcoming).</p>
                     <p>To facilitate the conversion, reading, and analysis of data created in ENTMARKUS and COMARKUS, we have developed a search and retrieval platform called X-MARKUS and a spatial analysis platform called MUNDa. Both operate in a similar manner as COMARKUS and IMMARKUS, running in the browser and working with local files saved on the desktop or in the cloud. X-MARKUS essentially converts all text, schema, annotation, and metadata files into a textual database. In contextual annotation in the MARKUS environment the link between annotation data and their location in the full text is preserved. This type of location information is used in X-MARKUS and MUNDa to allow researchers to swiftly move between datapoints in various displays and the annotated source text. Below we briefly highlight key functionality of X-MARKUS and MUNDa in the analysis of complex textual data clusters; for the analysis of entity and other labels in the DocuSky and DocuGIS platforms that inspired the design of X-MARKUS and MUNDa we refer the reader to earlier published work (De Weerdt 2020; Lin 2018; Tu et al. 2020).  </p>
                     <p>Figure 7A shows the document reading and search view (accessible by clicking the magnifying glass icon on the far-left menu). This view appears after all ENTMARKUS and COMARKUS files in a given corpus have been converted to XML — this is step one accessible from the data conversion icon located on top of the magnifying glass icon. Earlier converted XML files can also be imported from the top bar. In this view readers can query all annotations and metadata, and, at the same time, search in free form comments and the full text. Figure 7A shows the results of a query of the materials used in bridge renovation events (see search string in the top bar) in a corpus of annotated Fujian bridge inscriptions. On the left the results are aggregated by normalized tags, with a dropdown option to navigate the texts where each material was tagged. The number in brackets indicates how many events include that specific material. Reading from the top left, 'bamboo' is one of the materials mentioned in bridge renovation events, appearing as 簰 (<hi rend="italic">pai</hi>, bamboo raft) in one event. In the document pane in the middle the full text of the ten inscriptions featuring relevant events are shown with their annotations, along with their metadata on top. (X-MARKUS also gives viewers the option during conversion to structure and display each inscription with its events as a separate document; in Figure 7A results are shown by event, the same text may appear multiple times if it contains multiple events.) In the right pane the events relevant to the query are listed, along with their attributes (event annotation type and subtype, tag id, and tag content). Event clusters and individual event tags can be clicked to highlight them in the text in the middle; tag names and ids can be shown or hidden from the view options on the right. Keyword search results are similarly highlighted. In the middle pane tags with ids can be clicked to view related content from authority databases (e.g. biographical information or maps for places). Query results can be exported to XML. </p>
                     
                     <p>Relations between and among different event attributes can also be explored in the knowledge graph (the network icon on the far left menu). For example, Figure 7B gives an overview of the participation of Buddhist monks in different types of roles in construction and renovation events. The query targets the normalized tag “buddhist_monk,” specifically examining its presence in the sponsor, initiator, and beneficiary properties within two event types: construction and renovation. The resulting graph allows users to identify patterns of participation across roles and event types: Buddhist monks appear as sponsors in 16 events (13 renovation, 3 construction), initiators in 7 events (5 renovation, 2 construction), and beneficiaries in 2 events (1 renovation, 1 construction). Readers can link to the relevant event from the network display. </p>
                     
                     <p>The XML file created in X-MARKUS to view and query the textual database and the knowledge graph, can also be used to map annotations and query results in MUNDa (the map icon on the far left menu), which runs as a separate service. MUNDa supports interactive spatial and textual exploration through a browser-based interface composed of three main sections: a left sidebar for basic operations, a central GIS-based interactive map, and a right pane for data filtering and analysis. </p>
                     <p>In MUNDa, events can be filtered and searched in similar ways as in X-MARKUS. The relevant events are shown in a GIS environment in which various base layers are available, including topographical and historical administrative layers. MUNDa converts the XML file imported from X-MARKUS into data tables so that all data and query results can be exported as TSV or KML files for further spatial analysis in ARCGIS, QGIS, and other dedicated software. These layer files can also be re-imported in MUNDa to be shown in a user-defined symbology alongside other layers. The data table view in MUNDa also allows for additional querying, including, for example, time ranges. Given that MUNDa is lightweight and browser-based, dedicated spatial analysis packages are recommended for larger datasets and larger number of layers. Figure 7C maps the same query as the one used in Figure 7B, with Buddhist monks’ roles represented as distinct map layers. The query results are exported from X-MARKUS and imported in the MUNDa spatial analysis platform, in this view, the sponsor role layer is active.  </p>
                    
                     <p>Queries can also be performed on the map itself, for example, by demarcating an area for further investigation. This locates all events on the map in the middle pane, and, in the right pane, produces an overview of events in the selected area comprising basic infographics as well as the annotated source texts. Texts or events can here also be arranged in chronological sequence. MUNDa incorporates generative AI services, allowing users to produce prompts to have the results analyzed by the selected service, e.g., Gemini or ChatGPT. All data points on the map can be clicked to view event data and the source text with its annotations, metadata, and comments. Here too annotations can be linked to external authorities. And so, even though they are designed to contextualize singular events in time and space at various scales, X-MARKUS and MUNDa promote critical data evaluation skills, and the close reading and analysis of primary sources, skills that remain of critical importance.</p>
                     <p>The annotation methodologies employed in the infrastructural history project parallel foundational tasks in the Natural Language Processing (NLP) subfield of Information Extraction (IE). The semantic entity tagging performed using ENTMARKUS aligns with Named Entity Recognition (NER). The contextual, hierarchical annotations created using COMARKUS mirror the goals of document-level Relation Extraction (RE) and Event Extraction (EE). The emergence of Transformer-based models, and more recently, the advent of Large Language Models (LLMs), have augmented the potential for automating these IE tasks, particularly for document-level analysis where information can be scattered and context is paramount. </p>
                     <p>As will be further elaborated in Xi Wangzhi's ongoing work (Xi in progress), we are exploring this potential by developing an automated event extraction pipeline, which operates in parallel, and in continuous dialogue, with our established annotation workflows. These processes are designed to transform unstructured texts into structured or semi-structured databases that are traceable, allowing researchers to verify annotations against the original source, and also flexible enough to be modified or amplified for future re-use from different analytical perspectives. Our automated approach leverages the capabilities of LLMs to generate a high-recall set of event candidates by instructing the LLM to identify potential event triggers and associated arguments across the full document. This initial, broad pass over the inscriptions produces an output designed to be more aligned with general IE standards. It involves identifying actions as <hi rend="italic">event triggers</hi> (categorized into predefined event types: construction, renovation, destruction, expansion, and failure) and then linking various entities to specific <hi rend="italic">event argument roles</hi>. These roles encompass the main infrastructure objects along with their materials and dimensions, temporal and spatial information, the actors involved, their designated roles, event causes, and other specifics described in the ontologies.</p>
                     <p>This initial dataset then undergoes a series of refinement steps. Here, we are experimenting with a hybrid approach, which involves further LLM-based processing and other deep learning methods. For example, we are exploring the use of smaller, targeted classifiers (fine-tuned on BERT-based models with our manually annotated data) for the fine-grained classification of event causes and the normalization of specific entity types. The objective of this refinement is to incrementally transform the IE-standard-aligned data into a set of annotations that are more closely aligned with the research-question-driven schemas and data structures used in COMARKUS annotations and subsequent historical analysis workflows. This iterative process results in two sets of structured data: one that adheres more closely to the standards for IE tasks, and another that is tailored for integration with X-MARKUS and MUNDa. To enable this integration, the automatically extracted and structured data can be transformed back into formats compatible with our existing platforms. This includes generating HTML and JSON file pairs that can be imported into ENTMARKUS and COMARKUS, as well as XML outputs for X-MARKUS. This interoperability allows historians to review, curate, and validate the machine-generated annotations for the hundreds of unannotated inscriptions in our corpora.</p>
                  </div>
               </div>
               <div>
                  <head>From image tagging to data-rich semantic annotation with ontologies and custom data models</head>
                  <p>Similar to text annotation, structural and semantic image annotation has been developed for a wide range of scholarly purposes. In the humanities and cultural heritage sector images have been annotated to add metadata, to prepare images for placement and formatting in publication projects, to tag and identify features in images, and to transcribe, translate, and comment on select image areas. The Text Encoding Initiative includes basic guidelines for graphic material (TEI Consortium 2023) as do editors like the oXygen XML Editor. Other notable examples include MIRADOR which allows users of this open-source viewer to draw selections on images with shape and freeform tools and add tags or insert text, links, and images in a popup box (Project Mirador 2021, Zundert 2018). MIRADOR has been extended for text editorial projects in the Ten Thousand Room Project (Lu, Hunter, and Yale’s Information Technologies Services, 2017). </p>
                  <p>Similarly building on top of MIRADOR, the work of Kiyonori Nagasaki et al. has facilitated the comparison of manuscript and print editions of Buddhist works in the “IIIF Manifests for Buddhist Studies” and associated digital services (SAT Daizōkyō Text Database Committee and International Institute for Digital Humanities n.d.). Basic tagging and georeferencing of images is also included in the Recogito platform designed by Elton Barker, Rainer Simon et al. (Pelagios network n.d., Simon et al. 2019).  </p>
                  <p>As we sought to further contextualize and situate data (Haraway 1988, Lavin 2021) from inscription texts and turned to photographs of stelae, rubbings, and infrastructures, printed and manuscript maps, and archeological reports and diagrams, it became clear that we would need to develop an image annotation service for a kind of deep semantic annotation equivalent to ENTMARKUS and COMARKUS for texts. </p>
                  <div>
                     <head>Modeling Image Data and Relations between Text and Image</head>
                     <p>As in the case of COMARKUS, we proceeded from the modeling of the data and metadata of sources relevant to our project on the history of infrastructures and based on the kinds of questions of interest to us. Our efforts have so far mainly focused on images of printed maps of walled settlements included in gazetteers, manuscript maps depicting city walls and military fortifications, photographs of stelae and rubbings related to infrastructural projects, and diagrams of wall, road, and bridge remains in archeological reports. We developed data models for each of these image source types to address questions relating to the materiality of infrastructures; map symbology; the representation of city walls on print and manuscript maps; the relation among infrastructures and their relation to environmental features such as water in gazetteer maps; the deeper history of infrastructures for which inscriptions existed; the dimensions, materiality, layout, and placement of stelae and the differences between stelae and their transcriptions in gazetteers in this respect. For some of these questions it was necessary to model not only the image sources, but also the relationship between image and textual data and the source ecologies in which both map and inscription text were situated (Lee under review b). Below we discuss on the basis of the example of historical print and manuscript maps how to model relevant data and metadata and how to model the relationships between texts and images. We also show how such a model can be implemented in the IMMARKUS environment. Even though we recommend modeling as a first step in a well-designed research project, this step is not required or can also come at a later stage. Models can be designed on the fly, in the process of annotation introduced in the next section and set out in more detail in the <ref target="https://github.com/rsimon/immarkus/wiki">IMMARKUS wiki</ref> (De Weerdt et al. 2024a). </p>
                     <p>Maps of city walls, especially those in late imperial Chinese printed gazetteers and manuscript atlases, illustrate our modeling approach. These maps, produced for a wide range of audiences including emperors, officials, local elites, and tourists, display a highly standardized visual grammar: a central walled city often surrounded by moats, rivers, and mountains with key infrastructures represented inside. Among these are government offices, schools, temples, bridges, and roads. While adhering to shared visual repertoires, the maps also incorporate local variations in wall structures and environmental surroundings. When examined alongside other images and textual sources, it becomes more evident how visual representations both reflected and responded to historical changes–for instance, shifts in the material practices of city wall construction and repair. As traditional rammed-earth walls were increasingly replaced by masonry walls during the sixteenth and seventeenth centuries, maps accordingly emphasized the materiality of the walls. Mapmakers employed different visual strategies depending on the medium: manuscript maps often used color to differentiate materials, while black-and-white woodblock-printed maps adopted patterns including stripes or layered interlocking rectangles to convey similar information.</p>
                     <p>The proliferation of such maps–numbering around one thousand in county gazetteers from just four provinces in late imperial China–poses significant methodological challenges: how to analyze, compare, and contextualize divergent representations of city walls while preserving the spatial, temporal, and material specificity of each source. We therefore designed a model to examine the shared and distinctive ways in which walls — and their relationships to other infrastructures and surrounding environments — are depicted, across genres and periods. The model also facilitates integration with other types of sources, notably archeological diagrams or commemorative inscriptions.</p>
                     <p>In this data model, we defined a list of entity classes: major infrastructures (object) and their constituent components (obj_part). Each object entity is assigned a set of shared properties, including identifiers (e.g., ID and name), descriptors, location, and visual characteristics, such as color and texture. Properties like identifiers and location facilitate comparison of how the same infrastructure or place is represented in different maps and also in related archeological or textual sources. Descriptive and visual properties enable us to record features relevant to our research interests, specifically whether and how the mapmaker depicted the materials used for city walls and bridges.</p>
                     <p>Within the main object class, we defined two key subclasses: city wall and bridge. These subclasses inherit the properties of the parent class (object) but additional attributes specific to each subtype were also defined. For the city wall subclass, additional properties include the presence of roads and the depiction of multiple wall phases in cases where both older and newer walls appear on the same map. For the bridge subclass, we record bridge type, spatial relationship to the city wall (e.g., extramural or intramural), the presence of a cover, and the number of supporting pillars depicted. These attributes help us analyze how a bridge’s position relative to the city wall influenced how prominently and in what manner it was depicted. </p>
                     <p>The obj_part class similarly includes a set of shared attributes — such as name, descriptor, and color — for components of major infrastructures. Subclasses — for example, gate, moat, or shrine — carry specific attributes, including directional orientation, spatial relation to the main wall, and depicted texture. This level of detail allows us to analyze which components of infrastructure received greater visual emphasis over time and how their material qualities were represented.</p>
                     <p>Beyond these infrastructure-related classes, we also include entities for natural features such as landforms and bodies of water. Properties for these features describe their spatial or functional relationship to the city wall. These attributes allow us to explore, for example, how water bodies gained visual prominence during periods of environmental instability, reflecting their growing importance to urban residents amid climate fluctuations and natural disasters.</p>
                     <p>In addition to defining individual entities or tags, we also model the relationships between them. Capturing these relationships makes it possible to analyze the spatial and functional connections not only among different types of infrastructure but also between infrastructure and natural features. These relationships are essential for investigating how maps depict infrastructures within broader urban and environmental landscapes. For instance, we define a crossing relationship between a bridge and a named water body in order to analyze how their spatial positioning reflects shifting infrastructural priorities and environmental concerns.</p>
                     <p>In line with our modeling structure for text sources, we also define a metadata model to store bibliographic information specific to each source type. We provide a small set of predefined metadata models for import and customization, including one for historical printed illustrations, artworks, stele and rubbing, and archeological diagrams. The metadata model includes shared properties with the publication metadata we used in COMARKUS (e.g. gazetteer title, location, author) that support cross-source searches. The metadata model can be set at both the folder and image levels. For gazetteer maps, which are categorized as historical printed illustrations, we record shared metadata at the gazetteer folder level (e.g. title, author, place, and date publication), and image-specific metadata at the individual image level (e.g. volume, page number, and source URL). </p>
                     <p>Figure 8A visualizes this model within an ontological framework, building on the same conceptual structure introduced in Figure 3A. It distinguishes between physical entities — such as infrastructure (reginfra:object_main), their components (reginfra:obj_part), landforms (reginfra:landform), and water bodies (reginfra:water) — and their visual representations on the map, captured as separately annotated shapes (reginfra:annotated_shape). This approach conceptually preserves the distinction between physical entities (including our core entities, their direction, spatial relation to other entities, and other physical features) and their visual rendering. Visual characteristics, including color and texture, are linked to the annotated shape instance. Annotations are also connected to their source images and the corresponding metadata. This framework offers an abstract representation of the annotation types that allow historians to examine the representations of infrastructures and their components, as well as information about map production. </p>
                     <p>Figure 8B shows how this model is implemented through a concrete example: an annotated city map of Yangzhou from the <hi rend="italic">Gazetteer of Weiyang</hi> (<hi rend="italic">Yangzhou Prefecture</hi>) (Zhu and Sheng 1542). The shapes of Yangzhou city wall ("yangzhou_cheng") and its components, such as gate, barbican, moat, are annotated and linked to the physical entities they represent. Other main infrastructures defined in the model, such the bridge “yangzhou_xin_qiao,” are also annotated when present on the map. The visual textures used to depict these entities are recorded using normalized descriptors like “striped” or “layered_interlocking_rectangular_shape.” Spatial relationships between different entities, such as the position of bridges and roads relative to the city wall, or the orientation of gates and barbicans, are recorded as data properties. These annotations are further connected to the map’s metadata, including the gazetteer’s title, compiler, and publication date. Together, Figures 8A and 8B demonstrate how this data model captures the interrelations among infrastructure features, their visual representations, and their contextual metadata.   </p>
                     
                  </div>
                  <div>
                     <head>Collecting and Annotating Images with IMMARKUS</head>
                     <p>IMMARKUS is a browser-based service with which any user can collect, organize, annotate, or transcribe images in a personal annotation workspace, with the optional assistance of a range of open and commercial AI models including their own. Images can be used either directly from the user’s computer, or streamed from libraries, museums, or private collections using the <ref target="https://iiif.io">IIIF-standard</ref> (Snydman et al. 2015). As in COMARKUS described in the previous section, all data produced by the user–annotations, metadata and user-designed data models–are stored locally; all data and models can be exported and shared at the user’s sole discretion. Below we offer a brief description of key functionality focusing on the question of how complex and hierarchically structured annotations can be created in IMMARKUS, for more extensive instructions on these and other aspects we refer to the illustrated IMMARKUS wiki guidelines (De Weerdt et al. 2024a) which are continuously updated with explanations of new features, recommended IIIF collections, and compatible IIIF services.</p>
                     <p> Figures 9A-C illustrate the annotation process using an image of a stele rubbing commemorating the 1446 renovation of the Xuanfu wall; the corresponding transcription in a gazetteer was previously shown in Figures 4A-B.  The Images view (top icon on the left menu) shows the subfolders and images contained in the local or cloud folder selected by the user. In this view folder or image metadata can be viewed or edited, and IIIF images can be imported along with their metadata and structural subdivisions if applicable. In the latter case, images are not downloaded, saving storage space on the user end, but streamed on the basis of the imported IIIF manifest. Clicking on any given image opens up the annotation view. Further images can be added from the top bar and rearranged in a variety of layouts, or users can browse through all images in a given folder. The annotation process consists of several steps. First, the user draws a region on the image, thus creating an image snippet. A wide range of drawing tools can be used, including simple shapes (boxes, ovals, polygons, paths allowing for smooth curves) and AI-powered smart selection tools (smart scissors to quickly and accurately trace complex shapes, edge snap to trace object with straight lines, and auto select to select image parts and refine them automatically by hovering over the image and clicking on the desired part(s)). Image selections can also be added to or subtracted from each other, allowing for the selection of donut-shaped objects and the like. Comments and annotations can also be generated through the auto-transcription of any text in the selected image for which a wide and increasing array of free and commercial AI services have been made available. Image snippets can be edited by dragging, adding or deleting connection points.</p>
                    
                     <p>After an image area has been defined, an entity class (i.e., a tag) can be added to it, for example, in the case of the stele rubbing, this could be an individual rubbing sheet, and/or sections of the stele layout (title, main text, list of sponsors, but also ornament, etc.). Each of these entity classes or user-defined tags can be given attributes and attribute formats can also be specified (including text, number, user-defined list of options, URI, geo-coordinates, measurements, color hex codes, and a range of external authorities). For example, in the case of rubbings and stelae, ornaments can include a list of frequently occurring types (clouds, dragon, turtle, etc) and their location on the stele surface (head or body, front or back, etc), information that can be used to compare the design and layout of different types of infrastructural stelae and rubbings. The location of image parts can be expressed descriptively but also as a relation between two image areas as in Figure 9B. The right panel shows the spatial arrangements of different textual and ornamental elements on the stele surface, supporting analysis of which types of information were emphasized and how. The annotation tools located in the top right of the main annotation window include next to the shape and smart selection tools, a relation annotation tool. Like other annotations, relations can also be given a type attribute. Tags, attributes, and relations can be filled out on the fly, by creating new tags, attributes, or relation types, or they can be selected from pre-defined models under the Data Model menu — newly added entities and relations in annotation view will also be included in the corresponding data models. Existing annotations as well as image metadata can be viewed, modified, or deleted from the tabs on the right pane. </p>
                     <p>We generally recommend that different source types be organized in separate folders so that appropriate data models can be designed for them and so that data models do not become unwieldy. While it is possible to select from a range of metadata models, only one data model can be applied to a project (a folder with or without subfolders), ideally this model is designed to align with appropriate disciplinary and methodological practices and address specific research questions. We illustrate this with another example.  In the infrastructural history project, we work with archaeological diagrams alongside historical maps, photographs of stelae, and rubbings. Figure 10 illustrates the use of a data model tailored to archaeological diagrams. The entities used in the annotation of the diagram are suited to the source type; they are also tailored to the specific questions in infrastructural history we aim to address.</p>
                     <p>Objects are excavated in campaigns that occur in irregular patterns over extended periods of time, with different institutions involved in the excavations. The written reports that serve as the source of these diagrams use documentation standards that are inconsistent across reports and evolve over time. Compiling data on infrastructure remains excavated at complex or multiple sites is therefore a challenge. At the same time, archaeological image documentation — particularly stratigraphic diagrams — offers valuable insight into the spatial and temporal relationships among strata and structures. Stratigraphy, a concept adapted from geology, describes the layering of ground at a site. The stratification of each site is governed by the principles of archaeological stratigraphy, it provides essential context for archaeological findings, delineating distinct phases and sequences of site use (Harris 1989; May 2020), including historical infrastructure. </p>
                     <p>Figure 10 (left) demonstrates that archaeological site maps contain various types of location information critical for interpreting both the image and the excavation it represents. Because of modern development and urbanization, parts of these structures often remain buried beneath contemporary cities. The darker blue squares indicate the locations of different excavations, which — across multiple publications — help reconstruct the outlines of city walls (green), roads (light blue), bridges (red), and other features. All of this information can be annotated and integrated using IMMARKUS. The image on the right in Figure 10, showing the annotation view in IMMARKUS, features a stratigraphic diagram derived from excavation reports. Relationships between strata are encoded using the Relation function, which models the physical relationships of layers and their relative chronologies. In this example, the annotations capture different phases of use and abandonment of the city walls with the directed relation “covers” that indicates that the source entity is positioned above the target entity: Layer 6 (brown) which contains traces of a trampled dirt road, covers earlier city wall phases (green) labeled 7 and 8. In turn, Layer 6 is overlaid by a new construction phase, represented by the remains of walls labeled 5A and 5B. The data model implemented in the annotation view of the site plan and stratigraphic diagram in Figure 10 is designed to depict relationships on an archaeological site, and IMMARKUS allows researchers to capture them by selecting and relating the image regions to which they correspond (Stojević under review).</p>
                    
                  </div>
                  <div>
                     <head>Querying and Analyzing Image Annotations in IMMARKUS and X-MARKUS</head>
                     <p>All annotation data and metadata of a given image corpus can be viewed, filtered, and queried in the knowledge graph. The default view (Hierarchy and Annotation mode) displays all images (blue nodes) and entity or tag classes (green nodes), connected by blue edges that indicate which entities or tags have been used to annotate which images. Users can adjust the display by clicking the settings icon at the bottom right corner of the screen, allowing them to change how data is shown — for example, hiding text labels for better visibility. To run a query, users can click the magnifying glass icon (circled in blue in Figure 11) to open the graph search dialogue box and enter search conditions. Figure 11 shows a query for images with annotations of walls depicted in interlocking layered rectangular shapes on maps preserved in Shandong gazetteers, spanning the Ming to the Qing dynasties. In the central panel, blue nodes indicate all images matching the query criteria. Selecting a specific image (marked with an orange circle) reveals the entity classes used in the annotation of the selected image as connected green nodes. Annotations for the selected image are also listed in the right-hand panel, from where users can move to the source image in the Image Gallery, explore relationship annotations, or edit the image’s metadata.</p>
                     <p>The query results––including annotations, metadata (user-supplied or imported through IIIF), and relations between annotations––can be exported in JSON for further analysis or, along with image snippets, in CSV.  The exported data can, in the example of city wall maps, be used to visualize changes in cartographic conventions for depicting wall layouts and materials across different periods and regions. The data obtained from queries like the one displayed in Figure 11 yields the insight that the use of bricks in city walls appeared in gazetteer map symbology from the early seventeenth century onwards, reflecting growing attention to materiality (Lee 2024). The IMMARKUS wiki include a fuller explanation of all functionality in the knowledge graph (De Weerdt et al. 2024a). </p>
                    
                     <p>The knowledge graph in IMMARKUS offers powerful querying options, but it is limited to one project. In order to query across image annotation projects (for example, historical maps, stelae, rubbings, archeological diagrams, and photographs of infrastructural objects) or to query across textual and image datasets we designed X-MARKUS to detect shared entity types and entity properties as well as shared metadata fields in different datasets. We first identified shared entities or tags, shared external authorities in properties, and shared metadata fields in the ontologies described in the Appendix. We then used this as the basis for the complex task of visualizing relationships between different and cross-media datasets, thus making information about the same objects or the same location, or from the same source or author more easily discoverable. The photographic images of stone stelae and rubbings described above on one hand, and the event annotation data discussed in sections two on the other, provide a first example. In this case, the source metadata (title, place and place id, infrastructure type, year, author and author id, etc.) and the main object name and id can be linked to data and metadata in the event annotation of the transcribed text included in one or more local gazetteers. The inscription text shown above in Figures 4A-B was likely transcribed into the county gazetteer from the stele represented in the rubbing shown in Figures 9A-B; stele and transcription can in this case be linked through their metadata. Collecting and developing a data model for stone stelae and rubbings ensures that other elements such as stone size and format, its placement, the layout and font size of textual elements, decorations, front and back inscriptions with, for example, the names and social roles of people often not included in the transcriptions of stelae in local gazetteers offer additional inroads into the social history of infrastructures (De Weerdt et al. under review). In the design of X-MARKUS, shared metadata across different sources can be matched through multiple conditioned queries within a combined image and text corpus. For instance, a query might search for a piece title in a textual source and a stele title in an image source, while also requiring that the author’s identifier in external authority databases (CBDB ID 67470) is the same in both sources. The query yields a filtered network graph, as shown in Figure 12, where sources that meet the query criteria are displayed along with the features extracted from their annotations. With the relevant objects displayed in the graph, additional research can be performed on their similarities and differences. For example, the differences between the stele text transcribed in the annotation of the image and the gazetteer text can be easily researched with text comparison algorithms like PARALLELLS (De Weerdt and Gelein 2021). </p>
                     
                     <p>Lest this example is still too text-oriented, Figure 13 offers an example of how archeological diagrams, historical maps, and texts can be made discoverable in the same environment. When annotating the wall complexes of Yangzhou as documented in archaeological report diagrams, we used the same entity classes and properties as those used in textual inscriptions related to walls –– such as object (wall) name, material, dimensions, and TGAZ ID (indicating the location of the historical jurisdiction). Most of these entities and properties are also used in the annotation of historical city and regional maps.</p>
                     
                     <p>The use of these entity or tag classes and the same external authorities for their properties allows us to call up annotations added to sources in different media and compare the information, arguments, and perspectives expressed in them. It allows us to assess what may have been unknown or left out in textual accounts that often lack information about early foundations. Conversely, it also allows us to examine how archeologists select and selectively interpret historical accounts. Overall, it is a step forward in the direction of the mapping out of the poor state of the archeology of infrastructure (Wilkinson 2018). The link with maps on which color and pattern are sometimes used to represent materials similarly allows for the comparison of materials identified and represented on stratigraphic diagrams or the representation thereof in infrastructural events in gazetteer texts. </p>
                     <p>In sum, the logic of contextual annotation in COMARKUS and image annotation in IMMARKUS is very similar, with the image selections drawn by a user serving as the equivalent of a contextual or event annotation. The image selection serves as the space within which entities and their properties are grouped together. Whereas in contextual annotation, an event or cluster structures entities and their ids and acquires these as attributes, in image annotation an image snippet acquires an entity and its properties as attributes. The knowledge graph function in X-MARKUS builds on this shared logic to identify and link common features and their hierarchical structure across text and image sources, enabling integrated research and comparison.</p>
                  </div>
               </div>
               <div>
                  <head>Conclusion: Contextualizing data through annotation and the creation of contexts in platform design</head>
                  <p>In the design of COMARKUS and IMMARKUS we have sought to offer a set of methods that allow researchers to contextualize entities and tagged content and thus create contextualized data. Annotation in COMARKUS and IMMARKUS starts from the modeling of source texts and images and steers the researcher from simple tagging towards structuring annotations into higher-order entities with properties that capture semantic relationships as she reads them in texts and images. </p>
                  <p>As we have illustrated on the basis of the creation of an event-based dataset of material infrastructures, this has allowed us to lay the foundation for an entirely new way to interpret the history of infrastructures. As digital historians and digital humanists we have sought to contextualize inscriptional and other sources in ways that allow us to reinterpret the social and political construction of infrastructures alongside the demolition, repair, and failures at different scales and in relation with environmental, demographic, military, and political conditions. By examining social events of infrastructural history and by reading data from textual inscriptions in the context of data created from material objects, archeological diagrams, and maps we are also prompted to reflect on the situatedness of each of the source types and genres included in our analysis. Figure 14 presents our design for the digital historical data journey in a flow chart — mapping the stages from source selection and corpora curation to data modelling, annotation, and integration across media and platforms, including feedback loops for the use of AI, at this stage mainly in entity, event, and image annotation and data analysis, but this is extensible to all stages.</p>
                  
                  <p>To make good use of the methods presented here also requires the reading and analysis of the data resulting from contextual annotation in an environment that maximizes contextual reading opportunities. Texts annotated in ENTMARKUS and COMARKUS can be transformed into textual databases in X-MARKUS with tagged content, metadata, and relations between entities and tags brought into view as filters, and free form comments providing the kind of free annotation environment that is part of the humanities scholarly habitus (Bradley 2012). Further contextualization is offered by the option to define different operations on entities linked to external authorities, most notably the option to create spatial layers and network tables and visualizations, and examine the resulting data in a range of quantitative infographs, with datapoints hyperlinked to the annotated source texts. MUNDa infographs allow the user to interpret attributes in context, including absence of information for each record in its information displays. Thus, to examine labor, material, or action causes in particular types of events, the percentage of records for which no such information is available is also shown. Spatial layers can be further examined against existing historical spatial and other layers. Data can be exported in XML, CSV, and KML formats.</p>
                  <p>IMMARKUS was initially designed to facilitate the creation of project-specific image databases with similar functionality and, through the integration of IMMARKUS data in X-MARKUS, to facilitate contextualization across media and across text and graphic genres. By investing in cross-media methodological design, we have been able to go further than first anticipated. We are comparing and correlating the spread of the use and representation of materials such as brick not only in texts, but also in symbology of county maps from the Song through the Qing dynasties (Lee under review a). We can write a better-informed social history of infrastructural projects by comparing social and political actors in texts transcribed in gazetteers to the texts and layout of infrastructural stelae and rubbings and, in this way, set out their different social and political profiles (De Weerdt et al. under review). </p>
                  <p>	Nevertheless, as we stated in the introduction, contextualization remains an unfulfilled mission and a moving target. Much context is already dropped when selecting a particular rendition of a text, object or graphic for analysis. In our own project, we see more room and need for historians to try and represent the full dimensionality of their sources, including not only their location in space and time, but also their transformation and the transformation of their relations to other sources (De Weerdt under review). Similarly, the combination of text- and image-based data in data visualization and analysis remains a challenge, one that will hopefully open up new possibilities for reading, analyzing, and interpreting primary texts, graphic representations of historical objects, and secondary constructions together.  </p>
               </div>
            </div>
         </div>
      </body>
      <back>
         <listBibl>
            <bibl/>
         </listBibl>
      </back>
   </text>
</TEI>
