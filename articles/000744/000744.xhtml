<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>[PREVIEW] DHQ: Digital Humanities Quarterly: </title>
      <link href="../../common/css/dhq.css" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_screen.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_print.css" media="print" type="text/css" rel="stylesheet" />
      <style type="text/css">
        #mainContent {
          float: none;
          padding-top: 2em;
          padding-left: 4em;
          padding-right: 4em;
          margin-left: 225px;
           
        }</style>
   </head>
   <body>
      <div id="mainContent">
         <div class="DHQarticle">
            <div id="pubInfo">Preview<br />Volume  Number </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            
            <div class="DHQheader">
               
               
               
               <h1 class="articleTitle lang en">Deep Learning for Historical Cadastral Maps and Satellite Imagery Analysis: 
                  Insights from Styria's Franciscean Cadastre</h1>
               
               <div class="author"><span style="color: grey">Wolfgang Thomas Göderle
                     </span></div>
               
               <div class="author"><span style="color: grey">Fabian Rampetsreiter
                     </span></div>
               
               <div class="author"><span style="color: grey">Christian Macher
                     </span></div>
               
               <div class="author"><span style="color: grey">Katrin Mauthner
                     </span></div>
               
               <div class="author"><span style="color: grey">Oliver Pimas
                     </span></div>
               
               
               
               
               
               
               
               <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Deep%20Learning%20for%20Historical%20Cadastral%20Maps%20and%20Satellite%20Imagery%20Analysis%3A%20Insights%20from%20Styria's%20Franciscean%20Cadastre&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=&amp;rft.volume=&amp;rft.issue=&amp;rft.aulast=Göderle&amp;rft.aufirst=Wolfgang Thomas&amp;rft.au=Wolfgang Thomas%20Göderle&amp;rft.au=Fabian%20Rampetsreiter&amp;rft.au=Christian%20Macher&amp;rft.au=Katrin%20Mauthner&amp;rft.au=Oliver%20Pimas"> </span></div>
            
            <div id="DHQtext">
               
               
               <div id="abstract">
                  <h2>Abstract</h2>
                  
                  <p>Cadastres from the 19th century are a complex as well as rich source for historians
                     and archaeologists, the study of which 
                     presents great challenges. For archaeological and historical remote sensing, we have
                     trained several Deep Learning models, CNNs, 
                     and Vision Transformers to extract large-scale data from this knowledge representation.
                     We present the principle results of our 
                     work here and demonstrate our browser-based tool that allows researchers and public
                     stakeholders to quickly identify spots that 
                     featured buildings in the 19th century Franciscean cadastre. The tool not only supports
                     scholars and fellow researchers in 
                     building a better understanding of the settlement history of the region of Styria; it also helps public 
                     administration and fellow citizens to swiftly identify areas of heightened sensibility
                     with regard to the cultural heritage of the 
                     region.
                     </p>
                  </div>
               
               
               
               
               <div class="div div0">
                  
                  
                  <div class="counter"><a href="#p1">1</a></div>
                  <div class="ptext" id="p1">Cadastral maps, which were produced with meticulous quality standards from the early
                     19th century onwards for large parts of 
                     Europe, offer a unique and complex representation of knowledge [<a class="ref" href="#goderle_2017">Göderle 2017</a>] 
                     [<a class="ref" href="#goderle_2023">Göderle 2023</a>] [<a class="ref" href="#wheeler_2023">Wheeler 2023</a>] [<a class="ref" href="#femenia-ribera_mora-navarro_santos-perez">Femenia-Ribera et al. 2022</a>]. In the 
                     case of Habsburg Central Europe, where cadastral mapping occurred between 1816 and 1861, these maps 
                     provide detailed information on individual houses at a scale ranging from 1:720 to
                     1:5760, with a standard scale of 1:2880. They 
                     also document land use, contemporary roads and pathways, land boundaries, and other
                     relevant data 
                     [<a class="ref" href="#katastral_1824">Katastral-Vermessungs Instruktion 1824</a>] [<a class="ref" href="#bundesamt_2017">Bundesamt 2017</a>, 44]. Apart from their historical significance, cadastral maps 
                     are valuable for contemporary spatial analysis, including environmental and transport
                     history, building history, and economic and 
                     social history, as well as questions related to land use and landscape transformation
                     in the Anthropocene era and resource 
                     extraction during the time of their creation [<a class="ref" href="#stahl_weimann_2022">Ståhl and Weimann 2022</a>] <span class="error"><a class="ref" href="roberts_et_al_2024">roberts_et_al_2024</a></span>.
                     </div>
                  
                  <div class="figure">
                     
                     
                     
                     <div class="ptext"><a href="resources/images/figure01.png" rel="external"><img src="resources/images/figure01.png" style="width: 700px" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 1. </div>Extract from cadastre from 1828. Wooden houses are visible in yellow, along with paths
                        and agricultural land.</div>
                  </div>
                  
                  <div class="counter"><a href="#p2">2</a></div>
                  <div class="ptext" id="p2">Cadastral maps constitute a key resource for historical research into this region,
                     as they enable the spatialization of historical 
                     processes, contexts, and interdependencies. However, accessing and processing cadastral
                     data can be challenging due to their 
                     multimodal structure and primary focus on images and geodata. This presents difficulties
                     for digital humanities researchers, 
                     whose work is often located in the textual domain [<a class="ref" href="#champion_2017">Champion 2017</a>] <span class="error"><a class="ref" href="#van-noord_2022">#van-noord_2022</a></span>. We are convinced 
                     that recent advances in the field of deep neural networks enable multimodal analysis
                     of historical sources 
                     [<a class="ref" href="#smits_wevers_2020">Smits and Wevers 2020</a>]. This would, in turn, open up new opportunities to analyze those non-written sources
                     that 
                     emerged in Europe (as well as globally) in the long 19th century. Sources such as the cadastre are
                     unique and central 
                     representations of knowledge from this period, but have so far been insufficiently
                     analyzed, especially in social and economic 
                     history research ([<a class="ref" href="#hosseini_et_al_2021">Hosseini et al. 2021</a>].
                     </div>
                  
                  <div class="counter"><a href="#p3">3</a></div>
                  <div class="ptext" id="p3">Digitization has made cadastres more accessible to a wider audience, although accessing
                     the physical volumes stored in archives 
                     remains challenging for historians and researchers [<a class="ref" href="#bundesamt_2017">Bundesamt 2017</a>] 
                     [<a class="ref" href="#femenia-ribera_mora-navarro_santos-perez">Femenia-Ribera et al. 2022</a>] [<a class="ref" href="#hagemans_et_al_2022">Hagemans et al. 2022</a>] [<a class="ref" href="#mcdonough_2024">McDonough 2024</a>]. 
                     Despite digitization efforts, the comprehensive evaluation of cadastral data, particularly
                     in Habsburg Central 
                     Europe, where 300,000 square kilometers were surveyed between 1816 and 1861, remains labor-intensive
                     due to the sheer 
                     volume of individual map sheets documenting every aspect of land use and property
                     [<a class="ref" href="#bundesamt_2017">Bundesamt 2017</a>].
                     </div>
                  
                  <div class="counter"><a href="#p4">4</a></div>
                  <div class="ptext" id="p4">The 2022 Austrian Science Fund (FWF) project RePaSE (Reading the Past from the Surface
                     of the Earth) aimed to use AI-assisted 
                     extraction to identify historical building outlines and locations from geo-referenced
                     map sheets of the Franziszeische Kataster 
                     (Franciscean Cadastre).<a class="noteRef" href="#d4e326">[1]</a> This involved training an AI model for 
                     building extraction from both historical maps and modern, high-resolution aerial and
                     satellite images. By overlaying the extracted 
                     historical and present-day building information, the project sought to identify potential
                     archaeological sites, facilitating 
                     large-scale archaeological remote sensing. The hypothesis driving RePaSE is that by
                     combining historical cadastral map data with 
                     modern satellite imagery, it's possible to identify regions where buildings once stood,
                     aiding in the discovery of vanished structures 
                     and potentially significant archaeological sites.
                     </div>
                  
                  <div class="counter"><a href="#p5">5</a></div>
                  <div class="ptext" id="p5">In addition to the cadastre, we worked with current spatial images in our study. We
                     were supported by the relevant department of 
                     the Province of Styria, which provided us with high-resolution aerial photographs from different flight
                     periods as 
                     well as two digital terrain models. It has been shown that even the transfer of information
                     from georeferenced historical map 
                     images to different spatial representations of the present has enormous cognitive
                     potential. We were able to draw on 
                     high-resolution aerial photographs from 1952; images from the 1970s, 1980s, and 1990s;
                     and current and extremely accurate images 
                     from recent years.
                     </div>
                  
                  <div class="counter"><a href="#p6">6</a></div>
                  <div class="ptext" id="p6">The results of RePaSE, and the tools that emerge from it, should create opportunities
                     for digital humanities researchers to 
                     analyze the information contained in historical maps. Possibilities for automated
                     segmentation of the information contained 
                     therein would enable us to further quantitatively process data contained in maps and
                     to utilize new possibilities for qualitative 
                     analysis [<a class="ref" href="#hosseini_et_al_2021">Hosseini et al. 2021</a>]. In HGIS systems that contain georeferenced historical maps, it is already possible
                     
                     to calculate areas; thus, automated segmentation would significantly advance historical
                     analysis 
                     [<a class="ref" href="#baeten_lave_2020">Baeten and Lave 2020</a>]. Furthermore, new feature complexes could be defined and searched for automatically,
                     extending 
                     the logics of distant reading to map analysis [<a class="ref" href="#arnold_tilton_2019">Arnold and Tilton 2019</a>]. For example, mills not explicitly identified in 
                     the French cadastre could be automatically identified, which would allow a profound
                     analysis of hydropower use in Central 
                     Europe in the early 19th century and enable the investigation of local or regional differences.
                     </div>
                  
                  <div class="counter"><a href="#p7">7</a></div>
                  <div class="ptext" id="p7">We do not consider cadastre, satellite photograph, or aerial photography authentic
                     representations of reality. Rather, we treat 
                     them as high-profile sources providing us with several layers of research data [<a class="ref" href="#gil-fournier_parikka_2021">Gil-Fournier and Parikka 2021</a>] 
                     [<a class="ref" href="#hosseini_et_al_2021">Hosseini et al. 2021</a>].
                     </div>     
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">State of Research</h1>
                  
                  <div class="counter"><a href="#p8">8</a></div>
                  <div class="ptext" id="p8">Despite the accessibility challenges mentioned above, there is substantial historical
                     research that deals either with the 
                     construction of cadastral maps or with the information stored in them [<a class="ref" href="#dolejs_forejt_2019">Dolejš and Forejt 2019</a>]. Prior to their 
                     digitization, cadastral maps have already played an important role in historical and
                     particularly archeological research on the 
                     micro-level [<a class="ref" href="#petek_urbanc_2004">Petek and Urbanc 2004</a>]. Cadastral maps have long been a research resource with regard to genealogical 
                     research. They have been used as sources in agricultural and environmental history,
                     environmental studies, archeological remote 
                     sensing, social and economic history, and in the development of a broader understanding
                     of the evolution of landscapes 
                     [<a class="ref" href="#drobesch_2013">Drobesch 2013</a>] [<a class="ref" href="#rumpler_2013">Rumpler 2013</a>] [<a class="ref" href="#scharr_2024">Scharr 2024</a>] 
                     [<a class="ref" href="#rumpler_scharr_ungureanu_2015">Rumpler, Scharr, and Ungureanu 2015</a>] [<a class="ref" href="#hohensinner_et_al_2021">Hohensinner et al. 2021</a>]. Their value, however, has frequently been 
                     limited by accessibility issues and the difficulties of extending analysis beyond
                     relatively limited borders.
                     </div>
                  
                  <div class="counter"><a href="#p9">9</a></div>
                  <div class="ptext" id="p9">Access to historical cadastral maps in Central Europe became publicly available relatively late, with data now 
                     accessible through projects like Arcanum Maps (https://maps.arcanum.com/en/).<a class="noteRef" href="#d4e390">[2]</a> In most cases, the digitization of cadastral maps is accompanied by georeferencing.
                     
                     However, these repositories often lack comprehensive metadata and may require payment
                     for research use. Public authorities have 
                     increasingly made parts of the Franziszeische Kataster available online for research
                     purposes, offering data at various quality 
                     levels for free [<a class="ref" href="#pivac_et_al_2021">Pivac et al. 2021</a>]. Exploration of historical map data, including cadastral maps, has accelerated 
                     due to recent advancements in machine learning [<a class="ref" href="#chiang_et_al_2020">Chiang et al. 2020</a>] [<a class="ref" href="#budig_2017">Budig 2017</a>]. Deep learning 
                     technologies, in particular, have revolutionized feature extraction [<a class="ref" href="#chen_et_al_2016">Chen et al. 2016</a>], focusing on streets 
                     [<a class="ref" href="#ekim_sertel_kabaday%C4%B1_2021">Ekim, Sertel, and Kabadayı 2021</a>] [<a class="ref" href="#can_gerrits_kabaday%C4%B1_2021">Can, Gerrits, and Kabadayı 2021</a>] [<a class="ref" href="#jiao_heitzler_hurni_2021">Jiao, Heitzler, and Hurni 2021</a>] 
                     [<a class="ref" href="#jiao_heitzler_hurni_2022">Jiao, Heitzler, and Hurni 2022</a>] [<a class="ref" href="#uhl_et_al_2022">Uhl et al. 2022</a>] and buildings [<a class="ref" href="#heitzler_hurni_2020">Heitzler and Hurni 2020</a>] 
                     [<a class="ref" href="#uhl_et_al_2020">Uhl et al. 2020</a>], among other applications [<a class="ref" href="#wu_et_al_2023">Wu et al. 2023</a>] 
                     [<a class="ref" href="#petitpierre_kaplan_di-lenardo_2021">Petitpierre, Kaplan, and Di Lenardo 2021</a>] [<a class="ref" href="#garcia-molsosa_et_al_2021">Garcia-Molsosa et al. 2021</a>].
                     </div>
                  
                  <div class="counter"><a href="#p10">10</a></div>
                  <div class="ptext" id="p10">These advancements offer new possibilities for researchers in history, archaeology,
                     and historical geography. Recent research has 
                     focused on feature extraction from cadastral maps, particularly in the context of
                     the Venetian cadastre and the 1900 Atlas of 
                     Paris [<a class="ref" href="#oliveira_et_al_2019">Oliveira et al. 2019</a>] [<a class="ref" href="#petitpierre_guhennec_2023">Petitpierre and Guhennec 2023</a>]. As Petitpierre and 
                     Guhennec point out, consistent annotation is the main challenge with regard to automatized
                     vectorization. However, 
                     the bulk of current research is directed towards the analysis of aerial and satellite
                     imagery 
                     [<a class="ref" href="#jiao_heitzler_hurni_2022">Jiao, Heitzler, and Hurni 2022</a>]. This research spans a wide range of objectives and interests, with stakeholders
                     
                     including municipal and urban administrations, as well as archaeological remote sensing
                     missions. Significant attention has also 
                     been given to LIDAR data and research on urban landscape transformation, in addition
                     to real-time surveillance tasks involving 
                     UAVs [<a class="ref" href="#li_et_al_2022">Li et al. 2022</a>] [<a class="ref" href="#li_et_al_2023">Li et al. 2023</a>] [<a class="ref" href="#ji_wei_lu_2019">Ji, Wei, and Lu 2019</a>]  
                     [<a class="ref" href="#fiorucci_et_al_2020">Fiorucci et al. 2020</a>] [<a class="ref" href="#fiorucci_et_al_2022">Fiorucci et al. 2022</a>] [<a class="ref" href="#bickler_2021">Bickler 2021</a>] 
                     [<a class="ref" href="#ren_et_al_2015">Ren et al. 2015</a>] [<a class="ref" href="#ding_zhang_2021">Ding and Zhang 2021</a>] [<a class="ref" href="#luo_wu_wang_2022">Luo, Wu, and Wang 2022</a>] 
                     [<a class="ref" href="#lee_wang_lee_2023">Lee, Wang, and Lee 2023</a>] [<a class="ref" href="#chen_zou_shi_2021">Chen, Zou, and Shi 2021</a>] [<a class="ref" href="#uhl_et_al_2021">Uhl et al. 2021</a>].
                     </div>
                  
                  <div class="counter"><a href="#p11">11</a></div>
                  <div class="ptext" id="p11">The Franciscean Cadastre, covering an extensive area of Habsburg Central Europe spanning around 
                     300,000 square kilometers, stands out as an exceptional historical source. Its nearly
                     half-century production period and stringent 
                     quality standards provide historians, archaeologists, and environmental scientists
                     with privileged insights into 19th-century 
                     land use and spatial organization ([<a class="ref" href="#feucht_2008">Feucht 2008</a>]. Nevertheless, the cadastre also contains inaccuracies and errors, 
                     which are magnified by the size of the operation. It represents a historical primary
                     source and as such requires meticulous and 
                     thorough critical reading. Werner Drobesch has recently provided the first comprehensive analysis of the economics of 
                     the cadastre. From this and from the savings constraints he has pointed out, there
                     are also comprehensive indications of the 
                     weaknesses of this source [<a class="ref" href="#scharr_2024">Scharr 2024</a>]. Further, a great deal of the accuracy of the Franciscean Cadastre depends 
                     on the quality of the individual's work. The scale of the recording varies considerably,
                     with a high level of detail in urban 
                     areas, a medium level of detail in rural areas, and very coarse details in exposed
                     terrain and high mountains. Many of the 
                     weaknesses encountered in dealing with the Franciscean Cadastre resemble those that
                     Hosseini et al. describe and 
                     scrutinize in detail with regard to the Ordnance Survey [<a class="ref" href="#hosseini_et_al_2021">Hosseini et al. 2021</a>].
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Objective</h1>
                  
                  <div class="counter"><a href="#p12">12</a></div>
                  <div class="ptext" id="p12">The objective of RePaSE was twofold: first, RePaSE should prove that AI-assisted extraction
                     of large amounts of data — in our use 
                     case, the location and the form of buildings — from the cadastre is already possible
                     with existing resources and, in the best 
                     case, identify suitable models to that purpose.<a class="noteRef" href="#d4e495">[3]</a> The second objective was to make RePaSE fit for future multimodal applications 
                     and to identify and test models that could be used to extract the locations and forms
                     of buildings from current, already available 
                     aerial and satellite imagery that is already available [<a class="ref" href="#smits_wevers_2023">Smits and Wevers 2023</a>].
                     </div>
                  
                  <div class="counter"><a href="#p13">13</a></div>
                  <div class="ptext" id="p13">The larger context in which our work is embedded is the question of the possibilities
                     that deep neural networks open up for the 
                     work of historians, archaeologists, and other humanities scholars. A central challenge
                     that we are addressing with this project is 
                     to make the huge data structures that represent historical cadastres searchable at
                     a higher level of analysis. On the one hand, we 
                     see potential for a quantitative economic and social history. Structuring and classifying
                     the information encoded in cadastres 
                     would make it possible to analyze land use at regional or provincial level, for example.
                     In the field of archaeology, a 
                     cost-effective type of remote sensing in the automated comparison of historical and
                     current visual representations of space would 
                     allow faster identification of potentially archaeologically relevant large-scale historical
                     structures. On the other hand, our 
                     tool would also make it possible to extend the archaeological view to larger spatial
                     units with relatively little effort and to 
                     better visualize translocal or regional contexts for experts.
                     </div>
                  
                  <div class="counter"><a href="#p14">14</a></div>
                  <div class="ptext" id="p14">Our research strategy involved two main sub-tasks: Task 1 focused on detecting buildings
                     in scans of historical cadastral map 
                     data, while Task 2 aimed to detect buildings in current satellite and aerial imagery.
                     We then superimposed the output layers of 
                     both tasks, specifically targeting places where buildings were present in the cadastre
                     but absent in the present. This overlay 
                     combined historical cadastral map data with current satellite imagery, allowing us
                     to identify relevant locations for further 
                     analysis. These locations were then utilized for analyzing different spatial representations,
                     including satellite and aerial 
                     imagery.
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Approach</h1>
                  
                  <div class="counter"><a href="#p15">15</a></div>
                  <div class="ptext" id="p15">Because the size of the annotated map patches had a significant impact on the performance
                     of our models, we resized all map 
                     patches to the uniform size of 3747x2235, which proved effective. We also employed
                     three different zoom levels: close, medium, 
                     and far. We then used the software tool cvat to annotate the map patches [<a class="ref" href="#cvat_n.d.">CVAT n.d.</a>]. The first task to be 
                     addressed was an image segmentation problem, in order to successfully extract houses
                     from cadastral map material. In our first 
                     attempt, we followed a low-key approach and tried clustering algorithms to tackle
                     this challenge, which was unsuccessful. In line 
                     with the fail-fast approach of our proof-of-concept study, we subsequently turned
                     to a completely different method. When it comes 
                     to deep neural networks in this area of application, convolutional neural networks
                     (CNN) have outperformed other architectures in 
                     recent years [<a class="ref" href="#rawat_wang_2017">Rawat and Wang 2017</a>] [<a class="ref" href="#oshea_nash_2015">O'Shea and Nash 2015</a>]. A CNN is a type of deep learning algorithm that is 
                     well-suited for analyzing visual data. It uses principles from linear algebra, especially
                     convolution operations, to extract 
                     features and identify patterns within images. CNNs use a series of layers, each of
                     which detects different features of an input 
                     image. Depending on the complexity of its intended purpose, a CNN can contain dozens,
                     hundreds, or even thousands of layers. As 
                     building extraction can be considered a computer vision problem, fully convolutional
                     networks are the most widespread 
                     state-of-the-art solution to address this kind of problem [<a class="ref" href="#chen_zou_shi_2021">Chen, Zou, and Shi 2021</a>]. We therefore chose the Google 
                     DeepLabv3 model [<a class="ref" href="#chen_et_al_2016">Chen et al. 2016</a>], which is very efficient in dealing with the multi-scale problem due to its 
                     atrous convolution layer [<a class="ref" href="#chen_et_al_2016">Chen et al. 2016</a>]. We finetuned DeepLabv3 with 50 annotated example images that we split 
                     into 6 squares each to give 300 images in total. The images were split into training,
                     testing, and validation sets according to 
                     the following scheme:
                     </div>
                  
                  <div class="figure">
                     
                     
                     
                     <div class="ptext"><a href="resources/images/figure02.png" rel="external"><img src="resources/images/figure02.png" style="width: 700px" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 2. </div>Finetuning the DeepLabv3 model. Blue = validation data, red = training data, and green
                        = test data.</div>
                  </div>
                  
                  <div class="counter"><a href="#p16">16</a></div>
                  <div class="ptext" id="p16">The validation set was automatically populated with squares lacking buildings to teach
                     the model the absence of structures, which 
                     accounts for its larger size compared to the test and train sets. Each dataset (train,
                     test, validation) contained unique images 
                     without duplication across sets. Finetuning utilized a repository designed for transfer
                     learning in semantic segmentation 
                     [<a class="ref" href="#singh_popescu_2021">Singh and Popescu 2021</a>], building upon DeepLabv3 with Resnet 101. Finetuning spanned 20 epochs on various
                     computing 
                     platforms until satisfactory results were achieved [<a class="ref" href="#pytorch_n.d.">PyTorch n.d.</a>].
                     </div>
                  
                  <div class="counter"><a href="#p17">17</a></div>
                  <div class="ptext" id="p17">The second task to be addressed was another image segmentation problem: the extraction
                     of buildings from high-resolution aerial 
                     and satellite data. As the quality of freely available satellite imagery has further
                     increased in the two years between the setup 
                     of the project idea and the project execution, we could now use higher quality satellite
                     imagery than we originally expected, as 
                     well as add high-resolution aerial photography and LiDAR data to the research data
                     under scrutiny. Unlike the 19th century 
                     cadastral map data that we were dealing with in Task 1, we were addressing an entirely
                     different problem here, as buildings in 
                     ortho- and satellite imagery can take on a wide range of very different appearances.
                     
                     </div>
                  
                  <div class="counter"><a href="#p18">18</a></div>
                  <div class="ptext" id="p18">Due to the significantly different challenge, we chose an adapted approach. Vision
                     transformers break down input images into 
                     patches, convert each patch into a vector, and then process those vectors using a
                     transformer encoder. This allows the model to 
                     understand the content of the image, and this method has been used for various computer
                     vision tasks such as image recognition, 
                     image segmentation, and object detection. Vision transformers offer relatively economic
                     computational overhead and memory 
                     consumption while still achieving state-of-the-art accuracy [<a class="ref" href="#chen_zou_shi_2021">Chen, Zou, and Shi 2021</a>]. We therefore trained a sparse 
                     token transformer (STTnet) from scratch, using a GPU. STTnet is a state-of-the-art
                     vision transformer with very promising results 
                     in comparable tasks [<a class="ref" href="#chen_zou_shi_2021">Chen, Zou, and Shi 2021</a>].
                     </div>
                  
                  <div class="counter"><a href="#p19">19</a></div>
                  <div class="ptext" id="p19">Building on Resnet50 as backbone, we then selected 2,657 labelled images from the
                     AIRS dataset. This was so that we could avoid 
                     labelling houses in the satellite images ourselves. The effort for this would have
                     been considerable, because training from 
                     scratch requires substantially more training examples than does finetuning. All images
                     resembled the Alpine topography and the 
                     landscape characteristics of our target region, Styria. We also used images taken in Austin, 
                     TX; Chicago, IL; Kitsap, WA; Tyrol (a historical 
                     region in the Alps of northern Italy and western Austria; and Vienna, Austria. 
                     The training took place over 98 epochs; once the loss rate and the F1 score did not
                     feature significant changes anymore, the 
                     training was considered completed. The model was then tested with 224 labelled images.
                     </div>
                  
                  <div class="counter"><a href="#p20">20</a></div>
                  <div class="ptext" id="p20">Subsequently, the extracted layers were superimposed and negative profiles were created.
                     The negative profiles contain 
                     potentially interesting locations for archaeological research. While these locations
                     once featured buildings, they are not 
                     overbuilty at present.
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Results</h1>
                  
                  <div class="counter"><a href="#p21">21</a></div>
                  <div class="ptext" id="p21">The results for Task 1, the extraction of buildings from cadastral maps via DeepLabv3,
                     were very successful.
                     </div>
                  
                  <div class="figure">
                     
                     
                     
                     <div class="ptext"><a href="resources/images/figure03.png" rel="external"><img src="resources/images/figure03.png" style="width: 700px" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 3. </div>Building extraction from cadastral maps with finetuned DeepLabv3.</div>
                  </div>
                  
                  <div class="counter"><a href="#p22">22</a></div>
                  <div class="ptext" id="p22">As can be seen from the images, the extraction of red houses (stone houses), for which
                     the model was finetuned, worked impeccably, 
                     which is reflected in the metrics we obtained. We calculated the parameter intersection
                     over union (IoU), where the labelled mask, 
                     or the image that we prepared for training by labelling, is compared with the predicted
                     mask. The IoU scores range from 0 to 1, 
                     with a score of 1 indicating a perfect overlap between the predicted and ground truth
                     bounding boxes. A high IoU score indicates 
                     that the object detection algorithm is accurately localizing the object in the image.
                     The value was calculated per class, with two 
                     defined classes: house (Class 1) and background (Class 2). We calculated two values
                     as follows:
                     </div>
                  
                  <div class="example">           
                     
                     <div class="ptext">
                        $$\text{Micro average} = \frac{\text{Intersection House} + \text{Intersection Background}}{\text{Union
                        House} + \text{Union Background}}$$
                        </div>
                     
                     <div class="ptext">
                        $$\text{Macro average} = \frac{\text{IoU House} + \text{IoU Background}}{2}$$ 
                        </div>
                     
                     <div class="caption-no-label">
                        <div class="label">Example 1. </div>
                     </div>
                  </div>
                  
                  <div class="counter"><a href="#p23">23</a></div>
                  <div class="ptext" id="p23">Our results yielded a mean micro average IoU of 0.990389 and a mean macro average
                     IoU of 0.89516, which represent outstanding 
                     values. The accuracy of the model was thus sufficiently high. Among the problems we
                     encountered were some streets that were 
                     mistaken for houses, as well as minor differences in the color schemes (shades) in
                     the hand-drawn maps. These were, however, minor 
                     issues, which we believe we could resolve by labelling more training examples and
                     retraining the model. Further finetuning could 
                     include teaching the model to recognize additional structures, particularly yellow
                     houses (wooden buildings) and streets, which 
                     will be our priority in a follow-up project.
                     </div>
                  
                  <div class="counter"><a href="#p24">24</a></div>
                  <div class="ptext" id="p24">The results of Task 2 were slightly different. The achieved IoUs of 0.537755 (macro)
                     and 0.795838 (micro) proved to be 
                     satisfactory in this context from a pragmatical perspective, as we were able to work
                     with the obtained results. Although these 
                     results are significantly below the values achieved for Task 1, we consider this task
                     successfully resolved. The building outlines 
                     contained in the negative layer must be kept more generous, in any case, because it
                     is evident, especially in the terrain model, 
                     that the terrain is affected by the development beyond the actual building boundaries,
                     through the levelling of the built-over 
                     area. The red markings in the upper layer mark false positives (e.g., a house was
                     detected where no house existed), while the 
                     green markings designate false negatives (e.g., the model failed to detect the house),
                     and the white markings indicate correct 
                     identifications. The model sometimes displays difficulties correctly identifying houses
                     at the margins of the detection area. 
                     Furthermore, it was difficult for the model to achieve good results outside a certain
                     (optimal) zoom range. This problem could be 
                     circumvented by properly addressing the issue in the data preprocessing. As a rule,
                     the model tended to minimally enlarge the 
                     recognized buildings, which was quite convenient for our work, as already noted. From
                     an academic perspective, we see some 
                     possibilities to optimize the model. We are certain that additional training, such
                     as adding more epochs, would substantially 
                     improve the model's performance.
                     </div>
                  
                  <div class="figure">
                     
                     
                     
                     <div class="ptext"><a href="resources/images/figure04.png" rel="external"><img src="resources/images/figure04.png" style="width: 700px" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 4. </div>STT results Tyralia (left) and STT results Vienna (right).</div>
                  </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Next Steps</h1>
                  
                  <div class="counter"><a href="#p25">25</a></div>
                  <div class="ptext" id="p25">RePaSE provided proof-of-concept with regard to AI-driven data extraction from historical
                     maps, and our results represent a 
                     a valuable way forward. The most important finding is that structures can be extracted
                     from historical cadastral map material 
                     accurately and economically in very high quality. This opens up a wide range of new
                     possibilities, and this is a field we plan 
                     on engaging further based on the results we gathered in RePaSE and in cooperation
                     with several other groups working in this 
                     field of research. In particular, we expect that the findings of our colleagues, Jiao,
                     Heitzler, and Hurni concerning the 
                     synthetic production of suitable training data will allow for a significant breakthrough
                     in extracting relevant data from 
                     historical maps at scale [<a class="ref" href="#jiao_heitzler_hurni_2022">Jiao, Heitzler, and Hurni 2022</a>].
                     </div>
                  
                  <div class="counter"><a href="#p26">26</a></div>
                  <div class="ptext" id="p26">In view of the rapid progress in the extraction of graphic structures from high-resolution
                     satellite and aerial photographs, it 
                     seems sensible to orient our work with regard to the current state of research rather
                     than investing significant resources in 
                     improving the technology. Nevertheless, it is critical to remain up-to-date with advances
                     in the field, as digital humanities and 
                     humanities data science often struggle to access state-of-the-art technologies, models,
                     and datasets to process information. We 
                     consider the solution we identified, STTnet, viable and expandable, though it will
                     require substantial effort to raise our outputs 
                     to a level at which the quality of results will be robust enough to qualify for positive
                     profiles. The STTnet we trained works 
                     well in a project context such as RePaSE, but it will require some adjustments to
                     work in a different context where a higher IoU 
                     metric might be required.
                     </div>
                  
                  <div class="counter"><a href="#p27">27</a></div>
                  <div class="ptext" id="p27">We have identified structures that can be detected very well when using computer vision
                     and which bear important time signatures, 
                     promising to render visible to researchers' eyes the past that is hidden in the surface
                     of the Earth. Furthermore, because we have 
                     recently found encouraging results using other object detectors for related tasks,
                     we believe we have identified a promising path 
                     of development in this field.
                     </div>
                  
                  <div class="counter"><a href="#p28">28</a></div>
                  <div class="ptext" id="p28">Our study has shown us that, in principle, our models would also be suitable for recognising
                     and reporting structural changes over 
                     time in a more finely graduated manner. With a different model (e.g., experiments
                     with YOLOv5 were promising), building outlines 
                     in the cadastral material could be recognised even more finely and, theoretically,
                     buildings that may not have undergone any 
                     structural changes could be detected automatically. Although RePaSE was not aimed
                     at determining the structures that replaced 
                     historical buildings, the models could also contribute to clarifying such questions
                     with a manageable adaptation effort.
                     </div>
                  
                  <div class="counter"><a href="#p29">29</a></div>
                  <div class="ptext" id="p29">A follow-up to RePaSE has recently been granted by the Austrian Science Fund (FWF),
                     which will fully integrate the two models 
                     trained and finetuned within RePaSE (DeepLabv3 and STTnet). The objective of this
                     follow-up is to identify and train two further 
                     models with a focus on historical road infrastructure.
                     </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Conclusion</h1>
                  
                  <div class="counter"><a href="#p30">30</a></div>
                  <div class="ptext" id="p30">RePaSE provides a wide variety of stakeholders, from municipal authorities and political
                     decision-makers at the local and regional 
                     level to historians and archeologists, with a powerful tool to detect sites of potential
                     archeological relevance, as is shown in 
                     the following two figures:
                     </div>
                  
                  <div class="figure">
                     
                     
                     
                     <div class="ptext"><a href="resources/images/figure05.png" rel="external"><img src="resources/images/figure05.png" style="width: 700px" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 5. </div>High-resolution aerial image of a part of the rural municipality Heiligenkreuz in the present day. The Red 
                        bounding boxes mark the automatically detected locations of buildings that featured
                        in the 1820s cadastre. The yellow shade 
                        marks the identified present-day buildings.</div>
                  </div>
                  
                  <div class="figure">
                     
                     
                     
                     <div class="ptext"><a href="resources/images/figure06.png" rel="external"><img src="resources/images/figure06.png" style="width: 700px" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 6. </div>The respective map patch in the cadastre. The bounding boxes mark the buildings that
                        have since disappeared.</div>
                  </div>
                  
                  <div class="counter"><a href="#p31">31</a></div>
                  <div class="ptext" id="p31">Based on our findings, we are convinced that the results of RePaSE will be an important
                     support for various stakeholders in 
                     Central Europe. In the field of construction management, our model is likely to be used to identify
                     archaeologically 
                     and historically sensitive areas in advance of major construction and infrastructure
                     projects. In the context of RePaSE, we 
                     define “archaeologically and historically sensitive” areas as sites that once featured historic buildings and may require 
                     archaeological investigation in the course of construction activities or current land
                     use. RePaSE can support the identification 
                     of such sites in advance and thus help to prevent so-called emergency excavations
                     (e.g., by changing the route or planned 
                     archaeological intervention before construction begins). The model can also help to
                     identify relevant structures in cultural 
                     heritage management and make them more comprehensively visible, for example, in existing
                     GIS and HGIS systems. Primarily, however, 
                     we see RePaSE as the basis for a research tool designed to support digital humanists
                     in identifying and extracting relevant 
                     research data from mapped sources.
                     </div>
                  
                  <div class="counter"><a href="#p32">32</a></div>
                  <div class="ptext" id="p32">The question arises to what extent neural networks can also be trained to detect visually
                     relevant anomalies in different 
                     dimensions of surface representations (digital terrain model, different high-resolution
                     aerial photographs) without having to rely 
                     on concrete knowledge from historical knowledge representations. Such detection could
                     be achieved by a neural network by 
                     identifying complex feature clusters in multimodal visual input signals, such as the
                     superimposition of DTM and high-resolution 
                     aerial images from different aerial surveys.
                     </div>
                  
                  <div class="counter"><a href="#p33">33</a></div>
                  <div class="ptext" id="p33">The RePaSE-team is currently working to set up a server to provide the above-mentioned
                     group with full access to the entire 
                     dataset processed in the project runtime.<a class="noteRef" href="#d4e721">[4]</a> 
                     While RePaSE currently supports research on the region of Styria, we expect that it could easily be expanded for 
                     the adjoining regions of Carinthia, Lower Austria, Salzburg, and Slovenia. 
                     As Croatia and Burgenland were part of the Transleithanian cadastre, which features slightly different 
                     optical features, we expect to encounter some difficulties there, though these issues
                     could likely be resolved through another 
                     round of finetuning.
                     </div>
                  
                  <div class="counter"><a href="#p34">34</a></div>
                  <div class="ptext" id="p34">RePaSE demonstrates the enormous potential of machine learning, particularly regarding
                     the use of computer vision, image 
                     segmentation, and object detection to scale up analysis of historical map material
                     and combine these insights with AI-harvested 
                     data gained from current, high-resolution imagery of the surface of the Earth. Models
                     of the latest generation feature outstanding 
                     usability and require manageable effort to successfully extract data from large-scale
                     knowledge representations. In the context of 
                     this project, however, domain knowledge plays an increasingly important role.
                     </div>
                  
                  <div class="counter"><a href="#p35">35</a></div>
                  <div class="ptext" id="p35">Due to the availability, usability, and accessibility of image segmentation, it is
                     increasingly becoming a standard technology. 
                     With this in mind, we must consider what tools digital humanities will be using to
                     work with such data in the near future. 
                     Based on our results, we believe that object detection bears enormous potential for
                     many crucial tasks, particularly when it comes 
                     to the analysis of historical map data at scale. The object detectors we have been
                     working with so far display a wide range of 
                     possible applications, which reach far beyond the purposes for which they were developed.
                     The fact that many object identification 
                     models combine excellent object recognition with relatively manageable hardware requirements
                     makes them suitable tools for use in 
                     DH contexts. That being said, the most relevant potential for these tools is their
                     capacity to bring spatial analysis in a 
                     historical context to scale. What is more, a large set of different tools exists to
                     visualize such changes, which will help 
                     historians and fellow humanists to develop a deeper understanding of how space transforms
                     over time.
                     </div>
                  </div>
               
               
               
               
               </div>
            
            <div id="notes">
               <h2>Notes</h2>
               <div class="endnote" id="d4e326"><span class="noteRef lang en">[1] RePaSE was funded by the Austrian Science Fund (FWF) under the reference 
                     TAI 591. Further information on RePaSE and access to the demonstrator is available
                     at 
                     <a href="https://repase.uni-graz.at" onclick="window.open('https://repase.uni-graz.at'); return false" class="ref">https://repase.uni-graz.at</a>. The demonstrator can be accessed via 
                     <a href="https://repase.know-center.at" onclick="window.open('https://repase.know-center.at'); return false" class="ref">https://repase.know-center.at</a>.</span></div>
               <div class="endnote" id="d4e390"><span class="noteRef lang en">[2] Further relevant repositories and projects 
                     focusing on the cadastre can be found under <a href="https://www.franziszeischerkataster.at" onclick="window.open('https://www.franziszeischerkataster.at'); return false" class="ref">https://www.franziszeischerkataster.at</a>. 
                     Additionally, the project HiLaK (Historische Landnutzung als Grundlage für Klimaschutzmaßnahmen
                     heute), directed by Kurt 
                     Scharr, and its follow-up project HiLuC display state-of-the-art approaches to cadastre-based
                     multi-disciplinary research in 
                     the field with regard to Austria.</span></div>
               <div class="endnote" id="d4e495"><span class="noteRef lang en">[3] We were granted access to the highest resolution research data hosted by 
                     <a href="https://gis.stmk.gv.at/wgportal/atlasmobile" onclick="window.open('https://gis.stmk.gv.at/wgportal/atlasmobile'); return false" class="ref">https://gis.stmk.gv.at/wgportal/atlasmobile</a>. Similar research data 
                     are available for all nine provinces of Austria. For example, data for the province of Carinthia is 
                     available at <a href="https://gis.ktn.gv.at/webgisviewer/atlas-mobile/" onclick="window.open('https://gis.ktn.gv.at/webgisviewer/atlas-mobile/'); return false" class="ref">https://gis.ktn.gv.at/webgisviewer/atlas-mobile/</a>. 
                     Unfortunately, comparable access is not easy in all successor states of the Habsburg monarchy. The Arcanum service 
                     offers good usability and orientation possibilities, but no metadata is offered free
                     of charge that would enable scholarly work 
                     and the resolution is limited.</span></div>
               <div class="endnote" id="d4e721"><span class="noteRef lang en">[4] We will provide all datasets that we used and produced to the scientific 
                     community as soon as the project has been concluded administratively, which will most
                     probably be the case in Q1/2024.</span></div>
            </div>
            <div id="worksCited">
               <h2>Works Cited</h2>
               <div class="bibl"><span class="ref" id="arnold_tilton_2019"><!-- close -->Arnold and Tilton 2019</span> Arnold, T. and Tilton, L. (2019) “Distant viewing: 
                  Analyzing large visual corpora”, <cite class="title italic">Digital Scholarship in the Humanities</cite>, 34(Supplement 1), pp. i3-i6. 
                  <a href="https://doi.org/10.1093/llc/fqz013" onclick="window.open('https://doi.org/10.1093/llc/fqz013'); return false" class="ref">https://doi.org/10.1093/llc/fqz013</a>.
                  </div>
               <div class="bibl"><span class="ref" id="baeten_lave_2020"><!-- close -->Baeten and Lave 2020</span> Baeten, J. and Lave, R. (2020) “Retracing rivers and drawing 
                  swamps: Using a drawing tablet to reconstruct an historical hydroscape from Army corps
                  survey maps”, <cite class="title italic">Historical 
                     Methods</cite>, 53(3), pp. 182–198. 
                  <a href="https://doi.org/10.1080/01615440.2020.1748151" onclick="window.open('https://doi.org/10.1080/01615440.2020.1748151'); return false" class="ref">https://doi.org/10.1080/01615440.2020.1748151</a>.
                  </div>
               <div class="bibl"><span class="ref" id="bickler_2021"><!-- close -->Bickler 2021</span> Bickler, S.H. (2021) “Machine learning arrives in archaeology”, 
                  <cite class="title italic">Advances in Archeological Practice</cite>, 9(2), pp. 186–192. 
                  <a href="https://doi.org/10.1017/aap.2021.6" onclick="window.open('https://doi.org/10.1017/aap.2021.6'); return false" class="ref">https://doi.org/10.1017/aap.2021.6</a>.
                  </div>
               <div class="bibl"><span class="ref" id="budig_2017"><!-- close -->Budig 2017</span> Budig, B. (2017) <cite class="title italic">Extracting spatial information from historical maps: 
                     Algorithms and interaction</cite>. Würzburg, Germany: Würzburg University Press.
                  </div>
               <div class="bibl"><span class="ref" id="bundesamt_2017"><!-- close -->Bundesamt 2017</span> Bundesamt für Eich- und Vermessungswesen (ed.) (2017) 
                  <cite class="title italic">Österreichisches Kulturgut: 200 Jahre Kataster, 1817–2017</cite>.
                  </div>
               <div class="bibl"><span class="ref" id="cvat_n.d."><!-- close -->CVAT n.d.</span> CVAT (n.d.) <cite class="title italic">CVAT: Open data annotation platform</cite>. Available at: 
                  <a href="https://www.cvat.ai/" onclick="window.open('https://www.cvat.ai/'); return false" class="ref">https://www.cvat.ai/</a>.
                  </div>
               <div class="bibl"><span class="ref" id="can_gerrits_kabadayı_2021"><!-- close -->Can, Gerrits, and Kabadayı 2021</span> Can, Y.S., Gerrits, P.J., and Kabadayı, M.E. (2021) 
                  “Automatic detection of road types from the third military mapping survey of Austria-Hungary
                  historical map series with 
                  deep convolutional neural networks”, <cite class="title italic">IEEE Access</cite>, 9. 
                  <a href="https://doi.org/10.1109/ACCESS.2021.3074897" onclick="window.open('https://doi.org/10.1109/ACCESS.2021.3074897'); return false" class="ref">https://doi.org/10.1109/ACCESS.2021.3074897</a>.
                  </div>
               <div class="bibl"><span class="ref" id="champion_2017"><!-- close -->Champion 2017</span> Champion, E.M. (2017) “Digital humanities is text heavy, visualization 
                  light, and simulation poor”, <cite class="title italic">Digital Scholarship in the Humanities</cite>, 32(Supplement 1), pp. 25–32. 
                  <a href="https://doi.org/10.1093/llc/fqw053" onclick="window.open('https://doi.org/10.1093/llc/fqw053'); return false" class="ref">https://doi.org/10.1093/llc/fqw053</a>.
                  </div>
               <div class="bibl"><span class="ref" id="chen_et_al_2016"><!-- close -->Chen et al. 2016</span> Chen, L. et al. (2016) “DeepLab: Semantic image segmentation with 
                  deep convolutional nets, atrous convolution, and fully connected CRFs”, <cite class="title italic">arXiv</cite>. Available at: 
                  <a href="http://arxiv.org/abs/1606.00915" onclick="window.open('http://arxiv.org/abs/1606.00915'); return false" class="ref">http://arxiv.org/abs/1606.00915</a>.
                  </div>
               <div class="bibl"><span class="ref" id="chen_et_al_2017"><!-- close -->Chen et al. 2017</span> Chen, L. et al. (2017) “Rethinking atrous convolution for semantic 
                  image segmentation”, <cite class="title italic">arXiv</cite>. Available at: 
                  <a href="https://arxiv.org/abs/1706.05587" onclick="window.open('https://arxiv.org/abs/1706.05587'); return false" class="ref">https://arxiv.org/abs/1706.05587</a>.
                  </div>
               <div class="bibl"><span class="ref" id="chen_zou_shi_2021"><!-- close -->Chen, Zou, and Shi 2021</span> Chen, K., Zou, Z., and Shi, Z. (2021) “Building extraction 
                  from remote sensing images with sparse token transformers building extraction from
                  remote sensing images with sparse token 
                  transformers”, <cite class="title italic">Remote Sensing</cite> 13(21). 
                  <a href="https://doi.org/10.3390/rs13214441" onclick="window.open('https://doi.org/10.3390/rs13214441'); return false" class="ref">https://doi.org/10.3390/rs13214441</a>.
                  </div>
               <div class="bibl"><span class="ref" id="chiang_et_al_2020"><!-- close -->Chiang et al. 2020</span> Chang, Y. et al. (2020) <cite class="title italic">Using historical maps in scientific 
                     studies: Applications, challenges, and best practices</cite>. New York: Springer.
                  </div>
               <div class="bibl"><span class="ref" id="ding_zhang_2021"><!-- close -->Ding and Zhang 2021</span> Ding, W. and Zhang, L. (2021) “Building detection in remote 
                  sensing image based on improved YOLOV5”, <cite class="title italic">17th Annual International Conference on Computational Intelligence and 
                     Security (CIS)</cite>. Chengdu, China, 19-22 November. pp. 133-136. 
                  <a href="https://doi.org/10.1109/CIS54983.2021.00036" onclick="window.open('https://doi.org/10.1109/CIS54983.2021.00036'); return false" class="ref">https://doi.org/10.1109/CIS54983.2021.00036</a>.
                  </div>
               <div class="bibl"><span class="ref" id="dolejs_forejt_2019"><!-- close -->Dolejš and Forejt 2019</span> Dolejš, M. and Forejt, M. (2019) ““Franziscean cadastre in 
                  landscape structure research: A systematic review”, <cite class="title italic">Quaestiones Geographicae</cite>, 38(1), pp. 131–144. 
                  <a href="https://doi.org/10.2478/quageo-2019-0013" onclick="window.open('https://doi.org/10.2478/quageo-2019-0013'); return false" class="ref">https://doi.org/10.2478/quageo-2019-0013</a>.
                  </div>
               <div class="bibl"><span class="ref" id="drobesch_2013"><!-- close -->Drobesch 2013</span> Drobesch, W. (ed.) (2013) <cite class="title italic">Kärnten Am Übergang von Der Agrar-Zur 
                     Industriegesellschaft: Fallstudien Zur Lage Und Leistung Der Landwirtschaft Auf Der
                     Datengrundlage Des Franziszeischen Katasters 
                     (1823-1844)</cite>. Klagenfurt, Austria: Verlag des Geschichtsvereines Kärnten.
                  </div>
               <div class="bibl"><span class="ref" id="ekim_sertel_kabadayı_2021"><!-- close -->Ekim, Sertel, and Kabadayı 2021</span> Ekim, B., Sertel, E., and Kabadayı, M.E. (2021) 
                  “Automatic road extraction from historical maps using deep learning techniques: A regional
                  case study of Turkey in a 
                  German World War II map”, <cite class="title italic">ISPRS International Journal of Geo-Information</cite>, 100(8). 
                  <a href="https://doi.org/10.3390/ijgi10080492" onclick="window.open('https://doi.org/10.3390/ijgi10080492'); return false" class="ref">https://doi.org/10.3390/ijgi10080492</a>.
                  </div>
               <div class="bibl"><span class="ref" id="femenia-ribera_mora-navarro_santos-perez"><!-- close -->Femenia-Ribera et al. 2022</span> Femenia-Ribera, C., Mora-Navarro, G., and Santos 
                  Pérez, L.J. (2022) “Evaluating the use of old cadastral maps”, <cite class="title italic">Land Use Policy</cite>, 114. 
                  <a href="https://doi.org/10.1016/j.landusepol.2022.105984" onclick="window.open('https://doi.org/10.1016/j.landusepol.2022.105984'); return false" class="ref">https://doi.org/10.1016/j.landusepol.2022.105984</a>.
                  </div>
               <div class="bibl"><span class="ref" id="feucht_2008"><!-- close -->Feucht 2008</span> Feucht, R. (2008.) <cite class="title italic">Flächenangaben Im Österreichischen Kataster</cite>. 
                  Diploma thesis. Vienna University of Technology. Available at: 
                  <a href="https://repositum.tuwien.at/handle/20.500.12708/11046" onclick="window.open('https://repositum.tuwien.at/handle/20.500.12708/11046'); return false" class="ref">https://repositum.tuwien.at/handle/20.500.12708/11046</a>.
                  </div>
               <div class="bibl"><span class="ref" id="fiorucci_et_al_2020"><!-- close -->Fiorucci et al. 2020</span> Fiorucci, M. (2020) “Machine learning for cultural 
                  heritage: A survey”, <cite class="title italic">Pattern Recognition Letters</cite>, 133(May), pp. 102–108. 
                  <a href="https://doi.org/10.1016/j.patrec.2020.02.017" onclick="window.open('https://doi.org/10.1016/j.patrec.2020.02.017'); return false" class="ref">https://doi.org/10.1016/j.patrec.2020.02.017</a>.
                  </div>
               <div class="bibl"><span class="ref" id="fiorucci_et_al_2022"><!-- close -->Fiorucci et al. 2022</span> Fiorucci, M. (2022) “Deep learning for archaeological 
                  object detection on LiDAR: New evaluation measures and insights”, <cite class="title italic">Remote Sensing</cite>, 14. 
                  <a href="https://doi.org/10.3390/rs14071694" onclick="window.open('https://doi.org/10.3390/rs14071694'); return false" class="ref">https://doi.org/10.3390/rs14071694</a>.
                  </div>
               <div class="bibl"><span class="ref" id="garcia-molsosa_et_al_2021"><!-- close -->Garcia-Molsosa et al. 2021</span> Garcia-Molsosa, A. (2021) “Potential of deep 
                  learning segmentation for the extraction of archaeological features from historical
                  map series”, <cite class="title italic">Archaeological 
                     Prospection</cite>, 28(2), pp. 187–99. 
                  <a href="https://doi.org/10.1002/arp.1807" onclick="window.open('https://doi.org/10.1002/arp.1807'); return false" class="ref">https://doi.org/10.1002/arp.1807</a>.
                  </div>
               <div class="bibl"><span class="ref" id="gil-fournier_parikka_2021"><!-- close -->Gil-Fournier and Parikka 2021</span> Gil-Fournier, A. and Parikka, J. (2021) 
                  “Ground truth to fake geographies: Machine vision and learning in visual practices”, <cite class="title italic">AI and 
                     Society</cite>, 36, pp. 1253–1262. 
                  <a href="https://doi.org/10.1007/s00146-020-01062-3" onclick="window.open('https://doi.org/10.1007/s00146-020-01062-3'); return false" class="ref">https://doi.org/10.1007/s00146-020-01062-3</a>.
                  </div>
               <div class="bibl"><span class="ref" id="goderle_2017"><!-- close -->Göderle 2017</span> Göderle, W.T. (2017) “Modernisierung Durch Vermessung? Das Wissen Des 
                  Modernen Staats in Zentraleuropa, circa 1760–1890”, <cite class="title italic">Archiv Für Sozialgeschichte</cite>, 57, pp. 155–186.
                  </div>
               <div class="bibl"><span class="ref" id="goderle_2023"><!-- close -->Göderle 2023</span> Göderle, W. (2023) “Imperiales Wissen: Zensus und Karte: 
                  Landesvermessungen und Volkszählungen im Habsburgerreich in der Sattelzeit (1750-1850)”, in Feichtinger, J. and Uhl, H. (eds.) 
                  <cite class="title italic">Das integrative Empire: Wissensproduktion und kulturelle Praktiken in Habsburg-Zentraleuropa</cite>. Bielefeld, 
                  Germany: transcript, pp. 73-96.
                  </div>
               <div class="bibl"><span class="ref" id="hagemans_et_al_2022"><!-- close -->Hagemans et al. 2022</span> Hagemans, E. (2022) “The new, LADM inspired, data model 
                  of the Dutch cadastral map”, <cite class="title italic">Land Use Policy</cite>, 117(June). 
                  <a href="https://doi.org/10.1016/j.landusepol.2022.106074" onclick="window.open('https://doi.org/10.1016/j.landusepol.2022.106074'); return false" class="ref">https://doi.org/10.1016/j.landusepol.2022.106074</a>.
                  </div>
               <div class="bibl"><span class="ref" id="heitzler_hurni_2020"><!-- close -->Heitzler and Hurni 2020</span> Heitzler, M. and Hurni, L. (2020) “Cartographic 
                  reconstruction of building footprints from historical maps: A study on the Swiss Siegfried
                  map”, <cite class="title italic">Transactions 
                     in GIS</cite>, 24(2), pp. 442–61. <a href="https://doi.org/10.1111/tgis.12610" onclick="window.open('https://doi.org/10.1111/tgis.12610'); return false" class="ref">https://doi.org/10.1111/tgis.12610</a>.
                  </div>
               <div class="bibl"><span class="ref" id="hohensinner_et_al_2021"><!-- close -->Hohensinner et al. 2021</span> Hohensinner, S. (2021) “Land use and cover change 
                  in the industrial era: A spatial analysis of Alpine River catchments and Fluvial corridors”, <cite class="title italic">Frontiers in 
                     Environmental Science</cite>, 9(June). 
                  <a href="https://doi.org/10.3389/fenvs.2021.647247" onclick="window.open('https://doi.org/10.3389/fenvs.2021.647247'); return false" class="ref">https://doi.org/10.3389/fenvs.2021.647247</a>.
                  </div>
               <div class="bibl"><span class="ref" id="hosseini_et_al_2021"><!-- close -->Hosseini et al. 2021</span> Hosseini, K. et al. “Maps of a nation? The digitized 
                  ordnance survey for new historical research”, <cite class="title italic">Journal of Victorian Culture</cite>, 26(2), pp. 284–299. 
                  <a href="https://doi.org/10.1093/jvcult/vcab009" onclick="window.open('https://doi.org/10.1093/jvcult/vcab009'); return false" class="ref">https://doi.org/10.1093/jvcult/vcab009</a>.
                  </div>
               <div class="bibl"><span class="ref" id="ji_wei_lu_2019"><!-- close -->Ji, Wei, and Lu 2019</span> Ji, S., Wei, S., and Lu, M. (2019) “Fully convolutional 
                  networks for multisource building extraction from an open aerial and satellite imagery
                  data set”, <cite class="title italic">IEEE 
                     Transactions on Geoscience and Remote Sensing</cite>, 57(1), pp. 574–586. 
                  <a href="https://doi.org/10.1109/TGRS.2018.2858817" onclick="window.open('https://doi.org/10.1109/TGRS.2018.2858817'); return false" class="ref">https://doi.org/10.1109/TGRS.2018.2858817</a>.
                  </div>
               <div class="bibl"><span class="ref" id="jiao_heitzler_hurni_2021"><!-- close -->Jiao, Heitzler, and Hurni 2021</span> Jiao, C., Heitzler, M., and Hurni, L. (2021) 
                  <cite class="title italic">A survey of road feature extraction methods from raster maps</cite>, <cite class="title italic">Transactions in GIS</cite>, 
                  25(6), pp. 2734–2763. <a href="https://doi.org/10.1111/tgis.12812" onclick="window.open('https://doi.org/10.1111/tgis.12812'); return false" class="ref">https://doi.org/10.1111/tgis.12812</a>.
                  </div>
               <div class="bibl"><span class="ref" id="jiao_heitzler_hurni_2022"><!-- close -->Jiao, Heitzler, and Hurni 2022</span> Jiao, C., Heitzler, M., and Hurni, L. (2022) 
                  “A fast and effective deep learning approach for road extraction from historical maps
                  by automatically generating 
                  training data with symbol reconstruction”, <cite class="title italic">International Journal of Applied Earth Observation and 
                     Geoinformation</cite>, 113(September). 
                  <a href="https://doi.org/10.1016/j.jag.2022.102980" onclick="window.open('https://doi.org/10.1016/j.jag.2022.102980'); return false" class="ref">https://doi.org/10.1016/j.jag.2022.102980</a>.
                  </div>
               <div class="bibl"><span class="ref" id="katastral_1824"><!-- close -->Katastral-Vermessungs Instruktion 1824</span> <cite class="title italic">Katastral-Vermessungs Instruktion</cite> 
                  (1824). Available at: 
                  <a href="http://www.franziszeischerkataster.at/images/1820_KATASTRALVERMESSUNGSINSTRUKTION.pdf" onclick="window.open('http://www.franziszeischerkataster.at/images/1820_KATASTRALVERMESSUNGSINSTRUKTION.pdf'); return false" class="ref">http://www.franziszeischerkataster.at/images/1820_KATASTRALVERMESSUNGSINSTRUKTION.pdf</a>.
                  </div>
               <div class="bibl"><span class="ref" id="lee_wang_lee_2023"><!-- close -->Lee, Wang, and Lee 2023</span> Lee, K., Wang, B., and Lee, S. (2023) 
                  “Analysis of YOLOv5 and DeepLabv3+ algorithms for detecting illegal cultivation on
                  public land: A case study of a 
                  riverside in Korea”, <cite class="title italic">International Journal of Environmental Research and Public Health</cite>, 20(3). 
                  <a href="https://doi.org/10.3390/ijerph20031770" onclick="window.open('https://doi.org/10.3390/ijerph20031770'); return false" class="ref">https://doi.org/10.3390/ijerph20031770</a>.
                  </div>
               <div class="bibl"><span class="ref" id="li_et_al_2022"><!-- close -->Li et al. 2022</span> Li, J. et al. “A review of building detection from very high 
                  resolution optical remote sensing images”, <cite class="title italic">GIScience and Remote Sensing</cite>, 59(1), pp. 1199-1225. 
                  <a href="https://www.tandfonline.com/doi/full/10.1080/15481603.2022.2101727" onclick="window.open('https://www.tandfonline.com/doi/full/10.1080/15481603.2022.2101727'); return false" class="ref">https://www.tandfonline.com/doi/full/10.1080/15481603.2022.2101727</a>.
                  </div>
               <div class="bibl"><span class="ref" id="li_et_al_2023"><!-- close -->Li et al. 2023</span> Li, M. et al. “Method of building detection in optical remote sensing 
                  images based on SegFormer”, <cite class="title italic">Sensors</cite>, 23(3). 
                  <a href="https://doi.org/10.3390/s23031258" onclick="window.open('https://doi.org/10.3390/s23031258'); return false" class="ref">https://doi.org/10.3390/s23031258</a>.
                  </div>
               <div class="bibl"><span class="ref" id="luo_wu_wang_2022"><!-- close -->Luo, Wu, and Wang 2022</span> Luo, X., Wu, Y., and Wang, F. (2022) “Target detection 
                  method of UAV aerial imagery based on improved YOLOv5”, <cite class="title italic">Remote Sensing</cite>, 14(19). 
                  <a href="https://doi.org/10.3390/rs14195063" onclick="window.open('https://doi.org/10.3390/rs14195063'); return false" class="ref">https://doi.org/10.3390/rs14195063</a>.
                  </div>
               <div class="bibl"><span class="ref" id="mcdonough_2024"><!-- close -->McDonough 2024</span> McDonough, K. (2024) “Maps as data: Computational spatial 
                  history”, in Tilton, L., Mimno, D., and Johnson, J.M. (eds.) <cite class="title italic">Computational humanities</cite>. Minneapolis, 
                  Minnesota: University of Minnesota Press.
                  </div>
               <div class="bibl"><span class="ref" id="noord_2022"><!-- close -->Noord 2022</span> Noord, N.V. (2022) “A survey of computational methods for iconic image 
                  analysis”, <cite class="title italic">Digital Scholarship in the Humanities</cite>, 37(4), pp. 1316–1338. 
                  <a href="https://doi.org/10.1093/llc/fqac003" onclick="window.open('https://doi.org/10.1093/llc/fqac003'); return false" class="ref">https://doi.org/10.1093/llc/fqac003</a>.
                  </div>
               <div class="bibl"><span class="ref" id="oshea_nash_2015"><!-- close -->O'Shea and Nash 2015</span> O’Shea, K. and Nash, R. (2015) “An introduction to 
                  convolutional neural networks”, <cite class="title italic">ArXiv</cite>. 
                  <a href="https://arxiv.org/abs/1511.08458" onclick="window.open('https://arxiv.org/abs/1511.08458'); return false" class="ref">https://arxiv.org/abs/1511.08458</a>.
                  </div>
               <div class="bibl"><span class="ref" id="oliveira_et_al_2019"><!-- close -->Oliveira et al. 2019</span> Oliveira, A. et al. (2019) “A deep learning approach 
                  to cadastral computing”, <cite class="title">Digital humanities conference 2019</cite>, Utrecht, Netherlands, 8-12 July. Available at: 
                  <a href="https://infoscience.epfl.ch/record/268282?ln=en" onclick="window.open('https://infoscience.epfl.ch/record/268282?ln=en'); return false" class="ref">https://infoscience.epfl.ch/record/268282?ln=en</a>.
                  </div>
               <div class="bibl"><span class="ref" id="petek_urbanc_2004"><!-- close -->Petek and Urbanc 2004</span> Petek, F. and Urbanc, M. (2004) “The Franziscean land 
                  cadastre as a key to understanding the 19th-century cultural landscape in Slovenia”, <cite class="title italic">Acta geographica 
                     Slovenica</cite>, 44(1), pp. 89-113. 
                  <a href="http://doi.org/10.3986/AGS44104" onclick="window.open('http://doi.org/10.3986/AGS44104'); return false" class="ref">http://doi.org/10.3986/AGS44104</a>.
                  </div>
               <div class="bibl"><span class="ref" id="petitpierre_guhennec_2023"><!-- close -->Petitpierre and Guhennec 2023</span> Petitpierre, R. and Guhennec, P. (2023) 
                  “Effective annotation for the automatic vectorization of cadastral maps”, <cite class="title italic">Digital 
                     Scholarship in the Humanities</cite>, 38(3), pp. 1227–1237. 
                  <a href="https://doi.org/10.1093/llc/fqad006" onclick="window.open('https://doi.org/10.1093/llc/fqad006'); return false" class="ref">https://doi.org/10.1093/llc/fqad006</a>.
                  </div>
               <div class="bibl"><span class="ref" id="petitpierre_kaplan_di-lenardo_2021"><!-- close -->Petitpierre, Kaplan, and Di Lenardo 2021</span> Petitpierre, R., Kaplan, F., and 
                  Di Lenardo, I. (2021) “Generic semantic segmentation of historical maps”, <cite class="title italic">Conference on 
                     computation humanities research (CHR2021)</cite>, Amsterdam, Netherlands, 17-19 November. Available at: 
                  <a href="https://ceur-ws.org/Vol-2989/long_paper27.pdf" onclick="window.open('https://ceur-ws.org/Vol-2989/long_paper27.pdf'); return false" class="ref">https://ceur-ws.org/Vol-2989/long_paper27.pdf</a>.
                  </div>
               <div class="bibl"><span class="ref" id="pivac_et_al_2021"><!-- close -->Pivac et al. 2021</span> Pivac, D. et al. (2021) “Availability of historical cadastral 
                  data”, <cite class="title italic">Land</cite>, 10(9). 
                  <a href="https://doi.org/10.3390/land10090917" onclick="window.open('https://doi.org/10.3390/land10090917'); return false" class="ref">https://doi.org/10.3390/land10090917</a>.
                  </div>
               <div class="bibl"><span class="ref" id="pytorch_n.d."><!-- close -->PyTorch n.d.</span> PyTorch (n.d.) <cite class="title italic">DeepLabv3</cite>. Available at: 
                  <a href="https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/" onclick="window.open('https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/'); return false" class="ref">https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/</a>.
                  </div>
               <div class="bibl"><span class="ref" id="rawat_wang_2017"><!-- close -->Rawat and Wang 2017</span> Rawat, W. and Wang, Z. (2017) “Deep convolutional neural 
                  networks for image classification: A comprehensive review”, <cite class="title italic">Neural Computation</cite>, 29(9), pp. 2352–2449. 
                  <a href="https://doi.org/10.1162/neco_a_00990" onclick="window.open('https://doi.org/10.1162/neco_a_00990'); return false" class="ref">https://doi.org/10.1162/neco_a_00990</a>.
                  </div>
               <div class="bibl"><span class="ref" id="ren_et_al_2015"><!-- close -->Ren et al. 2015</span> Ren, S. et al. (2015) “Faster R-CNN: Towards real-time object 
                  detection with region proposal networks”, <cite class="title italic">NeurIPS 2015 conference</cite>, Montréal, Canada, 7-12 December. 
                  Available at: 
                  <a href="https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf" onclick="window.open('https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf'); return false" class="ref">https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf</a>.
                  </div>
               <div class="bibl"><span class="ref" id="roberts_et_al_2024"><!-- close -->Roberts et al. 2024</span> Roberts, P. et al. (2024) “Using urban pasts to speak to urban 
                  presents in the Anthropocene”, <cite class="title italic">Nature Cities</cite>, 1(30-41). 
                  <a href="https://doi.org/10.1038/s44284-023-00014-4" onclick="window.open('https://doi.org/10.1038/s44284-023-00014-4'); return false" class="ref">https://doi.org/10.1038/s44284-023-00014-4</a>.
                  </div>
               <div class="bibl"><span class="ref" id="rumpler_2013"><!-- close -->Rumpler 2013</span> Rumpler, H. (ed.) (2013) <cite class="title italic">Der Franziszeische Kataster im Kronland Kärnten 
                     (1823-1844)</cite>. Klagenfurt am Wörthersee, Austria: Geschichtsverein Kärnten.
                  </div>
               <div class="bibl"><span class="ref" id="rumpler_scharr_ungureanu_2015"><!-- close -->Rumpler, Scharr, and Ungureanu 2015</span> Rumpler, H., Scharr, K. and Ungureanu, C. (eds.) 
                  (2015) <cite class="title italic">Der Franziszeische Kataster im Kronland Bukowina/Czernowitzer Kreis (1817-1865): Statistik
                     und 
                     Katastralmappen</cite>. Vienna, Austria: Böhlau Verlag.
                  </div>
               <div class="bibl"><span class="ref" id="scharr_2024"><!-- close -->Scharr 2024</span> Scharr, K. (ed.) (2024) <cite class="title italic">Der Franziszeische Kataster im Kronland 
                     Österreichisch-Schlesien (1821–1851): The Franciscan cadastre in the crown land Austrian
                     Silesia: Statistik und Katastralmappen</cite>.
                  Vienna, Austria: Böhlau Verlag.
                  </div>
               <div class="bibl"><span class="ref" id="singh_popescu_2021"><!-- close -->Singh and Popescu 2021</span> Singh, M. and Popescu, A.C. (2021) 
                  <cite class="title italic">DeepLabv3FineTuning</cite>. Available at: 
                  <a href="https://Github.Com/Msminhas93/DeepLabv3FineTuning" onclick="window.open('https://Github.Com/Msminhas93/DeepLabv3FineTuning'); return false" class="ref">https://Github.Com/Msminhas93/DeepLabv3FineTuning</a>.
                  </div>
               <div class="bibl"><span class="ref" id="smits_wevers_2020"><!-- close -->Smits and Wevers 2020</span> Smits, T. and Wevers, M. (2020) “The visual digital turn: 
                  Using neural networks to study historical images”, <cite class="title italic">Digital Scholarship in the Humanities</cite>, 35(1), pp. 
                  194–207. <a href="https://doi.org/10.1093/llc/fqy085" onclick="window.open('https://doi.org/10.1093/llc/fqy085'); return false" class="ref">https://doi.org/10.1093/llc/fqy085</a>.
                  </div>
               <div class="bibl"><span class="ref" id="smits_wevers_2023"><!-- close -->Smits and Wevers 2023</span> Smits, T. and Wevers, M. (2020) “A multimodal turn in digital 
                  humanities: Using contrastive machine learning models to explore, enrich, and analyze
                  digital visual historical collections”, 
                  <cite class="title italic">Digital Scholarship in the Humanities</cite>, 38(3), pp. 1267–1280. 
                  <a href="https://doi.org/10.1093/llc/fqad008" onclick="window.open('https://doi.org/10.1093/llc/fqad008'); return false" class="ref">https://doi.org/10.1093/llc/fqad008</a>.
                  </div>
               <div class="bibl"><span class="ref" id="stahl_weimann_2022"><!-- close -->Ståhl and Weimann 2022</span> Ståhl, N. and Weimann, L. (2022) “Identifying wetland 
                  areas in historical maps using deep convolutional neural networks”, <cite class="title italic">Ecological Informatics</cite>, 68(May). 
                  <a href="https://doi.org/10.1016/J.ECOINF.2022.101557" onclick="window.open('https://doi.org/10.1016/J.ECOINF.2022.101557'); return false" class="ref">https://doi.org/10.1016/J.ECOINF.2022.101557</a>.
                  </div>
               <div class="bibl"><span class="ref" id="uhl_et_al_2020"><!-- close -->Uhl et al. 2020</span> Uhl, J.H. et al. (2020) “Automated extraction of human settlement 
                  patterns from historical topographic map series using weakly supervised convolutional
                  neural networks”, 
                  <cite class="title italic">IEEE Access</cite>, 8. 
                  <a href="https://doi.org/10.1109/ACCESS.2019.2963213" onclick="window.open('https://doi.org/10.1109/ACCESS.2019.2963213'); return false" class="ref">https://doi.org/10.1109/ACCESS.2019.2963213</a>.
                  </div>
               <div class="bibl"><span class="ref" id="uhl_et_al_2021"><!-- close -->Uhl et al. 2021</span> Uhl, J.H. et al. (2021) “Towards the automated large-scale 
                  reconstruction of past road networks from historical maps”, <cite class="title italic">Computers, Environment and Urban Systems</cite>, 
                  94(June). <a href="https://doi.org/10.1016/j.compenvurbsys.2022.101794" onclick="window.open('https://doi.org/10.1016/j.compenvurbsys.2022.101794'); return false" class="ref">https://doi.org/10.1016/j.compenvurbsys.2022.101794</a>.
                  </div>
               <div class="bibl"><span class="ref" id="uhl_et_al_2022"><!-- close -->Uhl et al. 2022</span> Uh, J.H. et al. (2022) “Combining remote-sensing-derived data and 
                  historical maps for long-term back-casting of urban extents”, <cite class="title italic">Remote Sensing</cite>, 13(18). 
                  <a href="https://doi.org/10.3390/rs13183672" onclick="window.open('https://doi.org/10.3390/rs13183672'); return false" class="ref">https://doi.org/10.3390/rs13183672</a>.
                  </div>
               <div class="bibl"><span class="ref" id="wheeler_2023"><!-- close -->Wheeler 2023</span> Wheeler, R. (2023) “European official surveys of the nineteenth century 
                  available online”, <cite class="title italic">Charles Close Society</cite>. Available at: 
                  <a href="https://www.charlesclosesociety.org/C19EuropeSurveys" onclick="window.open('https://www.charlesclosesociety.org/C19EuropeSurveys'); return false" class="ref">https://www.charlesclosesociety.org/C19EuropeSurveys</a>.
                  </div>
               <div class="bibl"><span class="ref" id="wu_et_al_2023"><!-- close -->Wu et al. 2023</span> Wu, S. et al. (2023) “Domain adaptation in segmenting historical 
                  maps: A weakly supervised approach through spatial co-occurrence”, <cite class="title italic">ISPRS Journal of Photogrammetry and Remote 
                     Sensing</cite>, 197(March), pp. 199–211. 
                  <a href="https://doi.org/10.1016/j.isprsjprs.2023.01.021" onclick="window.open('https://doi.org/10.1016/j.isprsjprs.2023.01.021'); return false" class="ref">https://doi.org/10.1016/j.isprsjprs.2023.01.021</a>.
                  </div>
            </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            <div class="license"><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
               </div>
         </div>
      </div>
   </body>
</html>