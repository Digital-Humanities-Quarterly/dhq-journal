<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xmlns:cc="http://web.resource.org/cc/"
     xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
     xmlns:mml="http://www.w3.org/1998/Math/MathML"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="article" xml:lang="en">Deep Learning for Historical Cadastral Maps and Satellite Imagery Analysis: 
               Insights from Styria's Franciscean Cadastre</title>
            <dhq:authorInfo>
               <dhq:author_name>Wolfgang Thomas <dhq:family>Göderle</dhq:family>
               </dhq:author_name>
               <idno type="ORCID">https://orcid.org/0000-0002-9417-5316</idno>
               <dhq:affiliation>University of Innsbruck; Max Planck Institute of Geoanthropology</dhq:affiliation>
               <email>wolfgang.goederle@uni-graz.at</email>
               <dhq:bio>
                  <p>Wolfgang Göderle is a postdoc in the History Department of the <name>University of Innsbruck</name> and a Research Associate with 
                     the <name>Max Planck Institute of Geoanthropology</name> in <name>Jena</name>. His expertise lies with the processing and the 
                     analysis of large historical datasets in 19th century <name>Habsburg</name> Central <name>Europe</name>, particularly cadastral map 
                     data and serial publications, such as the <title rend="italic">Schematismus</title>. He is the PI of several research projects that 
                     explore the potential of deep learning for historical and archeological research work.
                  </p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <dhq:author_name>Fabian <dhq:family>Rampetsreiter</dhq:family>
               </dhq:author_name>
               <idno type="ORCID">https://orcid.org/0009-0004-5155-3032</idno>
               <dhq:affiliation>University of Graz</dhq:affiliation>
               <email>rampman@gmx.net</email>
               <dhq:bio>
                  <p>Fabian Rampetsreiter is a historian and computer scientist at the <name>University of Graz</name> with a strong focus on 
                     early modern archeology and material culture. He supports the RePaSE team with his expertise in the above mentioned fields 
                     and in this capacity bridges the gap between history and archeology on the one hand and computer and data science on the other.
                  </p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <dhq:author_name>Christian <dhq:family>Macher</dhq:family>
               </dhq:author_name>
               <idno type="ORCID">https://orcid.org/0009-0009-7299-8547</idno>
               <dhq:affiliation>Know Center</dhq:affiliation>
               <email>cmacher@know-center.at</email>
               <dhq:bio>
                  <p>Christian Macher has several years of professional experience in the financial industry as a risk modeler. Since 2021, Christian has 
                     been working as a data scientist at the <name>Know Center</name> in various projects and on various topics (time series modeling, 
                     predictive analytics, natural language processing (NLP), etc.).
                  </p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <dhq:author_name>Katrin <dhq:family>Mauthner</dhq:family>
               </dhq:author_name>
               <idno type="ORCID">https://orcid.org/0009-0003-1227-1190</idno>
               <dhq:affiliation>Know Center</dhq:affiliation>
               <email>kmauthner@know-center.at</email>
               <dhq:bio>
                  <p>Katrin Mauthner is team member of the Data Insights area at the <name>Know Center</name>, a research center for trustworthy 
                     AI. She holds a degree in applied mathematics, with a special focus on statistics and optimization. She has gained professional 
                     experience in various industries, including software and automotive, before joining the K<name>now Center</name> as a senior 
                     data scientist. Her current work is devoted to turning AI projects into reality.
                  </p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <dhq:author_name>Oliver <dhq:family>Pimas</dhq:family>
               </dhq:author_name>
               <idno type="ORCID">https://orcid.org/0009-0002-5480-1543</idno>
               <dhq:affiliation>Know Center</dhq:affiliation>
               <email>opimas@know-center.at</email>
               <dhq:bio>
                  <p>Oliver Pimas heads the Data Insights area at the <name>Know Center</name>, a research center for trustworthy AI. Together with a 
                     team of data scientists, he helps companies realise the value-adding potential of data and AI. Prior to that, he was a researcher 
                     in the field of natural language processing (NLP) and worked as a data scientist at a <name>London</name>-based start-up called 
                     Mendeley, as part of a <name>Marie Curie</name> secondment.
                  </p>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <idno type="DHQarticle-id">000744</idno>
            <idno type="volume"><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006--></idno>
            <idno type="issue"><!--issue number, without leading zeroes: e.g. 2--></idno>
            <date><!--include @when with ISO date and also content in the form 23 February 2024--></date>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND">
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
            <taxonomy xml:id="project_keywords">
               <bibl>DHQ project registry; full list available at <ref target="http://www.digitalhumanities.org/dhq/projects.xml">http://www.digitalhumanities.org/dhq/projects.xml</ref>
               </bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords">
               <term corresp="#geospatial"/>
               <term corresp="#archaeology"/>
               <term corresp="#machine_learning"/>
            </keywords>
            <keywords scheme="#authorial_keywords">
               <list type="simple">
                  <item>map feature extraction</item>
                  <item>remote sensing</item>
                  <item>cadastral map</item>
                  <item>aerial photography</item>
               </list>
            </keywords>
            <keywords scheme="#project_keywords">
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <change>The version history for this file can be found on <ref target="https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/main/articles/000744/000744.xml">GitHub
                   </ref>
         </change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract>
            <p>Cadastres from the 19th century are a complex as well as rich source for historians and archaeologists, the study of which 
               presents great challenges. For archaeological and historical remote sensing, we have trained several Deep Learning models, CNNs, 
               and Vision Transformers to extract large-scale data from this knowledge representation. We present the principle results of our 
               work here and demonstrate our browser-based tool that allows researchers and public stakeholders to quickly identify spots that 
               featured buildings in the 19th century Franciscean cadastre. The tool not only supports scholars and fellow researchers in 
               building a better understanding of the settlement history of the region of <name>Styria</name>; it also helps public 
               administration and fellow citizens to swiftly identify areas of heightened sensibility with regard to the cultural heritage of the 
               region.
            </p>
         </dhq:abstract>
         <dhq:teaser>
            <p>Explore the past with precision: discover how cutting-edge AI tools help unlock historical secrets from the 19th-century Franciscean 
               cadastre, aiding scholars and the public in unraveling <name>Styria</name>'s cultural heritage.</p>
         </dhq:teaser>
      </front>
      <body>
        <div>
          <head/>
            <p>Cadastral maps, which were produced with meticulous quality standards from the early 19th century onwards for large parts of 
              <name>Europe</name>, offer a unique and complex representation of knowledge <ptr target="#goderle_2017"/> 
              <ptr target="#goderle_2023"/> <ptr target="#wheeler_2023"/> <ptr target="#femenia-ribera_mora-navarro_santos-perez"/>. In the 
              case of <name>Habsburg</name> Central <name>Europe</name>, where cadastral mapping occurred between 1816 and 1861, these maps 
              provide detailed information on individual houses at a scale ranging from 1:720 to 1:5760, with a standard scale of 1:2880. They 
              also document land use, contemporary roads and pathways, land boundaries, and other relevant data 
              <ptr target="#katastral_1824"/> <ptr target="#bundesamt_2017" loc="44"/>. Apart from their historical significance, cadastral maps 
              are valuable for contemporary spatial analysis, including environmental and transport history, building history, and economic and 
              social history, as well as questions related to land use and landscape transformation in the Anthropocene era and resource 
              extraction during the time of their creation <ptr target="#stahl_weimann_2022"/> <ptr target="#roberts_et_al_2024"/>.
            </p>
            <figure>
              <head>Extract from cadastre from 1828. Wooden houses are visible in yellow, along with paths and agricultural land.</head>
              <figDesc></figDesc>
                <graphic url="resources/images/figure01.png" style="width: 700px"/>
            </figure>
            <p>Cadastral maps constitute a key resource for historical research into this region, as they enable the spatialization of historical 
               processes, contexts, and interdependencies. However, accessing and processing cadastral data can be challenging due to their 
               multimodal structure and primary focus on images and geodata. This presents difficulties for digital humanities researchers, 
               whose work is often located in the textual domain <ptr target="#champion_2017"/> <ptr target="#van-noord_2022"/>. We are convinced 
               that recent advances in the field of deep neural networks enable multimodal analysis of historical sources 
               <ptr target="#smits_wevers_2020"/>. This would, in turn, open up new opportunities to analyze those non-written sources that 
               emerged in <name>Europe</name> (as well as globally) in the long 19th century. Sources such as the cadastre are unique and central 
               representations of knowledge from this period, but have so far been insufficiently analyzed, especially in social and economic 
               history research (<ptr target="#hosseini_et_al_2021"/>.
            </p>
            <p>Digitization has made cadastres more accessible to a wider audience, although accessing the physical volumes stored in archives 
               remains challenging for historians and researchers <ptr target="#bundesamt_2017"/> 
               <ptr target="#femenia-ribera_mora-navarro_santos-perez"/> <ptr target="#hagemans_et_al_2022"/> <ptr target="#mcdonough_2024"/>. 
               Despite digitization efforts, the comprehensive evaluation of cadastral data, particularly in <name>Habsburg</name> Central 
               <name>Europe</name>, where 300,000 square kilometers were surveyed between 1816 and 1861, remains labor-intensive due to the sheer 
               volume of individual map sheets documenting every aspect of land use and property <ptr target="#bundesamt_2017"/>.
            </p>
            <p>The 2022 Austrian Science Fund (FWF) project RePaSE (Reading the Past from the Surface of the Earth) aimed to use AI-assisted 
               extraction to identify historical building outlines and locations from geo-referenced map sheets of the Franziszeische Kataster 
               (Franciscean Cadastre).<note>RePaSE was funded by the <name>Austrian Science Fund</name> (<name>FWF</name>) under the reference 
               TAI 591. Further information on RePaSE and access to the demonstrator is available at 
               <ref target="https://repase.uni-graz.at">https://repase.uni-graz.at</ref>. The demonstrator can be accessed via 
               <ref target="https://repase.know-center.at">https://repase.know-center.at</ref>.</note> This involved training an AI model for 
               building extraction from both historical maps and modern, high-resolution aerial and satellite images. By overlaying the extracted 
               historical and present-day building information, the project sought to identify potential archaeological sites, facilitating 
               large-scale archaeological remote sensing. The hypothesis driving RePaSE is that by combining historical cadastral map data with 
               modern satellite imagery, it's possible to identify regions where buildings once stood, aiding in the discovery of vanished structures 
               and potentially significant archaeological sites.
            </p>
            <p>In addition to the cadastre, we worked with current spatial images in our study. We were supported by the relevant A17 State and 
               Regional Development – Department of Statistics and Geoinformation of the Province of <name>Styria</name>, which provided us with 
               high-resolution aerial photographs from different flight periods as well as two digital terrain models. It has been shown that even 
               the transfer of information from georeferenced historical map images to different spatial representations of the present has enormous 
               cognitive potential. We were able to draw on high-resolution aerial photographs from 1952; images from the 1970s, 1980s, and 1990s; and 
               current and extremely accurate images from recent years.
            </p>
            <p>The results of RePaSE, and the tools that emerge from it, should create opportunities for digital humanities researchers to 
               analyze the information contained in historical maps. Possibilities for automated segmentation of the information contained 
               therein would enable us to further quantitatively process data contained in maps and to utilize new possibilities for qualitative 
               analysis <ptr target="#hosseini_et_al_2021"/>. In HGIS systems that contain georeferenced historical maps, it is already possible 
               to calculate areas; thus, automated segmentation would significantly advance historical analysis 
               <ptr target="#baeten_lave_2020"/>. Furthermore, new feature complexes could be defined and searched for automatically, extending 
               the logics of distant reading to map analysis <ptr target="#arnold_tilton_2019"/>. For example, mills not explicitly identified in 
               the French cadastre could be automatically identified, which would allow a profound analysis of hydropower use in Central 
               <name>Europe</name> in the early 19th century and enable the investigation of local or regional differences.
            </p>
            <p>We do not consider cadastre, satellite photograph, or aerial photography authentic representations of reality. Rather, we treat 
               them as high-profile sources providing us with several layers of research data <ptr target="#gil-fournier_parikka_2021"/> 
               <ptr target="#hosseini_et_al_2021"/>.
            </p>     
        </div>
        <div>
          <head>State of Research</head>
            <p>Despite the accessibility challenges mentioned above, there is substantial historical research that deals either with the 
               construction of cadastral maps or with the information stored in them <ptr target="#dolejs_forejt_2019"/>. Prior to their 
               digitization, cadastral maps have already played an important role in historical and particularly archeological research on the 
               micro-level <ptr target="#petek_urbanc_2004"/>. Cadastral maps have long been a research resource with regard to genealogical 
               research. They have been used as sources in agricultural and environmental history, environmental studies, archeological remote 
               sensing, social and economic history, and in the development of a broader understanding of the evolution of landscapes 
               <ptr target="#drobesch_2013"/> <ptr target="#rumpler_2013"/> <ptr target="#scharr_2024"/> 
               <ptr target="#rumpler_scharr_ungureanu_2015"/> <ptr target="#hohensinner_et_al_2021"/>. Their value, however, has frequently been 
               limited by accessibility issues and the difficulties of extending analysis beyond relatively limited borders.
            </p>
            <p>Access to historical cadastral maps in Central <name>Europe</name> became publicly available relatively late, with data now 
               accessible through projects like Arcanum Maps (https://maps.arcanum.com/en/).<note>Further relevant repositories and projects 
               focusing on the cadastre can be found under <ref target="https://www.franziszeischerkataster.at">https://www.franziszeischerkataster.at</ref>. 
               Additionally, the project HiLaK (Historische Landnutzung als Grundlage für Klimaschutzmaßnahmen heute), directed by <name>Kurt 
               Scharr</name>, and its follow-up project HiLuC display state-of-the-art approaches to cadastre-based multi-disciplinary research in 
               the field with regard to <name>Austria</name>.</note> In most cases, the digitization of cadastral maps is accompanied by georeferencing. 
               However, these repositories often lack comprehensive metadata and may require payment for research use. Public authorities have 
               increasingly made parts of the Franziszeische Kataster available online for research purposes, offering data at various quality 
               levels for free <ptr target="#pivac_et_al_2021"/>. Exploration of historical map data, including cadastral maps, has accelerated 
               due to recent advancements in machine learning <ptr target="#chiang_et_al_2020"/> <ptr target="#budig_2017"/>. Deep learning 
               technologies, in particular, have revolutionized feature extraction <ptr target="#chen_et_al_2016"/>, focusing on streets 
               <ptr target="#ekim_sertel_kabadayı_2021"/> <ptr target="#can_gerrits_kabadayı_2021"/> <ptr target="#jiao_heitzler_hurni_2021"/> 
               <ptr target="#jiao_heitzler_hurni_2022"/> <ptr target="#uhl_et_al_2022"/> and buildings <ptr target="#heitzler_hurni_2020"/> 
               <ptr target="#uhl_et_al_2020"/>, among other applications <ptr target="#wu_et_al_2023"/> 
               <ptr target="#petitpierre_kaplan_di-lenardo_2021"/> <ptr target="#garcia-molsosa_et_al_2021"/>.
            </p>
            <p>These advancements offer new possibilities for researchers in history, archaeology, and historical geography. Recent research has 
               focused on feature extraction from cadastral maps, particularly in the context of the Venetian cadastre and the 1900 Atlas of 
               Paris <ptr target="#oliveira_et_al_2019"/> <ptr target="#petitpierre_guhennec_2023"/>. As <name>Petitpierre</name> and 
               <name>Guhennec</name> point out, consistent annotation is the main challenge with regard to automatized vectorization. However, 
               the bulk of current research is directed towards the analysis of aerial and satellite imagery 
               <ptr target="#jiao_heitzler_hurni_2022"/>. This research spans a wide range of objectives and interests, with stakeholders 
               including municipal and urban administrations, as well as archaeological remote sensing missions. Significant attention has also 
               been given to LIDAR data and research on urban landscape transformation, in addition to real-time surveillance tasks involving 
               UAVs <ptr target="#li_et_al_2022"/> <ptr target="#li_et_al_2023"/> <ptr target="#ji_wei_lu_2019"/>  
               <ptr target="#fiorucci_et_al_2020"/> <ptr target="#fiorucci_et_al_2022"/> <ptr target="#bickler_2021"/> 
               <ptr target="#ren_et_al_2015"/> <ptr target="#ding_zhang_2021"/> <ptr target="#luo_wu_wang_2022"/> 
               <ptr target="#lee_wang_lee_2023"/> <ptr target="#chen_zou_shi_2021"/> <ptr target="#uhl_et_al_2021"/>.
            </p>
            <p>The Franciscean Cadastre, covering an extensive area of <name>Habsburg</name> Central <name>Europe</name> spanning around 
               300,000 square kilometers, stands out as an exceptional historical source. Its nearly half-century production period and stringent 
               quality standards provide historians, archaeologists, and environmental scientists with privileged insights into 19th-century 
               land use and spatial organization (<ptr target="#feucht_2008"/>. Nevertheless, the cadastre also contains inaccuracies and errors, 
               which are magnified by the size of the operation. It represents a historical primary source and as such requires meticulous and 
               thorough critical reading. <name>Werner Drobesch</name> has recently provided the first comprehensive analysis of the economics of 
               the cadastre. From this and from the savings constraints he has pointed out, there are also comprehensive indications of the 
               weaknesses of this source <ptr target="#scharr_2024"/>. Further, a great deal of the accuracy of the Franciscean Cadastre depends 
               on the quality of the individual's work. The scale of the recording varies considerably, with a high level of detail in urban 
               areas, a medium level of detail in rural areas, and very coarse details in exposed terrain and high mountains. Many of the 
               weaknesses encountered in dealing with the Franciscean Cadastre resemble those that <name>Hosseini</name> et al. describe and 
               scrutinize in detail with regard to the Ordnance Survey <ptr target="#hosseini_et_al_2021"/>.
            </p>
        </div>
        <div>
          <head>Objective</head>
            <p>The objective of RePaSE was twofold: first, RePaSE should prove that AI-assisted extraction of large amounts of data — in our use 
               case, the location and the form of buildings — from the cadastre is already possible with existing resources and, in the best 
               case, identify suitable models to that purpose.<note>We were granted access to the highest resolution research data hosted by 
               <ref target="https://gis.stmk.gv.at/wgportal/atlasmobile">https://gis.stmk.gv.at/wgportal/atlasmobile</ref>. Similar research data 
               are available for all nine provinces of <name>Austria</name>. For example, data for the province of <name>Carinthia</name> is 
               available at <ref target="https://gis.ktn.gv.at/webgisviewer/atlas-mobile/">https://gis.ktn.gv.at/webgisviewer/atlas-mobile/</ref>. 
               Unfortunately, comparable access is not easy in all successor states of the <name>Habsburg</name> monarchy. The Arcanum service 
               offers good usability and orientation possibilities, but no metadata is offered free of charge that would enable scholarly work 
               and the resolution is limited.</note> The second objective was to make RePaSE fit for future multimodal applications 
               and to identify and test models that could be used to extract the locations and forms of buildings from current, already available 
               aerial and satellite imagery that is already available <ptr target="#smits_wevers_2023"/>.
            </p>
            <p>The larger context in which our work is embedded is the question of the possibilities that deep neural networks open up for the 
               work of historians, archaeologists, and other humanities scholars. A central challenge that we are addressing with this project is 
               to make the huge data structures that represent historical cadastres searchable at a higher level of analysis. On the one hand, we 
               see potential for a quantitative economic and social history. Structuring and classifying the information encoded in cadastres 
               would make it possible to analyze land use at regional or provincial level, for example. In the field of archaeology, a 
               cost-effective type of remote sensing in the automated comparison of historical and current visual representations of space would 
               allow faster identification of potentially archaeologically relevant large-scale historical structures. On the other hand, our 
               tool would also make it possible to extend the archaeological view to larger spatial units with relatively little effort and to 
               better visualize translocal or regional contexts for experts.
            </p>
            <p>Our research strategy involved two main sub-tasks: Task 1 focused on detecting buildings in scans of historical cadastral map 
               data, while Task 2 aimed to detect buildings in current satellite and aerial imagery. We then superimposed the output layers of 
               both tasks, specifically targeting places where buildings were present in the cadastre but absent in the present. This overlay 
               combined historical cadastral map data with current satellite imagery, allowing us to identify relevant locations for further 
               analysis. These locations were then utilized for analyzing different spatial representations, including satellite and aerial 
               imagery.
            </p>
        </div>
        <div>
          <head>Approach</head>
            <p>Because the size of the annotated map patches had a significant impact on the performance of our models, we resized all map 
               patches to the uniform size of 3747x2235, which proved effective. We also employed three different zoom levels: close, medium, 
               and far. We then used the software tool cvat to annotate the map patches <ptr target="#cvat_n.d."/>. The first task to be 
               addressed was an image segmentation problem, in order to successfully extract houses from cadastral map material. In our first 
               attempt, we followed a low-key approach and tried clustering algorithms to tackle this challenge, which was unsuccessful. In line 
               with the fail-fast approach of our proof-of-concept study, we subsequently turned to a completely different method. When it comes 
               to deep neural networks in this area of application, convolutional neural networks (CNN) have outperformed other architectures in 
               recent years <ptr target="#rawat_wang_2017"/> <ptr target="#oshea_nash_2015"/>. A CNN is a type of deep learning algorithm that is 
               well-suited for analyzing visual data. It uses principles from linear algebra, especially convolution operations, to extract 
               features and identify patterns within images. CNNs use a series of layers, each of which detects different features of an input 
               image. Depending on the complexity of its intended purpose, a CNN can contain dozens, hundreds, or even thousands of layers. As 
               building extraction can be considered a computer vision problem, fully convolutional networks are the most widespread 
               state-of-the-art solution to address this kind of problem <ptr target="#chen_zou_shi_2021"/>. We therefore chose the Google 
               DeepLabv3 model <ptr target="#chen_et_al_2016"/>, which is very efficient in dealing with the multi-scale problem due to its 
               atrous convolution layer <ptr target="#chen_et_al_2016"/>. We finetuned DeepLabv3 with 50 annotated example images that we split 
               into 6 squares each to give 300 images in total. The images were split into training, testing, and validation sets according to 
               the following scheme:
            </p>
            <figure>
              <head>Finetuning the DeepLabv3 model. Blue = validation data, red = training data, and green = test data.</head>
              <figDesc></figDesc>
                <graphic url="resources/images/figure02.png" style="width: 700px"/>
            </figure>
            <p>The validation set was automatically populated with squares lacking buildings to teach the model the absence of structures, which 
               accounts for its larger size compared to the test and train sets. Each dataset (train, test, validation) contained unique images 
               without duplication across sets. Finetuning utilized a repository designed for transfer learning in semantic segmentation 
               <ptr target="#singh_popescu_2021"/>, building upon DeepLabv3 with Resnet 101. Finetuning spanned 20 epochs on various computing 
               platforms until satisfactory results were achieved <ptr target="#pytorch_n.d."/>.
            </p>
            <p>The second task to be addressed was another image segmentation problem: the extraction of buildings from high-resolution aerial 
               and satellite data. As the quality of freely available satellite imagery has further increased in the two years between the setup 
               of the project idea and the project execution, we could now use higher quality satellite imagery than we originally expected, as 
               well as add high-resolution aerial photography and LiDAR data to the research data under scrutiny. Unlike the 19th century 
               cadastral map data that we were dealing with in Task 1, we were addressing an entirely different problem here, as buildings in 
               ortho- and satellite imagery can take on a wide range of very different appearances. 
            </p>
            <p>Due to the significantly different challenge, we chose an adapted approach. Vision transformers break down input images into 
               patches, convert each patch into a vector, and then process those vectors using a transformer encoder. This allows the model to 
               understand the content of the image, and this method has been used for various computer vision tasks such as image recognition, 
               image segmentation, and object detection. Vision transformers offer relatively economic computational overhead and memory 
               consumption while still achieving state-of-the-art accuracy <ptr target="#chen_zou_shi_2021"/>. We therefore trained a sparse 
               token transformer (STTnet) from scratch, using a GPU. STTnet is a state-of-the-art vision transformer with very promising results 
               in comparable tasks <ptr target="#chen_zou_shi_2021"/>.
            </p>
            <p>Building on Resnet50 as backbone, we then selected 2,657 labelled images from the AIRS dataset. This was so that we could avoid 
               labelling houses in the satellite images ourselves. The effort for this would have been considerable, because training from 
               scratch requires substantially more training examples than does finetuning. All images resembled the Alpine topography and the 
               landscape characteristics of our target region, <name>Styria</name>. We also used images taken in <name>Austin</name>, 
               <name>TX</name>; <name>Chicago</name>, <name>IL</name>; <name>Kitsap</name>, <name>WA</name>; <name>Tyrol</name> (a historical 
               region in the Alps of northern <name>Italy</name> and western <name>Austria</name>; and <name>Vienna</name>, <name>Austria</name>. 
               The training took place over 98 epochs; once the loss rate and the F1 score did not feature significant changes anymore, the 
               training was considered completed. The model was then tested with 224 labelled images.
            </p>
            <p>Subsequently, the extracted layers were superimposed and negative profiles were created. The negative profiles contain 
               potentially interesting locations for archaeological research. While these locations once featured buildings, they are not 
               overbuilty at present.
            </p>
        </div>
        <div>
          <head>Results</head>
            <p>The results for Task 1, the extraction of buildings from cadastral maps via DeepLabv3, were very successful.
            </p>
            <figure>
              <head>Building extraction from cadastral maps with finetuned DeepLabv3.</head>
              <figDesc></figDesc>
                <graphic url="resources/images/figure03.png" style="width: 700px"/>
            </figure>
            <p>As can be seen from the images, the extraction of red houses (stone houses), for which the model was finetuned, worked impeccably, 
               which is reflected in the metrics we obtained. We calculated the parameter intersection over union (IoU), where the labelled mask, 
               or the image that we prepared for training by labelling, is compared with the predicted mask. The IoU scores range from 0 to 1, 
               with a score of 1 indicating a perfect overlap between the predicted and ground truth bounding boxes. A high IoU score indicates 
               that the object detection algorithm is accurately localizing the object in the image. The value was calculated per class, with two 
               defined classes: house (Class 1) and background (Class 2). We calculated two values as follows:
            </p>
            <dhq:example>           
              <p>
                <formula rend="block" notation="tex">$$\text{Micro average} = \frac{\text{Intersection House} + \text{Intersection Background}}{\text{Union House} + \text{Union Background}}$$</formula>
              </p>
              <p>
                <formula rend="block" notation="tex">$$\text{Macro average} = \frac{\text{IoU House} + \text{IoU Background}}{2}$$</formula> 
              </p>
            </dhq:example>
            <p>Our results yielded a mean micro average IoU of 0.990389 and a mean macro average IoU of 0.89516, which represent outstanding 
               values. The accuracy of the model was thus sufficiently high. Among the problems we encountered were some streets that were 
               mistaken for houses, as well as minor differences in the color schemes (shades) in the hand-drawn maps. These were, however, minor 
               issues, which we believe we could resolve by labelling more training examples and retraining the model. Further finetuning could 
               include teaching the model to recognize additional structures, particularly yellow houses (wooden buildings) and streets, which 
               will be our priority in a follow-up project.
            </p>
            <p>The results of Task 2 were slightly different. The achieved IoUs of 0.537755 (macro) and 0.795838 (micro) proved to be 
               satisfactory in this context from a pragmatical perspective, as we were able to work with the obtained results. Although these 
               results are significantly below the values achieved for Task 1, we consider this task successfully resolved. The building outlines 
               contained in the negative layer must be kept more generous, in any case, because it is evident, especially in the terrain model, 
               that the terrain is affected by the development beyond the actual building boundaries, through the levelling of the built-over 
               area. The red markings in the upper layer mark false positives (e.g., a house was detected where no house existed), while the 
               green markings designate false negatives (e.g., the model failed to detect the house), and the white markings indicate correct 
               identifications. The model sometimes displays difficulties correctly identifying houses at the margins of the detection area. 
               Furthermore, it was difficult for the model to achieve good results outside a certain (optimal) zoom range. This problem could be 
               circumvented by properly addressing the issue in the data preprocessing. As a rule, the model tended to minimally enlarge the 
               recognized buildings, which was quite convenient for our work, as already noted. From an academic perspective, we see some 
               possibilities to optimize the model. We are certain that additional training, such as adding more epochs, would substantially 
               improve the model's performance.
            </p>
            <figure>
              <head>STT results <name>Tyralia</name> (left) and STT results <name>Vienna</name> (right).</head>
              <figDesc></figDesc>
                <graphic url="resources/images/figure04.png" style="width: 700px"/>
            </figure>
        </div>
        <div>
          <head>Next Steps</head>
            <p>RePaSE provided proof-of-concept with regard to AI-driven data extraction from historical maps, and our results represent a 
               a valuable way forward. The most important finding is that structures can be extracted from historical cadastral map material 
               accurately and economically in very high quality. This opens up a wide range of new possibilities, and this is a field we plan 
               on engaging further based on the results we gathered in RePaSE and in cooperation with several other groups working in this 
               field of research. In particular, we expect that the findings of our colleagues, Jiao, Heitzler, and Hurni concerning the 
               synthetic production of suitable training data will allow for a significant breakthrough in extracting relevant data from 
               historical maps at scale <ptr target="#jiao_heitzler_hurni_2022"/>.
            </p>
            <p>In view of the rapid progress in the extraction of graphic structures from high-resolution satellite and aerial photographs, it 
               seems sensible to orient our work with regard to the current state of research rather than investing significant resources in 
               improving the technology. Nevertheless, it is critical to remain up-to-date with advances in the field, as digital humanities and 
               humanities data science often struggle to access state-of-the-art technologies, models, and datasets to process information. We 
               consider the solution we identified, STTnet, viable and expandable, though it will require substantial effort to raise our outputs 
               to a level at which the quality of results will be robust enough to qualify for positive profiles. The STTnet we trained works 
               well in a project context such as RePaSE, but it will require some adjustments to work in a different context where a higher IoU 
               metric might be required.
            </p>
            <p>We have identified structures that can be detected very well when using computer vision and which bear important time signatures, 
               promising to render visible to researchers' eyes the past that is hidden in the surface of the Earth. Furthermore, because we have 
               recently found encouraging results using other object detectors for related tasks, we believe we have identified a promising path 
               of development in this field.
            </p>
            <p>Our study has shown us that, in principle, our models would also be suitable for recognising and reporting structural changes over 
               time in a more finely graduated manner. With a different model (e.g., experiments with YOLOv5 were promising), building outlines 
               in the cadastral material could be recognised even more finely and, theoretically, buildings that may not have undergone any 
               structural changes could be detected automatically. Although RePaSE was not aimed at determining the structures that replaced 
               historical buildings, the models could also contribute to clarifying such questions with a manageable adaptation effort.
            </p>
            <p>A follow-up to RePaSE has recently been granted by the Austrian Science Fund (FWF), which will fully integrate the two models 
               trained and finetuned within RePaSE (DeepLabv3 and STTnet). The objective of this follow-up is to identify and train two further 
               models with a focus on historical road infrastructure.
            </p>
        </div>
        <div>
          <head>Conclusion</head>
            <p>RePaSE provides a wide variety of stakeholders, from municipal authorities and political decision-makers at the local and regional 
               level to historians and archeologists, with a powerful tool to detect sites of potential archeological relevance, as is shown in 
               the following two figures:
            </p>
            <figure>
              <head>High-resolution aerial image of a part of the rural municipality <name>Heiligenkreuz</name> in the present day. The Red 
                  bounding boxes mark the automatically detected locations of buildings that featured in the 1820s cadastre. The yellow shade 
                  marks the identified present-day buildings.</head>
              <figDesc></figDesc>
                <graphic url="resources/images/figure05.png" style="width: 700px"/>
            </figure>
            <figure>
              <head>The respective map patch in the cadastre. The bounding boxes mark the buildings that have since disappeared.</head>
              <figDesc></figDesc>
                <graphic url="resources/images/figure06.png" style="width: 700px"/>
            </figure>
            <p>Based on our findings, we are convinced that the results of RePaSE will be an important support for various stakeholders in 
               Central <name>Europe</name>. In the field of construction management, our model is likely to be used to identify archaeologically 
               and historically sensitive areas in advance of major construction and infrastructure projects. In the context of RePaSE, we 
               define <q>archaeologically and historically sensitive</q> areas as sites that once featured historic buildings and may require 
               archaeological investigation in the course of construction activities or current land use. RePaSE can support the identification 
               of such sites in advance and thus help to prevent so-called emergency excavations (e.g., by changing the route or planned 
               archaeological intervention before construction begins). The model can also help to identify relevant structures in cultural 
               heritage management and make them more comprehensively visible, for example, in existing GIS and HGIS systems. Primarily, however, 
               we see RePaSE as the basis for a research tool designed to support digital humanists in identifying and extracting relevant 
               research data from mapped sources.
            </p>
            <p>The question arises to what extent neural networks can also be trained to detect visually relevant anomalies in different 
               dimensions of surface representations (digital terrain model, different high-resolution aerial photographs) without having to rely 
               on concrete knowledge from historical knowledge representations. Such detection could be achieved by a neural network by 
               identifying complex feature clusters in multimodal visual input signals, such as the superimposition of DTM and high-resolution 
               aerial images from different aerial surveys.
            </p>
            <p>The RePaSE-team is currently working to set up a server to provide the target group with full access to the entire 
               dataset processed in the project runtime.<note>We will provide all datasets that we used and produced to the scientific 
               community as soon as the project has been concluded administratively, which will most probably be the case in Q1/2024.</note> 
               While RePaSE currently supports research on the region of <name>Styria</name>, we expect that it could easily be expanded for 
               the adjoining regions of <name>Carinthia</name>, Lower <name>Austria</name>, <name>Salzburg</name>, and <name>Slovenia</name>. 
               As <name>Croatia</name> and <name>Burgenland</name> were part of the Transleithanian cadastre, which features slightly different 
               optical features, we expect to encounter some difficulties there, though these issues could likely be resolved through another 
               round of finetuning.
            </p>
            <p>RePaSE demonstrates the enormous potential of machine learning, particularly regarding the use of computer vision, image 
               segmentation, and object detection to scale up analysis of historical map material and combine these insights with AI-harvested 
               data gained from current, high-resolution imagery of the surface of the Earth. Models of the latest generation feature outstanding 
               usability and require manageable effort to successfully extract data from large-scale knowledge representations. In the context of 
               this project, however, domain knowledge plays an increasingly important role.
            </p>
            <p>Due to the availability, usability, and accessibility of image segmentation, it is increasingly becoming a standard technology. 
               With this in mind, we must consider what tools digital humanities will be using to work with such data in the near future. 
               Based on our results, we believe that object detection bears enormous potential for many crucial tasks, particularly when it comes 
               to the analysis of historical map data at scale. The object detectors we have been working with so far display a wide range of 
               possible applications, which reach far beyond the purposes for which they were developed. The fact that many object identification 
               models combine excellent object recognition with relatively manageable hardware requirements makes them suitable tools for use in 
               DH contexts. That being said, the most relevant potential for these tools is their capacity to bring spatial analysis in a 
               historical context to scale. What is more, a large set of different tools exists to visualize such changes, which will help 
               historians and fellow humanists to develop a deeper understanding of how space transforms over time.
            </p>
        </div>
      </body>
      <back>
        <listBibl>
          <bibl xml:id="arnold_tilton_2019" label="Arnold and Tilton 2019">Arnold, T. and Tilton, L. (2019) <title rend="quotes">Distant viewing: 
             Analyzing large visual corpora</title>, <title rend="italic">Digital Scholarship in the Humanities</title>, 34(Supplement 1), pp. i3-i6. 
             <ref target="https://doi.org/10.1093/llc/fqz013">https://doi.org/10.1093/llc/fqz013</ref>.
          </bibl>
          <bibl xml:id="baeten_lave_2020" label="Baeten and Lave 2020">Baeten, J. and Lave, R. (2020) <title rend="quotes">Retracing rivers and drawing 
             swamps: Using a drawing tablet to reconstruct an historical hydroscape from Army corps survey maps</title>, <title rend="italic">Historical 
             Methods</title>, 53(3), pp. 182–198. 
             <ref target="https://doi.org/10.1080/01615440.2020.1748151">https://doi.org/10.1080/01615440.2020.1748151</ref>.
          </bibl>
          <bibl xml:id="bickler_2021" label="Bickler 2021">Bickler, S.H. (2021) <title rend="quotes">Machine learning arrives in archaeology</title>, 
             <title rend="italic">Advances in Archeological Practice</title>, 9(2), pp. 186–192. 
             <ref target="https://doi.org/10.1017/aap.2021.6">https://doi.org/10.1017/aap.2021.6</ref>.
          </bibl>
          <bibl xml:id="budig_2017" label="Budig 2017">Budig, B. (2017) <title rend="italic">Extracting spatial information from historical maps: 
             Algorithms and interaction</title>. Würzburg, Germany: Würzburg University Press.
          </bibl>
          <bibl xml:id="bundesamt_2017" label="Bundesamt 2017">Bundesamt für Eich- und Vermessungswesen (ed.) (2017) 
             <title rend="italic">Österreichisches Kulturgut: 200 Jahre Kataster, 1817–2017</title>.
          </bibl>
          <bibl xml:id="can_gerrits_kabadayı_2021" label="Can, Gerrits, and Kabadayı 2021">Can, Y.S., Gerrits, P.J., and Kabadayı, M.E. (2021) 
             <title rend="quotes">Automatic detection of road types from the third military mapping survey of Austria-Hungary historical map series with 
             deep convolutional neural networks</title>, <title rend="italic">IEEE Access</title>, 9. 
             <ref target="https://doi.org/10.1109/ACCESS.2021.3074897">https://doi.org/10.1109/ACCESS.2021.3074897</ref>.
          </bibl>
          <bibl xml:id="champion_2017" label="Champion 2017">Champion, E.M. (2017) <title rend="quotes">Digital humanities is text heavy, visualization 
             light, and simulation poor</title>, <title rend="italic">Digital Scholarship in the Humanities</title>, 32(Supplement 1), pp. 25–32. 
             <ref target="https://doi.org/10.1093/llc/fqw053">https://doi.org/10.1093/llc/fqw053</ref>.
          </bibl>
          <bibl xml:id="chen_zou_shi_2021" label="Chen, Zou, and Shi 2021">Chen, K., Zou, Z., and Shi, Z. (2021) <title rend="quotes">Building extraction 
             from remote sensing images with sparse token transformers building extraction from remote sensing images with sparse token 
             transformers</title>, <title rend="italic">Remote Sensing</title> 13(21). 
             <ref target="https://doi.org/10.3390/rs13214441">https://doi.org/10.3390/rs13214441</ref>.
          </bibl>
          <bibl xml:id="chen_et_al_2016" label="Chen et al. 2016">Chen, L. et al. (2016) <title rend="quotes">DeepLab: Semantic image segmentation with 
             deep convolutional nets, atrous convolution, and fully connected CRFs</title>, <title rend="italic">arXiv</title>. Available at: 
             <ref target="http://arxiv.org/abs/1606.00915">http://arxiv.org/abs/1606.00915</ref>.
          </bibl>
          <bibl xml:id="chen_et_al_2017" label="Chen et al. 2017">Chen, L. et al. (2017) <title rend="quotes">Rethinking atrous convolution for semantic 
             image segmentation</title>, <title rend="italic">arXiv</title>. Available at: 
             <ref target="https://arxiv.org/abs/1706.05587">https://arxiv.org/abs/1706.05587</ref>.
          </bibl>
          <bibl xml:id="chiang_et_al_2020" label="Chiang et al. 2020">Chang, Y. et al. (2020) <title rend="italic">Using historical maps in scientific 
             studies: Applications, challenges, and best practices</title>. New York: Springer.
          </bibl>
          <bibl xml:id="cvat_n.d." label="CVAT n.d.">CVAT (n.d.) <title rend="italic">CVAT: Open data annotation platform</title>. Available at: 
             <ref target="https://www.cvat.ai/">https://www.cvat.ai/</ref>.
          </bibl>
          <bibl xml:id="ding_zhang_2021" label="Ding and Zhang 2021">Ding, W. and Zhang, L. (2021) <title rend="quotes">Building detection in remote 
            sensing image based on improved YOLOV5</title>, <title rend="italic">17th Annual International Conference on Computational Intelligence and 
            Security (CIS)</title>. Chengdu, China, 19-22 November. pp. 133-136. 
            <ref target="https://doi.org/10.1109/CIS54983.2021.00036">https://doi.org/10.1109/CIS54983.2021.00036</ref>.
          </bibl>
          <bibl xml:id="dolejs_forejt_2019" label="Dolejš and Forejt 2019">Dolejš, M. and Forejt, M. (2019) <title rend="quotes">“Franziscean cadastre in 
             landscape structure research: A systematic review</title>, <title rend="italic">Quaestiones Geographicae</title>, 38(1), pp. 131–144. 
             <ref target="https://doi.org/10.2478/quageo-2019-0013">https://doi.org/10.2478/quageo-2019-0013</ref>.
          </bibl>
          <bibl xml:id="drobesch_2013" label="Drobesch 2013">Drobesch, W. (ed.) (2013) <title rend="italic">Kärnten Am Übergang von Der Agrar-Zur 
             Industriegesellschaft: Fallstudien Zur Lage Und Leistung Der Landwirtschaft Auf Der Datengrundlage Des Franziszeischen Katasters 
             (1823-1844)</title>. Klagenfurt, Austria: Verlag des Geschichtsvereines Kärnten.
          </bibl>
          <bibl xml:id="ekim_sertel_kabadayı_2021" label="Ekim, Sertel, and Kabadayı 2021">Ekim, B., Sertel, E., and Kabadayı, M.E. (2021) 
             <title rend="quotes">Automatic road extraction from historical maps using deep learning techniques: A regional case study of Turkey in a 
             German World War II map</title>, <title rend="italic">ISPRS International Journal of Geo-Information</title>, 100(8). 
             <ref target="https://doi.org/10.3390/ijgi10080492">https://doi.org/10.3390/ijgi10080492</ref>.
          </bibl>
          <bibl xml:id="femenia-ribera_mora-navarro_santos-perez" label="Femenia-Ribera et al. 2022">Femenia-Ribera, C., Mora-Navarro, G., and Santos 
             Pérez, L.J. (2022) <title rend="quotes">Evaluating the use of old cadastral maps</title>, <title rend="italic">Land Use Policy</title>, 114. 
             <ref target="https://doi.org/10.1016/j.landusepol.2022.105984">https://doi.org/10.1016/j.landusepol.2022.105984</ref>.
          </bibl>
          <bibl xml:id="feucht_2008" label="Feucht 2008">Feucht, R. (2008.) <title rend="italic">Flächenangaben Im Österreichischen Kataster</title>. 
             Diploma thesis. Vienna University of Technology. Available at: 
             <ref target="https://repositum.tuwien.at/handle/20.500.12708/11046">https://repositum.tuwien.at/handle/20.500.12708/11046</ref>.
          </bibl>
          <bibl xml:id="fiorucci_et_al_2020" label="Fiorucci et al. 2020">Fiorucci, M. (2020) <title rend="quotes">Machine learning for cultural 
             heritage: A survey</title>, <title rend="italic">Pattern Recognition Letters</title>, 133(May), pp. 102–108. 
             <ref target="https://doi.org/10.1016/j.patrec.2020.02.017">https://doi.org/10.1016/j.patrec.2020.02.017</ref>.
          </bibl>
          <bibl xml:id="fiorucci_et_al_2022" label="Fiorucci et al. 2022">Fiorucci, M. (2022) <title rend="quotes">Deep learning for archaeological 
             object detection on LiDAR: New evaluation measures and insights</title>, <title rend="italic">Remote Sensing</title>, 14. 
             <ref target="https://doi.org/10.3390/rs14071694">https://doi.org/10.3390/rs14071694</ref>.
          </bibl>
          <bibl xml:id="garcia-molsosa_et_al_2021" label="Garcia-Molsosa et al. 2021">Garcia-Molsosa, A. (2021) <title rend="quotes">Potential of deep 
             learning segmentation for the extraction of archaeological features from historical map series</title>, <title rend="italic">Archaeological 
             Prospection</title>, 28(2), pp. 187–99. 
             <ref target="https://doi.org/10.1002/arp.1807">https://doi.org/10.1002/arp.1807</ref>.
          </bibl>
          <bibl xml:id="gil-fournier_parikka_2021" label="Gil-Fournier and Parikka 2021">Gil-Fournier, A. and Parikka, J. (2021) 
             <title rend="quotes">Ground truth to fake geographies: Machine vision and learning in visual practices</title>, <title rend="italic">AI and 
             Society</title>, 36, pp. 1253–1262. 
             <ref target="https://doi.org/10.1007/s00146-020-01062-3">https://doi.org/10.1007/s00146-020-01062-3</ref>.
          </bibl>
          <bibl xml:id="goderle_2017" label="Göderle 2017">Göderle, W.T. (2017) <title rend="quotes">Modernisierung Durch Vermessung? Das Wissen Des 
             Modernen Staats in Zentraleuropa, circa 1760–1890</title>, <title rend="italic">Archiv Für Sozialgeschichte</title>, 57, pp. 155–186.
          </bibl> 
          <bibl xml:id="goderle_2023" label="Göderle 2023">Göderle, W. (2023) <title rend="quotes">Imperiales Wissen: Zensus und Karte: 
            Landesvermessungen und Volkszählungen im Habsburgerreich in der Sattelzeit (1750-1850)</title>, in Feichtinger, J. and Uhl, H. (eds.) 
            <title rend="italic">Das integrative Empire: Wissensproduktion und kulturelle Praktiken in Habsburg-Zentraleuropa</title>. Bielefeld, 
            Germany: transcript, pp. 73-96.
          </bibl>
          <bibl xml:id="hagemans_et_al_2022" label="Hagemans et al. 2022">Hagemans, E. (2022) <title rend="quotes">The new, LADM inspired, data model 
             of the Dutch cadastral map</title>, <title rend="italic">Land Use Policy</title>, 117(June). 
             <ref target="https://doi.org/10.1016/j.landusepol.2022.106074">https://doi.org/10.1016/j.landusepol.2022.106074</ref>.
          </bibl>
          <bibl xml:id="heitzler_hurni_2020" label="Heitzler and Hurni 2020">Heitzler, M. and Hurni, L. (2020) <title rend="quotes">Cartographic 
             reconstruction of building footprints from historical maps: A study on the Swiss Siegfried map</title>, <title rend="italic">Transactions 
             in GIS</title>, 24(2), pp. 442–61. <ref target="https://doi.org/10.1111/tgis.12610">https://doi.org/10.1111/tgis.12610</ref>.
          </bibl>
          <bibl xml:id="hohensinner_et_al_2021" label="Hohensinner et al. 2021">Hohensinner, S. (2021) <title rend="quotes">Land use and cover change 
             in the industrial era: A spatial analysis of Alpine River catchments and Fluvial corridors</title>, <title rend="italic">Frontiers in 
             Environmental Science</title>, 9(June). 
             <ref target="https://doi.org/10.3389/fenvs.2021.647247">https://doi.org/10.3389/fenvs.2021.647247</ref>.
          </bibl>
          <bibl xml:id="hosseini_et_al_2021" label="Hosseini et al. 2021">Hosseini, K. et al. <title rend="quotes">Maps of a nation? The digitized 
             ordnance survey for new historical research</title>, <title rend="italic">Journal of Victorian Culture</title>, 26(2), pp. 284–299. 
             <ref target="https://doi.org/10.1093/jvcult/vcab009">https://doi.org/10.1093/jvcult/vcab009</ref>.
          </bibl>
          <bibl xml:id="ji_wei_lu_2019" label="Ji, Wei, and Lu 2019">Ji, S., Wei, S., and Lu, M. (2019) <title rend="quotes">Fully convolutional 
             networks for multisource building extraction from an open aerial and satellite imagery data set</title>, <title rend="italic">IEEE 
             Transactions on Geoscience and Remote Sensing</title>, 57(1), pp. 574–586. 
             <ref target="https://doi.org/10.1109/TGRS.2018.2858817">https://doi.org/10.1109/TGRS.2018.2858817</ref>.
          </bibl>
          <bibl xml:id="jiao_heitzler_hurni_2021" label="Jiao, Heitzler, and Hurni 2021">Jiao, C., Heitzler, M., and Hurni, L. (2021) 
             <title rend="italic">A survey of road feature extraction methods from raster maps</title>, <title rend="italic">Transactions in GIS</title>, 
             25(6), pp. 2734–2763. <ref target="https://doi.org/10.1111/tgis.12812">https://doi.org/10.1111/tgis.12812</ref>.
          </bibl>
          <bibl xml:id="jiao_heitzler_hurni_2022" label="Jiao, Heitzler, and Hurni 2022">Jiao, C., Heitzler, M., and Hurni, L. (2022) 
             <title rend="quotes">A fast and effective deep learning approach for road extraction from historical maps by automatically generating 
             training data with symbol reconstruction</title>, <title rend="italic">International Journal of Applied Earth Observation and 
             Geoinformation</title>, 113(September). 
             <ref target="https://doi.org/10.1016/j.jag.2022.102980">https://doi.org/10.1016/j.jag.2022.102980</ref>.
          </bibl>
          <bibl xml:id="katastral_1824" label="Katastral-Vermessungs Instruktion 1824"><title rend="italic">Katastral-Vermessungs Instruktion</title> 
             (1824). Available at: 
             <ref target="http://www.franziszeischerkataster.at/images/1820_KATASTRALVERMESSUNGSINSTRUKTION.pdf">http://www.franziszeischerkataster.at/images/1820_KATASTRALVERMESSUNGSINSTRUKTION.pdf</ref>.
          </bibl>
          <bibl xml:id="lee_wang_lee_2023" label="Lee, Wang, and Lee 2023">Lee, K., Wang, B., and Lee, S. (2023) 
             <title rend="quotes">Analysis of YOLOv5 and DeepLabv3+ algorithms for detecting illegal cultivation on public land: A case study of a 
             riverside in Korea</title>, <title rend="italic">International Journal of Environmental Research and Public Health</title>, 20(3). 
             <ref target="https://doi.org/10.3390/ijerph20031770">https://doi.org/10.3390/ijerph20031770</ref>.
          </bibl>
          <bibl xml:id="li_et_al_2022" label="Li et al. 2022">Li, J. et al. <title rend="quotes">A review of building detection from very high 
             resolution optical remote sensing images</title>, <title rend="italic">GIScience and Remote Sensing</title>, 59(1), pp. 1199-1225. 
             <ref target="https://www.tandfonline.com/doi/full/10.1080/15481603.2022.2101727">https://www.tandfonline.com/doi/full/10.1080/15481603.2022.2101727</ref>.
          </bibl>
          <bibl xml:id="li_et_al_2023" label="Li et al. 2023">Li, M. et al. <title rend="quotes">Method of building detection in optical remote sensing 
             images based on SegFormer</title>, <title rend="italic">Sensors</title>, 23(3). 
             <ref target="https://doi.org/10.3390/s23031258">https://doi.org/10.3390/s23031258</ref>.
          </bibl>
          <bibl xml:id="luo_wu_wang_2022" label="Luo, Wu, and Wang 2022">Luo, X., Wu, Y., and Wang, F. (2022) <title rend="quotes">Target detection 
             method of UAV aerial imagery based on improved YOLOv5</title>, <title rend="italic">Remote Sensing</title>, 14(19). 
             <ref target="https://doi.org/10.3390/rs14195063">https://doi.org/10.3390/rs14195063</ref>.
          </bibl>
          <bibl xml:id="mcdonough_2024" label="McDonough 2024">McDonough, K. (2024) <title rend="quotes">Maps as data: Computational spatial 
             history</title>, in Tilton, L., Mimno, D., and Johnson, J.M. (eds.) <title rend="italic">Computational humanities</title>. Minneapolis, 
             Minnesota: University of Minnesota Press.
          </bibl>
          <bibl xml:id="oliveira_et_al_2019" label="Oliveira et al. 2019">Oliveira, A. et al. (2019) <title rend="quotes">A deep learning approach 
             to cadastral computing</title>, <title>Digital humanities conference 2019</title>, Utrecht, Netherlands, 8-12 July. Available at: 
             <ref target="https://infoscience.epfl.ch/record/268282?ln=en">https://infoscience.epfl.ch/record/268282?ln=en</ref>.
          </bibl>
          <bibl xml:id="oshea_nash_2015" label="O'Shea and Nash 2015">O’Shea, K. and Nash, R. (2015) <title rend="quotes">An introduction to 
             convolutional neural networks</title>, <title rend="italic">ArXiv</title>. 
             <ref target="https://arxiv.org/abs/1511.08458">https://arxiv.org/abs/1511.08458</ref>.
          </bibl>
          <bibl xml:id="petek_urbanc_2004" label="Petek and Urbanc 2004">Petek, F. and Urbanc, M. (2004) <title rend="quotes">The Franziscean land 
             cadastre as a key to understanding the 19th-century cultural landscape in Slovenia</title>, <title rend="italic">Acta geographica 
             Slovenica</title>, 44(1), pp. 89-113. 
             <ref target="http://doi.org/10.3986/AGS44104">http://doi.org/10.3986/AGS44104</ref>.
          </bibl>
          <bibl xml:id="petitpierre_guhennec_2023" label="Petitpierre and Guhennec 2023">Petitpierre, R. and Guhennec, P. (2023) 
             <title rend="quotes">Effective annotation for the automatic vectorization of cadastral maps</title>, <title rend="italic">Digital 
             Scholarship in the Humanities</title>, 38(3), pp. 1227–1237. 
             <ref target="https://doi.org/10.1093/llc/fqad006">https://doi.org/10.1093/llc/fqad006</ref>.
          </bibl>
          <bibl xml:id="petitpierre_kaplan_di-lenardo_2021" label="Petitpierre, Kaplan, and Di Lenardo 2021">Petitpierre, R., Kaplan, F., and 
             Di Lenardo, I. (2021) <title rend="quotes">Generic semantic segmentation of historical maps</title>, <title rend="italic">Conference on 
             computation humanities research (CHR2021)</title>, Amsterdam, Netherlands, 17-19 November. Available at: 
             <ref target="https://ceur-ws.org/Vol-2989/long_paper27.pdf">https://ceur-ws.org/Vol-2989/long_paper27.pdf</ref>.
          </bibl>
          <bibl xml:id="pivac_et_al_2021" label="Pivac et al. 2021">Pivac, D. et al. (2021) <title rend="quotes">Availability of historical cadastral 
             data</title>, <title rend="italic">Land</title>, 10(9). 
             <ref target="https://doi.org/10.3390/land10090917">https://doi.org/10.3390/land10090917</ref>.
          </bibl>
          <bibl xml:id="pytorch_n.d." label="PyTorch n.d.">PyTorch (n.d.) <title rend="italic">DeepLabv3</title>. Available at: 
             <ref target="https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/">https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/</ref>.
          </bibl>
          <bibl xml:id="rawat_wang_2017" label="Rawat and Wang 2017">Rawat, W. and Wang, Z. (2017) <title rend="quotes">Deep convolutional neural 
             networks for image classification: A comprehensive review</title>, <title rend="italic">Neural Computation</title>, 29(9), pp. 2352–2449. 
             <ref target="https://doi.org/10.1162/neco_a_00990">https://doi.org/10.1162/neco_a_00990</ref>.
          </bibl>
          <bibl xml:id="ren_et_al_2015" label="Ren et al. 2015">Ren, S. et al. (2015) <title rend="quotes">Faster R-CNN: Towards real-time object 
             detection with region proposal networks</title>, <title rend="italic">NeurIPS 2015 conference</title>, Montréal, Canada, 7-12 December. 
             Available at: 
             <ref target="https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf">https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf</ref>.
          </bibl>
          <bibl xml:id="roberts_et_al_2024" label="Roberts et al. 2024">Roberts, P. et al. (2024) <title rend="quotes">Using urban pasts to speak to urban 
             presents in the Anthropocene</title>, <title rend="italic">Nature Cities</title>, 1(30-41). 
             <ref target="https://doi.org/10.1038/s44284-023-00014-4">https://doi.org/10.1038/s44284-023-00014-4</ref>.
          </bibl>
          <bibl xml:id="rumpler_2013" label="Rumpler 2013">Rumpler, H. (ed.) (2013) <title rend="italic">Der Franziszeische Kataster im Kronland Kärnten 
             (1823-1844)</title>. Klagenfurt am Wörthersee, Austria: Geschichtsverein Kärnten.
          </bibl>
          <bibl xml:id="rumpler_scharr_ungureanu_2015" label="Rumpler, Scharr, and Ungureanu 2015">Rumpler, H., Scharr, K. and Ungureanu, C. (eds.) 
             (2015) <title rend="italic">Der Franziszeische Kataster im Kronland Bukowina/Czernowitzer Kreis (1817-1865): Statistik und 
             Katastralmappen</title>. Vienna, Austria: Böhlau Verlag.
          </bibl>
          <bibl xml:id="scharr_2024" label="Scharr 2024">Scharr, K. (ed.) (2024) <title rend="italic">Der Franziszeische Kataster im Kronland 
             Österreichisch-Schlesien (1821–1851): The Franciscan cadastre in the crown land Austrian Silesia: Statistik und Katastralmappen</title>.
             Vienna, Austria: Böhlau Verlag.
          </bibl>
          <bibl xml:id="singh_popescu_2021" label="Singh and Popescu 2021">Singh, M. and Popescu, A.C. (2021) 
             <title rend="italic">DeepLabv3FineTuning</title>. Available at: 
             <ref target="https://Github.Com/Msminhas93/DeepLabv3FineTuning">https://Github.Com/Msminhas93/DeepLabv3FineTuning</ref>.
          </bibl>
          <bibl xml:id="smits_wevers_2020" label="Smits and Wevers 2020">Smits, T. and Wevers, M. (2020) <title rend="quotes">The visual digital turn: 
             Using neural networks to study historical images</title>, <title rend="italic">Digital Scholarship in the Humanities</title>, 35(1), pp. 
             194–207. <ref target="https://doi.org/10.1093/llc/fqy085">https://doi.org/10.1093/llc/fqy085</ref>.
          </bibl>
          <bibl xml:id="smits_wevers_2023" label="Smits and Wevers 2023">Smits, T. and Wevers, M. (2020) <title rend="quotes">A multimodal turn in digital 
             humanities: Using contrastive machine learning models to explore, enrich, and analyze digital visual historical collections</title>, 
             <title rend="italic">Digital Scholarship in the Humanities</title>, 38(3), pp. 1267–1280. 
             <ref target="https://doi.org/10.1093/llc/fqad008">https://doi.org/10.1093/llc/fqad008</ref>.
          </bibl>
          <bibl xml:id="stahl_weimann_2022" label="Ståhl and Weimann 2022">Ståhl, N. and Weimann, L. (2022) <title rend="quotes">Identifying wetland 
             areas in historical maps using deep convolutional neural networks</title>, <title rend="italic">Ecological Informatics</title>, 68(May). 
             <ref target="https://doi.org/10.1016/J.ECOINF.2022.101557">https://doi.org/10.1016/J.ECOINF.2022.101557</ref>.
          </bibl>
          <bibl xml:id="uhl_et_al_2020" label="Uhl et al. 2020">Uhl, J.H. et al. (2020) <title rend="quotes">Automated extraction of human settlement 
             patterns from historical topographic map series using weakly supervised convolutional neural networks</title>, 
             <title rend="italic">IEEE Access</title>, 8. 
             <ref target="https://doi.org/10.1109/ACCESS.2019.2963213">https://doi.org/10.1109/ACCESS.2019.2963213</ref>.
          </bibl>
          <bibl xml:id="uhl_et_al_2021" label="Uhl et al. 2021">Uhl, J.H. et al. (2021) <title rend="quotes">Towards the automated large-scale 
             reconstruction of past road networks from historical maps</title>, <title rend="italic">Computers, Environment and Urban Systems</title>, 
             94(June). <ref target="https://doi.org/10.1016/j.compenvurbsys.2022.101794">https://doi.org/10.1016/j.compenvurbsys.2022.101794</ref>.
          </bibl>
          <bibl xml:id="uhl_et_al_2022" label="Uhl et al. 2022">Uh, J.H. et al. (2022) <title rend="quotes">Combining remote-sensing-derived data and 
             historical maps for long-term back-casting of urban extents</title>, <title rend="italic">Remote Sensing</title>, 13(18). 
             <ref target="https://doi.org/10.3390/rs13183672">https://doi.org/10.3390/rs13183672</ref>.
          </bibl>
          <bibl xml:id="van-noord_2022" label="Van Noord 2022">Van Noord, N. (2022) <title rend="quotes">A survey of computational methods for iconic image 
             analysis</title>, <title rend="italic">Digital Scholarship in the Humanities</title>, 37(4), pp. 1316–1338. 
             <ref target="https://doi.org/10.1093/llc/fqac003">https://doi.org/10.1093/llc/fqac003</ref>.
          </bibl>
          <bibl xml:id="wheeler_2023" label="Wheeler 2023">Wheeler, R. (2023) <title rend="quotes">European official surveys of the nineteenth century 
             available online</title>, <title rend="italic">Charles Close Society</title>. Available at: 
             <ref target="https://www.charlesclosesociety.org/C19EuropeSurveys">https://www.charlesclosesociety.org/C19EuropeSurveys</ref>.
          </bibl>
          <bibl xml:id="wu_et_al_2023" label="Wu et al. 2023">Wu, S. et al. (2023) <title rend="quotes">Domain adaptation in segmenting historical 
             maps: A weakly supervised approach through spatial co-occurrence</title>, <title rend="italic">ISPRS Journal of Photogrammetry and Remote 
             Sensing</title>, 197(March), pp. 199–211. 
             <ref target="https://doi.org/10.1016/j.isprsjprs.2023.01.021">https://doi.org/10.1016/j.isprsjprs.2023.01.021</ref>.
          </bibl>
        </listBibl>
      </back>
   </text>
</TEI>
