<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>[PREVIEW] DHQ: Digital Humanities Quarterly: </title>
      <link href="../../common/css/dhq.css" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_screen.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_print.css" media="print" type="text/css" rel="stylesheet" />
      <style type="text/css">
        #mainContent {
          float: none;
          padding-top: 2em;
          padding-left: 4em;
          padding-right: 4em;
          margin-left: 225px;
           
        }</style>
   </head>
   <body>
      <div id="mainContent">
         <div class="DHQarticle">
            <div id="pubInfo">Preview<br />Volume 010 Number 3</div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            
            <div class="DHQheader">
               
               
               
               
               <h1 class="articleTitle lang en">Six Degrees of Francis Bacon: A Statistical Method for
                  Reconstructing Large Historical Social Networks </h1>
               
               <div class="author"><span style="color: grey">Christopher N.
                     Warren</span> &lt;<a href="mailto:cnwarren_at_cmu_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('cnwarren_at_cmu_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('cnwarren_at_cmu_dot_edu'); return false;">cnwarren_at_cmu_dot_edu</a>&gt;, Carnegie Mellon University</div>
               
               <div class="author"><span style="color: grey">Daniel Shore</span> &lt;<a href="mailto:ds663_at_georgetown_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('ds663_at_georgetown_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('ds663_at_georgetown_dot_edu'); return false;">ds663_at_georgetown_dot_edu</a>&gt;, Georgetown University</div>
               
               <div class="author"><span style="color: grey">Jessica Otis</span> &lt;<a href="mailto:jotis_at_andrew_dot_cmu_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('jotis_at_andrew_dot_cmu_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('jotis_at_andrew_dot_cmu_dot_edu'); return false;">jotis_at_andrew_dot_cmu_dot_edu</a>&gt;, Carnegie Mellon University</div>
               
               <div class="author"><span style="color: grey">Lawrence Wang</span> &lt;<a href="mailto:lawrencw_at_andrew_dot_cmu_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('lawrencw_at_andrew_dot_cmu_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('lawrencw_at_andrew_dot_cmu_dot_edu'); return false;">lawrencw_at_andrew_dot_cmu_dot_edu</a>&gt;, Carnegie Mellon University</div>
               
               <div class="author"><span style="color: grey">Mike Finegold</span> &lt;<a href="mailto:mfinegold_at_gmail_dot_com" onclick="javascript:window.location.href='mailto:'+deobfuscate('mfinegold_at_gmail_dot_com'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('mfinegold_at_gmail_dot_com'); return false;">mfinegold_at_gmail_dot_com</a>&gt;, Carnegie Mellon University</div>
               
               <div class="author"><span style="color: grey">Cosma Shalizi</span> &lt;<a href="mailto:cshalizi_at_stat_dot_cmu_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('cshalizi_at_stat_dot_cmu_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('cshalizi_at_stat_dot_cmu_dot_edu'); return false;">cshalizi_at_stat_dot_cmu_dot_edu</a>&gt;, Carnegie Mellon University</div>
               
               
               
               
               
               
               
               
               <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Six%20Degrees%20of%20Francis%20Bacon%3A%20A%20Statistical%20Method%20for%20Reconstructing%20Large%20Historical%20Social%20Networks&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=2016-07-12&amp;rft.volume=010&amp;rft.issue=3&amp;rft.aulast=Warren&amp;rft.aufirst=Christopher N.&amp;rft.au=Christopher N.%20Warren&amp;rft.au=Daniel%20Shore&amp;rft.au=Jessica%20Otis&amp;rft.au=Lawrence%20Wang&amp;rft.au=Mike%20Finegold&amp;rft.au=Cosma%20Shalizi"> </span></div>
            
            
            <div id="DHQtext">
               
               
               <div id="abstract">
                  <h2>Abstract</h2>
                  
                  
                  <p>In this paper we present a statistical method for inferring historical social
                     networks from biographical documents as well as the scholarly aims for doing so.
                     Existing scholarship on historical social networks is scattered across an
                     unmanageable number of disparate books and articles. A researcher interested in
                     how persons were connected to one another in our field of study, early modern
                     Britain (c. 1500-1700), has no global, unified resource to which to turn.
                     Manually building such a network is infeasible, since it would need to represent
                     thousands of nodes and tens of millions of potential edges just to include the
                     relations among the most prominent persons of the period. Our <cite class="title italic">Six Degrees of Francis Bacon</cite> project takes up recent
                     statistical techniques and digital tools to reconstruct and visualize the early
                     modern social network.</p>
                  
                  <p>We describe in this paper the natural language processing tools and statistical
                     graph learning techniques that we used to extract names and infer relations from
                     the <cite class="title italic">Oxford Dictionary of National Biography</cite>. We
                     then explain the steps taken to test inferred relations against the knowledge of
                     experts in order to improve the accuracy of the learning techniques. Our
                     argument here is twofold: first, that the results of this process, a global
                     visualization of Britain’s early modern social network, will be useful to
                     scholars and students of the period; second, that the pipeline we have developed
                     can, with local modifications, be reused by other scholars to generate networks
                     for other historical or contemporary societies from biographical documents.</p>
                  </div>
               
               
               
               
               <div class="div div0">
                  
                  <h1 class="head">Introduction</h1>
                  
                  <div class="counter"><a href="#p1">1</a></div>
                  <div class="ptext" id="p1">Historians and critics have long studied the ways that early modern writers and
                     thinkers associated with each other and participated in various kinds of formal
                     and informal groups. Although their findings have been published in countless
                     books and articles, there is currently no way to obtain a unified view of the
                     early modern social network. A scholar must start largely from scratch if she
                     seeks to understand complex relations between multiple people, identify
                     potentially important relationships that have yet to be explored, understand the
                     extent of communities of interaction, or visualize the scholarly consensus
                     regarding networks, whether small or large. The creation of a large scale early
                     modern social network gives scholars a visual way to explore scholarly knowledge
                     of relationships and to see what has – or hasn’t – been studied in the extant
                     historiography.</div>
                  
                  <div class="counter"><a href="#p2">2</a></div>
                  <div class="ptext" id="p2"> The most desirable outcome of our work would of course be a comprehensive map of
                     the way early modern persons were related. Yet practical challenges abound. The
                     population of Britain rose to over 5.5 million people by the end of the
                     seventeenth century, and little documentary evidence survives on much of that
                     population. Attempting to reconstruct the full network would be unrealistic.
                     Even if we limited ourselves to people alive in 1700 and successfully gathered
                     5.5 million names, the number of potential relationships in that set exceeds 15
                     billion. Social relations are exceedingly complex, even in societies
                     considerably smaller than our own. There are thus excellent reasons to proceed
                     more conservatively–focusing only on small, well-documented subsets of the
                     population. Some of the best known digital networks projects, such as Stanford
                     University’s <cite class="title italic">Mapping the Republic of Letters</cite> and
                     Oxford University's <cite class="title italic">Cultures of Knowledge</cite>, do just
                     that. Adhering to historians’ venerable practice, they proceed incrementally and
                     only include relationships directly attested by documents such as letters. This
                     approach produces relatively small, highly substantiated networks – on the order
                     of, say, 500 nodes [<a class="ref" href="#ahnert2014">Ahnert and Ahnert 2014</a>]
                     [<a class="ref" href="#basu2015">Basu et al. 2015</a>] – but it also limits these networks to representing an
                     infinitesimal sliver of the rich and varied kinds of relationships between
                     people.</div>
                  
                  <div class="counter"><a href="#p3">3</a></div>
                  <div class="ptext" id="p3"> Taking a different approach, we identified biographical data as the most
                     productive starting point for our network reconstruction, which we have named
                     <cite class="title italic">Six Degrees of Francis Bacon</cite> (SDFB), after the
                     early modern figure whose life spanned the sixteenth and seventeenth centuries
                     and whose career spanned the domains of politics, science, and letters. We chose
                     biographies because they are a well-established and highly standardized product
                     of modern historical scholarship. Moreover, a central collection of such data
                     was already available to us digitally through the <cite class="title italic">Oxford
                        Dictionary of National Biography</cite> (ODNB), which comprises the
                     biographies of people deemed by its editors as significant to British history.
                     Jerome McGann has argued that “the whole of our cultural
                     inheritance has to be recurated and reedited in digital forms and
                     institutional structures”
                      [<a class="ref" href="#mcgann2014">McGann 2014</a>, 1]. Most often, in his account, this involves <em class="emph">transference</em> of
                     text “from bibliographical to digital
                     machines.” SDFB tackles a related but more difficult problem: the
                     <em class="emph">transformation</em> of biographical text, which focuses on a single
                     person but contains rich information about social relations, into a global
                     (non-egocentric) network graph, which requires extracting information about
                     nodes (persons) and edges (relations) while ignoring or discarding other kinds
                     of biographical information.</div>
                  
                  <div class="counter"><a href="#p4">4</a></div>
                  <div class="ptext" id="p4">From the ODNB biographies of persons who lived between 1500-1700 we created an
                     initial dataset of 13,309 actor nodes. Each actor node could potentially be
                     connected to any of the other nodes, leading to over 88 million potential edges
                     to explore. Even within this initial dataset, already limited for manageability,
                     it was not feasible to verify each potential edge. One approach might have been
                     to curate these relationships in an ad-hoc order, as a scholar became interested
                     in a particular relationship or as relationships were explicitly documented in a
                     scholarly source. We would then have collected as many relationships as the time
                     and labor of scholars allowed, but we would have had little to say about the
                     relative importance of collected relationships and nothing at all to say about
                     those relationships yet to be curated. For instance, would the absence of an
                     edge mean that the two nodes shared no association or that the association has
                     yet to be explored in our network? Rather than rebuilding the network by hand,
                     we chose to employ a computational and statistical approach, unifying the
                     dispersed knowledge already extant in the literature into an inferred graph of
                     the network that can then be made available to scholars for correction and
                     curation.</div>
                  
                  <div class="counter"><a href="#p5">5</a></div>
                  <div class="ptext" id="p5">In the following sections, we lay out our statistical method for reconstructing
                     the early modern social network in four broad steps, then examine the
                     significance and limitations of our results from the perspective of humanist
                     scholarship. In section one, we discuss the process of identifying a collection
                     of textual documents to use as input, considering both direct and indirect
                     evidence of historical relationships. In section two, we explain how we used
                     Named-Entity Recognition (NER) to process the unstructured text into structured
                     data – specifically a matrix of documents and named entities – that was amenable
                     to statistical analysis. In section three, we give an overview of how we applied
                     statistical graph-learning methods to our structured data, with more detailed
                     technical information included an appendix. In section four, we discuss methods
                     of validating a sample of proposed relationships using the local expertise of
                     humanist scholars. In section five, we step back to examine the broader
                     significance of this process from the perspective of twenty-first-century
                     researchers in the humanities. We also examine the assumptions underlying our
                     statistical methods and potential areas of modification necessary before
                     redeploying these methods with other historical corpora.</div>
                  
                  <div class="counter"><a href="#p6">6</a></div>
                  <div class="ptext" id="p6">In developing this method, we have demonstrated the feasibility of applying graph
                     learning methods to any large collection of biographical text – early modern or
                     otherwise. This is neither a completely automated process nor a perfect one, but
                     we have also developed a practical mechanism by which expert feedback can
                     improve the network as well as the statistical procedures used to infer it. We
                     have thus created a viable and transferrable approach to inferring large-scale
                     historical social networks, which should be of particular interest to digital
                     humanists, scholars of networks and prosopography, as well as scholars
                     interested in the history of scholarship itself.</div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">1. Source Material</h1>
                  
                  <div class="counter"><a href="#p7">7</a></div>
                  <div class="ptext" id="p7">The first step of our process was identifying the extent of available texts and
                     determining which texts were potentially the most useful for network inference.
                     Numerous types of primary and secondary sources can provide evidence of
                     historical relationships. Some of these sources provide direct evidence of a
                     link between two actors – for example, society membership rolls, marriage
                     certificates, or archival letters. Other sources may collectively provide
                     indirect evidence: the same two people mentioned together in numerous accounts
                     or biographies is highly suggestive of the possibility that those two people may
                     have come into contact with one another.</div>
                  
                  <div class="counter"><a href="#p8">8</a></div>
                  <div class="ptext" id="p8"> In an ideal world we would have made use of all the relevant historical sources
                     and scholarship. In this one, we needed to begin with a collection of texts that
                     was well-defined, accessible, machine readable, and relatively uniform. We also
                     wanted to begin with a collection that included a broad range of potentially
                     relevant figures, according to social, geographic, and temporal standards. We
                     therefore decided to focus on the 58,625 biographical entries that make up the
                     ODNB. Running to sixty volumes in its print format, the ODNB is the labor of
                     10,000 scholars who have collectively contributed its 62 million words. </div>
                  
                  <div class="counter"><a href="#p9">9</a></div>
                  <div class="ptext" id="p9"> On a technical level, the ODNB was praised upon its 2004 release for being “the first to exploit the
                     potential of electronic publication on so vast and imaginative a
                     scale”
                      [<a class="ref" href="#collini2005">Collini 2005</a>]. We considered the ODNB an appropriate choice for several other reasons
                     as well. Several of the collaborators on this project share a primary interest
                     in the early modern era (c. 1500-1700) in Britain, a period well covered by the
                     ODNB. Both Carnegie Mellon University and Georgetown University have
                     subscriptions to the ODNB, providing us with legal access to the “many possibilities opened up by
                     the online version for accessing and organising the hoard of
                     information”
                      [<a class="ref" href="#collini2005">Collini 2005</a>]. The ODNB’s dense-in-data documents fit the criteria of machine
                     readability and relative uniformity. Although the biographies vary in length,
                     all have a similar format and the raw text can be extracted in the same manner.
                     Lastly, as biographies, they contain both explicit mentions of relationships –
                     such as “Bacon’s life and career
                     during the 1590s was dominated by his close relationship with Robert
                     Devereux” – as well as numerous implicit indicators of potential
                     relationships. Robert Cecil, for example, is mentioned five times in one section
                     of Bacon’s biography [<a class="ref" href="#peltonen2004">Peltonen 2004</a>]. The ODNB thus offered
                     opportunities to analyze both direct and indirect relationship data from a
                     single collection.</div>
                  
                  <div class="counter"><a href="#p10">10</a></div>
                  <div class="ptext" id="p10"> As we worked with the ODNB data, a further advantage of this particular
                     collection emerged: its ability to shed light on the current state and history
                     of scholarship. Individually, each document in the ODNB is a roughly
                     chronological account of one person’s life, specifically an individual deemed by
                     nineteenth-, twentieth-, or twenty-first-century editors to have “in some way influenced [British]
                     national life”
                      [<a class="ref" href="#collini2005">Collini 2005</a>]. As a collection, therefore, the ODNB holds significant information about
                     what has and has not risen to the level of scholarly notice since the late
                     Victorian creation of the Dictionary of National Biography, the ODNB’s
                     precursor, in the 1880s. The original DNB primarily emphasized the political,
                     literary, and scientific accomplishments of famous men, dedicating only 5% of
                     its overall entries to women, and only 2% of the entries in the target date
                     range 1500-1700. In the ODNB’s current version, the percentage of women has only
                     increased to 11% overall and 6% in our target date range [<a class="ref" href="#matthew2004">Matthew and Harrison 2004</a>].</div>
                  
                  <div class="counter"><a href="#p11">11</a></div>
                  <div class="ptext" id="p11">In our era of text mining and network visualizations, such biases have continued
                     effects. A bias towards men is a known issue in existing historiography; this
                     bias is neither confined to the ODNB nor particularly surprising. However,
                     transforming textual secondary sources into visual representations allows for
                     more purposeful “critical scrutiny of what is
                     known, how, and by whom” – the branch of knowledge increasingly
                     referred to as “metaknowledge”
                      [<a class="ref" href="#evans2011">Evans 2011</a>]. Our visualizations of the early modern social network demonstrate the
                     need both for more scholarship on women and other marginalized groups and for
                     the integration of this scholarship into broader discussions of earlier modern
                     society and culture; more importantly, it identifies the local areas of the
                     network where the need for such scholarship is most pressing.</div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">2. Pre-Processing Source Material</h1>
                  
                  <div class="counter"><a href="#p12">12</a></div>
                  <div class="ptext" id="p12">After having identified our collection of source materials, we then had to
                     process the unstructured text – specifically a collection of HTML-formatted
                     documents acquired through the ODNB website – into a format more amenable for
                     analysis. This was done by extracting only the biographical portions of the text
                     from the initial HTML documents – stripping the HTML formatting, bibliographies,
                     and other extraneous text from the documents.<a class="noteRef" href="#d4e438">[1]</a>
                     We then ran the plaintext documents through two NER tools: one from Stanford’s
                     Natural Language Processing Group, denoted Stanford [<a class="ref" href="#finkel2005">Finkel et al. 2005</a>],
                     and another from the LingPipe collection of tools [<a class="ref" href="#alias2008">Alias-i 2008</a>].</div>
                  
                  <div class="counter"><a href="#p13">13</a></div>
                  <div class="ptext" id="p13"> These NER tools use probabilistic methods to identify names and to classify
                     those names according to types such as person, location, or organization. For
                     example, the following sentence – “The occasion
                     of ‘Lycidas’ was the death of Edward King, a fellow of Christ's College who
                     had drowned off the coast of Anglesey on 10 August 1637” – might be
                     processed as “The occasion of
                     ‘[PERSON]Lycidas[/PERSON]’ was the death of [PERSON]Edward
                     King[/PERSON], a fellow of [ORGANIZATION]Christ's College[/ORGANIZATION]
                     who had drowned off the coast of [PLACE]Anglesey[/PLACE] on [DATE]10
                     August 1637[/DATE]”
                      [<a class="ref" href="#campbell2004">Campbell 2004</a>]. This example shows that no classifier is perfect – “Lycidas” in fact is the title of Milton’s great elegy rather than an
                     historical person – and classifiers face particular challenges with
                     multiple-word entities such as “Christ’s College” where the the first word
                     separated from its follower could mistakenly if understandably be classed as a
                     person.</div>
                  
                  <div class="counter"><a href="#p14">14</a></div>
                  <div class="ptext" id="p14">For both Stanford and Lingpipe, we began with the default models trained on news
                     article corpora and ran the tools on ten randomly chosen documents from the
                     ODNB. These documents were then manually tagged to determine the accuracy of the
                     tools’ performance on our target dataset. Two measures of accuracy were used:
                     recall, the fraction of desired results obtained, and precision, or the fraction
                     of obtained results that are correct. For our purposes, high recall was
                     considered necessary, while high precision was desirable but less important.
                     Stanford achieved better recall than LingPipe, at 70.7% and 67.8% respectively,
                     but combining their results led to recall rates of 85.7%. The two tools were
                     combined by taking all of Stanford’s smatches, and then adding in LingPipe’s
                     matches if Stanford did not tag those specific words. In case of overlapping or
                     contradictory tags, we used Stanford’s matches.</div>
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row label">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Subset</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Recall</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Precision</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Stanford (ST), Person Tags Only <br /> LingPipe (LP), Person Tags
                              Only</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">63.51%<br />52.44%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">91.75%<br />72.11%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">ST, Person and Organization Tags<br />LP, Person and Organization
                              Tags</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">70.74%<br />67.83%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">74.02%<br />46.19%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">ST + LP, Person Tags Only<br />ST + LP, Person and Organization
                              Tags</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">79.37%<br />85.66%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">77.91%<br />51.61%</td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 1. </div>Recall and Precision for Various Subsets of NER Results</div>
                  </div>
                  
                  
                  <div class="counter"><a href="#p15">15</a></div>
                  <div class="ptext" id="p15">We then implemented two additional procedures to improve recall and precision.
                     First, to improve recall, we ran the documents through NER twice: once to create
                     the initial tags and a second time using the initial tags as a dictionary, which
                     enabled us to search for missed instances of phrases that were tagged during the
                     first pass through the documents. This latter search was particularly successful
                     at capturing partial name co-references, which occur within documents when
                     historical figures are referred to only by their first or last name. With few
                     exceptions, partial names that are part of a longer name found in that document
                     are not actually different people. “Bacon” in a document containing
                     “Francis Bacon” will refer, except in rare cases, to Francis Bacon. If
                     a partial name matched the subject of a biography, it was considered a mention
                     of that subject. Otherwise, partial names were considered mentions of the
                     matching most recent full-name mention.</div>
                  
                  <div class="counter"><a href="#p16">16</a></div>
                  <div class="ptext" id="p16">Second, to improve precision, we implemented manual rules to reduce the number of
                     non-human names detected. This included removing all phrases that contained
                     words beginning with lower-case letters; exceptions were made for the words
                     “of” and “de” which often form part of names during this period,
                     i.e. “Katherine of Aragon.” We also eliminated phrases with non-alphabetic
                     characters – such as $, *, and numbers – and common non-human proper names
                     supplied by our subject matter experts – such as “Commonwealth,”
                     “Catholic,”
                     “Greek,” and “Roman.”</div>
                  
                  <div class="counter"><a href="#p17">17</a></div>
                  <div class="ptext" id="p17">This resulted in final recall rates of 96.7% and precision rates of 65.5% on the
                     initial test set. Testing on six new randomly-chosen documents led to a similar
                     95.3% recall rate but a slightly lower 54.0% precision rate. As our priority was
                     a high recall rate, this was deemed acceptable. A later examination of a random
                     200-entity sample indicated the overall dataset’s precision rates were
                     approximately 59% with +/- 7% margin of error.</div>
                  
                  <div class="counter"><a href="#p18">18</a></div>
                  <div class="ptext" id="p18"> From these results, we created a large table of documents and named entities.
                     For each document, we tabulated the named entities and their number of mentions,
                     which led to 494,536 different named entities occurring throughout the
                     collection of 58,625 documents. We then reduced the number of named entities in
                     two ways. First, we ignored named entities that did not occur in an ODNB
                     biography within the period of interest (1500-1700). This made network inference
                     less costly computationally. So too with our second step, in which we omitted
                     names that occurred in fewer than five documents. Since correlations are very
                     difficult to determine with sparse data, inferring relations among low count
                     documents would have increased the number of false positives. While the five
                     mention threshold did unfortunately mean that we had to eliminate many less
                     prominent individuals, or those referred to by different names across the ODNB,
                     the tradeoff was that it helped us achieve better precision at less
                     computational cost. A final stage required further human curation –
                     specifically, searching for names in the ODNB – to disambiguate people who
                     shared the same name and de-duplicate people referenced under multiple names,
                     particularly for names obtained through the NER tools. While recent research in
                     the NLP community has focused on finding a way to automate this final stage,
                     such as the Berkeley Entity Resolution System, we preferred the accuracy of
                     manual curation [<a class="ref" href="#durrett2014">Durrett and Klein 2014</a>].</div>
                  
                  <div class="counter"><a href="#p19">19</a></div>
                  <div class="ptext" id="p19">The resulting table of 58,625 rows and 13,309 columns is known mathematically as
                     a matrix. This <em class="emph">n</em>×<em class="emph">p</em> matrix, Y, has <em class="emph">n</em> rows
                     representing documents and <em class="emph">p</em> columns representing people, or
                     actors, in the network. The number of times person <em class="emph">j</em> is mentioned
                     by name in document <em class="emph">i</em> gives us Y<span class="hi subscript">ij</span>, a
                     non-negative integer for each document/person pair. We used this document-count
                     matrix to infer the social network.</div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">3. Statistical Inference</h1>
                  
                  <div class="counter"><a href="#p20">20</a></div>
                  <div class="ptext" id="p20">We motivated our statistical model for the previously described document-count
                     matrix by assuming that direct connections between historical figures would be
                     reflected by their being mentioned together in documents. Indeed, prior work has
                     shown it possible to infer a rough graph based on co-mentions alone [<a class="ref" href="#bosch2011">Bosch and Camp 2011</a>]
                     [<a class="ref" href="#bosch2012">Bosch and Camp 2012</a>]. However, our model requires more than a simple count
                     of co-mentions because co-mentions sometimes result from confounding factors
                     such as mutual acquaintances. </div>
                  
                  
                  <div class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure01.png" rel="external"><img src="resources/images/figure01.png" style="" alt="" /></a></div>
                     
                     
                     <div class="caption">
                        <div class="label">Figure 1. </div>Charles I as a Confounding Variable.</div>
                  </div>
                  
                  
                  <div class="counter"><a href="#p21">21</a></div>
                  <div class="ptext" id="p21">Consider an example such as the one displayed in Figure 2. George Villiers, Duke
                     of Buckingham (1592-1628), knew King Charles I (1600-1649), and Charles I knew
                     Prince Rupert of the Rhine (1619-1682), but Buckingham and Prince Rupert – whose
                     lives only barely overlapped – never met. Because Prince Rupert and Charles I
                     are connected, they will tend to be mentioned together in source documents. How
                     often Prince Rupert is mentioned can therefore be predicted in part from how
                     often Charles I is mentioned. Likewise if Charles I and Buckingham are
                     connected, mentions of Buckingham predict mentions of Charles I. But in the case
                     of no direct tie between Prince Rupert and Buckingham, as here, their names may
                     still correlate due to mentions of Charles I. Despite such correlation, mentions
                     of Buckingham convey no information about mentions of Prince Rupert not already
                     accounted for by mentions of Charles I. We thus reasoned that co-mentions found
                     in our document-count matrix – and correlations between any two given nodes
                     derived from the matrix – might be the result of one or more confounding
                     factors.</div>
                  
                  <div class="counter"><a href="#p22">22</a></div>
                  <div class="ptext" id="p22">Under these assumptions, inferring the existence of network connections is the
                     same problem as inferring the conditional independence structure in a particular
                     statistical model – in this case, our document-count matrix [<a class="ref" href="#glymour2001">Glymour et al. 2001</a>]. The method we used to infer the conditional
                     independence structure of the document-count matrix is the Poisson Graphical
                     Lasso, a penalized regression method proposed by Allen and Liu. This method is a
                     generalization of Meinshausen and Bühlmann’s computationally faster
                     approximation to the graphical lasso [<a class="ref" href="#friedman2008">Friedman et al. 2008</a>]; it defines
                     the relationships between nodes by a conditional Poisson distribution, instead
                     of a multivariate normal distribution, which allows the penalized regression to
                     be modified by an individual node’s count data [<a class="ref" href="#allen2012">Allen and Liu 2012</a>]. This
                     method allowed us to create a symmetric <span class="hi italic">p</span>×<span class="hi italic">p</span> correlation matrix <span class="hi italic">θ̂</span>, where two
                     nodes <span class="hi italic">j</span> and <span class="hi italic">k</span> are conditionally
                     independent if and only if the coefficient <span class="hi italic">θ̂<span class="hi subscript">jk</span></span> = <span class="hi italic">θ̂<span class="hi subscript">kj</span></span> is zero.</div>
                  
                  <div class="counter"><a href="#p23">23</a></div>
                  <div class="ptext" id="p23">In some applications of graphical models to infer network structure, all non-zero
                     coefficients are of interest. For example, in gene networks, the expression
                     levels of two connected genes may be negatively (conditionally) correlated. In
                     our social network, however, we are primarily concerned with positive
                     coefficients, as a relationship between two people should lead to a positive
                     conditional correlation of their mentions in a document. A small or zero
                     correlation suggests a lack of relationship between two people, while negative
                     correlations might occur for a variety of reasons, including non-overlapping
                     lifespans or two-degree – i.e., friend-of-a-friend – relationships without
                     so-called triadic closure [<a class="ref" href="#simmel1950">Simmel 1950</a>].</div>
                  
                  <div class="counter"><a href="#p24">24</a></div>
                  <div class="ptext" id="p24"> We therefore used our initial correlation matrix to create an adjacency matrix Y
                     – a symmetric <span class="hi italic">p</span>×<span class="hi italic">p</span> matrix where
                     Y<span class="hi subscript">ij</span>=Y<span class="hi subscript">ji</span>=1 when there is
                     a positive correlation and assumed relationship between person <span class="hi italic">i</span> and person <span class="hi italic">j</span>, and 0 otherwise. Because our
                     data and methods provide more information about some edges than others, however,
                     we wanted to be able to attach a confidence estimate to potential edges instead
                     of simply obtaining a yes or no estimate. </div>
                  
                  <div class="counter"><a href="#p25">25</a></div>
                  <div class="ptext" id="p25">Confidence estimates were also better suited to the grey areas of humanistic
                     research often requiring interpretation and even guesswork. In order to create
                     this confidence estimate, we fit the Poisson Graphical Lasso on random subsets
                     of our data 100 times and added the resulting adjacency matrices into a final
                     matrix that we called our confidence matrix, C. This calculation gave us a
                     “confidence level” for the likelihood of a relationship’s existence
                     that ranged between 0 – never inferred – and 100 – always inferred.</div>
                  
                  <div class="counter"><a href="#p26">26</a></div>
                  <div class="ptext" id="p26">Throughout this process, we experimented with tuning parameters and found that
                     our final estimates did not vary significantly for all reasonable tuning
                     parameters, where reasonable is defined as a low enough penalty such that edges
                     are actually added, but high enough penalty that the algorithm converges
                     rapidly. We also conducted penalty parameter training – using expert knowledge
                     to manually confirm the existence of some relationships – but found this
                     produced only very localized changes and had little impact on the overall
                     network structure. The only significant manual intervention in this basic method
                     thus came from our name disambiguation procedures, as we had nearly one thousand
                     non-unique names in our node set. To deal with the the challenge of multiple
                     individuals sharing the same name, we first disallowed positive adjacency
                     estimates between two people with non-overlapping lifespans (with a one-year
                     margin of error for posthumous children). Second, we used probabilities based on
                     biography length to distribute adjacency estimates among people with overlapping
                     lifespans.</div>
                  
                  <div class="counter"><a href="#p27">27</a></div>
                  <div class="ptext" id="p27">A fuller explanation of our application of the Poisson Graphical Lasso can be
                     found in our Appendix, along with a link to our code.</div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">4. Expert Validation</h1>
                  
                  <div class="counter"><a href="#p28">28</a></div>
                  <div class="ptext" id="p28">Having constructed our confidence matrix of estimated relationships, we then
                     conducted three different types of validation checks: one to ensure that our
                     results showed the homophily that network studies have taught us to expect when
                     semantic context is taken into account; one to confirm that our results were
                     consistent with statistical theory; and one to evaluate the accuracy of our
                     results in comparison with an expert human reading of the ODNB biographies. We
                     first used topic modeling on approximately 90% of our dataset – excluding people
                     with duplicate names whose relationships had to be disambiguated – to evaluate
                     different kinds of actor connectivity in a semantic context. Then, on smaller
                     subsets of our data, we compared our results with alternative statistical
                     methods, and calculated precision and recall rates.</div>
                  
                  <div class="counter"><a href="#p29">29</a></div>
                  <div class="ptext" id="p29"> Our first validation step was motivated by the fact that the Poisson Graphical
                     Lasso counts names but ignores semantic context. As a way to test the validity
                     of this approach, we wanted to compare the connectivity of actors who are
                     mentioned in similar contexts to the connectivity of those mentioned in
                     different contexts, since actors who share contexts are more likely to know one
                     another than those who do not [<a class="ref" href="#mcpherson2001">McPherson, Smith-Love and Cook 2001</a>]. Thus for our first
                     validation step, we decided to create and analyze a latent dirichlet allocation
                     (LDA) topic model – an algorithm for extracting semantic clusters from a set of
                     text [<a class="ref" href="#blei2003">Blei et al. 2003</a>]
                     [<a class="ref" href="#weingart2012">Weingart 2012</a>]. We hoped to find our network data showed greater
                     connectivity between actors who share a context than between actors in different
                     contexts, as generated through the topic model. If so, we could conclude that
                     our approach produces results compatible with accepted, semantically-sensitive
                     approaches.</div>
                  
                  <div class="counter"><a href="#p30">30</a></div>
                  <div class="ptext" id="p30">To generate our topic model, we created a ‘bag of words’ for each person in our
                     dataset, comprised of all words that appear before and after the person’s name
                     in the ODNB. Specifically, for each person in the network, we located all
                     mentions in the ODNB, and used the previous fifteen words and next twenty-five
                     words – excluding named entities – as their “bag of words”. The choice of
                     these two numbers was motivated by attempting to capture the current sentence
                     and the previous and next sentences. We then removed all named-entity mentions
                     in these biographies and converted the remaining words into lower case. Next we
                     applied the Porter stemmer [<a class="ref" href="#porter1980">Porter 1980</a>], an algorithm that strips
                     away standard English suffixes in a specific order. For example, the Porter
                     stemmer turns the word ‘publisher’ into ‘publish’, and does same to the word
                     ‘published’. We then dropped words that are in a standard stoplist – which
                     includes words like ‘and’, ‘the’, etc. – provided in the text-mining R package
                     tm [<a class="ref" href="#feinerer2008">Feinerer et al. 2008</a>]. In addition, we dropped all month words, some
                     numbers, and select relationship terms – a complete list can be seen in our
                     topic modeling R code.<a class="noteRef" href="#d4e715">[2]</a>
                     The remaining words in the ‘bag of words’ for each person thus approximately
                     reflected their profession, accomplishments, or “historical significance”
                     as given by the ODNB. </div>
                  
                  <div class="counter"><a href="#p31">31</a></div>
                  <div class="ptext" id="p31">Using each of these “bags of words” as an individual text, we fit three
                     topic models to our collection of texts.<a class="noteRef" href="#d4e727">[3]</a> The three topic models were generated with
                     five, ten, and twenty topics, respectively, to ensure the number of topics did
                     not significantly alter our results. The topics were generated automatically and
                     each text – and the person it represents – was assigned to the topic with the
                     highest probability match. The top representative terms in our ten-topic model
                     can be seen in Figure 3. The clustering of historical subjects and people in our
                     topics is encouraging, as many of the topics clearly represent different kinds
                     of historical activities. For example, Topic 3 in our ten-topic model contains
                     the words “bishop,”
                     “church,”
                     “minist” and “preach”, as well as a large number of churchmen such as
                     Richard Bancroft and John Whitgift (see Figure 3). Topic 8 includes the words
                     “publish”, “poem”, and “play,” along with poets like Robert
                     Herrick, John Donne, and John Dryden.</div>
                  
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row label">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 1</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 2</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 3</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 4</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 5</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">london<br />famili<br />merchant<br />coloni<br />trade<br />work</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">earl<br />lord<br />parliament<br />second<br />king<br />london</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">bishop<br />colleg<br />church<br />minist<br />preach<br />london</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">armi<br />command<br />return<br />forc<br />captain<br />ship</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">work<br />publish<br />letter<br />write<br />public<br />book</td>
                           </tr>
                        <tr class="row label">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 6</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 7</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 8</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 9</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Topic 10</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">king<br />polit<br />parliament<br />appoint<br />duke<br />lord<br /></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">work<br />london<br />publish<br />book<br />print<br />physician<br /></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">work<br />publish<br />poem<br />play<br />translat<br />edit<br /></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">earl<br />london<br />famili<br />marriag<br />second<br />will<br /></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">king<br />queen<br />english<br />england<br />court<br />royal<br /></td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 2. </div>A table of the top representative terms in the ten-topic model</div>
                  </div>
                  
                  
                  
                  <div class="counter"><a href="#p32">32</a></div>
                  <div class="ptext" id="p32">We then analyzed the frequency of our estimated relationships between people who
                     do and do not share topics. For all three topic models, estimated relationships
                     between people who shared a topic are more frequent than between-topic estimated
                     relationships; the specific results for the ten-topic model can be seen in
                     Figure 4. This coincides with the expectation for homophily (also known as
                     assortativity) and a qualitative, semantics-based reading of the same data: book
                     authors are more likely to be linked to other notable authors as opposed to
                     notable military personnel. While running a topic model with different
                     parameters (i.e. number of topics) changes the specific results, within-topic
                     relationships remain more frequent than between-topic relationships. We
                     therefore concluded that the Poisson Graphical Lasso produces results compatible
                     with other, semantically-sensitive methods.</div>
                  
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row label">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Measure</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Within-Topic</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Between-Topic</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Fraction of Edges with Confidence ≥ 90%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.0001444</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.0000117</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Fraction of Edges with Confidence ≥ 75%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.0004523</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.0000527</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Fraction of Edges with Confidence ≥ 50%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.0016402</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.0003082</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Fraction of Edges with Confidence ≥ 30%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.0033207</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">0.0007585</td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 3. </div>A table of relationship confidence estimates in the ten-topic model</div>
                  </div>
                  
                  
                  <div class="counter"><a href="#p33">33</a></div>
                  <div class="ptext" id="p33">Our second validation step was to compare our results with alternative methods of
                     constructing a confidence matrix. Using Spearman correlations, which measure how
                     well the ordering of two ranked lists align, we evaluated how each method
                     performed against expert-generated ranked relationship lists. We had earlier
                     considered using three possible methods for inferring a correlation matrix from
                     the document-count matrix: 1) ranking by simple correlation (high positive
                     correlations are higher ranked relationships); 2) running the Poisson Graphical
                     Lasso and ranking edges by the value of ϱ in which the edge was added to the
                     model (edges added with more penalization are higher ranked relationships); and
                     3) running the Poisson Graphical Lasso and ranking edges by the value of the
                     regression coefficient (higher positive coefficients are higher ranked
                     relationships). According to statistical theory, both versions of the Poisson
                     Graphical Lasso should perform as well as, if not better than, simple
                     correlation because of their ability to screen off friend-of-a-friend
                     connections, as described in section three above. We hoped to find this
                     reflected in our Spearman correlations, in order to conclude that our approach
                     produces results compatible with statistical theory.</div>
                  
                  <div class="counter"><a href="#p34">34</a></div>
                  <div class="ptext" id="p34">We chose to test this on James Harrington and John Milton by taking the top
                     thirty relationships according to each of these three methods and combining them
                     to create a master list of thirty and eighty relationships, respectively.
                     Faculty and PhD students with backgrounds in the early modern period were given
                     the combined names in random order and asked, first, to rank the relationships
                     according to a question we used to approximate relationship importance,
                     specifically “how unhappy would experts be if this relationship were not
                     included among the main actor’s top relationships?” and, second, to mark
                     the relationships as true/false. Despite only being an approximation to
                     relationship importance, the ranking list still proved far more difficult for
                     the humanists to generate than the true/false list.</div>
                  
                  <div class="counter"><a href="#p35">35</a></div>
                  <div class="ptext" id="p35"> We wanted to choose the statistical method that created lists most closely
                     correlated to the humanists’ list, as measured by Spearman correlation. The
                     Spearman correlations of each method were extremely similar in the humanists’
                     ranked lists and – combined with humanists’ concerns over producing the list in
                     the first place – led us to abandon the effort to optimize our algorithm for the
                     order of ranks. Instead, we attempted to determine which method obtained more
                     correct relationships – that is, relationships humanists marked as true – in the
                     top <span class="hi italic">k</span> estimated connections. For analysis of James
                     Harrington’s thirty connections, all three methods performed similarly; for John
                     Milton’s eighty connections, using simply the correlation coefficient led to
                     worse estimates earlier on, confirming that the Poisson Graphical Lasso can more
                     accurately reproduce sections of the network than correlation alone.</div>
                  
                  <div class="counter"><a href="#p36">36</a></div>
                  <div class="ptext" id="p36">Lastly, for our third validation step, we wanted to evaluate the accuracy of our
                     final inferred network, in comparison to the relational knowledge conveyed by a
                     humanist reading of the ODNB. We therefore chose twelve people from the network
                     and calculated the precision and recall rates for their relationships. The
                     twelve people were not a random sample. Rather, they were chosen to represent a
                     variety of conditions within our dataset, including gender, number of estimated
                     relationships, deduplicated names, and appearance within individual vs. shared
                     ODNB biographies. Some of these conditions are relatively rare within the
                     dataset on the whole. For each person, we checked their inferred edges from
                     40-100% confidence – qualitatively tagged as our “possible” to
                     “certain” confidence interval – against a list of associations manually
                     compiled from the ODNB documents by reading through each person’s biographical
                     entry and other entries in which their name appears.</div>
                  
                  <div class="counter"><a href="#p37">37</a></div>
                  <div class="ptext" id="p37">Together, these twelve people had twenty-eight relationships in our
                     likely-to-certain (60-100) confidence interval, of which three were incorrect,
                     leading to an 89.29% precision rate (see Figure 5). Expanding our confidence
                     interval to also include possible relationships (40-100) – in other words,
                     sacrificing precision to increase recall – gave us one hundred and seven
                     relationships of which twenty-seven were incorrect, leading to a
                     still-respectable 74.77% precision rate. The majority of these false positives
                     were caused by specific conditions within our data: group biographies, duplicate
                     names, and an abnormally high percentage of co-mentions within related
                     biographies. Removing the four people who satisfied these specific conditions
                     from our sample left us with fifty relationships and a 86.00% precision rate in
                     our 40-100 confidence interval, which suggests that many of the errors in our
                     dataset are associated with people who fulfill these conditions, which impaired
                     our algorithm’s ability to correctly capture their relationships via
                     co-mentions. Because our validation sample had taken care to include some of our
                     most problematic case-types, even though instances of some of those case-types
                     are relatively few, we deemed these measures of precision adequate as a starting
                     point for further curation of the network via crowd-sourcing on our website at
                     <a href="http://www.sixdegreesoffrancisbacon.com" onclick="window.open('http://www.sixdegreesoffrancisbacon.com'); return false" class="ref">www.sixdegreesoffrancisbacon.com</a>.</div>
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row label">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Confidence Interval</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Number of SDFB Inferred Relationships</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Precision <br />(# correct / # found)</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Article Recall<br />(# found in article / # in article)</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">SDFB Recall <br />(# found in article also in SDFB / # from
                              article)</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">80-100 (certain)</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">5</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">80.00%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">1.98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">3.96%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">60-100 (likely)</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">28</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">89.29%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">8.42%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">16.83%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">40-100 (possible)</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">107</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">74.77%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">25.74%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">51.49%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">10-100<br />(unlikely)</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">283</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">≥28.27%<a class="noteRef" href="#d4e1128">[4]</a></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">33.66%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">67.33%</td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 4. </div>Precision and Recall for a Subset of the Inferred Network</div>
                  </div>
                  
                  
                  <div class="counter"><a href="#p38">38</a></div>
                  <div class="ptext" id="p38">Calculating a global recall – the fraction of desired results obtained from the
                     ODNB as a whole – on our dataset would have required us to identify connections
                     across the entire biographical corpus of the ODNB, a prohibitively
                     labor-intensive process when done manually. We therefore calculated two partial
                     measures of recall instead. The first measure is article-level recall – that is,
                     a measure of the ability of our network to capture the same relationships as a
                     human reading a specific biographical article. By this measure, our recall
                     numbers were low, with our 40-100 confidence interval including only 25.74% of
                     the relationships mentioned in the article. Low article recall can be
                     attributed, at least in part, to two factors: first, the decision to impose a
                     five-mentions threshold during the NER stage, which excludes infrequently
                     mentioned names about which the ODNB provides insufficient network data, and,
                     second, the way some names are mentioned in the ODNB, which prevented them from
                     being picked up by NER.</div>
                  
                  <div class="counter"><a href="#p39">39</a></div>
                  <div class="ptext" id="p39">Next, we calculated the measure we call “SDFB” recall – that is, the ability
                     of our computer algorithms to infer relationships for the subset of people
                     mentioned in a specific biographical article who were also included in our
                     overall network. This adjustment – excluding people who did not pass the
                     five-mentions threshold or were not captured by NER – leads to a significantly
                     higher recall numbers, at 51.49%, again for the 40-100 confidence interval.
                     Further expansion of the confidence interval to 10-100 increases the SDFB recall
                     rate to 67.33%, showing that within the subset of names captured by NER and
                     included in our node dataset, high recall rates can be achieved at the lowest
                     confidence intervals. Though higher recall rates would of course be desirable in
                     theory, we deemed it preferable to have a relatively accurate but sparse network
                     rather than a full but error-ridden network, and further increases in recall
                     would require corresponding trade-offs in precision. </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">5. Humanities Significance</h1>
                  
                  
                  <div class="counter"><a href="#p40">40</a></div>
                  <div class="ptext" id="p40"> Though the map of the early modern social network created by our inference
                     procedures is far from perfect, it provides a sizeable base of persons and
                     relationships that can be gradually corrected and expanded to encompass the
                     interests of a wide range of humanist scholars. This network can also be
                     examined, validated, refined, and expanded by scholars, students, and other
                     end-users through a dynamic wiki front-end with sophisticated network
                     visualization tools. We consider such an approach complementary to several
                     successful approaches that focus on smaller subsets of society [<a class="ref" href="#long2013">Long and So 2013</a>]
                     [<a class="ref" href="#ahnert2015">Ahnert and Ahnert 2015</a>]
                     [<a class="ref" href="#basu2015">Basu et al. 2015</a>]
                     [<a class="ref" href="#during2015">During 2015</a>]. An important possible outcome of the project is the
                     integration, or re-integration, of disparate threads of network scholarship. </div>
                  
                  <div class="counter"><a href="#p41">41</a></div>
                  <div class="ptext" id="p41">The questions humanists care most about often turn on documentary evidence of
                     connections, and immersion in an archive or a published collection of letters
                     yields qualitative knowledge of unparalleled depth and richness. Yet the
                     humanities would need to see massive investments in historical analysis,
                     palaeography, languages, and other humanistic research skills in order to
                     investigate anything close to the number of relationships inferred using our
                     model. Since little in the current funding climate suggests that such
                     investments are immediately forthcoming, the promises of historical network
                     analysis would remain unrealized in the absence of a different approach. Hence
                     our probabilistic network inferences, which create a workable infrastructure for
                     subsequent investigation. Instead of starting the process of mapping the network
                     from scratch, we remediate existing scholarship for further addition, expansion,
                     development, and correction.</div>
                  
                  <div class="counter"><a href="#p42">42</a></div>
                  <div class="ptext" id="p42">The time, moreover, appears to be right. With open access research gaining
                     momentum, and more and more texts entering the public domain, probabilistic
                     text-mining approaches afford wider lenses and present new opportunities [<a class="ref" href="#elson2010">Elson et al. 2010</a>]
                     [<a class="ref" href="#hassan2012">Hassan et al. 2012</a>]
                     [<a class="ref" href="#underwood2013">Underwood et al. 2013</a>]
                     [<a class="ref" href="#makazhanov2014">Makazhanov et al. 2014</a>]
                     [<a class="ref" href="#riddell2014">Riddell 2014</a>]
                     [<a class="ref" href="#smith2014">Smith et al. 2014</a>]. Even as such approaches will always benefit from the
                     depth and precision afforded by more traditional archival analyses,
                     non-commercial repositories like the HathiTrust Research Center and commercial
                     ones (such as Google Books) represent exciting corpora for large scale
                     reconstruction of historical social networks. Treating the high-quality
                     historical scholarship as a source of unstructured data, moreover, helps us
                     avoid some of the pitfalls recently observed in studies based on less scholarly
                     data sources like Wikipedia and Freebase [<a class="ref" href="#gloor2015">Gloor et al. 2015</a>]
                     [<a class="ref" href="#schich2014">Schich et al. 2014</a>]
                     [<a class="ref" href="#weingart2015">Weingart 2015</a>]. Such studies based on declared links in
                     non-scholarly corpora haven’t yet achieved the plausibility achieved on the
                     smaller scale by old-fashioned archival work and entering attested links by
                     hand. </div>
                  
                  <div class="counter"><a href="#p43">43</a></div>
                  <div class="ptext" id="p43">At the same time, partnerships between traditional small-scale projects and
                     larger-scale projects like <cite class="title italic">Six Degrees of Francis
                        Bacon</cite> offer benefits to both sides. For those studying local
                     networks, large, probabilistic global networks offer chances to compare and
                     contextualize findings from smaller groups. For those working at larger scales
                     and with higher cumulative levels of uncertainty and error, small networks can
                     function as ground truths against which to test inferences and from which
                     partners may improve network models. </div>
                  
                  <div class="counter"><a href="#p44">44</a></div>
                  <div class="ptext" id="p44">Our approach isn’t just a new method. It yields substantive insights as well.
                     Applying quantitative network measures like network degree has allowed us to
                     identify interesting figures, such as those who have relatively high degrees but
                     who don’t have ODNB entries of their own. An analysis of high-degree nodes
                     without ODNB entries shows an intriguingly high representation of schoolmasters
                     and publishers. Individuals like Thomas Smelt, an ardent royalist who taught at
                     the Northallerton Free School in Yorkshire, and Edward Sylvester, who ran a
                     grammar school in Oxford, were not deemed significant enough to warrant full
                     biographical entries, but they are nevertheless key nodes connecting those who
                     were [<a class="ref" href="#otis2014b">Otis 2014b</a>].</div>
                  
                  <div class="counter"><a href="#p45">45</a></div>
                  <div class="ptext" id="p45">It is also possible from this work to understand more about non-British people
                     who figure prominently the life of the nation. Scholars can learn much about
                     international dimensions by attending to the frequency of non-native names
                     appearing frequently in the ODNB. Our five-mention threshold also helps us see
                     gender differences in a revealing light. The cultural practice of changing one’s
                     surname at marriage means that women face particular obstacles meeting our
                     artificially-imposed five-mention threshold. In several cases, men appear in the
                     dataset simply because they are mentioned in association with important women –
                     wives, sisters, or mothers who for various reasons may not themselves appear in
                     the dataset. The woman referred to in the ODNB as “Audrey,
                     widow of Sir Francis Anderson and eldest daughter of John Boteler, Baron
                     Boteler of Brantfield” does not appear in the dataset whereas John
                     Boteler does [<a class="ref" href="#seccombe2014">Seccombe and Kelsey 2014</a>]. Similarly, men like Thomas Bellenden
                     and Richard Stubbe aren’t known as historically significant, but they appear in
                     the dataset because their names remain consistent whereas their wives and
                     sisters appear by several names. In other cases, it isn’t a personal ODNB entry
                     that ensures a name gets included but a legal case or a much-cited will [<a class="ref" href="#otis2014b">Otis 2014b</a>]. Our analysis has also illustrated how inferred
                     networks differ based on ways of talking about people. James VI of Scotland and
                     James I of England name the same person, yet each name is associated with
                     substantially distinct social networks [<a class="ref" href="#otis2014a">Otis 2014a</a>]. </div>
                  
                  <div class="counter"><a href="#p46">46</a></div>
                  <div class="ptext" id="p46">Ultimately, our work with the ODNB has shown that processing an entire corpus of
                     documents and running a statistical procedure is computationally feasible with
                     the resources generally available to university scholars. We have also shown
                     that it is possible to implement a statistical approach that infers a validated
                     social network. While not all highest-confidence edges are among the strongest
                     identified by experts – and some expert-identified relationships are not near
                     the top edges found – there is enough overall validation on many classes of
                     relationships to suggest our method is viable for reconstructing historical
                     social networks, within a reasonable margin of error, from large textual
                     corpora. </div>
                  
                  <div class="counter"><a href="#p47">47</a></div>
                  <div class="ptext" id="p47"> This process admittedly has several shortcomings, especially from the
                     perspective of humanists for whom “margin of error” is a less than
                     reassuring phrase. Absent further research, there is no surefire way to
                     determine whether a given confidence estimate accurately reflects the current
                     state of scholarship (as represented by the ODNB) or is instead an artifact of
                     the bespoke model we developed. Nor are relationships in the resulting dataset
                     “typed” – friends and enemies remain functionally identical in our
                     results, though the difference of course matters decisively in real life. Proof
                     or other evidence about a given relationship will initially appear elusive: the
                     process yields few clues about where to start researching a relationship –
                     though our crowd-sourcing website does at least provide users links to ODNB and
                     JSTOR articles that mention both people in a relationship. And humanists must be
                     involved at every stage for validation, interpretation, de-duping, and
                     disambiguation. However, the end result of this process is of demonstrable use
                     to experts in early modern Britain and it is likely extensible to other large
                     corpora. </div>
                  
                  <div class="counter"><a href="#p48">48</a></div>
                  <div class="ptext" id="p48"> We are the first to acknowledge that our network inference procedure comes
                     freighted with assumptions and technical limitations that may pose obstacles to
                     its transferability to other social networks generated from other data sources.
                     Inferring a network from biographical texts requires assuming that the
                     co-occurrence of names in a document is a reasonable predictor of a relationship
                     between the named persons. Although we believe this is a reasonable and
                     productive assumption for ODNB texts, it is not an equally reasonable assumption
                     for all data sources. Network inference will be only as good as the NER on which
                     it depends. Differences in NER availability and accuracy for different languages
                     (Stanford, for example, has separate modules for Spanish, German, and Chinese),
                     as well as differences in naming conventions across cultures, time periods,
                     discourses, and biographical data may decrease its effectiveness, though NER can
                     be tuned for different datasets. Because the ODNB entries have been carefully
                     edited and checked, they are relatively error free, but projects that aim to
                     mine biographical reference works that exist only in uncorrected Optical
                     Character Recognition documents will begin with a significant level of textual
                     error. Those who seek to employ our procedures on other biographical data
                     sources should perform checks to ensure that it is inferring edges between nodes
                     at level of accuracy that they deem acceptable. </div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">Conclusion</h1>
                  
                  <div class="counter"><a href="#p49">49</a></div>
                  <div class="ptext" id="p49"> While our interest has been in reconstructing the social network of a specific
                     time and place – sixteenth- and seventeenth-century Britain – there are few
                     barriers to re-deploying our method in other historical or contemporary
                     societies. We used short biographical entries, but we could with minor changes
                     have used contemporary book prefaces, modern scholarly articles, blogs, or other
                     kinds of texts. All that is needed is machine-readable text in which the
                     co-occurrence of names is a reasonable indicator of connections between persons.
                     Future work on our specific project may thus involve expanding the collection of
                     documents used in our network. Target documents currently include the publishing
                     data in the English Short Title Catalog and the prefatory material in Early
                     English Books Online. We would also aim to incorporate datasets whose strengths
                     would mitigate the data’s current weaknesses, such as collections of letters
                     written by women or urban apprenticeship rolls.</div>
                  
                  <div class="counter"><a href="#p50">50</a></div>
                  <div class="ptext" id="p50"> We have also begun to expand our network through the data provided by individual
                     scholars via our website interface at <a href="http://www.sixdegreesoffrancisbacon.com" onclick="window.open('http://www.sixdegreesoffrancisbacon.com'); return false" class="ref">www.sixdegreesoffrancisbacon.com</a>. To encourage mass integration of
                     other datasets, we have incorporated features into our website to allow the
                     tagging of nodes and the visualization of sub-networks by those tags. However,
                     we also have a particular interest in scholars adding citations to confirm our
                     statistically predicted relationships, as well enriching those relationships by
                     providing information about their type and timespan. Our ultimate goal is to
                     create a versatile and extensible network that people interested in all aspects
                     of early modern Britain – including the scholarship on early modern Britain –
                     can use for their research, as well as to pioneer a general technique of
                     creating social networks from texts that other scholars can apply to other
                     periods and societies.</div>
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">APPENDIX: The Poisson Graphical Lasso</h1>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Introduction</h2>
                     
                     <div class="counter"><a href="#p51">51</a></div>
                     <div class="ptext" id="p51">Our statistical approach follows the model of G.I. Allen and Z. Liu [<a class="ref" href="#allen2012">Allen and Liu 2012</a>]. Inference of the network is based on statistical
                        graph learning techniques. Here we have a graph G=(V,E), where V is the set
                        of <span class="hi italic">p</span> nodes and E is the set of pairwise edges. We
                        relate the graph to a random vector Y=(Y<span class="hi subscript">1</span>, ... ,
                        Y<span class="hi subscript">p</span>) by requiring that for each non-edge
                        (j,k)∉E, the variables Y<span class="hi subscript">j</span> and Y<span class="hi subscript">k</span> are conditionally independent given all the
                        remaining variables Y<span class="hi subscript">∖{j,k}</span>, where ∖{j,k} denotes
                        the complement V∖{j,k}. Commonly, Y=(Y<span class="hi subscript">1</span>, ... ,
                        Y<span class="hi subscript">p</span>) is assumed to follow a multivariate normal
                        distribution N<span class="hi subscript">p</span>(µ,∑), in which case pairwise
                        conditional independence holds if and only if ∑<span class="hi subscript">jk</span><span class="hi superscript">-1</span>=0 [<a class="ref" href="#lauritzen1996">Lauritzen 1996</a>].
                        In this case, inferring the graph corresponds to inferring the non-zero
                        elements of ∑<span class="hi superscript">-1</span>.</div>
                     
                     <div class="counter"><a href="#p52">52</a></div>
                     <div class="ptext" id="p52"> If we have <span class="hi italic">n</span> independent and identically distributed
                        observations of Y, we can employ penalized likelihood methods, where we
                        place a one-norm penalty on elements of the concentration matrix. This
                        penalized likelihood can be maximized efficiently for large <span class="hi italic">p</span> using a graphical lasso [<a class="ref" href="#friedman2008">Friedman et al. 2008</a>]. Alternatively, an approximate solution can be obtained through a
                        sequence of penalized regressions of each variable Y<span class="hi subscript">j</span> on the remaining variables Y<span class="hi subscript">∖j</span>=Y<span class="hi subscript">∖{j}</span>. We estimate σ<span class="hi subscript">jk</span><span class="hi superscript">-1</span> = 0 if the estimated regression coefficients
                        of variable <span class="hi italic">j</span> on <span class="hi italic">k</span> or <span class="hi italic">k</span> on <span class="hi italic">j</span> are estimated to be 0
                        [<a class="ref" href="#meinshausen2006">Meinshausen and Bühlmann 2006</a>].</div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Poisson Graphical Lasso</h2>
                     
                     
                     <div class="counter"><a href="#p53">53</a></div>
                     <div class="ptext" id="p53"> For count data like ours the normality assumption may be inappropriate and a
                        modification of the above methods was developed by Allen and Liu for Poisson
                        graphical models, in which the relationships between nodes are defined by a
                        conditional Poisson distribution [<a class="ref" href="#allen2012">Allen and Liu 2012</a>]. For each node 
                        	\(p\left( Y_{j} \middle| Y_{\smallsetminus j} = \mathcal{Y}_{\smallsetminus j} \right)\sim\text{Poisson}\left(
                        \exp\left( \theta_{j} + \sum_{k \neq j}^{}{\theta_{\text{jk}}\mathcal{Y}_{k}} \right)
                        \right)\)
                        </div>
                     
                     
                     
                     
                     <div class="counter"><a href="#p54">54</a></div>
                     <div class="ptext" id="p54"> The Poisson Markov random field implied by this relationship is not amenable
                        to inferring network structures, as it requires θ<span class="hi subscript">jk</span> ≤ 0 for all pairs {j,k} [<a class="ref" href="#allen2012">Allen and Liu 2012</a>]. We
                        therefore proceed as they did by estimating the local log-linear models
                        	\(\log{\left( \mathbb{E}\left\lbrack Y_{j} \right.\  \middle| \left. \ Y_{\smallsetminus
                        j} = \mathcal{Y}_{\smallsetminus j} \right\rbrack \right) = \theta_{j} + \sum_{k \neq
                        j}^{}{\theta_{\text{jk}}\mathcal{Y}_{k}}}\)
                        
                        
                        
                        and combine the implied local relationships into a network structure.</div>
                     
                     <div class="counter"><a href="#p55">55</a></div>
                     <div class="ptext" id="p55"> We can then view θ<span class="hi subscript">ij</span> as a measure of relationship
                        strength between <span class="hi italic">i</span> and <span class="hi italic">j</span>. In
                        Allen and Liu, the model is fit using the Poisson Graphical Lasso – a
                        penalized regression method similar to the graphical lasso [<a class="ref" href="#friedman2008">Friedman et al. 2008</a>], but modified for count data. A penalized
                        Poisson regression is done for each node <span class="hi italic">j</span>’s counts
                        on the rest. That is, for each node we solve the following: 
                        	$${\widehat{\Theta}}_{\smallsetminus j,j} = \Theta_{\smallsetminus j,j}\frac{1}{n}\sum_{i
                        = 1}^{n}{\left\lbrack Y_{\text{ij}}\left( Y_{i, \smallsetminus j}\Theta_{\smallsetminus
                        j,j} \right) - \exp\left( Y_{i, \smallsetminus j}\Theta_{\smallsetminus j,j} \right)
                        \right\rbrack - \left\| \rho \star \Theta_{\smallsetminus j,j} \right\| 1}$$
                        </div>
                     
                     
                     
                     
                     <div class="counter"><a href="#p56">56</a></div>
                     <div class="ptext" id="p56"> Here ϱ is a matrix of penalty parameters and ⋆ denotes component-wise
                        multiplication. An edge is determined to exist between nodes <span class="hi italic">j</span> and <span class="hi italic">k</span> if <span class="hi italic">θ̂<span class="hi subscript">jk</span></span> &gt; 0 and/or <span class="hi italic">θ̂<span class="hi subscript">kj</span></span> &gt; 0. The tuning parameter ϱ
                        can be the same for all elements and can be chosen, for example, by
                        stability selection [<a class="ref" href="#meinshausen2010">Meinshausen and Bühlmann 2010</a>]. Later we will allow
                        elements of the ϱ matrix to differ.</div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Modifications</h2>
                     
                     
                     <div class="counter"><a href="#p57">57</a></div>
                     <div class="ptext" id="p57"> The motivating data for Allen and Liu are the RNA-sequencing measurements
                        from <span class="hi italic">p</span> genes in <span class="hi italic">n</span> experiments;
                        their goal is to determine which genes are “connected” to each other in
                        a metabolic process [<a class="ref" href="#allen2012">Allen and Liu 2012</a>]. Here we have the (noisy)
                        counts of <span class="hi italic">p</span> names in <span class="hi italic">n</span>
                        biographies; our goal is to determine which historical figures had
                        "connections" to each other in a variety of social contexts. Two modeling
                        considerations unique to this type of data and practical objective, which
                        lead us to slight modifications in method, are the variance of document
                        lengths and the irrelevance of negative edge estimates.</div>
                     
                     <div class="counter"><a href="#p58">58</a></div>
                     <div class="ptext" id="p58"> Documents in the ODNB vary greatly in length. People tend to have longer
                        biographies when biographers know more about them or have deemed them
                        historically significant. Allen and Liu note that it is important to
                        normalize the data to be approximately independent and identically
                        distributed Poisson random variables, since their model is sensitive to
                        deviations from this assumption [<a class="ref" href="#allen2012">Allen and Liu 2012</a>]. To achieve this,
                        we break the longer documents into 500 word sections and count each section
                        as an observation. This introduces weak dependence among some observations,
                        but the chronological nature of the documents may lessen this effect. That
                        is, the people mentioned in the first section of Bacon’s biography may be
                        very different from those mentioned in the last section. Being mentioned in
                        the same section of a document may also be greater evidence of a connection
                        than simply being mentioned in the same document.</div>
                     
                     <div class="counter"><a href="#p59">59</a></div>
                     <div class="ptext" id="p59">As a preliminary test of this method, we calculate the Spearman correlation
                        between lists of relationships provided by humanities scholars and</div>
                     
                     <div class="ptext">
                        <ol class="list">
                           <li class="item">relationships produced by simple correlation</li>
                           <li class="item">relationships produced by our model with document sectioning</li>
                           <li class="item">relationships produced by our model without document sectioning</li>
                        </ol>
                     </div>
                     
                     <div class="counter"><a href="#p60">60</a></div>
                     <div class="ptext" id="p60">For our test set, simple correlation fails first, while those for our model –
                        with and without sectioning – remain similar. Sectioning fails to improve
                        correlation on some historical actors, but it leads to slight improvements
                        in correlation for others.</div>
                     
                     <div class="counter"><a href="#p61">61</a></div>
                     <div class="ptext" id="p61"> Furthermore, when fitting the model, a large fraction of <span class="hi italic">θ̂<span class="hi subscript">jk</span></span> values are negative. When this
                        coefficient is negative, it does not make sense to estimate a resulting
                        edge, since negative coefficients imply a negative relationship between the
                        counts of name <span class="hi italic">j</span> and name <span class="hi italic">k</span>.
                        Because any specific person appears only in a small portion of the
                        documents, and is presumably related to only a small fraction of all the
                        people in the network, fitting this model tends to produce a large amount of
                        negative coefficients compared to positive coefficients. </div>
                     </div>
                  
                  <div class="div div1">
                     
                     
                     <h2 class="head">Confidence Estimate Procedure</h2>
                     
                     
                     <div class="counter"><a href="#p62">62</a></div>
                     <div class="ptext" id="p62"> We want to be able to attach a confidence estimate to all edges (which can
                        be used to rank connections), instead of just obtaining a yes or no estimate
                        for each potential edge. Let the matrix C represent a symmetric confidence
                        matrix (where each entry C<span class="hi subscript">jk</span> = C<span class="hi subscript">kj</span> = confidence attached to edge existing between
                        person <span class="hi italic">j</span> and <span class="hi italic">k</span>). An informal
                        confidence estimate can be obtained by refitting the model many times on
                        random subsets of the data and computing the fraction of models in which a
                        specific edge is found in the model. </div>
                     
                     <div class="counter"><a href="#p63">63</a></div>
                     <div class="ptext" id="p63"> The method of estimating the final edge confidences is as follows: </div>
                     
                     <div class="ptext">
                        <ol class="list">
                           <li class="item">Sample half of the rows in the data matrix </li>
                           <li class="item">Fit Poisson Graphical Lasso on this data as follows: 
                              <div class="ptext">
                                 <ul class="list">
                                    <li class="item">For each <span class="hi italic">j</span> (column), fit the model in
                                       Equation 3, and obtain the coefficient estimates for ϱ=0.001 </li>
                                    <li class="item">Ignore any coefficient that has been estimated as negative
                                       </li>
                                 </ul>
                              </div>
                              </li>
                           <li class="item">Repeat steps (1) and (2) 100 times.</li>
                           <li class="item">Estimate the confidence of an edge between node <cite class="title italic">j</cite> and <span class="hi italic">k</span> as 
                              	\({\widehat{C}}_{\text{ij}} = \frac{\Sigma_{t = 1}^{B}\left\lbrack I\left( {\widehat{\theta}}_{\text{jk}}^{(t)}
                              &gt; 0\text{\ or\ }{\widehat{\theta}}_{\text{kj}}^{(t)} &gt; 0 \right) \right\rbrack}{B}\)
                              	</li>
                        </ol>
                     </div>
                     
                     <div class="counter"><a href="#p64">64</a></div>
                     <div class="ptext" id="p64">Note that <span class="hi italic">θ̂<span class="hi superscript">(t)</span><span class="hi subscript">jk</span></span> is the estimate for the coefficient on
                        the t<span class="hi superscript">th</span> repetition of the model fitting in Step
                        2. </div>
                     
                     
                     <div class="counter"><a href="#p65">65</a></div>
                     <div class="ptext" id="p65"> There are a number of methods described in the literature for selecting the
                        tuning parameter ϱ. When the goal is prediction of the response variable,
                        cross-validation is a natural choice. When the goal is network inference –
                        specifically, we want to know whether each edge is “in” or “out” –
                        stability selection can be used instead, as is done in Allen and Liu [<a class="ref" href="#meinshausen2010">Meinshausen and Bühlmann 2010</a>]
                        [<a class="ref" href="#allen2012">Allen and Liu 2012</a>]. Of most use to humanities scholars, however, is
                        an organization of the current knowledge about relationships. Some scholars
                        may wish to explore numerous potential relationships to one actor. Ordering
                        the relationships correctly – in order of likelihood – is therefore more
                        important than determining a cutoff point and excluding all edges that do
                        not make the cut. </div>
                     
                     <div class="counter"><a href="#p66">66</a></div>
                     <div class="ptext" id="p66"> Our confidence estimates for a specific value of ϱ correspond to a single
                        point on the stability paths mentioned in Meinshausen and Bühlmann [<a class="ref" href="#meinshausen2010">Meinshausen and Bühlmann 2010</a>]. They note that the choice of range of ϱ to
                        use when computing the “stable variables” – or in this case, edges –
                        does not matter significantly. In our experiments with values of ϱ ranging
                        from 0.001 (many edges) to 100 (no edges), we also find the confidence
                        estimates tend to not vary too much for different reasonable values of ϱ,
                        where reasonable is defined as a low enough penalty such that variables are
                        actually added, but high enough penalty so that the algorithm converges
                        rapidly.</div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Name Disambiguation</h2>
                     
                     <div class="counter"><a href="#p67">67</a></div>
                     <div class="ptext" id="p67">Different people sometimes have the same names, and disambiguating them is
                        difficult. When name duplication only happens rarely, it may be feasible to
                        disambiguate manually. However, there are no less than twelve John Smith’s
                        and ten Archibald Campbell’s in our node set; overall nearly a thousand
                        names refer to multiple people. Furthermore, many of the people with these
                        names overlap in lifespans, including a large number of parents who gave
                        their own names to their children.</div>
                     
                     <div class="counter"><a href="#p68">68</a></div>
                     <div class="ptext" id="p68">To process these duplicate names, we use a twofold method. First, we employ
                        chronological filters on all our potential relationship edges. Two people
                        cannot have a relationship if their lifespans did not overlap. We do,
                        however, allow a one-year margin of error so that posthumous children may
                        still have edges to their biological fathers. For people with unknown birth
                        and death dates, we allow a twenty-year span before and after their known
                        period of activity. For people for whom only a birth or a death date is
                        known, we allow for up to a 110-year lifespan, erring on the side of
                        inclusivity rather than exclusivity.</div>
                     
                     <div class="counter"><a href="#p69">69</a></div>
                     <div class="ptext" id="p69">In the cases where there is chronological overlap in the lifespans of people
                        with duplicate names, we fall back on probabilities. If the name was
                        generated by NER, we evenly split the mentions among each of the people with
                        that name – that is, we assign them each an equal probability. However, if
                        our duplicates all have biographical entries, we assign each person a
                        probability based on the length of their biography. This serves as an
                        approximation of the relative frequency we expect each person to appear in
                        the overall ODNB, which we use to weight the mentions accordingly.</div>
                     
                     <div class="counter"><a href="#p70">70</a></div>
                     <div class="ptext" id="p70">For example, Francis Walsingham, the principal secretary, has a biography
                        that is 30 times the length of Francis Walsingham, the Jesuit. Therefore we
                        argue a mention of Francis Walsingham in some other ODNB biography is 30
                        times more likely to refer to the former rather than the latter. To follow
                        this logic through, we would assign weights of 97% to the principal
                        secretary and 3% to the Jesuit. Yet we don’t want to obscure the
                        lesser-known Jesuit so thoroughly. Therefore, we cap the percentages at a
                        max/min of 75% and 25% so that someone with an extremely long biography
                        cannot dominate the probabilities completely. Thus in the period of overlap
                        between their two lifespans, 75% of the instances of “Francis
                        Walsingham” are attached to the principal secretary and 25% are
                        attached to the Jesuit. In practice, this does yield lower confidence
                        estimates and more false positives for “split-mention” nodes’
                        relationships, but we consider this an acceptable as a starting point for
                        further, manual curation.</div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Incorporating Humanist Knowledge</h2>
                     
                     <div class="counter"><a href="#p71">71</a></div>
                     <div class="ptext" id="p71">Prospectively, after enough humanists contribute their expert knowledge to
                        the network via our crowd-sourcing website, it will be possible to use their
                        contributions to refine our inference model by making local changes to the
                        penalty parameter. We could do this by allowing the penalty matrix, ϱ, to
                        vary for different relationships. If our experts confirm a relationship
                        between actors <span class="hi italic">j</span> and <span class="hi italic">k</span>, we set
                        ϱ<span class="hi subscript">jk</span>=ϱ<span class="hi subscript">kj</span>=0, which
                        usually ensures that <span class="hi italic">θ̂<span class="hi subscript">jk</span></span>,
                        <span class="hi italic">θ̂<span class="hi subscript">kj</span></span> ≠ 0. Similarly,
                        for a confirmed non-relationship – that two figures are not connected – we
                        would set ϱ<span class="hi subscript">jk</span>=ϱ<span class="hi subscript">kj</span>=∞,
                        ensuring <span class="hi italic">θ̂<span class="hi subscript">jk</span></span>, <span class="hi italic">θ̂<span class="hi subscript">kj</span></span> = 0. As more experts
                        label more potential relationships, we could continue to refine our model
                        iteratively. By helping us to tune the penalty parameter, the contributions
                        of (say) a hundred experts could help us to assess millions of relations
                        more accurately.</div>
                     </div>
                  
                  <div class="div div1">
                     
                     <h2 class="head">Network Code</h2>
                     
                     <div class="counter"><a href="#p72">72</a></div>
                     <div class="ptext" id="p72">Further information on how we generated our network can be found, along with
                        our R code, at: <a href="https://github.com/sdfb/sdfb_network" onclick="window.open('https://github.com/sdfb/sdfb_network'); return false" class="ref">https://github.com/sdfb/sdfb_network</a><a class="noteRef" href="#d4e1633">[5]</a></div>
                     </div>
                  </div>
               
               
               
               
               
               
               
               
               
               </div>
            
            <div id="notes">
               <h2>Notes</h2>
               <div class="endnote" id="d4e438"><span class="noteRef lang en">[1] Our R code for both the
                     pre-processing and statistical analysis of our dataset is at <a href="https://github.com/sdfb/sdfb_network/tree/master/code/ODNB" onclick="window.open('https://github.com/sdfb/sdfb_network/tree/master/code/ODNB'); return false" class="ref">https://github.com/sdfb/sdfb_network/tree/master/code/ODNB</a>.</span></div>
               <div class="endnote" id="d4e715"><span class="noteRef lang en">[2]  Our R code for the topic modeling is at <a href="https://github.com/sdfb/sdfb_network/tree/master/code/topic_models" onclick="window.open('https://github.com/sdfb/sdfb_network/tree/master/code/topic_models'); return false" class="ref">https://github.com/sdfb/sdfb_network/tree/master/code/topic_models</a></span></div>
               <div class="endnote" id="d4e727"><span class="noteRef lang en">[3] For several of the known
                     limitations of topic models in digital humanities, see [<a class="ref" href="#meeks2012">Meeks and Weingart 2012</a>].</span></div>
               <div class="endnote" id="d4e1128"><span class="noteRef lang en">[4] We judged validating the additional 176 inferred
                     relationships in the 10-39 confidence interval to be too
                     labor-intensive, with little added benefit, to be worth calculating.
                     Given the number of already-validated relationships in the 40-100
                     confidence interval, we calculated the lowest possible precision
                     rate in our 10-100 confidence interval to be 28.27%. It is very
                     likely higher.</span></div>
               <div class="endnote" id="d4e1633"><span class="noteRef lang en">[5] Research for this
                     article was supported by a grant from the Council for Library and
                     Information Resources Award (Con_505), by Google Faculty Awards
                     2012_R1_189 and 2013_R1_26, and by a Falk Fellowship from Carnegie
                     Mellon University’s Dietrich College of Humanities and Social
                     Sciences.</span></div>
            </div>
            <div id="worksCited">
               <h2>Works Cited</h2>
               <div class="bibl"><span class="ref" id="ahnert2014"><!-- close -->Ahnert and Ahnert 2014</span> Ahnert, Ruth, and S.E.
                  Ahnert. “A Community Under Attack: Protestant Letter
                  Networks in the Reign of Mary I.”
                  <cite class="title italic">Leonardo</cite> 47, no. 3 (2014): 275–275.
                  doi:10.1162/LEON_a_00778.</div>
               <div class="bibl"><span class="ref" id="ahnert2015"><!-- close -->Ahnert and Ahnert 2015</span> Ahnert, Ruth, and S.E.
                  Ahnert. “Protestant Letter Networks in the Reign of Mary I:
                  A Quantitative Approach.”
                  <cite class="title italic">ELH</cite> 82, no. 1 (2015): 1-33.</div>
               <div class="bibl"><span class="ref" id="alias2008"><!-- close -->Alias-i 2008</span> LingPipe 4.1.0. <a href="http://alias-i.com/lingpipe" onclick="window.open('http://alias-i.com/lingpipe'); return false" class="ref">http://alias-i.com/lingpipe</a></div>
               <div class="bibl"><span class="ref" id="allen2012"><!-- close -->Allen and Liu 2012</span> Allen, G.I. and Z. Liu. “A Log-Linear Graphical Model for Inferring Genetic Networks
                  from High-Throughput Sequencing Data.”
                  <cite class="title italic">ArXiv e-prints</cite> (2012).</div>
               <div class="bibl"><span class="ref" id="basu2015"><!-- close -->Basu et al. 2015</span> Basu, Anupam, Jonathan Hope, and
                  Michael Witmore. “Networks and Communities in the Early
                  Modern Theatre.” In Roger Sell and Anthony Johnson, eds., <cite class="title italic">Community-making in Early Stuart Theatres: Stage and
                     Audience</cite>. Ashgate (forthcoming). <a href="http://winedarksea.org/wp-content/uploads/2014/08/WH7-Networks-and-Communities.pdf" onclick="window.open('http://winedarksea.org/wp-content/uploads/2014/08/WH7-Networks-and-Communities.pdf'); return false" class="ref">http://winedarksea.org/wp-content/uploads/2014/08/WH7-Networks-and-Communities.pdf</a></div>
               <div class="bibl"><span class="ref" id="bearman2002"><!-- close -->Bearman et al. 2002</span> Bearman, Peter, James Moody,
                  and Robert Faris. “Networks and History.”
                  <cite class="title italic">Complexity</cite> 8, no. 1 (2002): 61–71.
                  doi:10.1002/cplx.10054.</div>
               <div class="bibl"><span class="ref" id="blei2003"><!-- close -->Blei et al. 2003</span> Blei, David M., Andrew Y. Ng, and
                  Michael I. Jordan, “Latent Dirichlet Allocation.”
                  <cite class="title italic">Journal of Machine Learning Research</cite> 3 (2003):
                  993-1022.</div>
               <div class="bibl"><span class="ref" id="bosch2011"><!-- close -->Bosch and Camp 2011</span> Bosch, A. and M. Camp. “A Link to the Past: Constructing Historical Social
                  Networks.” In <cite class="title italic">The Proceedings of the Association
                     for Computational Linguistics Workshop on Computational Approaches to
                     Subjectivity and Sentiment Analysis</cite> (2011): 61–69.</div>
               <div class="bibl"><span class="ref" id="bosch2012"><!-- close -->Bosch and Camp 2012</span> Bosch, Antal van den and Matje
                  van de Camp. “The socialist network.”
                  <cite class="title italic">Decision Support Systems</cite> 53, no. 4 (2012): 761-69.
                  <a href="http://dx.doi.org/10.1016/j.dss.2012.05.031" onclick="window.open('http://dx.doi.org/10.1016/j.dss.2012.05.031'); return false" class="ref">doi:10.1016/j.dss.2012.05.031</a>.</div>
               <div class="bibl"><span class="ref" id="campbell2004"><!-- close -->Campbell 2004</span> Campbell, Gordon. “Milton, John (1608-1674), poet and polemicist.” In
                  Matthew, H.C.G. and Brian Harrison (eds). <cite class="title italic">Oxford Dictionary
                     of National Biography</cite>. Oxford University Press, Oxford (2004);
                  online edn, (2007).</div>
               <div class="bibl"><span class="ref" id="collini2005"><!-- close -->Collini 2005</span> Collini, Stefan. “Our Island Story,”<cite class="title italic"> London Review
                     of Books,</cite> 27.2 (2005): 3-8.</div>
               <div class="bibl"><span class="ref" id="during2015"><!-- close -->During 2015</span>  Düring, Marten, <cite class="title italic">Historical Network Research</cite>. <a href="http://historicalnetworkresearch.org/" onclick="window.open('http://historicalnetworkresearch.org/'); return false" class="ref">http://historicalnetworkresearch.org</a>.</div>
               <div class="bibl"><span class="ref" id="durrett2014"><!-- close -->Durrett and Klein 2014</span> Durret, Greg and Dan
                  Klein. “A Joint Model for Entity Analysis: Coreference,
                  Typing, and Linking” (2014). <a href="http://www.eecs.berkeley.edu/~gdurrett/papers/durrett-klein-tacl2014.pdf" onclick="window.open('http://www.eecs.berkeley.edu/~gdurrett/papers/durrett-klein-tacl2014.pdf'); return false" class="ref">http://www.eecs.berkeley.edu/~gdurrett/papers/durrett-klein-tacl2014.pdf</a></div>
               <div class="bibl"><span class="ref" id="elson2010"><!-- close -->Elson et al. 2010</span> Elson, David K., Nicholas Dames,
                  and Kathleen R. McKeown. “Extracting Social Networks from
                  Literary Fiction,”
                  <cite class="title italic">Proceedings of the 48th Annual Meeting of the Association
                     for Computational Linguistics</cite> (2010): 138-147. <a href="https://www.aclweb.org/anthology/P/P10/P10-1015.pdf" onclick="window.open('https://www.aclweb.org/anthology/P/P10/P10-1015.pdf'); return false" class="ref">https://www.aclweb.org/anthology/P/P10/P10-1015.pdf</a></div>
               <div class="bibl"><span class="ref" id="evans2011"><!-- close -->Evans 2011</span> Evans, James A. and Jacob G. Goster.
                  “Metaknowledge,”
                  <cite class="title italic">Science</cite>, 331.6018 (2011): 721-725.</div>
               <div class="bibl"><span class="ref" id="feinerer2008"><!-- close -->Feinerer et al. 2008</span> Feinerer, I., K. Hornik,
                  and D. Meyer. “Text Mining Infrastructure in R,”
                  <cite class="title italic">Journal of Statistical Software</cite> 25 (2008): 1-54.
                  <a href="http://www.jstatsoft.org/v25/i05/paper" onclick="window.open('http://www.jstatsoft.org/v25/i05/paper'); return false" class="ref">http://www.jstatsoft.org/v25/i05/paper</a></div>
               <div class="bibl"><span class="ref" id="finkel2005"><!-- close -->Finkel et al. 2005</span> Finkel, J.R., T. Grenager, and
                  C. Manning. “Incorporating Non-local Information into
                  Information Extraction Systems by Gibbs Sampling.” In <cite class="title italic">Proceedings of the 43rd Annual Meeting of the Association for
                     Computational Linguistics</cite> (2005): 363-370. <a href="http://nlp.standford.edu/manning/papers/gibbscrf3.pdf" onclick="window.open('http://nlp.standford.edu/manning/papers/gibbscrf3.pdf'); return false" class="ref">http://nlp.standford.edu/manning/papers/gibbscrf3.pdf</a></div>
               <div class="bibl"><span class="ref" id="friedman2008"><!-- close -->Friedman et al. 2008</span> Friedman, J., T. Hastie,
                  and R. Tibshirani. “Sparse inverse covariance estimation
                  with the graphical lasso.”
                  <cite class="title italic">Biostatistics</cite> 9 (2008): 432-441.</div>
               <div class="bibl"><span class="ref" id="gloor2015"><!-- close -->Gloor et al. 2015</span> Gloor, Peter, Patrick De Boer,
                  Wei Lo, Stefan Wagner, Keiichi Nemoto, and Hauke Fuehres. “Cultural Anthropology Through the Lens of Wikipedia - A Comparison of
                  Historical Leadership Networks in the English, Chinese, Japanese and German
                  Wikipedia.” arXiv:1502.05256 [cs], February 18, 2015. <a href="http://arxiv.org/abs/1502.05256" onclick="window.open('http://arxiv.org/abs/1502.05256'); return false" class="ref">http://arxiv.org/abs/1502.05256</a>.</div>
               <div class="bibl"><span class="ref" id="glymour2001"><!-- close -->Glymour et al. 2001</span> Glymour, Clark, Richard
                  Scheines, and Peter Spirtes. <cite class="title italic">Causation, Prediction, and
                     Search, 2nd Ed.</cite> MIT Press, Cambridge Mass. (2001).</div>
               <div class="bibl"><span class="ref" id="goldfarb2013"><!-- close -->Goldfarb et al. 2013</span> Goldfarb, Doron, Max
                  Arends, Josef Froschauer, and Dieter Merkl. “Comparing Art
                  Historical Networks.”
                  <cite class="title italic">Leonardo</cite> 46, no. 3 (2013): 279–279.
                  doi:10.1162/LEON_a_00575.</div>
               <div class="bibl"><span class="ref" id="hassan2012"><!-- close -->Hassan et al. 2012</span> Hassan, Ahmed, Amjad Abu-Jbara,
                  and Dragomir Radev, “Extracting Signed Social Networks From
                  Text.”
                  <cite class="title italic">Proceedings of the TextGraphs-7 Workshop</cite> (2012):
                  6-14. <a href="http://www.aclweb.org/anthology/W12-4102" onclick="window.open('http://www.aclweb.org/anthology/W12-4102'); return false" class="ref">http://www.aclweb.org/anthology/W12-4102</a></div>
               <div class="bibl"><span class="ref" id="lauritzen1996"><!-- close -->Lauritzen 1996</span> Lauritzen, S.L. <cite class="title italic"> Graphical Models.</cite> Oxford Statistical Science Series
                  17. The Clarendon Press Oxford University Press, New York (1996).</div>
               <div class="bibl"><span class="ref" id="long2013"><!-- close -->Long and So 2013</span> Long, Hoyt, and Richard So. “Network Science and Literary History.”
                  <cite class="title italic">Leonardo</cite> 46, no. 3 (2013): 274–274.
                  doi:10.1162/LEON_a_00570.</div>
               <div class="bibl"><span class="ref" id="makazhanov2014"><!-- close -->Makazhanov et al. 2014</span> Makazhanov, Aibek,
                  Denilson Barbosa, and Grzegorz Kondrak. “Extracting Family
                  Relationship Networks from Novels.” arXiv:1405.0603 [cs.CL].</div>
               <div class="bibl"><span class="ref" id="matthew2004"><!-- close -->Matthew and Harrison 2004</span> Matthew, H.C.G. and
                  Brian Harrison (eds). <cite class="title italic">Oxford Dictionary of National
                     Biography</cite>. Oxford University Press, Oxford (2004); online edn,
                  (2007).</div>
               <div class="bibl"><span class="ref" id="mcgann2014"><!-- close -->McGann 2014</span> McGann, Jerome. <cite class="title italic">A
                     New Republic of Letters: Memory and Scholarship in the Age of Digital
                     Reproduction</cite>. Cambridge, Massachusetts: Harvard University Press,
                  2014.</div>
               <div class="bibl"><span class="ref" id="mcpherson2001"><!-- close -->McPherson, Smith-Love and Cook 2001</span> McPherson,
                  Miller, Lynn Smith-Lovin and James M. Cook. “Birds of a
                  Feather: Homophily in Social Networks.”
                  <cite class="title italic">Annual Review of Sociology</cite> 27 (2001):
                  415-444.</div>
               <div class="bibl"><span class="ref" id="meeks2012"><!-- close -->Meeks and Weingart 2012</span> Elijah Meeks and Scott
                  Weingart, eds., <cite class="title italic">Journal of Digital Humanities</cite> 2.1
                  (2012), “Topic Modeling” special issue. </div>
               <div class="bibl"><span class="ref" id="meinshausen2006"><!-- close -->Meinshausen and Bühlmann 2006</span> Meinshausen, N.
                  and P. Bühlmann. “High-dimensional graphs and variable
                  selection with the lasso.”
                  <cite class="title italic">Annals of Statistics</cite> 34 (2006): 1436-1462.</div>
               <div class="bibl"><span class="ref" id="meinshausen2010"><!-- close -->Meinshausen and Bühlmann 2010</span> Meinshausen, N.
                  and P. Bühlmann. “Stability selection.”
                  <cite class="title italic">Journal of the Royal Statistical Society: Series B
                     (Statistical Methodology)</cite> 72 (2010): 417-473.</div>
               <div class="bibl"><span class="ref" id="moretti2011"><!-- close -->Moretti 2011</span> Moretti, Franco. “Network Theory, Plot Analysis.”
                  <cite class="title italic">New Left Review</cite> 68 (2011): 80–102.</div>
               <div class="bibl"><span class="ref" id="otis2014a"><!-- close -->Otis 2014a</span> Otis, Jessica. “What’s in a Name? The Many Nodes of King James VI and I.”
                  <cite class="title italic">Six Degrees of Francis Bacon: Reassembling the Early Modern
                     Social Network</cite>, Sept. 16, 2014. <a href="http://6dfb.tumblr.com/post/97645842306/" onclick="window.open('http://6dfb.tumblr.com/post/97645842306/'); return false" class="ref">http://6dfb.tumblr.com/post/97645842306/</a></div>
               <div class="bibl"><span class="ref" id="otis2014b"><!-- close -->Otis 2014b</span> Otis, Jessica. “Tales from the Raw NER Data.”
                  <cite class="title italic">Six Degrees of Francis Bacon: Reassembling the Early Modern
                     Social Network</cite>, Oct/Nov 2014. <a href="http://6dfb.tumblr.com/tagged/tales-from-the-raw-ner-data" onclick="window.open('http://6dfb.tumblr.com/tagged/tales-from-the-raw-ner-data'); return false" class="ref">http://6dfb.tumblr.com/tagged/tales-from-the-raw-ner-data</a></div>
               <div class="bibl"><span class="ref" id="peltonen2004"><!-- close -->Peltonen 2004</span> Peltonen, Markku. “Bacon, Francis, Viscount St Alban (1561-1626), lord
                  chancellor, politician, and philosopher”. In Matthew, H.C.G. and
                  Brian Harrison (eds). <cite class="title italic">Oxford Dictionary of National
                     Biography</cite>. Oxford University Press, Oxford (2004); online edn,
                  (2007).</div>
               <div class="bibl"><span class="ref" id="porter1980"><!-- close -->Porter 1980</span> Porter, M.F. “An
                  algorithm for suffix stripping.”
                  <cite class="title italic">Program</cite>, 14(3) (1980): 130−137. </div>
               <div class="bibl"><span class="ref" id="riddell2014"><!-- close -->Riddell 2014</span> Riddell, A. “How
                  to Read 22,198 Journal Articles: Studying the History of German Studies with
                  Topic Models.” In <cite class="title italic">Distant Readings: Topologies
                     of German Culture in the Long Nineteenth Century</cite>, edited by Matt
                  Erlin and Lynne Tatlock, 91--114. Rochester, New York: Camden House,
                  2014.</div>
               <div class="bibl"><span class="ref" id="schich2014"><!-- close -->Schich et al. 2014</span> Schich, Maximilian, Chaoming
                  Song, Yong-Yeol Ahn, Alexander Mirsky, Mauro Martino, Albert-László Barabási,
                  and Dirk Helbing. “A Network Framework of Cultural
                  History.”
                  <cite class="title italic">Science</cite> 345, no. 6196 (August 1, 2014): 558–62.
                  doi:10.1126/science.1240064.</div>
               <div class="bibl"><span class="ref" id="seccombe2014"><!-- close -->Seccombe and Kelsey 2014</span> Seccombe, Thomas and
                  Sean Kelsey. “Leigh, Francis, first earl of Chichester (d.
                  1653), politician and courtier”. In Matthew, H.C.G. and Brian
                  Harrison (eds). <cite class="title italic">Oxford Dictionary of National
                     Biography</cite>. Oxford University Press, Oxford (2004); online edn,
                  (2007).</div>
               <div class="bibl"><span class="ref" id="simmel1950"><!-- close -->Simmel 1950</span> Simmel, Georg. <cite class="title italic">The Sociology of Georg Simmel</cite>. Translated by Kurt H. Wolff. Simon
                  and Schuster, 1950.</div>
               <div class="bibl"><span class="ref" id="smith2014"><!-- close -->Smith et al. 2014</span> Smith, D.A., R. Cordell, E.M.
                  Dillon, N. Stramp, and J. Wilkerson. “Detecting and Modeling
                  Local Text Reuse.” In <cite class="title italic">2014 IEEE/ACM Joint
                     Conference on Digital Libraries (JCDL)</cite>, 183–92, 2014.
                  doi:10.1109/JCDL.2014.6970166.</div>
               <div class="bibl"><span class="ref" id="underwood2013"><!-- close -->Underwood et al. 2013</span> Underwood, Ted, Michael
                  L. Black, Loretta Auvil, and Boris Capitanu. “Mapping
                  Mutable Genres in Structurally Complex Volumes.”
                  <cite class="title italic">arXiv:1309.3323 [cs]</cite>, September 12, 2013. <a href="http://arxiv.org/abs/1309.3323" onclick="window.open('http://arxiv.org/abs/1309.3323'); return false" class="ref">http://arxiv.org/abs/1309.3323</a>.</div>
               <div class="bibl"><span class="ref" id="weingart2012"><!-- close -->Weingart 2012</span> Weingart, Scott. “Topic Modeling for Humanists: A Guided Tour.”
                  <cite class="title italic">The Scottbot Irregular</cite>, July 25, 2012. <a href="http://www.scottbot.net/HIAL/?p=19113" onclick="window.open('http://www.scottbot.net/HIAL/?p=19113'); return false" class="ref">http://www.scottbot.net/HIAL/?p=19113</a></div>
               <div class="bibl"><span class="ref" id="weingart2015"><!-- close -->Weingart 2015</span> Weingart, Scott. “Culturomics 2: The Search for More Money.”
                  <cite class="title italic">The Scottbot Irregular</cite>, March 5, 2015. <a href="http://www.scottbot.net/HIAL/?p=41200" onclick="window.open('http://www.scottbot.net/HIAL/?p=41200'); return false" class="ref">http://www.scottbot.net/HIAL/?p=41200</a>.</div>
            </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            <div class="license"><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
               </div>
         </div>
      </div>
   </body>
</html>