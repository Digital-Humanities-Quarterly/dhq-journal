<?xml version="1.0" encoding="UTF-8"?><?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?><?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:dhq="http://www.digitalhumanities.org/ns/dhq" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:cc="http://web.resource.org/cc/">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title>The Potential and Problems in using High Performance Computing in the Arts and Humanities: the Researching e-Science Analysis of Census Holdings (ReACH) Project.</title>
            <author>Melissa Terras</author>
            <dhq:authorInfo>
               <dhq:author_name>Melissa M. 
    <dhq:family>Terras</dhq:family>
               </dhq:author_name>
               <dhq:affiliation>Department of Information Studies, University College London</dhq:affiliation>
              <email>m.terras@ucl.ac.uk </email>
               <dhq:bio>
                 <p>Melissa Terras is the Senior Lecturer in Electronic Communication in the Department of Information Studies, University College London, and the Deputy Director of the new UCL Centre for Digital Humanities. With a background in Classical Art History and English Literature, and Computing Science, her doctorate (University of Oxford) examined how to use advanced information engineering technologies to interpret and read the Vindolanda texts. Publications include Image to Interpretation: Intelligent Systems to Aid Historians in the Reading of the Vindolanda Texts (2006, Oxford Studies in Ancient Documents. Oxford University Press) and Digital Images for the Information Professional (2008, Ashgate). She is a general editor of DHQ and Secretary of the Association of Literary and Linguistic Computing. Her research focuses on the use of computational techniques to enable research in the arts and humanities that would otherwise be impossible.</p>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt><publisher>Alliance of Digital Humanities Organizations</publisher><publisher>Association of Computers and the Humanities</publisher>
            <idno type="DHQarticle-id">000070</idno>
            <idno type="volume">003</idno>
            <idno type="issue">4</idno>
            <dhq:articleType>article</dhq:articleType>
            <date when="2010-03-20">20 March 2010</date>
            <dhq:articleType>article</dhq:articleType>
            <availability>
               <cc:License xmlns="http://digitalhumanities.org/DHQ/namespace" rdf:about="https://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>Authored for DHQ; migrated from original DHQauthor format</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available in the <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">DHQ keyword taxonomy</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en"/>
         </langUsage>
      </profileDesc>
      <revisionDesc>
         <change when="2009-01-30" who="Alyssa">Encoded document</change>
         <change when="2009-08-06" who="Alyssa">added bibl, put in SVN</change>
         <change when="2009-08-18" who="matthew">updated schema link</change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en">
      <front>
         <dhq:abstract>
            <p>e-Science and high performance computing (HPC) have the potential to allow large datasets to be searched and analysed quickly, efficiently, and in complex and novel ways. Little application has been made of the processing power of grid technologies to humanities data, due to lack of available large-scale datasets, and little understanding of or access to e-Science technologies. The Researching e-Science Analysis of Census Holdings (ReACH) scoping study, an AHRC-funded e-science workshop series, was established to investigate the potential application of grid computing to a large dataset of interest to historians, humanists, digital consumers, and the general public: historical census records. Consisting of three one-day workshops held at UCL in Summer 2006, the workshop series brought together expertise across different domains to ascertain how useful, possible, or feasible it would be to analyse datasets from Ancestry and The National Archives using the HPC facilities available at UCL. This article details the academic, technical, managerial, and legal issues highlighted in the project when attempting to apply HPC to historical data sets. Additionally, generic issues facing humanities researchers attempting to utilise HPC technologies in their research are presented. </p>
         </dhq:abstract>
         <dhq:teaser>
           <p>This paper covers with practical, logistical, and legal hurdles in using High Performance Computing for historical research with examples from research on historical census records. </p>
         </dhq:teaser>
      </front>
      <body>
         <head>The Potential and Problems in using High Performance Computing in the Arts and Humanities: the Researching e-Science Analysis of Census Holdings (ReACH) Project.</head>
         <div xml:id="section_1">
            <head>Introduction</head>
            <p>Although HPC, pooled computational resources, shared large scale datasets, and associated
    <q>e-Science</q>
               <note>
                  <q>e-Science</q> is a term given to a variety of
     technologies covering high performance, large scale, and grid enabled computing, and the shared
     data and computational resources used in these technologies. See <ptr target="#dunn2009"/> in this issue for an overview of the use of
     this term, and the US equivalent, <term>cyberinfrastructutre</term>.</note> technologies have large potential for analysing and sharing complex data sets, little application has been made of the processing power of the grid or HPC technologies to furthering research on humanities data. This could be due to the lack of large-scale datasets requiring such technologies for analysis, and little understanding of or access to these e-Science technologies. The ReACH workshop series was established to investigate the potential application of e-Science and HPC technologies to one of the largest humanities and social science datasets in existence: historical census records.</p>
            <p>Public interest in historical census data is phenomenal, as the overwhelming response to
    mounting the 1901 census online at The National Archives demonstrates <ptr target="#inman2002"/>. Yet the data is also much used for research by historians and social
    scientists (see <ptr target="#higgs2005"/> for an introduction).   There are many versions of
    historical census datasets available, covering a variety of aspect of the census, and digitised
    census records are one of the largest digital datasets available in arts and humanities
    research.  In the Arts and Humanities Data Service repository collection alone there are
    currently 155 datasets pertaining to historical census data (from the UK and abroad) created for
    research purposes <ptr target="#ahds2006"/>. Commercial firms dealing (or having dealt) in
    genealogy information (such as <ref target="http://www.ancestry.com/">Ancentry</ref>, <ref target="http://www.genesreunited.co.uk/">Genes Re-united</ref>, <ref target="http://www.qinetiq.com/">QinetiQ</ref>, <ref target="http://www.origins.net/bowelcome.aspx">British Origins</ref>, <ref target="http://www.thegenealogist.co.uk/">The Genealogist</ref>, and <ref target="http://www.1837online.com/">1837Online</ref>) have digitised vast swathes of historical census material (although to varying degrees of completeness and accuracy).  There is much interest from the historical community in using this emerging data for research, and developing tools and computational architectures which can aid historians in analysing this complex data (see <ptr target="#crocket2006"/>) for an advanced proposal regarding the creation of a longitudinal database of English individuals and households from 1851 to 1901 (see also the work of the <ref target="http://www.nappdata.org/napp/">North Atlantic Population Project</ref>).  However, there have been few opportunities for the application of HPC to utilise large scale processing power in the analysis of historical census material, especially analysing data across the spectrum of census years available in the UK (7 different censuses taken at 10 year intervals from 1841-1901).</p>
            <p>The aim of the ReACH series was to bring together disparate expertise in Computer Science,
    Archives, Genealogy, History, and Humanities Computing, to discuss how e-Science techniques could be applied to be of use to the historical research community.  The project partners each brought various expertise and input to the project. <ref target="http://www.ucl.ac.uk/slais/">UCL School of Library, Archives and Information Studies</ref>, hosted the workshop series, having expertise in digital humanities and advanced computational techniques, as well as digital records management. <ref target="http://www.nationarchives.gov.uk">The National Archives</ref>, who select, preserve and provide access to, and advice on, historical records, e.g. the censuses of England and Wales 1841-1901 (and also the Isle of Man, Channel Islands and Royal Navy censuses), were involved to provide access to and expertise regarding census material. <ref target="http://www.ancestry.co.uk">Ancestry.co.uk</ref>, who own a massive dataset of census holdings worldwide, and who have digitized the censuses of England and Wales under license from The National Archives, were involved to provide access to digitised census material: the input of Ancestry was central to this research to gain access to the complete range of UK census years in digital format. Finally, <ref target="http://www.ucl.ac.uk/research-computing/">UCL Research Computing</ref>, the UK's Centre for Excellence in networked computing, who have extensive HPC facilities available for use in research, provided much guidance and expertise regarding e-Science technologies to the project.</p>
            <p>The ReACH project aimed to investigate the reuse of pre-digitised census data: presuming there was not funding available to be in the business of digitisation of other record data for any pilot project. (Additionally, the Library, Archive, and Arts and Humanities communities have been merrily digitizing resources in earnest for over twenty years: it was hoped that by analysing one of the largest available digitized datasets with HPC that the appropriation of e-Science technologies for humanities research could be demonstrated.)   The project also wished to investigate the use of commercial datasets (as many of the large census data sets are owned by commercial firms: in this case, Ancestry), and the licensing and managerial issues this would raise. The project also wanted to establish how feasible, and indeed useful, undertaking such an analysis of historical census data would be.</p>
            <p>The results of the well-attended workshop series were a sketch for a 
    potential project, and also recommendations regarding the 
    implementation of e-Science (HPC) technologies in historical research. However, at the time, it was not thought possible to pursue the potential project primarily due to the quality and scope of available historical data. This paper describes the methodology of the workshops, reports on suggestions made during the series, sketches out a future project regarding how historical census material can be analysed utilising HPC, and extrapolates recommendations that can be applied in general to the use of e-Science in the arts and humanities research sectors.</p>
         </div>
         <div xml:id="section_2">
            <head>Methodology</head>
            <div xml:id="section_2.1">
               <head>Workshops</head>
               <p>The ReACH project was based around a series of workshops which aimed to bring together cross-disciplinary expertise from industry, government bodies, and academia. All workshops were held at UCL in summer 2006. The workshops were split into three topics.</p>
               <p>The All Hands Workshop aimed to ascertain how feasible, and indeed, useful utilizing e-Science technologies to analyse historical census data would be. Undertaking e-Science analysis of historical census records may be technically possible – but will it be useful to academic researchers? The workshop brought together a wide range of interdisciplinary expertise to ascertain the academic community’s view of the benefit and concerns in undertaking a full-scale research project utilizing available historical census data and the Research Computing facilities at UCL. Through various presentations and discussions, this workshop explained the technological issues and explored the historical techniques which may be useful for undertaking research of historical census material in this manner.</p>
               <p>The Technical workshop built on conclusions from the All Hands Meeting. Participants were a smaller group of those from interested parties, meeting in order to ascertain the technical issues regarding mounting Ancestry and TNA’s historical census data on the UCL Research Computing facilities. This workshop meeting aimed to ascertain how the data will be delivered to UCL, the size of the data, the structure of the data, the function of searches to be undertaken on the UCL Research Computing facilities, the duration of the project, the number and type of employees required, the equipment required to purchase, the equipment required to access to existing kit, the software required, software development issues, and other issues such as data security and management.</p>
               <p>The Managerial Workshop was the final workshop to be undertaken as part of this research series. The aim of this workshop was to ascertain the managerial and legal issues which would need to be resolved in order to undertake a research project using Ancestry's data, in conjunction with The National Archives, and UCL. Issues which were discussed included; licensing requirements from Ancestry, security of data, ownership of research outcomes, management structure, financial structure, paths to dissemination and publicity, and other topics suggested by participants.</p>
            </div>
            <div xml:id="section_2.2">
               <head>Follow Up to Workshops</head>
               <p>Following the workshops, points of interest were pursued. These included checking reference material to understand prior research which had been brought to the PI’s attention, making further links with other projects (such as the <ref target="http://fass.kingston.ac.uk/research/local-history/">Centre for Local History Studies</ref> at Kingston University London which is constructing a comprehensive database detailing major aspects of Kingston's economic and social evolution during the second half of the nineteenth century) and the holders of other large scale data sets (such as the <ref target="http://www.freebmd.org.uk/">Free BMD Register</ref> which aims to transcribe the Civil Registration index of births, marriages and deaths for England and Wales). Individuals were also consulted from a diverse range of sources, including the Arts and Humanities Research Council’s lawyers (who provided legal advice regarding the creation of new datasets through combining existing sources), the business development office at UCL, UCL’s Centre for Health Informatics and Multiprofessional Education (who provided expertise on data security and management), and researchers in Physics working on the <ref target="http://www2.astrogrid.org/">AstroGrid</ref> project (who were interested in seeing how results of a potential project could be useful for research involving scientific data).</p>
            </div>
         </div>
         <div xml:id="section_3">
            <head>Findings</head>
            <p>Findings from the workshops are presented here, utilising the framework in which the workshops were presented, breaking the project into academic benefits, technical infrastructure needed, and management and legal issues which arose from the discussions. The following section, future work, details how the project could proceed in developing a pilot e-Science project in this area.</p>
            <div xml:id="section_3.1">
               <head>Benefits for Historians – Would this be useful?</head>
               <p>There is significant interest in how HPC can aid historians in analysing, matching, and
     processing historical census data. Computational methods have been extensively used to clean,
     manage, manipulate and match census record holdings for decades (see <ptr target="#hc1992"/>,
     <ptr target="#hc1994"/>, <ptr target="#hc2006"/>, <ptr target="#prdh2000"/>, <ptr target="#dillon2001"/>, <ptr target="#schurer2002"/> for just a small indication of the breadth of research available) but most processes are still dependent on human input on some part of the processing chain. The use of computational techniques also has been hampered by lack of processing power, lack of availability of data, and problems in quality of data. If there was unlimited processing power, which could be used to search and manipulate all of the UK historical census data in automated processes, should it be available in digital form, what could it do which would aid in the research of historians? The <q>wish list</q> for tools and processes that would aid historians and genealogists was extensive and varied. Some suggestions were more likely to be computationally implementable than others, but all are included here, disregarding computational complexity or reliance on available data.</p>
               <p>The most popular request was the generation of automatic matches of records throughout the census years available, creating what is known as a <q>longitudinal database</q> of individuals across the census. This would require the investigation of tools, techniques, and algorithms, and modelling of procedures undertaken by historians when they carry out this task manually at present. It would result in a dataset which can be used historians to track individuals, families and population change across time, and inform other projects interested in building such datasets.</p>
               <p>An additional aid to historians would be the generation of rich variant lists for users.  The use of variants is important in dealing with the problematic nature of census data, which can often have errors due to its nature of collection (see <ref target="#section_4">Findings</ref>, below). By building up lists of common variants present in the UK census data, this would help to normalise the lookup process for historians, and provide probabilistic information which could be used in any computer architecture created to match records. Lists of variants fall into a variety of categories: typographic (provo versus probo), phonetic (Cathy versus Kathy), cultural (the use of Jack for those officially named John), temporal (1880 written down when actually they meant 1881) and spatial (Boston, when Cambridge was the official answer).  Using computers to automatically generate rich variant lists would be a relatively simple task, and of great use to historical researchers.</p>
               <p>Computational tools could be used to check and cleanse census data. The 5% sample of 1881
     census data digitised and developed by Kevin Schürer and Matthew Woollard <ptr target="#schurer2002"/> required a program of <q>enrichment</q> to reformat input
     data, perform a number of constituency checks, and add a number of enriched variables, mainly
     relating to household structure <ptr target="#schurer2002" loc="16"/>.  Manually checking a
     dataset of this size (around one million records) was not feasible, and <quote rend="inline" source="#schurer2002">automatic validation and enrichment of the data is intellectually more rigorous
      than manual intervention</quote> (ibid) whilst ensuring that the data is consistent across the
     dataset.  The processing power necessary for running such algorithms across the whole of the UK
     historical census data and across each UK census is large and would require that afforded by
     e-Science technologies: 29 million records (or so) per census, and 7 census years (1841-1901).
     (See <ptr target="#schurer2002" loc="Appendix C"/> for a detailed discussion of the procedures carried out in their study.)</p>
               <p>Calculating and identifying individuals who have been missed in various censuses is also possible. These may be individuals who were not <q>at home</q> on the night the census was taken, or those who were homeless, in mental institutions, etc. Identifying and calculating individuals who are missing from the census is a concern for modern day statisticians.  (In the 2001 census, for example, it was estimated that a significant number (600,000) of young men, in particular, had disappeared from the statistics, and were unaccounted for <ptr target="#bbc2004"/>.) This could be revealed through longitudinal studies – and also provide further information about the quality of the census data itself.</p>
               <p>Missing data in the digital records can be reconstituted through contextual information: for example, street numbers are missing in the Ancestry dataset, but could this be inferred from the surrounding data, allowing us to construct richer datasets looking at surrounding records? Can the number of rooms in dwellings be calculated? Reconstituted and enriched datasets can be useful to historians, provided that original transcripts are maintained and data integrity preserved for quality control, as in the enriched dataset in <ptr target="#schurer2002"/>).</p>
               <p>If digital data is held for all censuses, it can be used to generate simple statistics regarding the number of records for each parish. These results were previously published just after each census was collected in population reports (which are now being digitised themselves by the <ref target="http://www.histpop.org/demo-b/servlet/show?page=home">Online Historical Population Reports Project</ref>) and contain detailed analysis of the census results without naming individuals: for example, the reports give overviews of the size of parishes (geographically), the number of households, the number of male and female persons, numbers of male and female persons under 20 and over 20, etc. These statistics were calculated manually from the enumerator returns. It would be possible to check the accuracy of these by automatically counting the same fields in the digital records for each census. This, of course, could also be used to check the accuracy of the digital records: any discrepancies between the two would have to be investigated.</p>
               <p>A popular, yet computationally difficult, suggestion of facilities that would help researchers was the development of OCR techniques which can be used effectively on copperplate handwriting, in order to be able to digitise missing fields quickly and efficiently. (For example, the occupation field was missed from the Ancestry digitisation procedures to cut digitisation costs, but occupation data is one which is most often used by historians). Research into automatic optical character recognition of handwriting, although extensive, has yet to generate techniques with a high enough success rate to allow this to be a feasible project at this time (see <ptr target="#impedovo1993"/>) for an accessible overview of techniques and approaches commonly used).</p>
               <p>There was interest in using computers to map census data onto geographical information.
     Firstly, a popular suggestion was the name mapping of geography to names. There has been some
     success with this – a UCL project based in the <ref target="http://www.casa.ucl.ac.uk/">Centre for Advanced Spatial Analysis</ref> has been working on a <ref target="http://www.spatial-literacy.org/uclnames/">Surname Profiler</ref> which investigates the distribution of surnames in the UK in both historic (1881) and contemporary (1998) census datasets. (A conference regarding the benefits this has for research was held at UCL 28th- 31st April 2004. See <ptr target="#lloyd2004"/> for an overview and collection of papers presented.) Extrapolating the research across all the census years will require much processing power, firstly, to enable the cleansing and formatting of the data, secondly, to allow generation of results, and finally, to increase the sophistication of visualisation techniques to show the changing of distribution of surnames through time.</p>
               <p>There was also great interest in assigning grid references to historical data. The boundaries
     of districts, and indeed, names and areas of census parishes differ greatly from census to
     census (see <ptr target="#mills1989"/> for an overview of related research). There is currently no way of automatically relating places which appear within one parish in one census and another in the next. This makes automated linkage of records difficult. Investigating how geo-spatial references can be applied to individual areas across the spectrum of census data will allow new datasets to be formed which can aid historians in tracing how settlements have changed, irrespective of the changes in legislative boundaries.</p>
               <p>Related to this was the request for the addition of current geographical data to the census. It is a common request at the National Archives for people to be able to search historical census data on current postcodes. Although this will be a complex and difficult endeavour (many street layouts have changed, postal districts and boundaries change, and the attempt will require a thorough understanding of urban geography from 1841 onwards, which may be impossible to model computationally) this tool would be welcomed by, in particular, family historians and genealogists.</p>
               <p>Visualisation techniques could be employed to investigate how the data was collected, the
     distribution of different fields across the geography of the UK, and the way that the
     distribution of data changes from census to census. If geo-spatial data were to be generated,
     or become available, it could be manipulated through GIS, increasing the means to interrogate
     and conduct new research with the data. (Visualisation of scientific data has been a focus of the use of e-Science technologies within the mathematical and physical sciences, see <ptr target="#brodlie2004"/> and <ptr target="#riedel2007"/>, although again, use of these advanced computational techniques in the humanities is nascent.)</p>
               <p>A practical suggestion was for the generation of tools which can be used for social computing – looking at family histories as opposed to individual histories, to investigate family roles and structures across the different census years, which would be a useful practical addition for those carrying out genealogical research.</p>
               <p>Finally, separate from the analysis of the data itself would be the facilities to analyse how
     people were actually using the data: it is known to be popular, but not much more is known
     about how people search, analyse, and link census material. Log analysis of usage statistics
     from those accessing historical census data online could be undertaken to provide quantitative
     evidence regarding use, which would be useful to understand the nature of genealogical
     research, and also the procedures used to match records. (See <ptr target="#nicholas2006"/> and
     <ptr target="#huntington2007"/> regarding how these techniques have been employed to understand
     digital user behaviour of other online resources, and <ptr target="#warwick2008"/> for this technique applied particularly to those in the arts and humanities.) The popularity of the census material would mean that logs generated from the searching of these records would be large, and require the facilities afforded by e-Science technologies for efficient analysis.</p>
               <p>But where is the <q>e-Science</q> in all this? Most of these projects would require
     large processing power, to begin to sort through the large dataset.  Mike Mansfield, on 14th
     June, informed us Ancestry has approximately 600 Tera-Bytes of census data holdings, including
     image files <ptr target="#mansfield2006"/>. The English, Wales and Channel Islands textual data for 1841-1901
     is a mere 20 Giga-Bytes in comparison: with over 200 million individual records to perform some
     kind of task on.  Manipulating that volume of records as one dataset requires processing power
     not readily available in a desktop machine. The more complex the task, the bigger the data
     storage (both for temporary data manipulation and for storing results) required. Although this
     dataset is a lot smaller than most of the datasets scientists at UCL are using in their e-science projects (see <ref target="http://www.ucl.ac.uk/research-computing/">http://​www.ucl.ac.uk/​research-computing/</ref> for an overview), making use of the HPC facilities at UCL would allow this data to be interrogated in a reasonable and realistic timeframe.</p>
               <p>However, whether using HPC to manipulate data is actually <q>e-Science</q> is open to question. The AHRC’s definition of e-science varies somewhat, but is stated on their webpage as
     <cit>
                     <quote rend="block" source="#ahrc2006">a specific set of advanced technologies for Internet resource-sharing
      and collaboration: so-called grid technologies, and technologies integrated with them, for
      instance for authentication, data-mining and visualization.</quote>
                     <ptr target="#ahrc2006"/>
                  </cit>
     and in a presentation introducing the e-Science main call for funding more succinctly as
     <cit>
                     <quote rend="block" source="#robey2006">
                        <p>the development of <emph>advanced</emph> technologies for research collaboration and resource sharing across the Internet. 
      <list type="unordered">
                              <item>Grid technologies, and technologies integrated with them (<emph>service</emph> grid)</item>
                              <item>Not e-Research</item>
                           </list>
                        </p>
                     </quote>
                     <ptr target="#robey2006"/>
                  </cit>
     This raises larger questions about what e-Science actually is, and whether the development of new advanced high performance techniques would fit under this rubric. (Although research should be problem and solution led, rather than definition led, funding is required to carry out research of this type.)</p>
                <p>It is doubtful whether a project regarding processing of census data would either need to use (or be wise to use) computational grid technologies to undertake its processing (see <ref target="#section_3.2">Technical Implementation</ref> below).  Processing would be carried out by a high performance machine, not dispersed across the computational grid (why make the project more complex than it needs to be?) There are additional security problems in sharing processing and datasets across the computational grid, or making them available via the National Grid Service, or even the Internet. When dealing with commercially sensitive datasets such as the census data from Ancestry, the value of that data should be respected (and the potential consequences of leaking this data to the world realised): therefore, constraining the processing of the data to one individual system is advisable, rather than copying and distributing it over a network, which provides a higher chance for interception and malicious (or other) copying and unlawful dissemination.  Thus, any project would not be <q>e-Science</q> in this regard: as the data would not be distributed, or made more available than it currently is to those not part of the project.</p>
                <p>Finally, the question of the ownership of any newly created datasets from the programme is tricky, as is the extent to which the commercial data is part of these datasets, or compromised by sharing the datasets (see <ref target="#section_3.3">Managerial Issues</ref> below). Therefore, distribution of the <emph>results</emph> of the project may not be possible via Internet or Grid.</p>
               <p>The potential for (the AHRC’s definition of) e-Science when dealing with commercially sensitive data is therefore much reduced. In the future, as more datasets are being created in the public domain, this will become less of a problem as researchers should not have to rely on commercially provided data.</p>
                <p>A further important topic that was discussed in the All Hands Meeting was the quality and integrity of historical census data. This is reported on below in <ref target="#section_4">Future Research</ref>, and issues regarding data security and procedures are covered in <ref target="#section_3.3">Managerial Issues</ref>.</p>
            </div>
            <div xml:id="section_3.2">
               <head>Technical Implementation – Would this be feasible?</head>
               <p>In many respects, technical implementation of a project which would input Ancestry’s
     datasets, perform data manipulation, and output data, is much less of a problem than
     identifying the research question, due to the excellent research computing facilities and support available at UCL.  Discussion regarding the range of expertise, services and facilities on offer is available at <ref target="http://www.ucl.ac.uk/research-computing/information/services">http://​www.ucl.ac.uk/​research-computing/​information/​services/</ref>, but can be summarised as AccessGrid facilities for virtual collaboration, Central Computing Cluster (C³) for advanced batch style computing, e-Science Certification for use of national grid resources, Condor high-throughput commodity computing pool, Prism high-performance visualisation resource, The Sun Cluster <q>Keter</q> for serial and parallel computing, and the Altix for High-Performance Computing <ptr target="#ucl2006b"/>.</p>
               <p>For the security reasons outlined above and in <ref target="#section_3.3">Managerial Issues</ref> below, any project would have to use a standalone
     machine rather than distribute data via a network (such as the Condor computing pool) for
     processing via a grid or grids.   After consultation with UCL Research Computing regarding
     memory requirements, scalability and Input/Output (I/O) profile, it was determined that the
     <ref target="http://www.sgi.com/products/servers/altix/">SGI Alrtix</ref> facility at UCL (one
     of two facilities for parallel computing, the other being the Keter cluster) would be the most
     suitable choice, with 56 processors (Itanium2 1.3Ghz/3 MB cache processors) and 112GB shared
     memory offering speeds of approximately 135GFlops <ptr target="#ucl2006a"/>. Although various
     end-user packages are already installed on this system, the project would require development
     of its own software. The Altix facility has Intel C/C++ Compilers versions 7.1, 8.1 and 9.0
     installed, and so would support C++ 20 based programs: a standard in the development of
     software tools.<note>C++ is a general-purpose, high-level programming language with low-level
      facilities which supports both object-oriented and generic programming, popular in commercial
      computing since the 1990s (see <ptr target="#itic2003"/> for an overview).</note> C++ routines could be developed in a normal offline development environment, and sent to the Altix as a series of parallel jobs which would process the data. Obviously, this would require employing a programmer with prerequisite experience and abilities who could write C++ code for this project.  The difficulty lies in <emph>what</emph> to program.</p>
                <p>Because of security issues, data would be received from Ancestry on encrypted physical media rather than being transferred via Internet Technologies such as FTP. This would then be uploaded to the Altix when needed, whilst ensuring robust security measures were kept in place. Research Computing at UCL has much experience regarding data integrity and security with its many projects which carry out medical research such as those based at the Centre for Health Informatics and Multiprofessional Education (<ref target="http://www.chime.ucl.ac.uk/">CHIME</ref>). Other projects using UCL’s research computing facilities which require close management of ethical and security include the Co-operative Clinical e-Science Framework (<ref target="http://www.clinical-escience.org/">CLEF</ref>), which looks at, amongst other things, security and privacy of clinical data. Recommendations regarding security procedures are made in the following section.</p>
               <p>Likewise, temporary data storage facilities to allow processing would have to be secure, as would the storage of the results of the project. In many ways this is a simple I/O processing task: it is just the volume of the data, and the potential complexity of any developed algorithms which require high processing computing. There are no technical barriers to proceeding with this manner, and the facilities at UCL are even available free of charge for research to all UCL departments.</p>
            </div>
            <div xml:id="section_3.3">
               <head>Managerial Issues – Would This Be Achievable?</head>
               <p>Managerial issues of a potential, distributed project, fall into a variety of topics. Firstly, the managerial structure of the project. Secondly, management of security of data whilst the project is underway. Finally, ownership of results (whether datasets or algorithms) is of utmost concern in a project such as this which incorporates commercial partners: no-one wants to be exploited.</p>
               <p>Management structures in projects such as these are fairly standard.  A Principal Investigator from the Research institution would be responsible for the project overall, maintaining regular contact with the partners, having regular meetings, and reporting at regular intervals. An interdisciplinary steering committee is also advisable, to ensure all aspects of computation and historical interest would be represented. Regular meetings and updates are essential, as is the maintenance of documentation, and information provided publicly such as through a website. On an individual level, Research Assistants (particularly the programmer) should keep lab books regarding progress. All code should be commented, and documented. Backup procedures should be undertaken regularly.</p>
               <p>Security issues regarding dealing with commercially sensitive data need to be resolved before
     delivery of data is made. Consultation with data management expertise in CHIME resulted in the
     recommendation of ISO/IEC 7799:2005, a comprehensive set of controls comprising best practices
     in information security which is an internationally recognized generic information security
     standard <ptr target="#iso2005"/>. Far from being an impenetrable managerial report, the
     standard sets out guidelines and principles regarding initiating, implementing, maintaining and
     improving information security and is commonly used when dealing with ethically or commercially
     sensitive data. Most importantly, the standard aids in setting up <quote rend="inline" source="#iso2005">effective security management practices, and to help build confidence in
      inter-organizational activities</quote> 
                  <ptr target="#iso2005"/>.  Establishing policies and
     procedures which can be agreed with partners in advance of providing data will foster trust –
     and aim to protect the partner in the project to whom the data is being supplied. Other
     measures which should be undertaken is maintaining a register of assets, obtaining secure
     off-site backup, undertaking thorough risk analysis, and maintaining a <q>no
     surprises</q> approach to data flow to ensure good practice. Useful relevant literature
     regarding risk analysis, data management and systems security include <ptr target="#adams1995"/>, <ptr target="#anderson2001"/>, <ptr target="#stallings2005"/>, <ptr target="#stallings2008"/>.</p>
               <p>Legal agreements should also be undertaken about the fair use and application of data for the duration of a project, and what happens to the data after the project ends. This will require legal assistance from institutional lawyers (who often provide the service free to the project on behalf of the institution: if this is the case the project need not include legal costs in its budget). It should not be underestimated how long it would take to draw up these agreements.</p>
               <p>There are also considerations that need to be made regarding what happens to data resulting
     from the input of many project partners at the end of a project. Issues of longevity,
     preservation, and sustainability of research results are important, especially since the
     announcement that the AHRC will no longer fund the Arts and Humanities Data Service, where
     projects would have previously deposited their data to ensure long term access. More seriously, though, is the issue of who would own the resulting new data sets created as part of a project, or intellectual property rights on algorithms developed. Advice was taken from the <ref target="http://www.law.ed.ac.uk/ahrc/aboutus.aspx">AHRC Research Centre for Studies in Intellectual Property and Technology Law</ref> at the University of Edinburgh on this matter. There is currently much discussion in the legal field on the use of data in the research sector, and how the IP rules can best be used to support the aims of the teaching and learning community (see <ptr target="#davies2006"/> for an overview).  If a new database of results was created in a potential project, the underlying rights would seem to fall under the protection accorded by the Database Directive <ptr target="#ep1996"/> (although further legal advice should be taken on this as copyright may also be an issue). Broadly speaking, each of the institutions who contributed data may have the database right in the contents of their databases. Where a substantial part of the source database is used, then permission would be needed to extract and re-utilise the contents.  A <q>new</q> database right would result if these were combined for other purposes: the right would reside in the person or organisation who made an investment (whether it be financial, or time and effort) in compiling a new database. Much might depend on who was using or going to use the resultant product (for example, use may be limited to research and education). It is important that these questions are resolved at the outset of a project, to enable researchers to use and publish results, protect the commercial rights of the company, and also protect the intellectual investment of the researchers, especially regarding any outcomes which may be suitable for knowledge transfer or technological spin-off.</p>
               <p>In a case such as the proposed project with historical census material, suitable agreements and licenses would have to be drawn up between all parties prior to the research commencing. In response to gaining access to Ancestry’s datasets, for example, UCL could grant Ancestry a time limited license for application of research results with the genealogical market. The researchers should be careful not to sign away rights to research outcomes.</p>
               <p>For a grant application, it is important to establish managerial principles which will be resolved prior to the grant commencing, and to make sure that the institution has infrastructure to support these legal issues. The technology transfer office, or business office, at most universities will have expertise in this (usually in the scientific domain, but these procedures will also be applicable in the arts and humanities).  UCL Business PLC was contacted, and advised the standard procedures for setting up a project was to establish the following: that the Researcher and UCL will retain the right to publish, that UCL Business PLC, and the Contract Research Office, will arrange IPR agreements and commercial exploitation, that the foreground IP of the project will remain the property of UCL, that commercial background IPR (data, etc.) will be licensed accordingly, that UCL Business and the related infrastructure can assist in all of this, and finally, that standard Data Protection procedures should also be applied. It was also stressed that adequate time should be given to resolve licensing and technical matters prior to a project commencing.</p>
               <p>The barrier to setting up a project regarding processing of historical census data is not managerial: although it would take time on the part of the partner institutions to come to legal agreements regarding access to and sharing of the data. Many institutions have procedures in place to deal with such projects. Negotiating such licenses may take up a large portion of time at the outset of a project, however, and academic researchers should be prepared to come to grips with the intricacies of digital copyright and database law.</p>
            </div>
         </div>
         <div xml:id="section_4">
            <head>Future Research?</head>
            <p>Following consultation with historians, it was obvious that the most popular, useful, and popular, project to pursue from this research would be one that looked into the techniques and procedures used to create longitudinal databases – tracking and tracing individuals and families across different census years, and enabling historians to look at the <q>life histories</q> of individuals, families, and properties. By investigating these procedures, using the available datasets, and implementing techniques which could use the processing power of UCL’s HPC facilities (meaning that computational time would not be of concern to the project) it may be possible to undertake a comprehensive review of previous techniques used to carry out record linkage across the census, develop and implement new, robust procedures and techniques to undertake automated record matching using HPC across fuzzy datasets, and develop tools for historians undertaking the construction of longitudinal datasets, to aid them in checking and investigating possible linkages across datasets.</p>
            <p>The knowledge transfer opportunities from developing robust and benchmarkable techniques would be large: consultation with Physicists working on the AstroGrid , for example, revealed that they are facing the same problem: being able to track and trace individual entities across fuzzy and incomplete datasets. Datasets from local, and central, governments have the same problems, as do matching individuals across credit records in the financial sector. Moreover, the development of tested techniques would further the aims of historians in being able to create longitudinal datasets, and would be of great interest to genealogists, and companies operating in the genealogy sector. The results from such a project would sit alongside, and feed into, Crocket, Jones, and Schürer’s proposed Victorian Panel Study Project (2006).</p>
            <p>However, the problem of automatically matching individuals across census years is not trivial.
    Firstly, the nature of census data is that quality will always be of concern to the historian,
    and matching records across years therefore deals with great levels of uncertainty. There has
    been much research into the inherent qualities of census data (for example, see <ptr target="#holmes2006"/>, for an investigation into common problems in Ancestry’s datasets. Other
    relevant research includes <ptr target="#tillot1972"/>, <ptr target="#perkyns1991"/>, <ptr target="#perkyns1993"/> and <ptr target="#woollard1997"/>). Errors in the data can be
    introduced at every level: from those supplying the data (who may not have known, for example,
    how to spell their name or their precise birth date), from those writing down and transcribing
    those answers into the enumerator returns, and from those entering the data into the digital
    version of the records. This is something that has to be accepted when dealing with census data.
    Although computational methods can be use to check data quality and normalise some discrepancies
    (see <ptr target="#schurer2002"/>), census data will remain <q>fuzzy</q>, and often incomplete. This makes computational matching of data difficult.</p>
            <p>Added to this is the problem that the digital datasets themselves may not have certain fields digitised (depending on the digitiser, often important fields of data are missed to cut digitisation costs. The Ancestry datasets, for example, do not have occupation digitised, which can often be used as an indicator of identity). Without the full data available across the UK, it is difficult to develop algorithms or procedures which can undertake record linkage across the data.</p>
            <p>Ten years elapse from census to census – people can move, marry, remarry, be born, die, or change name. Techniques used to match individuals from census to census usually depend upon having other data available to <q>triangulate</q> individuals – for example civil registers such as births, deaths and marriages, or parish burial records. Often projects have to digitise the material themselves, as it is not often in the public domain (the <ref target="http://www.freebmd.org.uk/">FreeBMD</ref>  project aims to transcribe the Civil Registration index of births, marriages and deaths for England and Wales, and to provide free Internet access to the transcribed records – although this is very much work in progress, dependent on volunteer labour).  An example of a project utilising these different information sources to undertake longitudinal analysis of historical census data is the Cambridge Group for the History of Population and Social Structure, which has created 
    <cit>
                  <quote rend="block" source="#campop2006">Four parallel longitudinal data sets...by linking individuals in the
     decennial censuses of 1861-1901 with the births, deaths and marriages from civil registers for
     the lowland town of Kilmarnock, the Hebridean Island of Skye, and the rural parishes of
     Torthorwald and Rothiemay, places with contrasting economic and social structures and physical
     environments.</quote>
                  <ptr target="#campop2006" loc="26"/>
               </cit>
    This work was dependent on them being granted special permission by the General Register Office, Edinburgh, for access to the civil registers of births, marriages and deaths, and the creation of database of this material by a project worker.</p>
            <p>The <ref target="http://fass.kingston.ac.uk/research/local-history/projects/klhp/">Kingston Local History</ref> group is also interested in linking records across the different census years, and is constructing
    <cit>
                  <quote rend="block" source="#kingston2006">a comprehensive database detailing major aspects of Kingston's economic
     and social evolution during the second half of the nineteenth century. The core of the database
     is the complete census enumerators' returns for each census year 1851-1891 (145,000
     records).</quote>
                  <ptr target="#kingston2006"/>
               </cit>
    The project is dependent on four datasets, which they have either constructed or cleaned up: The
    Census Enumerators Books for Kingston Upon Thames Census Area - 1851 to 1891; the Bonner Hill
    Cemetery Burial Registers - 1855 to 1911; the Kingston Parish Burial Registers - 1850 to 1901;
    and the Kingston Parish Marriage Registers - 1850 to 1901. This obviously required much
    investment to allow the project to undertake research (see <ptr target="#tilley2003a"/> for
    further details of the project). Peter Tilley has also developed computational tools to allow
    record linkage to be undertaken, including some formalisation of the procedures historians use
    to undertake record linkage (see <ptr target="#tilley2003b"/> for an overview of these tools and research generated from them). The tools are not wholly automated, though – which would be necessary to generate a full scale longitudinal survey of the English historical census.</p>
            <p>Even with these difficulties, there is much interest in the possibilities of Automated Record
    Linkage techniques for linkage of census data (see <ptr target="#hc1992"/>, <ptr target="#hc1994"/> for an overview of research) in particular for the automated tracking and
    tracing of individuals across the different census years to produce what is known as a
    Longitudinal data set (see <ptr target="#hc2006"/>, and the Victorian Panel Study <ptr target="#crocket2006"/>). Projects have difficulties in two areas: projects are still dependent on human interaction in the data linking routines, meaning that routines are not wholly automated, and projects are dependent on the creation of more datasets (Campop, Kingston, and VPS.)</p>
            <p>Only when in depth datasets from across the UK are available will it be possible to carry out a full scale longitudinal survey: although there has been much financial, industrial and academic investment in the creation of digital records from historical datasets, there is not the quantity nor quality of information currently available to allow useful and usable results to be generated, checked, and assessed from undertaking automatic record linkage in this area. </p>
            <p>However, one of the aims of the ReACH project was to investigate <emph>re-use</emph> of digital data. The Kingston project has digitised material, and constructed a longitudinal dataset through the input of researchers regarding the area of Kingston Upon Thames in the Victorian era. A potential project lies in taking this dataset, and its constituent forms, and <emph>trying to recreate this data set computationally</emph>, thus being able to test and benchmark procedures against a <q>quality controlled</q> dataset. If computational algorithms can be developed which are as effective as a human researcher in creating linkage across this relatively small dataset, then perhaps these could be scaled to cover the whole of the English data when it becomes available.  Moreover, certain subsets of the data prepared by the Kingston team could be replaced at certain points in the project with other datasets – such as the Ancestry data from the same area – to investigate whether it would ever be possible to scale the project up using these pre-digitised datasets which had not been digitised for the purpose of record linkage.</p>
            <p>How would such a project proceed? A process of knowledge acquisition (conventionally defined
    as the gathering of information from any source) and Knowledge Elicitation<note>See <ptr target="#terras2006"/> for further exposition of the procedures which would need to be adopted to undertake knowledge elicitation and investigate automated record linkage.</note> (the subtask of
    gathering knowledge from a domain expert, see <ptr target="#mcgraw1989"/>, <ptr target="#mcgraw1990"/>, <ptr target="#shadbolt1990"/>) would have to be undertaken, regarding both how experts carry out record linkage manually, and a literature survey on previous research undertaking automated record linkage (not only restricted to that regarding historical census data). The available literature on automatic record linkage is large and expansive 28, and the techniques already attempted and employed not trivial: it will be difficult to contribute anything meaningful to this vast body of research 29. Given the amount of prior research in the area, the chances of developing novel architectures and algorithms which can carry out record linkage scaleable over the available census data is slim.   Access would have to be gained to a range of data (in this case Kingston datasets, but also those from Ancestry, Free BMD, and any other of the relevant census datasets which are available) and licenses for use and contracts negotiated for each. A secure system would have to be set up to receive and store data. Programming the potential techniques would then begin, constructing a system which would which mount data, apply techniques, and output results. Tools and techniques for monitoring and benchmarking the quality of these results against the test datasets would have to be established. Finally, results would have to be published and disseminated.</p>
            <p>It is obvious from this outline that this would project will take some time and manpower to carry out. It is estimated that a three to four year project featuring one historian/knowledge engineer and one computer scientist, as well as input from the Principal Investigator, and involving consultation with many historians, should be able to undertake this work.  Initial costings suggest this would be very expensive, however. The project is also very <q>blue-sky</q>. It may not be possible to automate the record linkage routines adequately, nor develop any automated record linkage techniques which are more effective than those which currently exist, or scale the results up at the moment due to the lack of existing datasets of quality, making this a potentially lengthy and costly exploration with a high risk factor.</p>
            <p>Unfortunately, should a record linkage project be carried out on the Kingston Upon Thames area data, developing routines which could be checked against the database which has already been constructed and checked by researchers is, at current time of writing, not available to allow results to be scaled up to the rest of the country. Births, marriages and death indexes are not fully available or digitised, and due to the economic climate of Kingston in the Victorian era, it can be argued that results from such a stable, middle-class environment would not be applicable to other, very different parts of England. Although the potential project is interesting, and could develop new algorithms for automated record linkage which could be checked and benchmarked against a human constructed linked database of quality, it was decided that at the current time, with the available data, that the low chance of obtaining positive research outcomes from the project would not balance the financial and intellectual investment required to undertake the research.</p>
         </div>
         <div xml:id="section_5">
            <head>Findings: e-Science and the Humanities</head>
            <p>Undertaking the ReACH series has resulted in various findings and recommendations which can be useful to other projects in the research field, but also useful to those considering using (or even funding!) e-Science or HPC technologies for humanities research.</p>
            <div xml:id="section_5.1">
               <head>For the Historian</head>
               <p>There were various points of note for historians. Firstly, although there has been much financial, industrial and academic investment in the creation of digital records from historical census data, there is not the quantity nor quality of information currently available to allow useful and usable results to be generated, checked, and assessed from undertaking automatic record linkage across the full range of census years.  If the project above were carried out on a subset of the census data, results would not yet be scaleable across England due to lack of data currently available. This will change as more data is digitised (and becomes available to the general research and genealogical community through publicly available websites operating under appropriate usage licenses). Secondly, the potential for high performance processing of large scale census data is large, and may result in useful datasets (for both historian and genealogist) when adequate census data becomes available. This should be revisited in the future. Access to computational facilities or expertise or managerial issues were not the limiting factors here (at least at UCL, although it is understood that other institutions may not have such easy access to such infrastructure).</p>
            </div>
            <div xml:id="section_5.2">
               <head>For the Arts and Humanities Researcher</head>
               <p>Generic issues raised which may be of interest to researchers in e-Science and the Arts and Humanities include the fact that the HPC and e-Science communities are very welcoming to researchers in the arts and humanities who wish to utilise and engage with their technologies.  There is also potential for research in the arts and humanities informing research in the sciences in this area, particularly in areas such as records management, information retrieval, and dealing with complex and fuzzy datasets.</p>
               <p>The problems facing e-Science research in the arts and humanities are predominantly not technical.  Although there is still fear in using HPC in the arts and humanities, dealing with the processing of (predominantly) textual data is not nearly as complex as the types of e-Science techniques (such as visualisation) used by scientific researchers. However, the nature of humanities data (being fuzzy, small scale, heterogeneous, of varying quality, and transcribed by human researchers) as opposed to scientific datasets (large scale, homogenous, numeric, and generated or collected/sampled automatically), means that novel computational techniques need to be developed to analyse and process humanities data for large scale projects, and often large enough data sets of high enough quality which warrant the use of these technologies are not available.</p>
               <p>Using the processing power of computational grids may be unnecessary for humanities projects if data sets are small, and projects have access to stand-alone machines which are powerful enough to undertake the task themselves. Processing data via computational grids can be a security risk: the more dispersed the data, the more points of interception there are to the dataset. Researchers should choose the technologies they use to carry out processing according to their need, but often running queries on a stand-alone high performance machine requires less managing at present than using processing power dispersed over a local, national, or international grid. Additionally, the challenging nature of humanities research questions mean that they are often not predisposed to batch processing and running as repetitive jobs.</p>
               <p>Finding arts and humanities data which is of a large enough size to warrant grid or high performance processing whilst being of high enough quality can be a problem for a researcher wishing to HPC in the arts and humanities. This may just have to be accepted, and the fuzzy and difficult data generated regarding arts and humanities data explored and understood to allow processing to happen.  In this way, using e-Science to deal with difficult datasets could benefit computing science and internet technologies too. Perhaps this is the main thrust of where e-Science applications in the arts and humanities may have uses for others – and knowledge transfer opportunities.</p>
               <p>Where commercial and sensitive data sets are involved in a research project, Intellectual Property Right issues and licensing agreements should be specified before projects commence. The importance of this issue cannot be stressed enough – especially when the project is wholly dependent on receiving access to datasets, or dealing with commercially valuable and sensitive data. Commercial companies are often keen to be involved in research if there are benefits to themselves: nevertheless, the IPR of academic institutions should be safeguarded. This can best be achieved through setting up specific licenses for the use of algorithms in the commercial world: again, this should be ascertained before the project commences.</p>
               <p>Those in arts and humanities research may not be used to dealing with legal aspects of research. Most universities have legal frameworks in place to deal with such queries in the case of medical and biomedical research. These facilities are generally available free of charge to arts and humanities projects within their institutions, and so funding would not be compromised by having to include legal charges in funding bids. The time taken to negotiate licenses for data use should not be underestimated, however. Advice should also be taken from those involved in biomedical research: the similarities between projects in this area and the arts and humanities are significant when it comes to data management, IPR, copyright, and licensing issues. In particular, where sensitive data sets are used, the arts and humanities researcher should look towards medical sciences for their methodologies in data security and management, in particular utilising ISO 17799 to maintain data integrity and security.</p>
            </div>
            <div xml:id="section_5.3">
               <head>For Funding Councils</head>
               <p>Where e-Science arts and humanities projects involving large datasets are proposed, it is likely that the complexity of the project will require large scale funding. Yet many of these projects will be <q>blue-sky</q>, and may require a variety of employed expertise over a number of years to undertake the work, as well as requiring technical expertise and infrastructure.  These projects will then be expensive: funding calls in e-Science for the Arts and Humanities should take this into account.</p>
               <p>Additionally, e-Science projects in the arts and humanities may be high risk with less definable outcomes than similar projects in the sciences, due to the complexity and inherent qualities of arts- and humanities-based data. If funding councils wish to foster success in this area, the risks of funding such projects should be acknowledged. The very attempt to develop <emph>practical</emph> projects which wish to apply e-Science technologies in the arts and humanities may result in cross fertilisation with the scientific disciplines.</p>
               <p>Definitions of e-Science vary from council to council. HPC is as much a part of <q>e-Science</q> in the sciences as distributed computational methods, yet the definition of e-Science for the arts and humanities focuses on networked computational methods. The two should not be distinguished from each other. If there are to be different definitions of e-Science between the arts and science councils, the reasons for this should be researched and expressed to elucidate different funding council’s approaches to e-Science, and to further explore where e-Science technologies can be of use to arts and humanities research.</p>
            </div>
         </div>
         <div xml:id="section_6">
            <head>Conclusion</head>
            <p>The ReACH workshop series has successfully brought together disparate expertise on history, records management, genealogy, computing science, information studies, and humanities computing, to ascertain how useful or feasible it would be to set up a pilot project utilising e-Science technologies to analyse historical census data.</p>
            <p>There was much interest in the series, as the topic of how HPC facilities can be embraced by the arts and humanities audience is a pertinent one: funding for e-Science facilities is now becoming available for researchers in the arts and humanities, but how can these be appropriated by the domain?</p>
            <p>An interesting aspect to the workshop series was defining the research question.  Datasets were available, expertise was available, and unlimited processing power was available – but could these be harnessed to provide a useful and useable product for historians? The <q>wish list</q> from historical researchers is illuminating, indicating the potential for HPC in this area if and when comprehensive data sets of high enough quality become available, although they do demonstrate that novel, advanced computational approaches may have to be developed to deal with the real world complexity of humanities research questions and complex humanities datasets.</p>
            <p>Aspects which may be peculiar to this project regarding collaborating with commercial partners indicate the managerial and legal similarities between research in the sciences and that in the arts and humanities. Researchers in the arts and humanities may find it useful to make contact with those in the sciences to ascertain which procedures are commonly undertaken in these areas. An interesting difference between the two, though, is the nature of humanities data, versus scientific data, which has been somewhat explored in this project.  Whereas scientific data tends to be large scale, homogenous, numeric, and generated (or collected/sampled) automatically, humanities data has a tendency to be fuzzy, small scale, heterogeneous, of varying quality, and transcribed by human researchers, making humanities data difficult (and different) to deal with computationally. However, ascertaining how large scale processing of this type of data can be undertaken will be useful for computer science: if procedures for dealing effectively with difficult and fuzzy data can be resolved, these can be applied to a range of computational activity out-with the arts and humanities domain.  Tackling e-Science projects in the arts and humanities may then inform developments in computer science for other applications.</p>
            <p>Although the ReACH series came to the conclusion that the time was not right to carry this project forward into a full scale funding proposal and project, it is hoped that the findings of the workshop series will be of interest to others wishing to apply high performance processing to large scale humanities datasets. e-Science technologies still have the potential to enable large-scale datasets to be searched analysed, and shared quickly, efficiently, and in complex and novel ways: developing a practical project which explores humanities data in this manner should be rewarding for both humanist and scientist alike.</p>
         </div>
         <div>
            <head>Acknowledgements</head>
            <p>The ReACH project involved many individuals from a range of academic backgrounds, and the project would not have been a success without the input from project partners, those attending the workshops, those who provided advice and support when approached, and those on the steering committee.</p>
            <p>Josh Hanna (Ancestry.com), Ruth Selman, and Dan Jones (both National Archives) all provided the project with their expertise. The project is particularly indebted to Jeremy Yates and Clare Gryce, both from Research Computing, UCL, for their continued input and support.</p>
            <p>The speakers from the first workshop were Clare Gryce (Research Computing, University College London), Ruth Selman (Knowledge and Academic Services Department, The National Archives), Keith Cole (Census Data Unit, National Dataset Services Group, MIMAS, The University of Manchester), Ros Davies, Eilidh Garrett and Alice Reid (Cambridge Group for the History of Population and Social Structure) Mike Wolfgramm (Vice President of Development, MyFamily).  The success of the workshop was dependent on their presentations, and follow up discussions, and the project appreciated their involvement.</p>
            <p>Participants of the various workshops, who were responsible for lively discussion and intellectual input into the project, included  Kevin Ashley (Head of Digital Archives, University of London Computer Centre), Tobias Blanke (Arts and Humanities e-Science Support Centre), Keith Cole (Director of the Census Data Unit, Deputy Director of National Dataset Services Group, MIMAS, The University of Manchester), Ros Davies (Cambridge Group for the History of Population and Social Structure), Eccy de Jonge (Research Administrator, UCL SLAIS), Matthew Dovey (Technical Manager, Oxford E-science Centre, University of Oxford), Eilidh Garrett (Cambridge Group for the History of Population and Social Structure), Clare Gryce (Manager UCL Research Computing, Department of Computer Science, UCL), Josh Hanna (Managing Director and Vice President, Ancestry Europe), Edward Higgs (Reader, Department of History, University of Essex), Richard Holmes (MA Research Student, UCL), Dan Jones (Licensing Manager, TNA), Andrew MacFarlane (Lecturer, Department of Information Science, City University), Duncan MacNiven (Registrar General for Scotland), Mike Mansfield (Director of Content Engineering and Search, MyFamily Inc), Pablo Mateos	(Department of Geography / CASA, University College London), Gill Newton	(Cambridge Group for the History of Population and Social Structure), David Nicholas (Chair of Library and Information Studies, UCL SLAIS), Chris Owens (Head of Access Development Services, The National Archives), Rob Procter (Research Director of the National Centre for e-Social Science), Alice Reid (Cambridge Group for the History of Population and Social Structure), Kevin Schürer (Director of the Economic and Social Data Service (ESDS) and the UK Data Archive (UKDA), Department of History, University of Essex), Ruth Selman (Knowledge and Information Manager, The National Archives), Leigh Shaw-Taylor (Cambridge Group for the History of Population and Social Structure), Edward Vanhoutte (Co-ordinator, Centre for Scholarly Editing and Document Studies (KANTL), Ghent), Claire Warwick (Lecturer in Electronic Communication and Publishing, UCL SLAIS), Jeremy Yates (UCL Research Computing, Lecturer in Physics and Astronomy, UCL), and Geoffrey Yeo (Lecturer in Archives and Records Management, UCL SLAIS).</p>
            <p>Following the workshops, various individuals provided further advice. Anna Clark and David Ashby (both UCL Business) provided legal advice;  Charlotte Waelde (AHRC Research Centre for Studies in Intellectual Property and Technology Law, School of Law, University of Edinburgh) also provided advice on legal matters. Nathan Lea (UCL Centre for Health Informatics &amp; Multiprofessional Education) provided advice on data security and management.</p>
            <p>Peter Tilley and Christopher French (both Centre for Local History Studies, Kingston University London) provided advice and were keen to collaborate on future research projects, offering access to the data which has emanated from their research projects. Ben Laurie (FreeBMD) also offered his support for the project, and was keen to collaborate further.</p>
            <p>The steering committee comprised of Tobias Blanke (Arts and Humanities e-Science Support Centre), Alastair Dunning (Arts and Humanities Data Service), Lorna Hughes (AHRC Methods Network), Dolores Iorizzo (Centre for the History of Science, Technology and Medicine, Imperial College London), Martyn Jessop (Centre for Computing and the Humanities, King's College London),  Dan Jones (The National Archives), David Nicholas (UCL SLAIS), Kevin Schürer (University of Essex), Ruth Selman (The National Archives),  Matthew Woollard (History Data Service), and Geoffrey Yeo (UCL SLAIS).</p>
            <p>The project would especially like to thank Tobias Blanke for his support and enthusiasm, Matthew Woollard for his sound advice, and Eccy de Jonge and Kerstin Michaels, both UCL SLAIS, who provided the project with excellent administrative support. Final thanks to Andrew Ostler for his support.</p>
         </div>
      </body>
      <back>
         <listBibl>
            <bibl xml:id="adams1995" label="Adams 1995" key="adams1995"> Adams, J. <title rend="italic">Risk</title>. Routledge (1995).</bibl>
            <bibl xml:id="anderson2001" label="Anderson 2001" key="anderson2001"> Anderson, R. <title rend="italic">Security Engineering</title>. John Wiley and Sons (2001). </bibl>
            <bibl xml:id="ahds2004" label="AHDS History 2004" key="ahds2004"> Arts and Humanities Data Service (AHDS) History. <title rend="italic">Organising Waiver of Deposit</title>. <ref target="http://ahds.ac.uk/history/depositing/waiver-of-deposit.htm">http://ahds.ac.uk/history/depositing/waiver-of-deposit.htm</ref> (2004). Accessed 15th November 2006. </bibl>
            <bibl xml:id="ahds2005" label="AHDS History 2005" key="ahds2005"> Arts and Humanities Data Service (AHDS) History. <title rend="italic">Invitation to Deposit</title>. <ref target="http://ahds.ac.uk/history/depositing/invitation-to-deposit.htm">http://ahds.ac.uk/history/depositing/invitation-to-deposit.htm</ref> (2005). Accessed 15th November 2006. </bibl>
            <bibl xml:id="ahds2006" label="AHDS 2006" key="ahds2006">Arts and Humanities Data Service (AHDS). <title rend="italic">Cross Search Catalogue</title>. <ref target="http://www.ahds.ac.uk/catalogue/search.htm">http://www.ahds.ac.uk/catalogue/search.htm</ref> (2006). Accessed 31st October 2006.</bibl>
            <bibl xml:id="ahrc2006" label="AHRC 2006" key="ahrc2006a"> Arts and Humanities Research Council (AHRC). <title rend="italic">e-Science, Background</title>. AHRC ICT Programme Activities and Services, <ref target="http://www.ahrcict.rdg.ac.uk/activities/e-science/background.htm">http://www.ahrcict.rdg.ac.uk/activities/e-science/background.htm</ref> (2006). Accessed 13th November 2006. </bibl>
            <bibl xml:id="bbc2004" label="BBC 2004" key="bbc2004"> BBC. <title rend="quotes">Where have all the men gone?</title> 
               <title rend="italic">Magazine</title>. <ref target="http://news.bbc.co.uk/1/hi/magazine/3601493.stm">http://news.bbc.co.uk/1/hi/magazine/3601493.stm</ref> (2004).  Accessed 13th November 2006. </bibl>
            <bibl xml:id="blaikie2005" label="Blaikie 2005" key="blaikie2005"> Blaikie, A. Garrett, E. and Davies, R. <title rend="quotes">Migration, Living Strategies and Illegitimate Childbearing; A Comparison of Two Scottish Settings: 1871-1881</title>, in A. Levene, T. Nutt and S. Williams eds. (2005). <title rend="italic">Illegitimacy in Britain, 1700-1920,</title> Palgrave Macmillan (2005): 141-167.</bibl>
            <bibl xml:id="brodlie2004" label="Brodlie et. al. 2004" key="brodlie2004"> Brodlie, K.,  Duce, J.,  Gallop, J.,  Sagar, M.,  Walton, J.,  Wood, J., <title rend="quotes">Visualization In Grid Computing Environments</title>, <title rend="italic">Visualization</title>, 2004. IEEE (2004): 155- 162. </bibl>
            <bibl xml:id="burnett1980" label="Burnett 1980" key="burnett1980"> Burnett, C. A., Tyler, C. W., Schoenbucher, A. K. and Terry, S. J.  <title rend="quotes">Use of Automated Record Linkage to Measure Patient Fertility After Family Planning Service</title> 
               <title rend="italic">American Journal of Public Health.</title> (1980) March; 70(3): 246250.</bibl>
            <bibl xml:id="campop2006" label="CamPop 2006" key="campop2006"> CamPop. <title rend="italic">Determining the Demography of Victorian Scotland through Record Linkage</title> 
               <ref target="http://www-hpss.geog.cam.ac.uk/research/projects/victorianscotlanddemography/">http://www-hpss.geog.cam.ac.uk/research/projects/victorianscotlanddemography/</ref> (2006). Accessed November 3rd 2006. </bibl>
            <bibl xml:id="crocket2006" label="Crocket et. al. 2006" key="crocket2006"> Crocket, A., Jones, C. E., and Schrer, K. <title rend="italic">The Victorian Panel Study</title>. Report Submitted to the ESRC (Award Ref: RES-500-25-5001) (2006).</bibl>
            <bibl xml:id="davies2005" label="Davies 2005" key="davies2005"> Davies, R. and Garrett, E. <title rend="quotes">More Irish Than the Irish? Nuptiality and Fertility Patterns on the Isle of Skye, Scotland 1881-1891</title>, in L. Kennedy &amp; R. J. Morris (eds). (2005) <title rend="italic">Ireland and Scotland: Order and disorder, 1600-2000,</title> Edinburgh (2005).</bibl>
            <bibl xml:id="davies2006" label="Davies &amp; Withers 2006" key="davies2006"> Davies, W. and Withers, K.  <title rend="italic">Public Innovation: Intellectual Property in a Digital Age</title>.  Institute for Public Policy Research (2006). </bibl>
            <bibl xml:id="dillon2001" label="Dillon and Thorvaldsen 2001" key="dillon2001b"> Dillon, L.Y. and Thorvaldsen, G. <title rend="quotes">A Look Into the Future  Using and Improving International Microdata for Historical Research</title>. In Hall, P.K., McCaa, R. and Thorvaldsen, G. (eds). <title rend="italic">Handbook of International Historical Microdata for Population Research</title>. International Microdata Access Group, Minnesota Population Center, Minneapolis, Minnesota (2001): 347-354. </bibl>
            <bibl xml:id="dunn1946" label="Dunn 1946" key="dunn1946"> Dunn, H. L. <title rend="quotes">Record Linkage.</title> 
               <title rend="italic">American Journal of Public Health</title>, Vol. 36 (1946): 1412-1416.</bibl>
            <bibl xml:id="dunn2009" label="Dunn &amp; Blanke 2009" key="dunn2009a"> Dunn, S. and Blanke, T. <title rend="quotes">Editorial</title>. <title rend="italic">Digital Humanities Quarterly Special Issue on Arts and Humanities e-Science</title>. Digital Humanities Quarterly (2009). </bibl>
            <bibl xml:id="ep1996" label="European Parliament 1996" key="ep1996"> European Parliament. <title rend="italic">Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the Legal Protection of Databases</title>. <ref target="http://eur-lex.europa.eu/lexuriserv/lexuriserv.do?uri=celex:31996l0009:en:html">http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31996L0009:EN:HTML</ref> (1996) Accessed 15th November 2006. </bibl>
            <bibl xml:id="fleury1956" label="Fleury 1956" key="fleury1956"> Fleury, M., and Henry, L. <title rend="italic">Des Registres Paroissiaux  l'Histoire de la Population. Manuel de Dpouillement et d'Exploitation de l'tat Civil Ancien</title>. Paris: Editions de l'INED (1956).</bibl>
            <bibl xml:id="fure2000" label="Fure 2000" key="fure2000"> Fure, E. <title rend="quotes">Interactive Record Linkage: The Cumulative Construction of Life Courses</title>. <title rend="italic">Demographic Research</title>. 3:11. <ref target="http://www.demographic-research.org/volumes/vol3/11/html/0.htm">http://www.demographic-research.org/Volumes/Vol3/11/html/0.htm</ref> (2000) Accessed 16th November 2006. </bibl>
            <bibl xml:id="garrett2006a" label="Garrett 2006a" key="garrett2006a"> Garrett, E.  <title rend="quotes">Urban-Rural Differences in Infant Mortality: a View from the Death Registers of Skye and Kilmarnock</title>, in E. Garrett, C. Galley, N. Shelton and R. Woods (2006).  <title rend="italic">Infant mortality: a continuing social problem?</title> Ashgate, 119-148.</bibl>
            <bibl xml:id="garrett2003" label="Garrett 2003" key="garrett2003"> Garrett, E. and Davies, R. <title rend="quotes">Birth Spacing and Infant Mortality on the Isle of Skye, Scotland, in the 1880s; a Comparison with the Town of Ipswich, England</title>, <title rend="italic">Local Population Studies</title>, 71(2003): 53-74.</bibl>
            <bibl xml:id="gutmann1977" label="Gutmann 1977" key="gutmann1977"> Gutmann, M. P. "Reconstituting Wandre. An Approach to Semi-automatic Family Reconstitution." <title rend="italic">Annales de Dmographie Historique </title>(1977): 315-41.</bibl>
            <bibl xml:id="higgs2005" label="Higgs 2005" key="higgs2005"> Higgs, E. <title rend="italic">Making Sense of the Census Revisited: Census Records for England and Wales 1801-1901: a Handbook for Historical Researchers.</title> London, Institute of Historical Research (2005).</bibl>
            <bibl xml:id="hc1992" label="History and Computing 1992" key="hc1992">
               <title rend="italic">History and Computing</title>. Special Issue on Record Linkage, 4.1.</bibl>
            <bibl xml:id="hc1994" label="History and Computing 1994" key="hc1994">
               <title rend="italic">History and Computing</title>. Special Issue on Record Linkage II, 6.3.</bibl>
            <bibl xml:id="hc2006" label="History and Computing 2006" key="hc2006">
               <title rend="italic">History and Computing</title>. Special Issue: <title rend="italic">Longitudinal and Cross-Sectional Historical Data: Intersections and Opportunities</title>. 14.1/14.2.</bibl>
            <bibl xml:id="holmes2006" label="Holmes 2006" key="holmes2006"> Holmes, R. <title rend="italic">The Accuracy and Consistency of the Census Returns for England 1841-1901 and their Indexes</title>.  School of Library, Archive and Information Studies, University College London. M.A. Dissertation (2006). </bibl>
            <bibl xml:id="huntington2007" label="Huntington et. al. 2007" key="huntington2007"> Huntingdon P., Nicholas D., Jamali H. R. <title rend="quotes">Employing Log Metrics to Evaluate Search Behaviour and Success: Case Study, the BBC Search Engine</title>. <title rend="italic">Journal of Information Science</title>, (2007) 33:5, 584-597.</bibl>
            <bibl xml:id="impedovo1993" label="Impedovo 1993" key="impedovo1993"> Impedovo, S.  <title rend="italic">Fundamentals in Handwriting Recogntion</title>.  NATO Advanced Study Workshop on Fundamentals in Handwriting Recognition, Chteau de Bonas, France, Springer-Verlag (1993).</bibl>
            <bibl xml:id="inman2002" label="Inman 2002" key="inman2002"> Inman P. <title rend="quotes">Genealogy</title>. <title rend="italic">The Guardian</title>, Thursday September 26, 2002, <ref target="http://www.guardian.co.uk/internetnews/story/0,,798781,00.html">http://www.guardian.co.uk/internetnews/story/0,,798781,00.html</ref> (2002). Accessed 3rd November 2006. </bibl>
            <bibl xml:id="itic2003" label="Information Technology Industry Council 2003" key="itic2003">Information Technology Industry Council. <title rend="italic">Programming languages  C++</title>. Second edition, Geneva: ISO/IEC. 14882:2003(E) (2003).</bibl>
            <bibl xml:id="iso2005" label="ISO 2005" key="iso2005">International Organization for Standardisation (ISO). <title rend="quotes">ISO/IEC 17799:2005 Information technology -- Security techniques -- Code of Practice for Information Security Management</title>  Available from <ref target="http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=39612&amp;ics1=35&amp;ics2=40&amp;ics3">http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=39612ICS1=35ICS2=40ICS3</ref> (2005)  Accessed November 13th 2006.</bibl>
            <bibl xml:id="katz1972" label="Katz 1972" key="katz1972"> Katz, M. and Tiller, J. <title rend="quotes">Record-Linkage for Everyman: A Semi-Automated Process.</title> 
               <title rend="italic">Historical Methods Newsletter</title> 5 (1972):144-150.</bibl>
            <bibl xml:id="kingston2006" label="Kingston Local History Project 2006" key="kingston2006">
               <title rend="quotes">The Kingston Local History Project</title> 
               <ref target="http://fass.kingston.ac.uk/research/local-history/projects/klhp/">http://fass.kingston.ac.uk/research/local-history/projects/klhp/</ref> (2006). Accessed 3rd November 2006. </bibl>
            <bibl xml:id="lloyd2004" label="Lloyd et. al. 2004" key="lloyd2004"> Lloyd, D., Webber, R.,  Longley, P. 
   <title rend="quotes">Surnames as a Quantative Resource: The Geography of British and Anglophone Surnames</title>. Conference, UCL, 28th-31th April, 2004, paper synopses available at <ptr target="http://www.casa.ucl.ac.uk/surnames/papers.htm"/> (2004). Accessed 9th November 2006. </bibl>
            <bibl xml:id="mansfield2006" label="Mansfield 2006" key="mansfield2006"> Mansfield, M. <title rend="quotes">Ancestry Census Records: Background, Technology, Structures</title>. Presentation for <title rend="italic">ReACH All Hands Workshop</title>, UCL, 14th June 2006. </bibl>
            <bibl xml:id="mcgraw1989" label="McGraw &amp; Harbison-Briggs 1989" key="mcgraw1989"> McGraw, K. L. and Harbison-Briggs, K.  <title rend="italic">Knowledge Acquisition: Principles and Guidelines</title>. London, Prentice-Hall International Editions (1989).</bibl>
            <bibl xml:id="mcgraw1990" label="McGraw &amp; Westphal 1990" key="mcgraw1990"> McGraw, K. L. and Westphal, C. R. (Eds). <title rend="italic">Readings in Knowledge Acquisition, Current Practices and Trends</title>.  London, Ellis Horwood Limited (1990).</bibl>
            <bibl xml:id="mills1989" label="Mills et. al. 1989" key="mills1989"> Mills, D., Pearce, C. Davies, R., Bird, J., and Lee, C. <title rend="italic">People and Places in the Victorian Census: A Review and Bibliography of Publications Based Substantially on the Manuscript Census Enumerators' Books 1841-1911</title>. Historical Geography Research Series, No. 23. Historical Geography Research Group of the Royal Geographical Society with the Institute of British Geographers (1989).</bibl>
            <bibl xml:id="newcombe1988" label="Newcombe 1988" key="newcombe1988"> Newcombe, H. B., <title rend="italic">Handbook of Record Linkage: Methods for Health and Statistical Studies, Administration, and Business</title>, Oxford: Oxford University Press (1988).</bibl>
            <bibl xml:id="nitsch2006" label="Nitsch 2006" key="nitsch2006"> Nitsch, D., Morton, S.,  DeStavola, B. L., Clark, H. and Leon, D. A. <title rend="quotes">How Good is Probabilistic Record Linkage to Reconstruct Reproductive Histories? Results from the Aberdeen Children of the 1950s Study</title> 
               <title rend="italic">BMC Medical Research Methodology</title>, 6 (2006):15</bibl>
            <bibl xml:id="nicholas2006" label="Nicholas et al 2006" key="nicholas2006"> Nicholas, D., Huntington P., Jamali H.R. and, Tenopir, C. <title rend="quotes">Finding Information in (Very Large) Digital Libraries: a Deep Log Approach to Determining Differences in Use According to Method of Access</title>. <title rend="italic">Journal of Academic Librarianship</title>, 32 (2) (2006): 119-126.</bibl>
            <bibl xml:id="perkyns1991" label="Perkyns 1991" key="perkyns1991"> Perkyns, A. <title rend="quotes">Birthplace Accuracy in the Censuses of Six Kentish Parishes 1851-1881,</title> in <title rend="italic">Local Population Studies</title>, 47 (reprinted in Mills, D.R., and Schurer, K. (eds.) (1996), <title rend="italic">Local Communities in the Victorian Census Enumerators' Books</title>, Oxford, Leopards Head Press.)</bibl>
            <bibl xml:id="perkyns1993" label="Perkyns 1993" key="perkyns1993"> Perkyns, A. <title rend="quotes">Age Checkability and Accuracy in the Censuses of Six Kentish Parishes 1851-1881,</title> in <title rend="italic">Local Population Studies</title>, 50 (reprinted in Mills, D.R., and Schurer, K. (eds.) (1996). <title rend="italic">Local Communities in the Victorian Census Enumerators' Books</title> Oxford, Leopards Head Press.)</bibl>
            <bibl xml:id="prdh2000" label="PRDH 2000" key="prdh2000">Programme de Recherche en Demographie Historique.
                <title rend="italic">The 1852 and 1881 Historical Censuses of Canada, 1881 Cleaning Manual, Phase 1</title> (2000). Available at <ptr target="http://www.prdh.umontreal.ca/census/en/uguide/OLD/1881projects.html"/> Accessed 14/11/06. </bibl>
            <bibl xml:id="reid2006" label="Reid 2006" key="reid2006"> Reid, A., Davies, R. and Garrett, E. <title rend="quotes">Nineteenth Century Scottish Demography from Linked Censuses and Civil Registers: a 'Sets of Related Individuals' Approach</title>, <title rend="italic">History and Computing</title>, 14.1 (2006).</bibl>
            <bibl xml:id="riedel2007" label="Riedel et. al. 2007" key="riedel2007"> Riedel, M., Eickermann, T., Habbinga, S., Frings, W., Gibbon, P., Mallmann, D., Wolf, F., Streit, A. Lippert, T.,   Schiffmann, W., Ernst, A., Spurzem, R., Nagel, W. E., <title rend="quotes">Computational Steering and Online Visualization of Scientific Applications on Large-Scale HPC Systems within e-Science Infrastructures</title>, <title rend="italic">IEEE International Conference on e-Science and Grid Computing</title>, 10-13 December 2007, Bangalore, India (2007): 483-490. </bibl>
            <bibl xml:id="robey2006" label="Robey 2006" key="robey2006"> Robey, D.  <title rend="quotes">AHRC-EPSRC-JISC Arts and Humanities e-Science Initiative, Research Grants and Studentships Scheme</title> Introductory Presentation, <title rend="italic">e-Science Research Grants and Studentships Open Meeting</title>, 8 September 2006, Woburn House, 20 Tavistock Square, London (2006).</bibl>
            <bibl xml:id="sauleau2005" label="Sauleau 2005" key="sauleau2005"> Sauleau, E. A., Paumier, J-P,  and Buemi, A. <title rend="quotes">Medical Record Linkage in Health Information Systems by Approximate String Matching and Clustering</title>. <title rend="italic">BMC Medical Informatics and Decision Making</title>, 5 (2005):32.</bibl>
            <bibl xml:id="schurer2002" label="Schürer &amp; Woollard 2002" key="schurer2002"> Schürer, K. and Woollard, M.
   <title rend="quotes">National Sample from the 1881 Census of Great Britain 5% Random Sample.
   Working Documentation v1.1</title>, University of Essex, Historical Census and Social Surveys
              Research Group. Available at <ref target="http://www.data-archive.ac.uk/doc/4177%5cmrdoc%5cpdf%5cguide.pdf">http://www.data-archive.ac.uk/doc/4177%5cmrdoc%5cpdf%5cguide.pdf</ref> (2002).  Accessed 9th November 2006. </bibl>
            <bibl xml:id="shadbolt1990" label="Shadbolt &amp; Burton 1990" key="shadbolt1990"> Shadbolt, N. and Burton, M. A. <title rend="quotes">Knowledge Elicitation Techniques - Some Experimental Results.</title> In  McGraw, K., L. and C. R. Westphal, (eds). <title rend="italic">Readings in Knowledge Acquisition, Current Practices and Trends</title>.  London, Ellis Horwood Limited (1990).</bibl>
            <bibl xml:id="stallings2005" label="Stallings 2005" key="stallings2005"> Stallings, W. <title rend="italic">Network Security Essentials: Applications and Standards</title>, Prentice Hall (2005). </bibl>
            <bibl xml:id="stallings2008" label="Stallings 2008" key="stallings2008"> Stallings, W. and Brown, L. <title rend="italic">Computer Security: Principles and Practice</title>, Prentice Hall (2008).</bibl>
            <bibl xml:id="terras2006" label="Terras 2006" key="terras2006a"> Terras, M. <title rend="italic">The Researching e-Science Analysis of Census Holdings Project: Final Report to AHRC</title>. AHRC e-Science Workshop scheme (2006). Available from www.ucl.ac.uk/reach/.</bibl>
            <bibl xml:id="tilley2003a" label="Tilley 2003a" key="tilley2003a"> Tilley, P. <title rend="quotes">The Kingston Local History Project. Creating Life Histories and Family Trees for Communities in Victorian Britain</title>. <title rend="italic">IMAG Workshop Paper, Longitudinal and Cross-sectional Historical Data, Intersections and Opportunities</title>, Montreal, 10th and 11th November 2003. </bibl>
            <bibl xml:id="tilley2003b" label="Tilley 2003b" key="tilley2003b"> Tilley, P. <title rend="quotes">A Restless Community. Preliminary Findings from a Study of Migration from Kingston on Thames in 1871</title>. Paper presented to the PhD workshop, Economic History Department, London School of Economics 5th November 2003. </bibl>
            <bibl xml:id="tillot1972" label="Tillot 1972" key="tillot1972"> Tillot, P. M. <title rend="quotes">Sources of Inaccuracy in the 1851 and 1861 Censuses</title>. In Wrigley (ed), <title rend="italic">Nineteenth-Century Society.  Essays in the Use of Quantitative Methods for the Study of Social Data</title>. Cambridge, Cambridge University Press (1972). 82-133. </bibl>
            <bibl xml:id="ucl2006a" label="UCL Research Computing 2006a" key="ucl2006a"> UCL Research Computing, <title rend="quotes">Altix</title>. <ptr target="http://www.ucl.ac.uk/research-computing/services/altix/index.html"/> (2006a). Accessed 13th November 2006. </bibl>
            <bibl xml:id="ucl2006b" label="UCL Research Computing 2006b" key="ucl2006b"> UCL Research Computing  <title rend="quotes">Services</title> 
                <ptr target="http://www.ucl.ac.uk/research-computing/information/services"/> (2006b). Accessed 13th November 2006. </bibl>
            <bibl xml:id="warwick2008" label="Warwick et al. 2008" key="warwick2008a"> Warwick, C., Terras, M., Huntington, P., and Pappa, N. <title rend="quotes">If You Build It Will They Come? The LAIRAH Study: Quantifying the Use of Online Resources in the Arts and Humanities Through Statistical Analysis of User Log Data.</title> 
               <title rend="italic">Literary and Linguistic Computing</title>. 23(1), 85-102 (2008). </bibl>
            <bibl xml:id="winchester1970" label="Winchester 1970" key="winchester1970"> Winchester, I. <title rend="quotes">The Linkage of Historical Records by Man and Computer: Techniques and Problems.</title> 
               <title rend="italic">Journal of Interdisciplinary History</title>, 1(1): 107-24</bibl>
            <bibl xml:id="winkler2001" label="Winkler 2001" key="winkler2001"> Winkler, W. E. <title rend="quotes">Records
   Linkage Software and Methods of Merging Administrative Lists</title>. <title rend="italic">Bureau of the Census Statistical Research Division, Statistical Research Report Series RR2001/3</title> (2001).  Available at <ptr target="http://www.census.gov/srd/papers/pdf/rr2001-03.pdf"/>.  Accessed November 16th 2005. </bibl>
            <bibl xml:id="woollard1997" label="Woollard 1997" key="woollard1997"> Woollard, M. <title rend="quotes"> 
                  <q>Shooting the Nets</q>: a Note on the Reliability of the 1881 Census Enumerators Books</title>.  <title rend="italic">Local Population Studies</title>, 59 (1997): 54-57.</bibl>
         </listBibl>
      </back>
   </text>
</TEI>