<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <!-- Author should supply the title and personal information-->
                <title type="article" xml:lang="en">Experiments in Distant Reading: Using Topic Modeling on Chinese Buddhist Texts from 500-800 CE</title>
                <!-- Add a <title> with appropriate @xml:lang for articles in languages other than English -->
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>first name(s) <dhq:family>family name</dhq:family></dhq:author_name>
                    <idno type="ORCID"><!-- if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000 --></idno>
                    <dhq:affiliation></dhq:affiliation>
                    <email></email>
                    <dhq:bio><p></p></dhq:bio>
                </dhq:authorInfo>
            </titleStmt>
            <publicationStmt><publisher>Alliance of Digital Humanities Organizations</publisher>
<publisher>Association for Computers and the Humanities</publisher>
                <idno type="DHQarticle-id"><!-- including leading zeroes: e.g. 000110 --></idno>

            	
            	<!-- This information will be completed at publication -->
                <idno type="volume"><!-- volume number, with leading zeroes as needed to make 3 digits: e.g. 006 --></idno>
                <idno type="issue"><!-- issue number, without leading zeroes: e.g. 2 --></idno>
                <date><!-- include @when with ISO date and also content in the form 23 February 2024 --></date>
                <dhq:articleType>article</dhq:articleType>
                <availability status="CC-BY-ND">
<!-- If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default): <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>     
                  CC-BY:  <cc:License rdf:about="https://creativecommons.org/licenses/by/2.5/"/>
                  CC0: <cc:License rdf:about="https://creativecommons.org/publicdomain/zero/1.0/"/>
-->                    
                    <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
                </availability>
            </publicationStmt>
            
            <sourceDesc>
                <p>This is the source</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <classDecl>
                <taxonomy xml:id="dhq_keywords">
                    <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
                </taxonomy>
                <taxonomy xml:id="authorial_keywords">
                    <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
                </taxonomy>
            	<taxonomy xml:id="project_keywords">
            		<bibl>DHQ project registry; full list available at <ref target="http://www.digitalhumanities.org/dhq/projects.xml">http://www.digitalhumanities.org/dhq/projects.xml</ref></bibl>
            	</taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en" extent="original"/>
                <!-- add <language> with appropriate @ident for any additional languages -->
            </langUsage>
            <textClass>
                <keywords scheme="#dhq_keywords">
                    <!-- Authors may suggest one or more keywords from the DHQ keyword list, visible at https://github.com/Digital-Humanities-Quarterly/dhq-journal/wiki/DHQ-Topic-Keywords; these may be supplemented or modified by DHQ editors -->
                	
                	<!-- Enter keywords below preceeded by a "#". Create a new <term> element for each -->
                    <term corresp=""/>
                </keywords>
                <keywords scheme="#authorial_keywords">
                    <!-- Authors may include one or more keywords of their choice -->
                    <list type="simple">
                        <item></item>
                    </list>
                </keywords>
            	<keywords scheme="#project_keywords">
            		<list type="simple">
            			<item></item>
            		</list>
            	</keywords>
            </textClass>
        </profileDesc>
        <revisionDesc>
        	<!-- Replace "XXXXXX" in the @target of ref below with the appropriate DHQarticle-id value. -->
        	<change>The version history for this file can be found on <ref target=
        		"https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/master/articles/000771/000771.xml">GitHub
        	</ref></change>
        </revisionDesc>
    </teiHeader>
    <!-- If a translation is added to the original article, add an enclosing <text> and <group> element -->
    <text xml:lang="en" type="original">
        <front>
            <dhq:abstract>
                <p>The article tries to answer whether the BERTopic topic modeling framework can be used to obtain topics that meaningfully distinguish two corpora of Buddhist Chinese texts from 500 to 800 CE. The first corpus consists of translated “Indian-Chinese” Buddhist texts, the second of “Chinese-Chinese” texts, 
                i.e. texts directly authored in Buddhist Chinese. Does the application of topic modeling reveal aspects that are typical for these corpora and do these topics suggest avenues for future research into the sinicization of Buddhism that took place during that time?
                For our implementation of BERTopic, we used the customized GuwenBERT, a large language model trained on classical Chinese. To reduce the dimensionality of the embeddings we used the UMAP algorithm. Next, the HDBSCAN takes care of hierarchical clustering. 
                The most relevant words of each cluster are identified with c-tf-idf. As a last step, we score each cluster by its monochromaticity – this is a measure of how likely the documents in the cluster are to be derived from either just the “Chinese-Chinese” or just the “Indian-Chinese” documents.
                In order to communicate the topics we create virtual paragraphs that combine most of the top twenty terms that represent a sample of ten highly monochromatic topics. Discussing these topics from a Buddhist Studies point of view, we find that our modified BERTopic workflow does indeed return topics 
                that are characteristic of their corpus and highlights facets that help to understand the process of how Buddhism became sinicized in the three centuries between 500 and 800 CE. Thus distant reading of latent topics in the corpus is possible. While some topics are in themselves unsurprising, 
                others highlight new promising areas for research.
                </p>
            </dhq:abstract>
            <dhq:teaser>
                <!-- Include a brief teaser, no more than a phrase or a single sentence -->
                <p></p>
            </dhq:teaser>
        </front>
         <body>
             <div>
             <head>1. Introduction</head>
                 <p>In an article on the “Genealogy of Distant Reading” Ted Underwood made the valid point that distant reading as a form of “macroscopic literary inquiry” did not originate with digital text (Underwood 2017). 
                     Still, all DH methods, by definition, process digital data, and most can only be applied effectively only within a computational setting. While some methods (e.g. markup or GIS) 
                     extend analog practice (such as editing or cartography) into the digital, others are digital natives.
                     Topic modeling is one of the computational methods that over the last twenty years have made their way from Natural Language Processing (Blei et al. 2003) into the Digital Humanities. 
                     It has been consistently associated with distant reading. In the introduction to a special issue on topic modeling in the Journal of the Digital Humanities the editors even called it 
                     “distant reading in the most pure sense” (Meeks and Weingart 2012).  As digital corpora grow ever larger, so does the need for distant reading. Thus topic modeling has survived early hype and critique (Schmidt 2012) 
                     and is still going strong in DH (Du 2019) and in information retrieval in general. Originally dominated by the application of Latent Dirichlet Allocation (Blei et al. 2003), by now there are several different approaches to topic modeling. 
                     Comparing their respective strengths and weaknesses has resulted in a veritable sub-genre of comparative studies (Kherwal and Bansal 2019, Vayansky and Kumar 2020, Fu et al. 2020, Ma et al. 2021; Egger and Yu 2022, Rüdiger et al. 2022, Chen et al. 2023). 
                     In this paper we will use a modified version of BERTopic (Grootendorst 2022), a new, neural network based approach, to distant read two related text corpora in Buddhist Chinese, a low-resource idiom. 
                     Although an attempt has been made to use BERTopic on Chinese poetry (Fang 2023), to our knowledge this is the first time BERTopic has been used on canonical Buddhist texts in any language. 
                </p>
                 <p>Our first question is whether BERTopic, which relies on BERT for word embeddings, does return coherent topics at all when confronted with a low-resource idiom such as Buddhist Chinese, which was not represented in the training data for BERT, 
                     and for which tokenization algorithms are available but not widely implemented (Wang 2020). Secondly, we would like to know whether the application of the BERTopic workflow can yield meaningful topics that can be taken to express concerns in Chinese Buddhist texts 
                     created between 500 and 800 CE and might in particular be used to distinguish two different corpora, Indian-Chinese and Chinese-Chinese texts, and how they might be used in furthering our understanding of the texts.
                 </p>
                 <p>Why this particular time-frame? In the centuries between 500 and 800 CE, Buddhism in China turned into Chinese Buddhism. The first Indian Buddhist texts were translated into Chinese in the second century. Starting from the late third century 
                     we are able to reconstruct an unbroken social network that connects generations of Chinese Buddhists until today (Bingenheimer 2021).  Until the 6th century this network was mainly informed by Indian-Chinese texts, i.e. Indian texts 
                     translated into Chinese. Chinese-Chinese texts, i.e. texts authored by Chinese (or Korean or Japanese) writers, began as paratext (prefaces, catalogs etc.) to these translations, then developed via short essays, apocrypha and commentaries, 
                     eventually blossoming into long historiographical and doctrinal works in the 6th century. The time between 500 and 800 is special in the sense that in spite of the continuing reception and translation of Indian texts, it were the Chinese-Chinese texts 
                     that were produced during that period that became distinctive for later Chinese Buddhism. The philosophical works of Zhiyi 智顗 (538–597) and Fazang 法藏 (643–712), the devotional treatises of Tanluan 曇鸞 (476-542) and Shandao 善導 (613–681), 
                     and the recorded sayings of early Chan masters like Huineng 慧能 (638–713) and Mazu Daoyi 馬祖道一 (709–788), to give but a few examples, became the textual foundation for the dominant traditions within Chinese, and indeed East Asian, 
                     Buddhism of the second millennium: Chan, Pure Land, and Tiantai Buddhism.                     
                 </p>
                 <p>While in the year 500 CE Buddhism in China was still very much dominated by the influx of Indian Buddhist ideas, by 800 CE Chinese Buddhists had started to put their own spin on Buddhism. Most features that would come to characterize Chinese Buddhism were in place, 
                     even if it took another few centuries for them to fully form: the dichotomy, both stable and dynamic, between meditative Chan and devotional Pure Land practice, an interest in historiography and lineage, a commitment to the lay-monastic distinction, 
                     and the necessity of apologetics in the framework of the Chinese state. While Buddhism declined in India after 800 CE and became virtually extinct there after the 12th century, Chinese Buddhism blossomed throughout the Song Dynasty (960–1279) 
                     and today remains the largest world religion in China with more than 200 million adherents (Pew Research Center 2023).
                 </p>
                 <p>The topics returned by topic modeling methods are notoriously open to interpretation. Whether or not they cohere with respect to a particular domain can only be evaluated by domain experts. In order to communicate how we read a topic to a wider audience
                     we combine the lists of terms that represent topics into “virtual paragraphs” (Appendix A). In that way we hope to make our reading transparent for non-specialists who can easily grasp what the topic is about. 
                     Creating virtual paragraphs from topics could also be used in teaching. When practiced in conjunction with close, linear reading of classical texts, students stand to gain familiarity with concepts and semantic fields that are latent in larger corpora.
                 </p>
             </div>
                <div>
                    <head>2. Data</head>
                    <p>Based on the largest digital archive of Chinese Buddhist texts (CBETA Ver. 2022) we have assembled two corpora of comparable size. 
                        1. Indian-Chinese: This consists of all 661 originally Indian texts in the CBETA corpus that were translated into Buddhist Chinese between 500 and 800 CE. Total number of characters: 17,959,037.
                        2. Chinese-Chinese: This corpus consists of all 293 texts in the CBETA corpus that were composed directly in Buddhist Chinese between 500 and 800 CE. Total number of characters: 21,136,841.
                        Both corpora might include material from before 500 CE. Obviously, the Indian-Chinese texts are translations and might have been authored before 500 CE. 
                        
                        But the Chinese-Chinese corpus too, although authored between 500 and 800 CE, contains commentaries on older texts and thus includes material (and topics) from earlier periods. 
                        This caveat notwithstanding the corpora represent two different modes of textual production in Chinese Buddhism during that period and an experiment in modeling is justified and might yield new insights. 
                        In Section 4 we will try to interpret select topics guided by the hypothesis that the topics in these two corpora differ meaningfully. It should be understood that the topic modeling workflow we implemented does not process the two corpora separately. 
                        Whether a topic is aligned with the Indian-Chinese or the Chinese-Chinese corpus is determined by its monochromaticity (s. Sec. 3).
                    </p>
                    <p>We use the term “Buddhist Chinese” here for the particular idiom (or set of idioms) in which pre-modern Buddhist texts were composed. Needless to say, across 1700 years there was a lot of variation. 
                        The translation of Indian Buddhist texts into Chinese was never standardized and there exists a many-to-many relationship in the translation of terms: One Indian word could be rendered by different Chinese characters, 
                        and the same Chinese character was used for different Indian terms. Chinese-Chinese Buddhist texts were generally closer to the classical idiom of literary Chinese than translated texts, but they share features with translated texts 
                        that sets them apart from the usual “classical Chinese” written in that period. Among these features are the morphology of Buddhist vocabulary which makes words more likely to be compounds of two more more characters, 
                        instead of the preferred one-character = one-semantic-unit equivalence of “classical classical Chinese.”
                    </p>
                    <p>The reason why there are more than twice as many Indian-Chinese than Chinese-Chinese texts is because in the eight century a large number of short dhāraṇī text were translated, or in fact rather transcribed. The main component of such texts is the dhāraṇī itself: 
                        a Sanskrit invocation or spell, which was used in the context of esoteric ritual (see also Sec. 4). Although longer than a mantra, dhāraṇīs could not be too long as many of them were supposed to be remembered by heart, but within esoteric Buddhism they were popular. 
                        Thus the Indian-Chinese corpus consists of a larger number of short texts, in spite of the corpus being overall smaller than the Chinese-Chinese corpus in terms of characters.
                    </p>
                   </div>
             <div>
                 <head>3. Method</head>
                 <p>Our method follows BERTopic (Grootendorst 2022), a recent topic modeling framework that has quickly attracted attention.  We use our own variation of the BERTopic pipeline, which we make available at https://github.com/mbingenheimer/cbetaCorpusSorted. 
                     Specifically, our implementation involves the following steps:
                     1.	Using a large language model trained on classical Chinese (Koichi Yasuoka’s variant of GuwenBERT), we embed every sentence in our corpus into a high dimensional vector space.
                     2.	We perform UMAP to reduce the sentence embeddings to a 3-dimensional set.
                     3.	We use HDBSCAN to determine clusters which we interpret as topics
                     4.	The words in the sentences of each topic are collected and ranked according to c-tf-idf to measure the degree to which they represent the entire topic.
                     5.	The individual sentences are tagged as to their provenance (whether they come from a Chinese-Chinese or a Chinese-Indian source). This allows us to compute the monochromaticity of each cluster and determine which clusters are mixed versus which ones are representative of one or the other of our corpora.
                     </p>
                 <p>The main idea of BERTopic is to take advantage of the capacity of modern neural networks to create sentence embeddings which respect semantic similarity, meaning that linguistic elements with similar meaning should be embedded close to each other in the target vector space. While many previous techniques are based on mapping language elements to vectors 
                     (with word2vec probably being the best-known), encoder-only models like BERT have the advantage of embedding language in a way that is sensitive to semantics. In particular the embedding of a multivalent word (e.g. bank) is dependent on the surrounding sentence. 
                     Thus homonyms can be disambiguated in the embedding. At the same time synonyms like happy and joyful that have a similar probability of occurring at a particular position in a sentence are defined with similar embeddings. As a result, any BERT model can be expected to display some degree of identifying semantic similarity. 
                     Specifically, these models operate by learning how to predict missing tokens (e.g. words) from a natural language sentence. To be successful, the model has to learn the probabilities associated with various possible words at a specific point in the sentence. 
                     This will necessarily entail disambiguating homonyms – if it would represent all instances of the word bank in the same way then it could not correctly learn the context-dependent likelihoods of the words money and river occurring elsewhere in the sentence. 
                     Similarly, it would be helpful (if not strictly necessary) for synonyms to have close embeddings; this would allow them to automatically treat their influence on the rest of the sentence similarly. On the other hand, such models can be explicitly trained to respect semantic similarity – this requires a custom dataset designed for this purpose.
                 </p>
                 <p>Our base model is Koichi Yasuoka’s variant of GuwenBERT.  GuwenBERT is a BERT model which is trained on the Daizhige 殆知阁 dataset, which according to the creators of GuwenBERT contains “15,694 books in Classical Chinese, covering Buddhism, Confucianism, Medicine, History, ...Taoism, [and others]”.  
                     Whereas the original GuwenBERT was trained on the corpus in simplified Chinese, Yasuoka’s model allows for traditional Chinese characters. To our knowledge, there is no semantic similarity training set for Classical Chinese; thus we rely on the level of semantic similarity native to our base model.  This results in the danger of outputting collocations instead of topics: 
                     For example, our pipeline sometimes picks up on ngrams that contain “十一eleven (-somethings)” or “四十forty (-somethings)”, resulting in clusters that are based on one or two characters rather than genuine semantic clustering.
                 </p>
                 <p>We pass each sentence of each document into our base model, thereby obtaining a high-dimensional vector representation of each sentence. These sentences are tagged according to the corpus they originated from. It is understood within data science that high dimensional datasets are difficult to work with; 
                     many mathematical algorithms designed for low dimensional datasets break down in high dimensions – this is known as the curse of dimensionality. Thus our set of high dimensional sentence representation is then passed through the UMAP algorithm (McInnes 2018) which reduces the representations to being 3-dimensional. 
                     UMAP is designed so that representations which are close (in some sense) in the high dimensional space will get transformed into representations which are still close in 3-dimensional space. This ensures that clusters that are observed in the 3 dimensional space do actually correspond to representations which are close in the high-dimensional space. 
                     If our embeddings display a high degree of semantic similarity, this should mean that sentences whose representations are clustered close together actually represent sentences with related meanings.
                 </p>
                 <p>Having reduced the sentences representations to three dimensions, we use HDBSCAN (McInnes 2015), a clustering algorithm, to identify and extract clusters. Each cluster is comprised of a set of sentences. To uncover what topic each cluster represents, the sentences are broken into words. Each word in the cluster is given a score determined by the frequency of the word in the cluster, 
                     multiplied by the information content (or rarity) of the word in the corpus. This metric is known as c-tf-idf. We take the top 20 scoring words as indicative of the cluster's content. As usual with topic modeling, the total number of topics varies with parameterization.
                 </p>
                 <p>Finally we score each cluster by how monochromatic (in our case: purely derived from the “Chinese-Chinese” corpus) and how large it is (i.e. how many sentences are represented in the cluster). Our intuition is that large clusters are more representative of the corpus. 
                     Monochromaticity (MC) is expressed by a score between 0 and 1, with values converging to 0 indicating a cluster largely derived from the Indian-Chinese corpus, convergence to 1 indicates a cluster mostly derived from the Chinese-Chinese corpus, and clusters with MC around 0.5 are derived equally from both corpora.
                 </p>
             </div>
             <div>
                 <head>4. Discussion</head>
                 <p>Orienting ourselves by monochromaticity and cluster size allows us to focus on the “coherent” topics that have the best chance at being “meaningful” for distinguishing between Indian-Chinese and Chinese-Chinese corpora. We found it useful to distinguish between these two orders of sense-making: 
                     We define “coherent” here not by one of the several computed coherence metrics for topic modeling (such as Umass, C-V etc.). 
                     In the case of BERTopic, that is already taken care of during the dimensionality reduction via HDBSCAN. 
                     Rather we use human evaluation to decide whether the terms in a topic semantically relate to each other in a way that allows a reader with domain knowledge 
                     to string them together in virtual paragraphs (Appendix A) without forcing associations. Domain knowledge remains indispensable for such exercises. 
                     On trying out the classic tf-idf formula on Woolf’s The Waves, Stephen Ramsey (2011: 12) wrote: “Few readers of The Waves would fail to see some emergence of pattern in this list”. 
                     It should be added that, conversely, for someone who has not read the text “patterns” are highly unlikely to emerge. A modified form of tf-idf remains part of BERTopic and other topic modeling frameworks, 
                     and although the topic coherence as assessed by computable metrics arguably has improved, the need for domain knowledge for “the ‘lighting up’ of an aspect (das ‘Aufleuchten’ eines Aspekts)” remains. 
                 </p>
                 <p>Beyond seeing a coherent pattern in the word lists that represent topics, a second-order of sense making is relevant. “Meaningful” topics must be meaningful not only in themselves (i.e. coherent) but also relevant in the wider context of a research question. 
                     Do the topics make heuristic sense for a researcher in Buddhist studies? Are they insightful to the distant reader? In our case, do they actually distinguish the Indian-Chinese from the Chinese-Chinese texts or are they just different? 
                     Obviously, coherence here is a condition of meaningfulness. If the top-twenty words that represent a topic do not cohere, there is no topic to discuss in a wider context.                    
                </p> 
                 <p>Below, we will discuss the heuristic value of ten topics suggested by BERTopic. These are presented as ‘virtual paragraphs’ in Appendix A. 
                     What signals does a distant reading of our two corpora discern? Among the topics that align strongly with the Indian-Chinese corpus the least surprising ones 
                     are two that relate to the introduction of tantric, esoteric Buddhism to China: maṇḍala (A1) and mantra (A2). 
                     Maṇḍalas were used in Indian esoteric Buddhism in visualization practice, as part of rituals, and as an art form. 
                     These three aspects are related as sophisticated maṇḍala paintings are not only used in rituals, but also as models for meditators who learn to visualize them as part of their meditative practice. 
                     In India, the earliest Buddhist uses of maṇḍala images are attested for the 6th century, well within our time-frame. 
                     In China, a host of texts on how to use maṇḍalas in rituals were translated in the 8th century (e.g. in the Taishō edition (T): 
                     T0850, T0852a, T0852b, T0862, T0911, T0912, T0959, T1001, T1004, T1040, T1067, T1167, T1168B, T1184). 
                     Texts containing mantras or the longer dhāraṇī spells (e.g. T0402, T0899, T0901, T0902, T0903, T0905, T0907, T0918, T0933, T0944A, T0952, T0956, T0962, T0963, T0964, T0967, T0968) 
                     were already mentioned above as the reason why the Indian-Chinese corpus has twice as many texts but an overall lower character count than the Chinese-Chinese corpus. 
                     Neither poetry nor prose, mantra and dhāraṇī texts are a distinctive genre in themselves. That distinctiveness, not surprisingly, appears in the BERTopic output. 
                     Topic A2 illustrates a ‘mantra’ topic; the terms mantra and dhāraṇī echo through several other topics and indeed also appear together in A5. 
                     Maṇḍalas and mantras/dhāraṇīs are the visual and aural elements of esoteric ritual and meditation practice that was introduced to China in the 8th century (and from there to Japan in the early 9th century). 
                     This was the last great transmission of a distinct Buddhist tradition from India to China and topic modeling picks up a clear signal of this process. 
                     This proves at the very least that BERTopic works for our corpus, and can identify “typical” Indian-Chinese topics.
                 </p>
                 <p>But there are other, more subtle topics, such as A3, “Yama Heaven,” where things get more interesting to think with. 
                     Indian cosmography posits a number of heavens above (and hells below) our “middle earth” (madhyadeśa).  
                     In Chinese Buddhism between 500 and 800 CE, the writings of Tanluan, Daochuo and Shandao laid the foundation for the Pure Land school in which practitioners aim to be reborn in the heavenly paradise of Amitābha Buddha. 
                     Their writings in turn are based on Mahāyāna Indian sūtra texts translated before 500 CE. The “Yama Heaven” topic signals that in the Indian texts translated 500-800 CE the traditional view of “layered” heavens still persisted, 
                     and was not yet subsumed into the otherworldly Pure Land of the West that became so extraordinarily influential in East Asian Buddhism in the second millennium. 
                     This generates new avenues for research: The texts connected to the topic (e.g. T21n1340, T13n0416, T16n0675, T18n0892, T14n0455, T17n0721) 
                     can now be further explored e.g. to see how the heavenly realms in Mahāyāna Indian-Chinese texts differed from Amitābha’s Pure Land extolled in the Chinese-Chinese works in our period.
                 </p>
                 <p>Another Indian topic related to place is A4 “The palace 宮 of Śākyamuni.” Like early Buddhist iconography the topic is in a way aniconic: it describes the city where Prince Siddhartha, 
                     the Sage (muni) of the Śākya clan grew up, but names only his father, Śuddhodana, not Śākyamuni Buddha himself. 
                     That the monochromaticity of the topic converges to 0 suggests the Buddha legend features highly in Indian-Chinese texts. 
                     And indeed, the topic appears not only in a dedicated Buddha legend epic (T0190), but also in (Mūlasārvastivādin) Vinaya texts 
                     (T1442, T1443, T1450), and encyclopedic collections (T2121, T2122). The latter are compiled in China, but contain extensive quotations from translated Indian texts. 
                     The topic marks an influx of Indian texts which speak of the historical Buddha in a Chinese Mahāyāna environment, 
                     where many other texts propagate the existence of a multitude of Buddhas “innumerable as grains of sands in the Ganges.” 
                     It is a reminder that the proliferation of Buddhas did not overwrite interest in the story of Śākyamuni, the historical Buddha.
                 </p>
                 <p>Topic A5 reflects an ongoing concern with the “propagation of the Dharma”. That this topic lights up in Indian texts translated 500-800 CE is perhaps an indication of the pressures Buddhism faced in India. 
                     While in China the Sui (581–618), Tang (618–907), and Song (960–1279) dynasties were (mostly) a long golden summer for Buddhism, in India autumn had set in by the 7th century. 
                     The invasion and rule of North India by the Alchon Huns in the sixth and early fifth centuries (c. 460-530 CE) was adversarial to Buddhism, 
                     and Xuanzang who traveled to India some hundred years later (629-645 CE) found many pilgrimage sites in decline. 
                     Besides the last blossoming of Buddhist philosophy in the works of Dharamakīrti and Candrakīrti (7th century), 
                     which were not translated into Chinese, the development and transmission of tantric esoteric Buddhism was the last major doctrinal development in Indian Buddhism. 
                     As Indian Buddhism slowly lost ground to powerful Hindu movements (Vaishnavism, Shaivaism, Bhakti etc.) 
                     the need to teach and propagate the Buddhist teachings to laypeople remained a concern in Buddhist literature.
                 </p>
                 <p>Two highly monochromatic topics are associated with monastic life and its rules, one (A6) tending to the Indian-Chinese corpus, 
                     the other (B1) to the Chinese-Chinese corpus. Whereas A6 draws on the more technical discourse of Buddhist canon law, the Vinaya, and its history, 
                     B1 is about precepts, the rules that Buddhists ought to follow. Returning to the texts we realize that topic A6 is connected to the translations of Yijing 義淨 (635–713), 
                     who went to India and returned with the Mūlasarvastivāda Vinaya and commentaries. Although in the end the authoritative version of the monastic rules in East Asian Buddhism relied on a different Vinaya tradition, 
                     A6 can be said to reflect an ongoing exchange between India and China in terms of canon law. 
                     Although associated with translated Indian texts the topic does not so much reflect a new concern within Indian Buddhism, 
                     but rather an ongoing Chinese interest in the Vinaya. Indeed, later historiographers have asserted the development of a “Vinaya School” 
                     律宗 in seventh and eighth century China. In contrast, B1 is marked as a Chinese-Chinese topic by the peculiar term jieti 戒體, the “essence” of the precepts, 
                     which had great traction in the Chinese Vinaya tradition, but for which there is no ready Indian equivalent. Distant reading A6 against B1, 
                     one can discern an important polarity which reflects two competing Vinaya traditions in East Asia. 
                     Next to the mainstream Indian Vinaya, there were the “Bodhisattva” precepts of an Eastern Mahāyāna Vinaya that formed around the,
                    probably apocryphal (Funayama 1996), Fanwang jing 梵網經. Both traditions were present in China during and beyond our timeframe in China as well as in Japan and Korea, 
                    but are rarely addressed as distinct. The two topics thus do not merely reflect historical reality, but highlight a fundamental distinction in the development of Buddhist norms. 
                    In addition, the association of the Fanwang jing vocabulary of B1 with Chinese-Chinese texts supports the claim that this sūtra was 
                    indeed apocryphal and topically related to Chinese, not Indian concerns.
                 </p>
                 <p>Regarding topic B2, “Early Translators,” one might at first be tempted to think that any “translation” topic (there are other, less monochromatic ones), 
                     might be due to paratext, such as the translator byline that precedes most fascicles of an Indian-Chinese text, but obviously this topic is aligned with the Chinese-Chinese corpus. 
                     Moreover, the topic is specifically about “early” translators, active from the second to the fourth centuries, before our timeframe. 
                     It therefore cannot reflect paratext, but rather a specific Chinese concern with Buddhist historiography, a fundamental difference between Chinese and Indian Buddhism in any period. 
                     Chinese Buddhists made use of Chinese historiographic genres to create catalogs, biographies, annals and more. Compared with India, 
                     the historical record for Chinese Buddhism of the first millennium is extremely rich and detailed. 
                     Although this might be better understood as a general cultural trait, not specific to Buddhism, topic B2 points to the role Buddhist historiography played in the formation of a distinct Chinese Buddhism.
                 </p>
                 <p>Another “typical” Chinese topic is “Pillars of the state” (B3) which clusters the titles of Chinese government officials, none of which would appear in an Indian text, 
                     where the administrative hierarchy was much less sophisticated. Which texts are responsible for the topic? The first two texts associated with it are anthologies of apologetic writing (T2110, T2103) 
                     where Buddhists are in debate with officials, friendly or adversarial. Next is the encyclopedic Fayuan zhulin 法苑珠林 (T2122), which, like T2110, too was compiled by Falin 法琳 (571-639). 
                     Then there are scriptural catalogs (T2156, T2157) and biographies (T2051 (again Falin), T2060). Thus a closer look at the sources of the terms that represent Topic B3
                     encourages us to reevaluate Falin’s role in the sinicization of Buddhism (Jülch 2014).
                 </p>
                 <p>A final monochromatic topic associated with the Chinese-Chinese corpus is B4 which seems to built around collocations of sheng 乘 ‘vehicle’ (Sk. yāna). 
                     The topic is meaningful in that it reflects a major concern in medieval Chinese Buddhism, namely the categorization of Buddhism in different traditions. 
                     After c. 400 CE Chinese Buddhists increasingly understood themselves as followers of Mahāyāna, a distinctive new development within Indian Buddhism. 
                     While in India Mahāyāna Buddhism developed further into esoteric or tantric Buddhism (Vajrayāna, Tantrayāna), Chinese Buddhism continue to define itself as Mahāyāna, 
                     although, as we saw above, was exposed to esoteric Buddhist doctrines in our time frame. In the sheng 乘 imaginaire earlier Indian mainstream Buddhism was cast as the 
                     ‘smaller (or ‘lesser’) vehicle’ Hīnayāna, in contrast to the ‘larger (or ‘greater’) vehicle’, the Mahāyāna. Topic B4 reflects this coming to terms with different counts of yānas, 
                     such as one (the single transcendent truth applicable to all), two (Hīnayāna and Mahāyāna), or five yānas (the teachings of non-Buddhist humans, deities, śrāvaka Buddhists, pratyekabuddhas, and bodhisattva Buddhists). 
                     Although not used in academic narratives of Buddhist history, these distinctions are still of interest to modern Chinese Buddhists and BERTopic is able to identify this concern in the texts produced between 500 and 800 CE.
                 </p>      
             </div>
             <div>
                 <head>5. Conclusion</head>
                 <p>Topic modeling is a real upgrade on divination. Traditional divination systems set up a randomized procedure that selects symbolic tokens from a given set. It is then left to the diviner to interpret the tokens for the question at hand. 
                     Whereas with divination systems the number of elements in the set is usually fixed (78 cards in the Marseille Tarot, 64 Yijing hexagrams, 12 zodiac signs etc.), topic modeling builds its topics as it goes along and can return any number of them. 
                     However, like divination, it relies heavily on the interpreter to perceive the internal coherence as well as the overall meaning of a topic. The output of topic modeling is certainly grounded in more sophisticated probabilistic methods than the randomness of lot drawing, 
                     but its susceptibility to parametrization and the fact that different approaches yield somewhat different topics all lend the procedure a vagueness and ambivalence not unlike the hermeneutic play of divination. 
                     In the BERTopic pipeline a degree of randomness, specifically in the UMAP dimensionality reduction, means that even with the same data and parameters, the top twenty words in a topic may be slightly different. 
                     As Benjamin Schmidt (2012) warned at the beginning of the DH topic modeling boom, topics are neither necessarily coherent nor stable. There is no surefire method to separate a “true” topic from a “fata morgana topic”. 
                     And whether a topic is meaningful in the context of a research question can (for now) only be decided by humans. This being said, our experiments with different BERTopic workflows, give us confidence that the latent topics are stable at least within this framework. 
                     Moreover, as argued in Section 4, our experiments indeed turned up coherent and meaningful topics. These topics mark differences between the Indian-Chinese and the Chinese-Chinese corpus, in spite of BERTopic working on a low-resource idiom (Buddhist Chinese). 
                     The caveats are: First, there is no guarantee that we have identified all relevant topics – the rate of recall is unknown and perhaps unknowable. Second, there is no guarantee to precision either, as other approaches might turn up different, but equally plausible topics.
                 </p>
                 <p>To counter these limitations to a degree, we are working on a follow-up study in which we use machine translated versions of the texts instead of the Chinese originals. The approach might confirm or undermine the stability of topics. 
                     Furthermore automating the production of ‘virtual paragraphs” might lead to greater involvement by the wider community of scholars interested in the corpus. In the end, to us the glass is half full: 
                     Our modified BERTopic workflow yields coherent topics that meaningfully distinguish Indian-Chinese and Chinese-Chinese texts in our time frame. Some of the topics are more surprising than others, 
                     but even those that at first glance seem obvious, such as the “translation” topic (B2) associated with the Chinese-Chinese corpus, turned out to be more complex than expected. Since all topics can be traced back to texts, 
                     it is possible to follow up and study them further. Thus the distant reading via topic modeling can nudge our close reading and research in directions it would not have taken otherwise.
                 </p>
             </div>
             <div>
                 <head>Acknonwledgments</head>
                 <p>Research on this paper was funded by the “Anatomy of Agency” project (Nichols, PI; 1003) via the “Launching Experimental Philosophy of Religion” grant (Ian Church, PI; 61886), itself supported by the John Templeton Foundation. 
                     We give special thanks to Robert Buswell, Nicholaos Jones, Song Wang, and Michael Radich for comments and correspondence leading to the improvement of this project.
                 </p>
             </div>
        </body>
        <back>
            <listBibl>
                <bibl xml:id="bingenheimer2021" label="Bigenheimer 2021">Bigenheimer, M. (2021) <title rend="quotes">The historical social network of Chinese Buddhism</title>, <title rend="italic">Journal of Historical Network Review</title>, 5: 233-257. Available at: <ref target="https://doi.org/10.25517/jhnr.v5i1.119">https://doi.org/10.25517/jhnr.v5i1.119</ref>
                </bibl>
                <bibl xml:id="blei2012" label="Blei 2012">Blei, D. M. (2021) <title rend="quotes">Topic modeling and digital humanities</title>, <title rend="italic">Journal of Digital Humanities </title>, 2.1. Available at: <ref target="https://journalofdigitalhumanities.org/2-1/topic-modeling-and-digital-humanities-by-david-m-blei/">https://journalofdigitalhumanities.org/2-1/topic-modeling-and-digital-humanities-by-david-m-blei/</ref>.
                    (Accessed November 2023.)</bibl>
                <bibl xml:id="blei_etal2003" label="Blei et al2003">Blei, D. M, Ng, A. and Jordan, M. (2003) <title rend="quotes">Latent dirichlet allocation</title>, <title rend="italic">Journal of Machine Learning Research </title>, 3: 993-1022. 
                </bibl>
        <!-- come back to this one --><bibl xml:id="cbetav2021" label="CBETA v. 2021"> CBETA v. 2021: Chinese Buddhist Electronic Text Association (2021)
                </bibl>
                <bibl xml:id="chen_atal2023" label="Chen et al 2023">Chen, Y., Zhao Peng, S.H.K., and Chang, W. C. (2023) <title rend="quotes">What we can do and cannot do with topic modeling: A systematic eeview</title>, <title rend="italic">Communication Methods and Measures</title>, 17-2: 111-130.
                    </bibl>
                <bibl xml:id="du2019" label="Du 2019">Du, k. (2019) <title rend="quotes">A survey on lda topic modeling in digital humanities</title>in: Abstract for <title rend="italic">Digital Humanities </title> (Utrecht). Available at: <ref target="https://doi.org/10.34894/H9UYPI">https://doi.org/10.34894/H9UYPI</ref>. 
              </bibl>
                <bibl xml:id="fang2023" label="Fang 2023">Fang, Y. (2023) <title rend="quotes">Theme classification of the complete Song Ci from the perspective of the digital humanities</title>, <title rend="italic">Lecture Notes on Language and Literature</title>, 13-24. Available at: <ref target="https://clausiuspress.com/assets/default/article/2023/08/17/article_1692280542.pdf">https://clausiuspress.com/assets/default/article/2023/08/17/article_1692280542.pdf</ref>. 
                </bibl>
                <bibl xml:id="fu_etal2020" label="Fu et al 2020">Fu, Q., Yufan, Z., Jiaxin, G., Yushu, Z., and Xin, G. (2020) <title rend="quotes">Agreeing to disagree: Choosing among eight topic-modeling methods</title>, <title rend="italic">Big Data Research</title>. Available at: <ref target="https://doi.org/10.1016/j.bdr.2020.100173">https://doi.org/10.1016/j.bdr.2020.100173</ref>. 
                </bibl>
                <bibl xml:id="funayama1996" label="Funayama 1996">Funayama, T. <foreign xml:lang="ja">船山徹</foreign> (1996) <title rend="quotes" xml:lang="ja">Gikyō Bonmōkyō seiritsu no shomondai 疑経『梵網経』成立の諸問題</title>, <title rend="italic" xml:lang="ja">Bukkyō shigaku kenkyū 佛教史學研究</title>, 39-1: 54-78. 
                </bibl>
                <bibl xml:id="grootendorst2022" label="Grootendorst 2022">Grootendorst, M. (2022) <title rend="quotes">BERTopic: Neural topic modeling with a class-based TF-IDF procedure</title>. Available at: <ref target="https://arxiv.org/abs/2203.05794">https://arxiv.org/abs/2203.05794</ref>. (Accessed 11 March 2022). 
                </bibl>
                <bibl xml:id="jülch2014" label="Jülch 2014">Jülch, T. (2014) <title rend="italic" xml:lang="de">Bodhisattva der apologetik - die mission des buddhistischen Tang-Mönches Falin</title>. München: Herbert Utz Verlag.
                </bibl>
                <bibl xml:id="kherwa2019" label="Kherwa 2019">Kherwa, P. (2019) <title rend="quotes">Topic modeling: A comprehensive review</title>, <title rend="italic">ICST Transactions on Scalable Information Systems</title>, 7. Available at: <ref target="https://eudl.eu/doi/10.4108/eai.13-7-2018.159623">https://eudl.eu/doi/10.4108/eai.13-7-2018.159623</ref>. 
                </bibl>
                <bibl xml:id="kirfel1920" label="Kirfel 1920">Kirfek, W. (1920) <title rend="italic">Die Kosmographie der Inder nach den Quellen dargestellt</title>. <foreign xml:lang="de">Bonn und Leipzig</foreign>: K Schroader.   
                </bibl>
                <bibl xml:id="lin1949" label="Lin 1949">Lin, Li-kouang <foreign xml:lang="zh">林藜光</foreign> (1949). <title rend="italic" xml:lang="fr">L’aide-mémoire de la Vraie Loi (Saddharma-smrtyupasthâna-sùtra). Recherches sur un Sûtra développé du Petit Véhicule</title>. Paris: Adrien-Maisonneuve. 
                </bibl>
                <bibl xml:id="ma_etal2021" label="Ma et al 2021">Ma, P., Qing Zeng-Treitler, Nelson, Stuart J. (2021) <title rend="quotes">Use of two topic modeling methods to investigate covid vaccine hesitancy</title>, <title rend="italic">Proceedings 14th International Conference on ICT, Society and Human Beings (ICT 2021), the 18th International Conference Web Based Communities and Social Media (WBC 2021)</title>: 221-226. 
                </bibl>
                <bibl xml:id="mcinnes_etal2017" label="McInnes et al 2017">McInnes, L., Healy, J., and Astels S. (2017) <title rend="quotes">HDBSCAN: Hierarchical density based clustering</title>, <title rend="italic">Journal of Open Source Software </title>, vol. 2.11: 205. 
                </bibl>
                <bibl xml:id="mcinnes_etal2018" label="McInnes et al 2018">McInnes, L., Healy, J., and Melville, J. (2018) <title rend="italic">Umap: Uniform manifold approximation and projection for dimension reduction</title>. Available at: <ref target="https://arxiv.org/abs/1802.03426">https://arxiv.org/abs/1802.03426</ref>.  
                </bibl>
                <bibl xml:id="meeks_etal2021" label="Meeks et al 2021">Meeks, E. and Weingart, S.B. (2021) <title rend="quotes">The digital humanities contribution to topic modeling</title>, <title rend="italic">” Journal of Digital Humanities </title>, 2.1. Available at: <ref target="http://journalofdigitalhumanities.org/2-1/dh-contribution-to-topic-modeling">http://journalofdigitalhumanities.org/2-1/dh-contribution-to-topic-modeling</ref>. (Accessed November 2023).   
                </bibl>
                <bibl xml:id="nichols_etal2020" label="Nichols et al 2020">Nichols, R., Slingerland, E., Nielbo, K. L., Kirby, P., and Logan, C. (2020) <title rend="quotes">Supernatural agents and prosociality in historical China: Micro-modeling the cultural evolution of gods and morality in textual corpora</title>, <title rend="italic">Religion, Brain &amp; Behavior</title>, 1-19. Available at: <ref target="https://doi.org/10.1080/2153599X.2020.1742778">https://doi.org/10.1080/2153599X.2020.1742778</ref>.       
                </bibl>
                <bibl xml:id="ramsay2011" label="Ramsay 2011">Ramsay, S. (2011) <title rend="italic">Reading machines: Toward an algorithmic criticism</title>. Urbana: University of Illinois Press.                    
                </bibl>
                <bibl xml:id="rüdiger_etal2022" label="Rüdiger et al 2022">Rüdiger, M., Antons, D., Joshi, A.M., and Salge, T.O. (2022) <title rend="quotes">Topic modeling revisited: New evidence on algorithm performance and quality metrics</title>, <title rend="italic">PLoS ONE </title>, 17(4): e0266325. Available at: <ref target="https://doi.org/10.1371/journal.pone.0266325">https://doi.org/10.1371/journal.pone.0266325</ref>.    
                </bibl>
                <bibl xml:id="pewresearchcenter2023" label="Pew Research Center 2023">Pew Research Center (2023) <title rend="quotes">Measuring religion in China</title>. Available at: <ref target="https://www.pewresearch.org/religion/2023/08/30/measuring-religion-in-china/">https://www.pewresearch.org/religion/2023/08/30/measuring-religion-in-china/</ref>. (Accessed November 2023). 
                </bibl>
                <bibl xml:id="schmidt2012" label="Schmidt 2012"> Schmidt, B. (2012) <title rend="quotes">Words alone: Dismantling topic models in the humanities</title>, <title rend="italic">Journal of Digital Humanities </title>, 2.1. Available at: <ref target="http://journalofdigitalhumanities.org/2-1/words-alone-by-benjamin-m-schmidt">http://journalofdigitalhumanities.org/2-1/words-alone-by-benjamin-m-schmidt</ref>. 
                </bibl>
                <bibl xml:id="vayamsky_etal2020" label="Vayansky et al 2020">Vayansky, I. and Kumar, S.A.P. (2020) <title rend="quotes">A review of topic modeling methods</title>, <title rend="italic">Information Systems</title>, 94.  
                </bibl>
                <bibl xml:id="wang2020" label="Wang 2020">Wang, Y.D. (2020) <title rend="quotes">Word segmentation for classical chinese Buddhist literature</title>, <title rend="italic">Journal of the Japanese Association for Digital Humanities</title>, 5-2: 154-172. Available at: <ref target="https://doi.org/10.17928/jjadh.5.2_154">https://doi.org/10.17928/jjadh.5.2_154</ref>. 
                </bibl>
            </listBibl>
           
        </back>
    </text>
</TEI>
