<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <!-- Author should supply the title and personal information-->
                <title type="article">Using an Advanced Text Index Structure for Corpus Exploration
                    in Digital Humanities</title>
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Tobias <dhq:family>Englmeier</dhq:family></dhq:author_name>
                    <dhq:affiliation>CIS, Ludwig-Maximilians University, Munich,
                        Germany</dhq:affiliation>
                    <email>englmeier@cis.uni-muenchen.de</email>
                    <dhq:bio>
                        <p> Tobias Englmeier is a PhD candidate at the Centrum für Informations- und
                            Sprachverarbeitung (CIS) at the Ludwig Maximilians University of Munich.
                            His PhD project is centered around the topics of string matching and OCR
                            postcorrection. Additionally he has been involved in the conception and
                            implementation of numerous Digital Humanities projects coordinated by
                            the IT Gruppe Geisteswissenschaften (ITG) at the Ludwig Maximilians
                            University of Munich. </p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <dhq:author_name>Marco <dhq:family>Büchler</dhq:family></dhq:author_name>
                    <dhq:affiliation>Institute of Computer Science, University of Göttingen,
                        Göttingen, Germany</dhq:affiliation>
                    <email>mbuechler@etrap.eu</email>
                    <dhq:bio>
                        <p> Marco Büchler holds a Diploma in Computer Science. From 2006 to 2014 he
                            worked as a Research Associate in the Natural Language Processing Group
                            at Leipzig University. From April 2008 to March 2011 Marco served as the
                            technical Project Manager for the eAQUA project and continued to work in
                            that capacity for the following eTRACES project. In March 2013 he
                            received his PhD in eHumanities. Since May 2014 he leads a Digital
                            Humanities Research Group at the Göttingen Centre for Digital
                            Humanities. His research includes Natural Language Processing on Big
                            Humanities Data. Specifically, he works on Historical Text Reuse
                            Detection and its application in the business world. In addition to his
                            primary responsibilities, Marco manages the Medusa project (Big Scale
                            co-occurrence and NGram framework) as well as the TRACER machine for
                            detecting historical text reuse.</p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <dhq:author_name>Stefan <dhq:family>Gerdjikov</dhq:family></dhq:author_name>
                    <dhq:affiliation>FMI, University of Sofia "St. Kliment Ohridski", Sofia,
                        Bulgaria</dhq:affiliation>
                    <email>st_gerdjikov@abv.bg</email>
                    <dhq:bio>
                        <p> Stefan Gerdjikov is an Assistent Professor at the Faculty for
                            Informatics and Mathematics in the University of Sofia. He holds a PhD
                            degree in Mathematics from the University of Sofia. His prime research
                            area is Natural Language Processing where he studies approximate search
                            techniques and index structures for text mining.</p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <dhq:author_name>Klaus U. <dhq:family>Schulz</dhq:family></dhq:author_name>
                    <dhq:affiliation>CIS, Ludwig-Maximilians University, Munich,
                        Germany</dhq:affiliation>
                    <email>schulz@cis.uni-muenchen.de</email>
                    <dhq:bio>
                        <p> Klaus U. Schulz is Professor in Computational Linguitics and since 1992
                            the technical director of the Centrum für Informations- und
                            Sprachverarbeitung (CIS) at the Ludwig Maximilians University of Munich.
                            The work of Professor Schulz concentrates on Semantic Search,
                            Construction of Ontologies and Taxonomies, Digital Libraries, Language
                            Technology for Optical Character Recognition and Document Analysis and
                            Finite-State Technology. </p>
                    </dhq:bio>
                </dhq:authorInfo>
            </titleStmt>
            <publicationStmt>
                <!-- This information will be completed at publication -->
                <publisher>Alliance of Digital Humanities Organizations</publisher>
                <publisher>Association for Computers and the Humanities</publisher>
                <idno type="DHQarticle-id">000526</idno>
                <idno type="volume">015</idno>
                <idno type="issue">1</idno>
                <date when="2021-05-21">21 May 2021</date>
                <dhq:articleType>article</dhq:articleType>
                <availability status="CC-BY-ND">
                    <cc:License rdf:about="http://creativecommons.org/licenses/by-nc-nd/2.5/"/>
                </availability>
            </publicationStmt>

            <sourceDesc>
                <p>This is the source</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <classDecl>
                <taxonomy xml:id="dhq_keywords">
                    <bibl>DHQ classification scheme; full list available at <ref
                            target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
                            >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
                </taxonomy>
                <taxonomy xml:id="authorial_keywords">
                    <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
                </taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en"/>
            </langUsage>
            <textClass>
                <keywords scheme="#dhq_keywords">
                    <!-- Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors -->
                    <list type="simple">
                        <item/>
                    </list>
                </keywords>
                <keywords scheme="#authorial_keywords">
                    <list type="simple">
                        <item>corpus exploration</item>
                        <item>metadata</item>
                        <item>phrase extraction</item>
                        <item>text alignment</item>
                        <item>SCDAWG</item>
                        <item>index structures</item>
                    </list>
                </keywords>
            </textClass>
        </profileDesc>
        <revisionDesc>
            <!-- Each change should include @who and @when as well as a brief note on what was done. -->
        	<change>The version history for this file can be found on <ref target=
        		"https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/master/articles/000526/000526.xml">GitHub
        	</ref></change>
        </revisionDesc>
    </teiHeader>

    <text>
        <front>
            <dhq:abstract>
                <!-- Include a brief abstract of the article -->
                <p> With suitable index structures many corpus exploration tasks can be solved in an
                    efficient way without rescanning the text repository in an online manner. In
                    this paper we show that symmetric compacted directed acyclic word graphs
                    (SCDAWGs) - a refinement of suffix trees - offer an ideal basis for corpus
                    exploration, helping to answer many of the questions raised in DH research in an
                    elegant way. From a simplified point of view, the advantages of SCDAWGs rely on
                    two properties. First, needing linear computation time, the index offers a joint
                    view on the similarities (in terms of common substrings) and differences between
                    all text. Second, structural regularities of the index help to mine interesting
                    portions of texts (such as phrases and concept names) and their relationship in
                    a language independent way without using prior linguistic knowledge. As a
                    demonstration of the power of these principles we look at text alignment, text
                    reuse in distinct texts or between distinct authors, automated detection of
                    concepts, temporal distribution of phrases in diachronic corpora, and related
                    problems. </p>
            </dhq:abstract>
            <dhq:teaser>
                <!-- Include a brief teaser, no more than a phrase or a single sentence -->
                <p>A study investigating the application of the SCDAWG index structure for large
                    scale corpus exploration</p>
            </dhq:teaser>
        </front>
        <body>
            <div xml:id="section01">
                <head>Introduction</head>

                <p>A text/corpus index is a kind of table that, given a string <formula
                        notation="tex" rend="inline">\(w\)</formula>, stores the positions of all
                    occurrences of <formula notation="tex" rend="inline">\(w\)</formula> in the
                    given text/corpus. The computation of the index is a preprocessing step to be
                    applied only once. Corpus index structures considerably simplify corpus analysis
                    since they help to avoid rescanning the complete texts for each task. The index
                    helps to directly answer many interesting questions, hence index based methods
                    in general are much faster and more elegant. In this paper we look at an
                    advanced corpus index structure and explain its potential use in Digital
                    Humanities. This index, called symmetric compacted directed acyclid word graph
                    (SCDAWG), is used to represent a collection of texts, each text is considered as
                    a flat sequence of symbols <ptr target="#inenaga2005"/>. SCDAWGs can be
                    considered as a refinement of suffix trees <ptr target="#weiner1973"/>, <ptr
                        target="#mccreight1976"/>, <ptr target="#ukkonen95"/>, <ptr
                        target="#gusfield1997"/>. The SCDAWG for a given text collection, as the
                    suffix tree, can be computed in time and space linear in the size of the corpus.
                    As a first advantage, the SCDAWG of a corpus is much smaller than the
                    corresponding suffix tree. Even more importantly, SCDAWGs have two special
                    features that make them very attractive for various corpus exploration tasks. </p>
                <p><label>Finding co-occurrences.</label> Using the SCDAWG it is simple to find all
                    co-occurrences of the same portions of text in two, several, or all texts of the
                    corpus. The index enables a joint search in all texts, there is no need for
                    comparing all pairs of texts individually. This joint search, which leads to all
                    co-occurrences, can be realized using a single scan of the index. The importance
                    of this feature in our context should be obvious: research in Digital Humanities
                    is often concentrated on the problem of finding phrases and text portions that
                    occur in distinct (two, several, or all) texts of a collection. For all these
                    problems the use of SCDAWGs offers an elegant solution. As a demonstration we
                    look at alignment of two or several texts, detection of text reuses in distinct
                    texts, and detection of text reuses between distinct authors. </p>
                <p><label>Mining interesting concepts and their relationship.</label> The nodes of
                    the SCDAWG represent portions of text (sequences of symbols, infixes). In
                    general, the number of all distinct infixes of a corpus <formula notation="tex"
                        rend="inline">\(C\)</formula> is quadratic in size <formula notation="tex"
                        rend="inline">\(|C|\)</formula> of the corpus. In contrast, the number of
                    nodes of the SCDAWG is always linear in <formula notation="tex" rend="inline"
                        >\(|C|\)</formula>. Yet, in a sense to be explained below, it contains all
                    infixes that are interesting from a linguistic point of view.<note>As a matter
                        of fact, there is no formal definition of text units (sequences of symbols)
                        that are linguistically relevant.</note> For example, names, concepts and
                    phrases etc. in general correspond to nodes of the SCDAWG. Compared to suffix
                    trees, SCDAWGs yield a much smaller set of nodes/infixes with this property.
                    Using structural regularities of the index, the set of all nodes can be even
                    further filtered to approximate the subset of linguistically relevant infixes.
                    Also hierarchical relationships and dependencies between these concepts and
                    phrases can be detected. From the perspective of Digital Humanities, these
                    mining techniques are relevant since they are completely language independent
                    and do not use any kind of prior linguistic knowledge. They point to interesting
                    concepts and bricks of text, the index helps to study their use, structure and
                    relationship. </p>
                <p>In this paper we first formally introduce SCDAWGs in <ref target="#section02"
                        >Section 2</ref>. We compare three related index structures, SCDAWGs, suffix
                    trees and DAWGs (directed acyclic graphs <ptr target="#blumer1987"/>), compare
                    the sizes of these index structures and explain the advantages of the SCDAWG for
                    corpus exploration tasks as those mentioned above. In <ref target="#section03">
                        Section 3</ref> we give a brief overview of the corpora used for the
                    experiments described in the paper. In <ref target="#section04"> Section 4</ref>
                    we show how SCDAWGs can be utilized to solve tasks in the fields of text
                    alignment and text reuse detection <ptr target="#büchler2012"/>. For these
                    problems, the full set of nodes of the SCDAWG is used. In <ref
                        target="#section05"> Section 5</ref> we sketch the afore-mentioned
                    filtering of nodes/infixes based on structural regularities (in <ref target="#gerdjikov2016">Gerdjikov and Schulz [2016]</ref> the filtering method is described in full detail).
                    Using the example corpora we illustrate how concepts and their relationships can
                    be mined in a language independent way. In <ref target="#section06"> Section
                        6</ref> we look at extensions of the SCDAWG index, adding metadata
                    information (e.g., on authors, temporal periods) from the texts. Examples from
                    our corpora show how to detect text reuses, e.g., between distinct authors and
                    to reveal the temporal flow of phrases across texts/authors. Before we come to a
                    short conclusion, <ref target="#section07">Section 7</ref> provides loose ends
                    for future research, indicating how SCDAWGs might help to treat diachronic
                    language variation and various text classification tasks. </p>
            </div>

            <div xml:id="section02">
                <head>SCDAWGs as a corpus index structure</head>
                <p>In the introduction we explained the general benefits that can be obtained for
                    corpus analysis when using an index structure. If we are only interested in the
                    distribution and occurrences of single words, a simple index structure is
                    sufficient that represents the corpus as a <q>bag of words</q>. Usually an
                        <q>inverted file</q> then stores for each word <formula notation="tex"
                        rend="inline">\(w\)</formula> occurring in the corpus the texts and
                    positions where <formula notation="tex" rend="inline">\(w\)</formula> occurs.
                    However, corpus analysis in Digital Humanities and other fields is often
                    focussed on other pieces of text: re-used portions of text, names,
                    terminological and other multi-word expressions, phrases that express semantic
                    relationships, syllables, morphems, to name a few. In this situation advanced
                    index structures are preferable that give direct access to the occurrences of
                    arbitrary infixes<note>A string <formula notation="tex" rend="inline"
                            >\(v\)</formula> is an infix of a text <formula notation="tex"
                            rend="inline">\(t\)</formula> if <formula notation="tex" rend="inline"
                            >\(t\)</formula> can be represented as a concatenation of the form
                            <formula notation="tex" rend="inline">\(t=uvw\)</formula>. A string is
                        an infix of a corpus if it is an infix of a text of the corpus.</note>. This
                    explains why corpus analysis tools in Digital Humanities or Computational
                    Biology are often based on the latter, more powerful type of index structures.
                    Among the latter type of index structure, directed acyclic word graphs (DAWGs)
                    and suffix trees have often been used for research, but refinements have not
                    received proper attention. In this paper we describe compacted directed acyclic
                    word graphs (CDAWGs) and a symmetric variant (SCDAWGs) and argue that these
                    index structures are preferable for many corpus analysis tasks.</p>
                <p>The common ideas behind DAWGS, suffix trees, CDAWGs and SCDAWGs are summarized in
                    the following way. <list>
                        <item>Each index represents a graph, nodes representing specific infixes of
                            the corpus. </item>
                        <item>Each infix of the corpus is represented at most once in the index. </item>
                        <item>The total size of the index structure is linear in the size of the
                            corpus. </item>
                        <item>Given any string <formula notation="tex" rend="inline">\(v\)</formula>
                            we may use the index to decide in time <formula notation="tex"
                                rend="inline">\(O(\vert v\vert)\)</formula> if <formula
                                notation="tex" rend="inline">\(v\)</formula> is an infix of the
                                corpus.<note><formula notation="tex" rend="inline">\(\vert
                                v\vert\)</formula> denotes the length of the string <formula
                                notation="tex" rend="inline">\(v\)</formula>.</note> It is also possible
                            to use the index <q>as a guide</q> for finding all texts and positions
                            where <formula notation="tex" rend="inline">\(v\)</formula> occurs.
                        </item>
                    </list> The nodes of a DAWG represent the infixes <formula notation="tex"
                        rend="inline">\(v\)</formula> that are <q>left-closed</q> in the sense that
                    there does <emph>not</emph> exist a unique symbol <formula notation="tex" rend="inline"
                        >\(\sigma\)</formula> directly in front of each occurrence of <formula
                        notation="tex" rend="inline">\(v\)</formula> in the corpus. The nodes of a
                    suffix tree represent the infixes <formula notation="tex" rend="inline"
                        >\(v\)</formula> that are <q>right-closed</q> in the sense that there does
                    <emph>not</emph> exist a unique symbol <formula notation="tex" rend="inline"
                        >\(\sigma\)</formula> directly after each occurrence of <formula
                        notation="tex" rend="inline">\(v\)</formula> in the corpus. The CDAWG and
                    the SCDAWG for a corpus have the same set of nodes representing the infixes
                        <formula notation="tex" rend="inline">\(v\)</formula> that are <q>left- and
                        right-closed</q> at the same time. Edges of a suffix tree, DAWG, or CDAWG
                    represent extensions of infixes in reading order (i.e., to the right). SCDAWGs
                    have two type of edges, respectively representing right extensions in standard
                    reading order and left-extensions in left-to-right order. <label> Example
                        2.1</label> As an example, consider the corpus with the two toy <q>texts</q>:
                    <list type="unordered">
                        <item><code>op 1 in A</code></item>
                        <item>
                            <code>op 2 in B</code></item>
                    </list>
                    <figure xml:id="figure01">
                        <head>DAWG, suffix tree, and symmetric compact DAWG (SCDAWG) for the corpus
                            with two toy texts <code>op 1 in A</code> and <code>op 2 in B</code>.</head>
                        <graphic url="resources/images/figure01.png"/>
                    </figure> Infixes <code>n</code> and <code
                            >in</code> are <emph>not</emph> left-closed since we find the symbol
                            <code>i</code> directly in front of each occurrence
                    of <code>n</code> and the blank directly in front of each
                    occurence of <code>in</code> in the corpus. In contrast,
                    infixes <code>in</code> , <code>i</code> and <code>op 1</code> are left-closed. Each
                    prefix of each text is left-closed, the corpus contains <formula notation="tex"
                        rend="inline">\(20\)</formula> left-closed infixes, its DAWG has <formula
                        notation="tex" rend="inline">\(20\)</formula> nodes (<ref target="#figure01"
                        >cf. Figure 1</ref>). Infixes <code>o</code> and <code>op</code> are <emph>not</emph> right-closed since we
                    find the symbol <code>p</code> directly after each
                    occurrence of <code>o</code> and the blank directly after
                    each occurence of <code>op</code> in the corpus. In
                    contrast, infixes <code>op</code> and <code>p</code>, <code>1 in A</code> are
                    right-closed. Each suffix of each text is right-closed, the corpus contains
                        <formula notation="tex" rend="inline">\(25\)</formula> right-closed infixes,
                    accordingly its suffix tree has <formula notation="tex" rend="inline"
                        >\(25\)</formula> nodes (<ref target="#figure01">cf. Figure 1</ref>). The
                    only infixes that are left- and right-closed are the empty string, the blank,
                    the strings <code>op</code> and <code>in
                        </code> and the two texts. Hence the (S)CDAWG only has <formula
                        notation="tex" rend="inline">\(6\)</formula> nodes (<ref target="#figure01"
                        >cf. Figure 1</ref>). Lines/transitions in the figures represent extensions
                    of nodes/infixes. In the DAWG in <ref target="#figure01">Figure 1</ref>, node
                            <code>in</code> has two extensions with <formula
                        notation="tex" rend="inline">\(A\)</formula> and <formula notation="tex"
                        rend="inline">\(B\)</formula>, respectively leading to the left-closed
                    infixes <code>op 1 in A</code> and <code
                            >op 2 in B</code>. In the suffix tree, node <code>op
                        </code> has two extensions with symbols <formula notation="tex"
                        rend="inline">\(1\)</formula> and <formula notation="tex" rend="inline"
                        >\(2\)</formula>, respectively leading to the right-closed infixes <code>op 1 in A</code> and <code>op 2 in
                            B</code>. In the SCDAWG in <ref target="#figure01">Figure 1</ref>,
                    black (blue) links represent right (left) extensions. Labels of left extensions
                    are written in right-to-left order. </p>

                <p> As we mentioned above, each index can be used to check if a string <formula
                        notation="tex" rend="inline">\(v\)</formula> represents an infix of the
                    corpus in time linear in <formula notation="tex" rend="inline">\(\vert
                        v\vert\)</formula>. We sketch the procedure for the SCDAWG in <ref
                        target="#figure01"> Figure 1</ref>. Assume we want to check if <code>p 1</code> is an infix. Starting from the top node
                    (empty string) we look for an extension to the right where the label starts with
                    the letter <code>p</code>. We find an extension with label
                            <code>p</code> leading to <code
                            >op</code>. We continue to look for a right extension of the new node
                    starting with <code>1</code>. We find the extension with
                    label <code>1 in A</code> leading to <code
                            >op 1 in A</code>. Hence <code>p 1</code> is an
                    infix.</p>


                <div>
                    <head>Advantages of the SCDAWG index</head>
                    <p>The strength of SCDAWGs compared to DAWGs and suffix trees relies on three
                        features. <list type="ordered">
                            <item>
                                <label>Number of nodes.</label> In general, the number of nodes in
                                the (S)CDAWG of a corpus is much smaller than the number of nodes in
                                a suffix tree or DAWG. This is seen in <ref target="#figure01"
                                    >Figure 1</ref>. A more informative picture is found in <ref
                                    target="#table01">Table 1</ref> where we compare the size of
                                these index structures for a small collection of corpora of distinct
                                sizes. For the sake of completeness, the table also includes data
                                for suffix tries, a simplified version of suffix trees where each
                                suffix represents a node.</item>
                            <item>
                                <label>Naturalness of nodes.</label> Most of the infixes
                                representing the nodes of a (S)CDAWG are very natural from an
                                intuitive point of view<note>An exception are very small infixes,
                                    which often also are left- and right-closed in the above
                                    sense.</note>: imagine we index the German version of Goethe's
                                Faust. Among the nodes of the suffix tree, we will find right-closed
                                infixes such as <code>ephisto</code>, <code>phisto</code>, <code
                                        >retchen</code>, and <code
                                    >etchen</code>. In the DAWG we find left-closed infixes such
                                as <code>Mephist</code>, <code
                                        >Mephis</code>, <code> Gretche</code>
                                and <code> Gretch</code>. In the (S)CDAWG we
                                only have the two-sided closures <code
                                        >Mephisto</code> and <code
                                    >Gretchen</code>. The example indicates that two-sided closure
                                is a very natural property when looking for <q>interesting</q> and
                                    <q>meaningful</q> infixes of a corpus.</item>
                            <item>
                                <label>Node Extension Property.</label> Among the infixes that
                                represent the nodes of the index (suffix tree, DAWG, or (S)CDAWG) in
                                general there are many inclusion relations where one infix <formula
                                    notation="tex" rend="inline">\(v\)</formula> is a substring of
                                another one <formula notation="tex" rend="inline">\(w\)</formula>.
                                In a suffix tree, DAWG, or CDAWG extension steps departing from node
                                    <formula notation="tex" rend="inline">\(v\)</formula> in many
                                cases do not lead to node <formula notation="tex" rend="inline"
                                    >\(w\)</formula>. For example, in the suffix tree in <ref
                                    target="#figure01">Figure 1</ref> we cannot reach <code>op 1 in A</code> from <code>in</code> following the transitions. In
                                contrast, the two-directional edge structure of SCDAWGs completely
                                covers infix containment in the sense that <emph>whenever node
                                        <formula notation="tex" rend="inline">\(v\)</formula> is a
                                    substring of <formula notation="tex" rend="inline"
                                        >\(w\)</formula> there exists a chain of left and right
                                    extensions leading from <formula notation="tex" rend="inline"
                                        >\(v\)</formula> to <formula notation="tex" rend="inline"
                                        >\(w\)</formula></emph>. In other words, starting from a
                                node <formula notation="tex" rend="inline">\(v\)</formula> and
                                traversing the index we find each context containing <formula
                                    notation="tex" rend="inline">\(v\)</formula>. For the sake of
                                reference, this property will be called the <q>Node Extension
                                    Property</q>. It can be used, for example, to find in a very
                                elegant way all texts where an infix <formula notation="tex"
                                    rend="inline">\(v\)</formula> occurs: starting from the node
                                that represents (the two-sided closure of) <formula notation="tex"
                                    rend="inline">\(v\)</formula>, compute all maximal chains of
                                left extensions followed by all maximal chains of right extensions.
                                The nodes reached at the end represent the texts in which <formula
                                    notation="tex" rend="inline">\(v\)</formula> occurs. For
                                example, in <ref target="#figure01">Figure 1</ref> starting from
                                        <code>op</code> or <code>in</code> we reach the nodes representing
                                the two input texts.</item>
                        </list>
                        <table xml:id="table01">
                            <head>Comparing the size of distinct index structures for four input
                                texts.</head>
                            <row role="label">
                                <cell/>
                                <cell>Suffix Trie</cell>
                                <cell>Suffix Tree</cell>
                                <cell>DAWG</cell>
                                <cell>CDAWG</cell>
                                <cell>SCDAWG</cell>
                            </row>

                            <row role="data">
                                <cell/>
                                <cell cols="5"><code>abcbc<formula notation="tex"
                                            rend="inline">\(abcab\)</formula></code>: 12 Bytes; 12
                                    symbols</cell>
                            </row>
                            <row role="data">
                                <cell> Nodes </cell>
                                <cell> 66 </cell>
                                <cell> 17 </cell>
                                <cell> 16 </cell>
                                <cell> 6 </cell>
                                <cell> 6 </cell>
                            </row>
                            <row role="data">
                                <cell> Edges </cell>
                                <cell> 65 </cell>
                                <cell> 16 </cell>
                                <cell> 23 </cell>
                                <cell> 13 </cell>
                                <cell> 21 </cell>
                            </row>
                            <row role="data">
                                <cell/>
                                <cell cols="5"><code>OCR page</code>: 7 KB; 6.945
                                    symbols</cell>
                            </row>
                            <row role="data">
                                <cell> Nodes </cell>
                                <cell> 21.418.626 </cell>
                                <cell> 7.355 </cell>
                                <cell> 11.995 </cell>
                                <cell> 1.163 </cell>
                                <cell> 1.163 </cell>
                            </row>
                            <row role="data">
                                <cell> Edges </cell>
                                <cell> 21.418.625 </cell>
                                <cell> 7.354 </cell>
                                <cell> 14.915 </cell>
                                <cell> 4.083 </cell>
                                <cell> 8.094 </cell>
                            </row>
                            <row role="data">
                                <cell/>
                                <cell cols="5"><code>Excerpt EU-Corpus</code>: 106 KB;
                                    ca. 106.000 symbols</cell>
                            </row>
                            <row role="data">
                                <cell> Nodes </cell>
                                <cell> - </cell>
                                <cell> 161.001 </cell>
                                <cell> 165.962 </cell>
                                <cell> 25.273 </cell>
                                <cell> 25.273 </cell>
                            </row>
                            <row role="data">
                                <cell> Edges </cell>
                                <cell> - </cell>
                                <cell> 161.000 </cell>
                                <cell> 227.515 </cell>
                                <cell> 86.826 </cell>
                                <cell> 170.358 </cell>
                            </row>
                            <row role="data">
                                <cell/>
                                <cell cols="5"><code>Small Corpus</code>: 1.2 MB; ca.
                                    1.250.000 symbols</cell>
                            </row>
                            <row role="data">
                                <cell> Nodes </cell>
                                <cell> - </cell>
                                <cell> 1.921.704 </cell>
                                <cell> 1.922.811 </cell>
                                <cell> 366.070 </cell>
                                <cell> 366.070 </cell>
                            </row>
                            <row role="data">
                                <cell> Edges </cell>
                                <cell> - </cell>
                                <cell> 1.921.703 </cell>
                                <cell> 2.730.597 </cell>
                                <cell> 1.173.856 </cell>
                                <cell> 2.355.669 </cell>
                            </row>

                        </table>
                        <label>Node-documents function.</label> Using the Node Extension Property in
                        one scan of the SCDAWG we may compute and store a function <formula
                            notation="tex" rend="inline">\(T\)</formula> that assigns to each node
                            <formula notation="tex" rend="inline">\(\mu\)</formula> (represented as
                        a number) the set of texts where <formula notation="tex" rend="inline"
                            >\(\mu\)</formula> occurs as an infix <ptr target="#blumer1987"/>.
                            <formula notation="tex" rend="inline">\(T\)</formula> is called the
                            <emph>node-documents function</emph>. Let us assume that each text comes
                        with a number. We define a procedure FindTexts, the input is a node number
                            <formula notation="tex" rend="inline">\(\mu\)</formula>, the output is a
                        set of text numbers. The procedure is called in the form FindTexts(root). As
                        a result, the function <formula notation="tex" rend="inline">\(T\)</formula>
                        is computed. 
                        
<eg lang="code-general">
Procedure FindTexts(<formula notation="tex" rend="inline">\(\mu\)</formula>) 
if <formula notation="tex" rend="inline">\(T(\mu)\)</formula> is already defined, then
    output <formula notation="tex" rend="inline">\(T(\mu)\)</formula>;
else if <formula notation="tex" rend="inline">\(\mu\)</formula> is a leaf (text), then
    let <formula notation="tex" rend="inline">\(n\)</formula> be the number of the text;
    define <formula notation="tex" rend="inline">\(T(\mu) := \{n\}\)</formula>;
    output <formula notation="tex" rend="inline">\(\{n\}\)</formula>;
otherwise
    let <formula notation="tex" rend="inline">\(\nu_1,\ldots,\nu_k\)</formula> be the (left or right) immediate successors of <formula notation="tex" rend="inline"
                                    >\(\mu\)</formula>.
    call FindTexts(<formula notation="tex" rend="inline">\(\nu_1\)</formula>), ...., FindTexts(<formula notation="tex" rend="inline">\(\nu_k\)</formula>);
    define <formula notation="tex" rend="inline">\(T(\mu) :=\bigcup_{i=1,\ldots, k} T(\nu_i);\)</formula>
    output <formula notation="tex"
                                    rend="inline">\(T(\mu)\)</formula>;
                        </eg> 
                        
                        The procedure first visits all successor nodes of the input node
                            <formula notation="tex" rend="inline">\(\mu\)</formula> and then assigns
                        the union of the sets of text numbers of the direct successors to <formula
                            notation="tex" rend="inline">\(\mu\)</formula>. It is simple to see that
                        each link of the index is used only once. Hence, if the number of all
                        distinct texts is treated as a constant, the procedure is linear in the size
                        of the index. <figure xml:id="figure02">
                            <head>A text <formula notation="tex" rend="inline">\(A\)</formula>
                                leading to a value <formula notation="tex" rend="inline"
                                    >\(r=130,000\)</formula> for the LIS problem if compared with a
                                similar parallel text <formula notation="tex" rend="inline"
                                    >\(B\)</formula>.</head>
                            <graphic url="resources/images/figure02.png"/>
                        </figure>
                    </p>

                </div>
            </div>
            <div xml:id="section03">
                <head>Corpora used for experiments</head>
                <p>For the experiments we selected corpora of different periods, languages, and
                    genres. Languages covered are Latin, English, German, French and Italian.
                    Domains vary from political texts to poetry, lyrics and literature. Metadata
                    include author, temporal data, and others.</p>
                <p><label>Poems Corpus.</label> The Poems Corpus consists of roughly 40k poems which
                    had been compiled from TEI – XML annotated documents from the TextGrid
                    Repository1. It contains poems written by German poets from about the time when
                    printing was invented to the beginning of the 20th century. Amongst these
                    authors are well known names like Johann Wolfgang v. Goethe, Friedrich Schiller,
                    Joseph v. Eichendorff, or Georg Trakl. All poems are written in German language.
                    In addition to the author each poem is furnished with the volume in which the
                    poem was published as well as dates referring to the timespan in which the
                    volume had been created. If this is not known the lifespan of the author is used
                    for the dates.</p>
                <p><label>Lyrics Corpus.</label> The Lyrics Corpus contains about 15k of popular
                    lyrics from songs, which had been present in the single charts of the
                    German-speaking world, reaching from the mid nineteen fifties to nowadays. This
                    corpus had been created by means of webcrawling. Aside from the interpreter it
                    stores the year, in which the song had been in the charts, the chart position
                    and whether the chart position had been a top 10 position, as well as the
                    language, in which the song was performed, as its metadata. The language had
                    been assigned automatically via n-gram based language classification. Since the
                    manner of appearance of the considered single charts has changed over time,
                    songs of the 80s and 90s are prevailing.</p>
                <p><label>Parallel OCR Corpus.</label> A smaller corpus of historic books, which
                    also had been digitized by means of OCR. All documents in this collection had
                    been created by two different OCR engines, leading to a parallel corpus of the
                    same content. The corpus was only used in the alignments, and there no metadata
                    had been considered.</p>
                <p><label>Wittgenstein Corpus.</label> The Wittgenstein Corpus consists of 3,871
                    original remarks of the German philosopher Ludwig Wittgenstein. Although the
                    general language is German, the corpus also contains a few remarks in
                    English.</p>
                <p><label>Medline Corpus.</label> The Medline Corpus is a collection of about 15
                    Million medical abstracts in English. Each abstract consists of about 10
                    sentences. We considered two subsets of this corpus. They were obtained by
                    randomly selecting 0.5% and 10%, respectively, of the abstracts and gathering
                    all the sentences in the resulting abstracts. The 0.5%-Medline Corpus consists
                    of 800 K sentences, whereas the 10%-Medline Corpus consists of about 15 M
                    sentences.</p>
            </div>

            <div xml:id="section04">
                <head>Using the index for alignment and text reuse</head>
                <p> In this section we use the node-documents function defined in <ref
                        target="#section02">Section 2</ref> to find large strings that co-occur in
                    several texts of the collection. Such strings point to some form of text
                    parallelism/reuse. Two applications are considered. In the first subsection we
                    show how to efficiently align two or more parallel texts in a linear manner. In
                    the second subsection we show how to explore large collections, looking at
                    maximal strings that co-occur in several texts of the corpus</p>
                <div>
                    <head>Index-based text alignment</head>
                    <p>In our context, to <q>align</q> two strings means to find a common linear
                        representation where <q>common parts</q> of the two strings are shown,
                        defining a linear sceleton, and where <q>deviations</q> or regions where the
                        two strings do not agree are associated with the <q>holes</q> of the
                        sceleton. The classical method for this task is the Needleman-Wunsch
                        Algorithm <ptr target="#needleman1970"/>: The input are two texts <formula
                            notation="tex" rend="inline">\(A\)</formula> and <formula notation="tex"
                            rend="inline">\(B\)</formula> of length <formula notation="tex"
                            rend="inline">\(m=|A|\)</formula>, <formula notation="tex" rend="inline"
                            >\(n=|B|\)</formula>. The algorithm finds an optimal alignment, given a
                        scoring function. Using dynamic programming it fills the cells of a <formula
                            notation="tex" rend="inline">\(|A|\times |B|\)</formula> matrix, cells
                        come with <q>backward pointers</q>. The backward pointers are then used to
                        find an optimal alignment. The complexity is <formula notation="tex"
                            rend="inline">\(O(mn)\)</formula>, which is problematic for large texts.
                        E.g., comparing two texts with <formula notation="tex" rend="inline"
                            >\(10^6\)</formula> symbols each, we need several terrabytes to store
                        the full matrix. For a better solution we look at a strategy to translate
                        the problem</p>
                    <p><label>Finding longest common subsequences and longest increasing
                            subsequences.</label> Such a translation can be found in the longest
                        common subsequence or the longest increasing subsequence problem: Assume the
                        scoring function for an alignment assigns value 1 to each pair of matching
                        symbols and value 0 to each disagreement (here: insertion, deletion, or
                        substitution). Then the matching symbols of the alignment are given by the
                        longest common subsequence (LCS) of the two strings. A subsequence of a
                        string <formula notation="tex" rend="inline">\(A= a_1\ldots a_m\)</formula>
                        is any string of the form <formula notation="tex" rend="inline">\(A=
                            a_{i_1}\ldots a_{j_k}\)</formula> where <formula notation="tex"
                            rend="inline">\(k \leq m\)</formula> and <formula notation="tex"
                            rend="inline">\(i_1 &lt; \ldots &lt; i_k\)</formula>. For example,
                            <q>bdf</q> is a subsequence of <q>abcdef</q>. </p>
                    <p>This means that for a particular and natural scoring function, finding the
                        LCS of two strings <formula notation="tex" rend="inline">\(A\)</formula> and
                            <formula notation="tex" rend="inline">\(B\)</formula> helps to solve the
                        global alignment problem for <formula notation="tex" rend="inline"
                            >\(A\)</formula> and <formula notation="tex" rend="inline"
                            >\(B\)</formula>. To avoid the above matrix computation with its large
                        complexity we may use an alternative approach to solve the LCS, utilizing
                        the longest increasing subsequence (LIS) problem. Given a sequence of
                        natural numbers, we look for the longest increasing subsequence. For
                        example, the LIS for <formula notation="tex" rend="inline"
                            >\(1-5-2-7-3-4\)</formula> is <formula notation="tex" rend="inline"
                            >\(1-2-3-4\)</formula>. Given <formula notation="tex" rend="inline">\(A=
                            a_1\ldots a_m\)</formula> and <formula notation="tex" rend="inline">\(B=
                            b_1\ldots b_n\)</formula>, the LCS problem for <formula notation="tex"
                            rend="inline">\(A\)</formula> and <formula notation="tex" rend="inline"
                            >\(B\)</formula> can be reduced to the LIS
                        problem <ptr target="#gusfield1997"/>. We ignore the details of the
                        translation, but look at the complexity of the new procedure for solving the
                        LCS. Let <formula notation="tex" rend="inline">\(r(i)\)</formula> denote the
                        number of occurrences of the letter <formula notation="tex" rend="inline"
                            >\(a_i\)</formula> in <formula notation="tex" rend="inline"
                            >\(B\)</formula>, let <formula notation="tex" rend="inline">\(r =
                            \sum^m_{i=1} r(i)\)</formula>. Using translation into LIS, the LCS
                        problem for <formula notation="tex" rend="inline">\(A\)</formula> and
                            <formula notation="tex" rend="inline">\(B\)</formula> can be solved
                        without dynamic programming in time <formula notation="tex" rend="inline"
                            >\(O(r\ log(n))\)</formula>. </p>
                    <p>In many cases, using the LIS method helps to reduce the computation time for
                        an alignment tasks. However, for large texts the value for the number
                            <formula notation="tex" rend="inline">\(r\)</formula> is typically very
                        large and the computation time remains enormous. For example, the
                            <q>innocent</q> text <formula notation="tex" rend="inline"
                            >\(A\)</formula> shown in <ref target="#figure02">Figure 2</ref>, which
                        is taken from a historical document, already leads to a value of <formula
                            notation="tex" rend="inline">\(r \sim 130,000\)</formula> when compared
                        with a similar text <formula notation="tex" rend="inline">\(B\)</formula>.
                        For more details on the LCS- or LIS- problem see <ptr target="#gusfield1997"
                        />. <label>Improved index-based alignment.</label> Consider the SCDAWG of
                        two texts <formula notation="tex" rend="inline">\(A\)</formula> and <formula
                            notation="tex" rend="inline">\(B\)</formula>. Applying the
                        Node-documents function <formula notation="tex" rend="inline"
                            >\(T\)</formula> it can be determined whether the infix represented by
                        each node occurs in both texts. The main observation now is that using this
                        information we immediately find large portions of the two texts that have a
                        perfect alignment. We use the following definition.</p>
                    <p><label>Definition 4.1</label><anchor xml:id="def_quasi_max"/> An index node <formula
                            notation="tex" rend="inline">\(\mu\)</formula> of the SCDAWG for two
                        texts <formula notation="tex" rend="inline">\(A\)</formula> and <formula
                            notation="tex" rend="inline">\(B\)</formula> is called <emph>quasi
                            maximal</emph> if <list type="ordered">
                            <item>the infix associated with <formula notation="tex" rend="inline"
                                    >\(\mu\)</formula> occurs in both texts <formula notation="tex"
                                    rend="inline">\(A\)</formula> and <formula notation="tex"
                                    rend="inline">\(B\)</formula>,</item>
                            <item><formula notation="tex" rend="inline">\(\mu\)</formula> does not
                                have any transition that leads to another node <formula
                                    notation="tex" rend="inline">\(\mu\)</formula>’ with the
                                Property 1.</item>
                        </list> As an illustration we refer to <ref target="#figure01">Figure
                            1</ref>. Our two example <q>texts</q> lead to two quasi maximal nodes
                                <code>op </code> and <code> in
                            </code>. Based on the <emph>Node-documents function</emph> there
                        exists a simple procedure to find all quasi-maximal nodes: a queue is
                        initialized with the root of the SCDAWG (empty string). We treat all entries
                        of the queue in the order they are added to the queue. The treatment of a
                        node <formula notation="tex" rend="inline">\(\mu\)</formula> involves two
                        steps: <list>
                            <item> We consider each node reached from <formula notation="tex"
                                    rend="inline">\(\mu\)</formula> with a single left or right
                                transition in the SCDAWG. Each such node representing an infix
                                occurring both in <formula notation="tex" rend="inline"
                                    >\(A\)</formula> and <formula notation="tex" rend="inline"
                                    >\(B\)</formula> is added to the end of the queue. </item>
                            <item> If <formula notation="tex" rend="inline">\(\mu\)</formula> does
                                not have any extension representing an infix occurring both in
                                    <formula notation="tex" rend="inline">\(A\)</formula> and
                                    <formula notation="tex" rend="inline">\(B\)</formula>, then
                                    <formula notation="tex" rend="inline">\(\mu\)</formula> is added
                                to the list of quasi maximal nodes. </item>
                        </list> Note that each index node is added to the queue and treated at most
                        once. At the end we obtain the full list of all quasi maximal nodes. Simple
                        additional calculations provide the positions of the occurrences of each
                        quasi maximal nodes. Technical details are omitted. </p>


                    <p>The full alignment method proceeds as follows: We compute the SCDAWG index
                        for the texts <formula notation="tex" rend="inline">\(A\)</formula> and
                            <formula notation="tex" rend="inline">\(B\)</formula> (linear time). We
                        traverse the index to find all quasi maximal nodes and the end positions of
                        occurrences in <formula notation="tex" rend="inline">\(A\)</formula> and
                            <formula notation="tex" rend="inline">\(B\)</formula>. We use end
                        positions and the LIS method to define the linear sceleton of the alignment.
                        When using the LIS method, the important new point to note is that the
                        strings corresponding to the quasi maximal nodes are treated as single
                            <q>symbols</q>. In this way, the factor <formula notation="tex"
                            rend="inline">\(r\)</formula> mentioned in the above formula is
                        drastically reduced. In the experiment from <ref target="#figure02"> Figure
                            2</ref>, the usual procedure leads to <formula notation="tex"
                            rend="inline">\(r \sim 130.000\)</formula>, using the SCDAWG and quasi
                        maximal nodes the value is <formula notation="tex" rend="inline"
                            >\(r=29\)</formula>. When aligning two OCR output texts of <formula
                            notation="tex" rend="inline">\(5.500\)</formula> symbols, the standard
                        method yields <formula notation="tex" rend="inline">\(r \sim
                            2.300.000\)</formula>, using the SCDAWG and quasi maximal nodes the
                        value is only <formula notation="tex" rend="inline">\(r=169\)</formula>.</p>

                    <p>In a project related to improving OCR on historical documents we use this
                        technique to align the outputs of distinct OCR engines for historical texts.
                            <q>Holes</q> obtained from the alignment based on quasi maximal nodes
                        sometimes cover portions of texts where a finer subanalysis helps to improve
                        results. <ref target="#figure03">Figure 3</ref> shows an alignment result
                        for two OCR outputs and two texts, with distinct levels of disagreement.</p>
                    <figure xml:id="figure03">
                        <head>Two OCR outputs for two pages aligned using index technology. Black
                            parts represent quasi maximal nodes and thus matches, red parts are
                            disagreement regions.</head>
                        <graphic url="resources/images/figure03.png"/>
                    </figure>
                    <p>
                        <label>Multiple string alignment.</label> When dealing with <formula
                            notation="tex" rend="inline">\(n>2\)</formula> texts <formula
                            notation="tex" rend="inline">\(A_1,\ldots, A_n\)</formula>, the notion
                        of a quasi maximal node is generalized. <label> Definition 4.2 </label> An
                        index node <formula notation="tex" rend="inline">\(\mu\)</formula> of the
                        SCDAWG for <formula notation="tex" rend="inline">\(A_1,\ldots,
                            A_n\)</formula> is called <emph> quasi maximal</emph> if <list
                            type="ordered">
                            <item>the infix associated with <formula notation="tex" rend="inline"
                                    >\(\mu\)</formula> occurs in all texts <formula notation="tex"
                                    rend="inline">\(A_1,\ldots, A_n\)</formula>,</item>
                            <item>
                                <formula notation="tex" rend="inline">\(\mu\)</formula> does not
                                have any transition that leads to another node <formula
                                    notation="tex" rend="inline">\(\mu\)</formula>’ with Property 1.
                            </item>
                        </list> For technical reasons we actually have the additional restriction
                        that quasi maximal nodes used for alignment only occur once in each text. A
                        generalization of the LIS algorithm can be used to find a maximal linear
                        sequence of quasi maximal nodes of all texts, which gives the desired
                        alignment sceleton. As an illustration, <ref target="#figure04">Figure
                            4</ref> shows the simultaneous alignment of three texts. Two sequences
                        represent parallel parts of the OCR-outputs of two OCR engines on a
                        historical document, the third sequence shows the corresponding part of the
                        ground truth file. <figure xml:id="figure04">
                            <head>Subsegment of the multi-alignment of
                                three texts (OCR outputs and ground truth) using quasi-maximal
                                nodes. Grey parts represent quasi-maximal nodes, for the coloured
                                regions at least two texts show a disagreement.</head>
                            <graphic url="resources/images/figure04.png"/>
                        </figure>
                    </p>
                </div>
                <div>
                    <head>Detecting text reuse and similarities across collections}</head>
                    <p>When comparing large collections of texts <formula notation="tex"
                            rend="inline">\(A_1,\ldots A_n\)</formula>, in most cases it is not
                        natural to ask for substrings that co-occur in all texts. For the following
                        experiment a node of the SCDAWG index for <formula notation="tex"
                            rend="inline">\(A_1,\ldots A_n\)</formula> is called quasi maximal if it
                        is quasi maximal for two texts in sense of <ref target="#def_quasi_max"
                            >Definition 4.1</ref>. We have seen that we can extract the set of all
                        quasi maximal nodes from the SCDAWG index in this sense, and for each such
                        node <formula notation="tex" rend="inline">\(\mu\)</formula> with string
                            <formula notation="tex" rend="inline">\(v_{\mu}\)</formula> we
                        immediately get the information in which texts <formula notation="tex"
                            rend="inline">\(A_i\)</formula> the string <formula notation="tex"
                            rend="inline">\(v_{\mu}\)</formula> occurs. In <ref target="#figure05"
                            >Figure 5</ref> this information is used to compute <q>survey</q> graphs
                        for text reuses in two complete collections (Poems Corpus and Lyrics
                        Corpus). Each graph contains two types of nodes. Large and small ellipses
                        respectively represent quasi maximal nodes and texts numbers of the
                        collection. For each node <formula notation="tex" rend="inline"
                            >\(\mu\)</formula> a prefix and a suffix of the node text <formula
                            notation="tex" rend="inline">\(v_{\mu}\)</formula> is shown. A link from
                        a quasi maximal node <formula notation="tex" rend="inline">\(\mu\)</formula>
                        to a text number <formula notation="tex" rend="inline">\(k\)</formula>
                        indicates that <formula notation="tex" rend="inline">\(v_{\mu}\)</formula>
                        is a substring of <formula notation="tex" rend="inline">\(A_k\)</formula>.
                            <figure xml:id="figure05">
                            <head>Text reuses in the Poems Corpus (top) and Lyrics Corpus (bottom) -
                                quasi maximal nodes and pointers to poems/lyrics. This bird's eye
                                perspective can be used to find interesting regions for closer
                                inspection using zooming techniques. To view these images in more detail, download the high-resolution PDFs (<ref target="resources/images/figure05_1.pdf">5.1</ref>, <ref target="resources/images/figure05_2.pdf">5.2</ref>).</head>
                            <graphic url="./resources/images/figure05_1.png"/>
                            <graphic url="./resources/images/figure05_2.png"/>
                        </figure>
                    </p>
                    <p>Depending on the text reuses in the collection, the graph becomes very large.
                        Still it is very useful to find interesting subregions with eye-catching
                        multiple text reuses. In the lyrics corpus, many reuse effects can be traced
                        back to covered songs. Since the song texts in the corpus were collected in
                        a community based way, texts differ in details. In the survey graph
                        eye-catching regions are mainly caused by songs that have been covered many
                        times. It is then possible to zoom to these regions and to see reused text
                        portions and the texts where these findings occur. Figures <ref
                            target="#figure06">6</ref>and <ref target="#figure07">7</ref> show such
                        zoomed regions. In <ref target="#figure06">Figure 6</ref> it can be seen
                        that five poems in the collection have many text reuse connections. Some
                        examples for reused text are (cf. <ref target="#figure06">Figure 6</ref>): <list>
                            <item>
                                <code>laut und leise, Unterric... träumt,
                                        Angenehme zu hören</code>
                            </item>
                            <item><code>wälzend kam die Sturmesf ... der Chor vom
                                        ganzen Haine</code>
                            </item>
                        </list>
                        <figure xml:id="figure06">
                            <head>Text reuses in the Poems Corpus - quasi maximal nodes and pointers
                                to 5 poems, zoomed subregion of upper graph in <ref
                                    target="#figure05">Figure 5</ref>.</head>
                            <graphic url="resources/images/figure06.png"/>
                        </figure> In <ref target="#figure07">Figure 7</ref> many test reuses are
                        centered around the word <q>Hallelujah</q>. Examples are <list>
                            <item><code>She tied you to a kitche .. Hallelujah,
                                        Hallelojah}</code>
                                
                            </item>
                            <item><code>s seen the light It's a -- ah Hallelujah,
                                        Hallelujah}</code>
                                
                            </item>
                        </list>
                        <figure xml:id="figure07">
                            <head>Text reuses in the Lyrics Corpus - quasi maximal nodes and
                                pointers to lyrics, zoomed subregion of lower graph in <ref
                                    target="#figure05">Figure 5</ref>.</head>
                            <graphic url="resources/images/figure07.png"/>
                        </figure>
                    </p>
                </div>
            </div>

            <div xml:id="section05">
                <head>Refined <q>linguistic</q> view on a corpus </head>
                <p> We have seen that the set of nodes of the (S)CDAWG for a corpus represents a
                    relatively small set of infixes that often are <q>natural</q> portions of text.
                    Experiments in <ref target="#gerdjikov2016">Gerdjikov and Schulz (2016)</ref> show that many of the phrases
                    corpus analyzers would look at (names, terminological expressions, stylistic
                    phrases, ...) are typically left- and right-closed and appear among the nodes of
                    the (S)CDAWG. This means that when just using the index nodes for corpus
                    exploration we do not miss important portions of text. </p>
                <p>From this point, the (S)CDAWG can be considered as a first step towards a new
                    kind of <q>linguistic corpus index</q> where nodes - in the ideal case - <emph>
                        exactly</emph> represent the linguistic units of interest (morphems, words,
                    phrases, sentences, ...) of the corpus and their relationships. In a way, such
                    an index would be the optimal basis for all corpus analysis tasks focussed on
                    linguistic units <note>More generally, the ideal index structure for corpus
                        analyzers would point to all and exactly those infixes that are relevant for
                        the analysis, their positions and their relationships.</note>. However, for
                    arbitrary texts there is not even a useful formal definition of a <q>phrase</q>
                    or <q>linguistic unit</q>, let alone a procedure for finding this strings. </p>
                <p>There are two possible main paths how to come closer to a <q>linguistic
                        refinement</q> of the (S)CDAWG. On the one hand side, we can take any
                    available NLP prodecure (parser, lexical analyser, phrase detector,..). Assuming
                    that the units found represent nodes of the (S)CDAWG, we arrive at a (S)CDAWG
                    substructure that directly points to units of interest and their occurrences in
                    the corpus. On the other hand we may try to further analyze regularities found
                    in the corpus to find a restricted set of nodes that comes closer to the idea of
                    a linguistic phrase. In <ref target="#gerdjikov2016">Gerdjikov and Schulz (2016)</ref>, we followed the second
                    path, which is completely language independent. Crucial assumptions are: <list>
                        <item> phrases appear in distinct contexts, </item>
                        <item> phrases are combined using function words as connectors, and </item>
                        <item> sentences have natural decompositions into phrases, overlaps
                            representing function words. </item>
                    </list> We then describe a bootstrapping method for finding function words,
                    phrases and sentence decompositions into phrases.<note>Since we have a
                        symbol-based view on corpora, the expression function <q>word</q> is
                        misleading. The blank, as well as strings such as <code>as
                                well as</code> may serve as a function <q>word</q>.</note> Using
                    the same kind of techniques, phrases can be further decomposed into 
                    <term>sub(sub)phrases</term>. As a matter of fact, for this form of decomposition also given
                    lists of function words could be used. The main point is that the bootstrapping
                    method in a completely unsupervised and language independent way leads to an
                    interesting set of phrases and subphrases that helps to considerably reduce the
                    set of nodes considered, thus coming closer to a <q>linguistic</q> index. </p>
                <p><label>Finding important concepts of the corpus.</label> When ignoring bordering
                    function words, <emph>atomic subphrases</emph> obtained in this way typically
                    represent content words or <q>concepts</q>. Analyzing the role of these concepts
                    in phrase decomposition it is possible to compute a ranked list of
                    characteristic concepts of the corpus. See <ref target="#gerdjikov2016">Gerdjikov and Schulz (2016)</ref> for
                    details. Below some examples for <emph>most characteristic atomic phrases</emph>
                    in the example corpora are given. For example, in the Wittgenstein Corpus,
                    central concepts found using the above methods are (cf. <ref target="#figure09"
                        >Figure 9</ref>) <code>Bedeutung</code> (meaning),
                            <code>Farbe</code>(colour), <code
                            >Sprache</code> (language), and <code
                        >Erklärung</code> (explanation). </p>
                <p>
                    <label>Exploring the use of concepts.</label> After computing characteristic
                    concepts, the aforementioned decomposition of phrases helps to find all larger
                    phrases where a given concept occurs. In this way the use of the concept in the
                    corpus can be studied. <ref target="#figure08">Figure 8</ref> shows the
                    hierarchical structure of phrases of the Wittgenstein Corpus extending <code>Bedeutung</code>. <figure xml:id="figure08">
                        <head><hi rend="bold">Exploring the use of concepts</hi>. The hierarchical
                            structure of phrases extending the concept <code
                                >Bedeutung</code> in the Wittgenstein Corpus detected by our
                            approach.</head>
                        <graphic url="./resources/images/figure08.png"/>
                    </figure>
                </p>
                <p>
                    <label>Exploring the relationship of concepts in a visual way.</label> A third
                    goal is to explore interesting relationships between the concepts. Existing
                    corpus exploration tools and automated approaches for exploring the
                    paradigmatics of lexical units typically look at the co-occurrence of terms in
                    documents, paragraphs, sentences or fixed size neighbourhoods <ptr
                        target="#schütze1993"/>,<ptr target="#storjohann2010"/>. Another, more
                        <q>syntactic</q> view is obtained when looking at the co-occurrence of
                    concepts in <emph>phrases</emph>. In Figures <ref target="#figure9">9</ref> and
                        <ref target="#figure10">10</ref> we see the relationship of concepts
                    (characteristic atomic kernels) in terms of co-occurrences in phrases. For
                    example, in the Wittgenstein Corpus, <code>Bedeutung</code>
                    (meaning) is strongly related to <code>Erklärung</code>
                    (explanation), as can be seen from phrases like <code
                            >Erklärung der Bedeutung eines Worts</code> (explanation of the
                    meaning of a word). In the Medline Corpus (cf. <ref target="#figure10">Figure
                        10</ref>), concepts found to be related to <code
                            >tumor</code> are, e.g., <code>risk</code>
                    (witness phrase <code>risk for tumor</code>), <code>chemotherapy</code> (witness phrase <code>tumor cells to chemotherapy</code>), and <code>vaccines</code> (witness phrase <code>tumor vaccines</code>). <figure xml:id="figure09">
                        <head><hi rend="bold">Exploring the relationship of concepts in a visual way</hi>.
                            Network with <q>witness phrases</q> for the relationship between
                            concepts derived from Wittgenstein Corpus.</head>
                        <graphic url="./resources/images/figure09.png"/>
                    </figure>
                    <figure xml:id="figure10">
                        <head><hi rend="bold">Exploring the relationship of concepts in a visual way</hi>.
                            Network with <q>witness phrases</q> for the relationship between
                            concepts derived from the Medline.</head>
                        <graphic url="./resources/images/figure10.png"/>
                    </figure>
                </p>
            </div>
            <div xml:id="section06">
                <head>Corpus exploration using metadata</head>
                <p> When metadata are available, many of the aforementioned techniques can be
                    refined for revealing similarities in the space of metadata. Technically, we
                    assign the metadata for the original documents to the nodes in the SCDAWG that
                    represent those documents. For the rest of the nodes we can retrieve this
                    information on demand by simple traversal of small parts of the SCDAWG. </p>
                <p>
                    <label>Comparing authors.</label> Our first illustration uses the Poems Corpus,
                    where we have authorship and temporal metadata for texts. In <ref
                        target="#figure11">Figure 11</ref> we use the aforementioned refined
                        <q>linguistic</q> view. After adding authorship information to the maximal
                    nodes of the index we first adapt the notion of a quasi maximal node: a node
                        <formula notation="tex" rend="inline">\(\mu\)</formula> with text <formula
                        notation="tex" rend="inline">\(v_{\mu}\)</formula> is called <term>quasi
                    maximal with respect to authors</term> if <formula notation="tex" rend="inline"
                        >\(v_{\mu}\)</formula> occurs in texts of two distinct authors, while any
                    phrase that properly extends <formula notation="tex" rend="inline"
                        >\(v_{\mu}\)</formula> only occurs in the works of one author. </p>

                <p> The nodes in <ref target="#figure11">Figure 11</ref> represent important
                    concepts in the corpus - some of the most characteristic atomic subphrases for
                    the Poems Corpus in the sense considered above. Our language independent
                    techniques revealed that <code>Welt</code> (world), <code>Sonne</code> (sun), <code
                            >Himmel</code> (sky/heaven), <code>Gold</code>
                    (gold), and <code>Schnee</code> (snow) are important
                    concepts in the Poems Corpus. In <ref target="#figure11">Figure 11</ref>, each
                    link between two concepts stands for a phrase that <list>
                        <item> contains both concepts, and </item>
                        <item> is quasi maximal with respect to authors. </item>
                    </list> The authors that have used the phrase are annotated with the link. For
                    example it is seen that <list>
                        <item>
                            <code>Schnee zur Erde</code> (snow to earth) was
                            both used by Nikolaus Lenau and Hermann Löns, and </item>
                        <item>
                            <code>der Himmel mit der Erde</code> (the heaven/sky
                            with the earth) was both used by Betty Paoli and Friedrich
                            Rückert.</item>
                    </list> This gives a basis for comparing two authors, now asking if both authors
                    used similar (quasi-maximal) phrases with the central concepts of the corpus.
                        <figure xml:id="figure11">
                        <head><hi rend="bold">Use of Metadata</hi>. Connecting concepts (nodes) by means
                            of phrases that are maximal with respect to the property of being used
                            by two poets. Edges represent phrases plus the two poets that used the
                            phrase.</head>
                        <graphic url="./resources/images/figure11.png"/>

                    </figure>
                </p>
                <p>
                    <label>Temporal development of similarities between authors.</label> In <ref
                        target="#figure12">Figure 12</ref> we see a dual variant of the graph where
                    the role of nodes and edges is changed. Nodes now represent authors, authors are
                    linked if they have used identical quasi maximal (w.r.t authors) phrases. Using
                    colouring of nodes, also temporal information about authors is added - we simply
                    used the year defining the middle point in the life of an author. The spectral
                    ordering of colours red-green-blue-purple represents the temporal timeline from
                    earlier periods to later periods. Links always point from earlier authors to
                    later authors. </p>
                <p> In the lower part of the graph we find a path from Anna Louisa Karsch (1756)
                        <ref target="#figure12">Figure 12</ref>, circle marker (1)) <formula
                        notation="tex" rend="inline">\(\longrightarrow\)</formula> Friedrich
                    Gottlieb Klopstock (1763) <formula notation="tex" rend="inline"
                        >\(\longrightarrow\)</formula> Ernst Schulze (1803) <ref target="#figure12"
                        >Figure 12</ref>, circle marker (2)). The latter is also reached with a link
                    from Johann Wolfgang von Goethe (1794) <ref target="#figure12">Figure 12</ref>,
                    circle marker (3)). Goethe has several successors. In this graph, an even more
                    central person is Ludwig Achim von Arnim (1806) <ref target="#figure12">Figure
                        12</ref>, circle marker (4)), who builds the center of the large cluster in
                    the middle of the figure. The temporal spectrum of this cluster corresponds to
                    the first half of the 19th century. Authors of the 17th and 18th century are
                    found in the second cluster on the top right part. An early <q>influential</q>
                    author of this period is Simon Dach (1632) <ref target="#figure12">Figure
                        12</ref>, circle marker (5)). </p>
                <p> The two clusters indicate a change of literary concepts covered between the
                    Baroque/Pre-Romantic period and the Romantic period. The three authors (John
                    Brinckman (1842), Fritz Reuter (1842), and Klaus Groth (1859) <ref
                        target="#figure12">Figure 12</ref>, circle marker (6)), who form the cluster
                    right to Romantic period cluster however are not connected to the cluster
                    consisting of other authors of their period due to the fact that all three were
                    writing poems in the german dialect of niederdeutsch. <figure xml:id="figure12">
                        <head><hi rend="bold">Use of Metadata in the Poems Corpus.</hi> The graph is
                            obtained as the dual variant of the graph in <ref target="#figure11"
                                >Figure 11</ref>. Links between two poets mean that both have used
                            similar maximal phrases around the concepts shown in <ref
                                target="#figure11">Figure11</ref>. Colours correspond to temporal
                            information for authors. Links point from earlier authors to later
                            authors.</head>
                        <graphic url="./resources/images/figure12.png"/>
                    </figure>
                </p>
                <p> When constructing this kind of graph for the Lyrics Corpus similar observations
                    can be made. The nodes of <ref target="#figure13">Figure 13</ref> again are
                    connected by co-occurring quasi maximal phrases. Instead of the author now band
                    names are used together with the mean of the release years of their
                    corresponding songs. The colour coding is the same as used in the previous
                    experiment. One of the first things that can be observed is a cluster of Italian
                    singers centered around Eros Ramazotti (1998) (See <ref target="#figure13"
                        >Figure 13</ref>, circle marker (1)), located at the right to the center of
                    the graph. Also lots of subgraphs, which only contain of two or three
                    interpreters are seen. They often vizualize relations between cover songs, which
                    are contained in the corpus. Therefore for instance Right Said Fred (1998) and
                    Peter Sarstedt (1969) (See <ref target="#figure13">Figure 13</ref>, circle
                    marker (2)) can be found at the bottom left. Another example of this is a three
                    node cluster at the top right with edges leading from Julie Covington (1977) and
                    Don McLean (1972) to Madonna (1996) (See <ref target="#figure13">Figure
                    13</ref>, circle marker (3)), who famously released covers of the songs <q>Don't
                        Cry For Me Argentina</q> and <q>American Pie</q>. Other subgraphs connect
                    interpreters who obviously belong to the same genre, e.g. at little to the right
                    of the center a path can be found leading from 2Pac (2000) <formula
                        notation="tex" rend="inline">\(\longrightarrow\)</formula> Busta Rhymes
                    (2001) <formula notation="tex" rend="inline">\(\longrightarrow\)</formula> Kanye
                    West (2007) (See <ref target="#figure13">Figure 13</ref>, circle marker (4)),
                    with the interpreters representing famous hip-hop artists. <figure
                        xml:id="figure13">
                        <head><hi rend="bold">Use of Metadata in the Lyrics Corpus.</hi> The graph is
                            obtained by connecting interpreters by their commonly used phrases. Node
                            colours again encode temporal metadata. Links point from older
                            interpreters to younger ones.</head>
                        <graphic url="./resources/images/figure13.png"/>
                    </figure>
                </p>
            </div>

            <div xml:id="section07">
                <head>Loose ends - diachronic language variation and classification tasks</head>
                <p>Even though the focus of the current paper are the problems of text-reuse and
                    mining of relationships based on it, we suggest that our approach can be
                    extended to other related problems, e.g. diachronic language variation and text
                    classification. </p>
                <p>In <ref target="#gerdjikov2013">Gerdjikov et al. (2013)</ref> and <ref target="#sariev2014">Sariev et al. (2014)</ref>, the authors
                    develop a historical text normalization system. Based on a modern dictionary and
                    several thousands of pairs, historical word and its modern variant, they show
                    that the DAWG structure can be used to automatically learn and extract spelling
                    variations. The main benefit of the infix structure is that: (i) it does not
                    restrict the spelling variation to any particular predefined patterns and (ii)
                    it reflects the entire structure of the language (on word level). In <ref target="#sariev2014">Sariev et al. (2014)</ref> the combination of this technique with a language
                    model for the modern language yields a complete historical text normalization
                    system.</p>
                <p>Of course, the requirement for training data sets practical limitations --
                    training data is often unavailable and its production is expensive and
                    time-consuming. In <ref target="#mitankin2014">Mitankin et al. (2014)</ref> the authors try to address this
                    problem and suggest a completely automatic historical text normalization
                    approach. The main idea is to automatically generate pairs of historical word
                    and its modern variant. <ref target="#mitankin2014">Mitankin et al. (2014)</ref> proposes to use
                    Levenshtein edit distance and approximate search in the modern dictionary in
                    order to generate for each historical word its most relevant modern variant(s).
                    Afterwards we are in the situation to run the historical text normalization
                    system from <ref target="#mitankin2014">Mitankin et al. (2014)</ref> and <ref target="#sariev2014">Sariev et al. (2014)</ref>.
                    Unfortunately, the Levenshtein edit distance, as a generator of pairs, turns out
                    to introduce a lot of noise in the system. In particular, the accuracy of the
                    normalization system drops from 94% to 82%. </p>
                <p>The results from the current paper suggest two straightforward approaches in
                    order to reduce the noise introduced by the unsupervised approximate search. The
                    first approach is the following. Instead of searching for <emph>historical
                        words</emph> and their <emph>modern word variants</emph>, to search for
                        <emph>historical phrases</emph> and their <emph>modern phrase
                        variants</emph>, automatically extracted from the SCDAWG structure for the
                    historical texts and modern texts, respectively. In this way we plug in
                    additional language context in the query, which in general will exclude
                    orthographically similar but semantically irrelevant candidates. On the other
                    hand, if the modern text corpus covers the domain of the historical texts, it is
                    possible that the basic phrases in the historic language have indeed been
                    preserved in the modern language and do have their spelling variants in the
                    modern language. Thus, without seriously reducing the recall, we could increase
                    the quality of the automatically generated pairs <emph>historical phrases</emph>
                    and their <emph>modern phrase var</emph>. The production of pairs of words is
                    then straightforward<note>Actually, the approach in <ref target="#gerdjikov2013">Gerdjikov et al. (2013)</ref> is not limited to words.</note>. </p>
                <p>The second approach is the following. Instead of modifying the searching space,
                    we can modify the edit-distance and use more relevant edit-distance mechanism.
                    As described in <ref target="#section04">Section 4</ref>, we can use the SCDAWG
                    structure in order to align different editions of the same source. In
                    particular, if the editions belong to close time periods, the most disagreements
                    in the alignment will be due to uncertainties in the spelling that have been
                    typical in this time period. This phenomenon can be used in order to constrain
                    the elementary edit-operations and the contexts in which they are applicable. As
                    a result we can expect that the generator of pairs, historic word and its modern
                    variant, will be more relevant with respect to the structure of the historical
                    language. </p>
                <p>We should stress that the arguments raised in the previous two paragraphs require
                    further research. It is also a challenging open problem to directly map the
                    SCDAWG structure of a historical corpus to a substructure of the SCDAWG
                    structure for a large modern language. The latter, of course, would resolve the
                    normalization problem. </p>
                <p>The substrings of a SCDAWG index could also be used to train models for text
                    classification tasks. A similiar approach, which uses maximal substrings of a
                    suffix tree and led to promising results, had been persued in <ref target="#okanohara2009">Okanohara and Tsujii (2009)</ref>. As stated in <ref target="#section02">Section
                        2</ref> the two-sided closures, which form the nodes of the SCDAWG,
                    represent more natural infixes than those of a suffix tree or DAWG. Therefore
                    they may render descriptive features which still are not restricted to fixed
                    word boundaries. To find optimal features in the substrings of a SCDAWG of a
                    corpus again metadata can be used to find longest or shortest substrings which
                    occur only in a certain instance of a metadata attribute. For example the
                    longest/shortest substrings which belong to the author <q>Goethe</q> can be used
                    as features to train a text classification model with regard of this metadata
                    attribute.</p>
            </div>
            <div xml:id="section08">
                <head>Conclusion</head>
                <p>In this paper we have shown how symmetric compact acyclic word graphs (SCDAWGs)
                    can help to efficiently mine interesting portions of texts in corpora, which
                    serve as a basis for many ways of comparing texts like alignment and the
                    detection of text reuse (<ref target="#section04">Section 4</ref>). These
                    findings can be refined by adding a form of <q>linguistic analysis</q> where
                        <q>phrases</q>, <q>subphrases</q>, <q>function words</q>, and <q>important
                        content words</q> (characteristic atomic kernels) are computed in an
                    unsupervised way without using prior linguistic knowledge (<ref
                        target="#section05">Section 5</ref>). If metadata for the texts in the
                    collection are available, additional information stored in the index and the
                    above techniques give a basis for finding similarities in the space of metadata
                        (<ref target="#section06">Section 6</ref>).</p>
                <p>Of course many of the here mentioned techniques would require more detailed
                    analysis and comparsion with other existing methods. However this was not the
                    purpose of this paper, since its focus didn't lie on the development and
                    description of a certain method but rather on showing how manifold and versatile
                    the application of such an index can be to the task of large scale corpus
                    exploration. In many cases, various variants exist for the concrete methods used
                    in our examples. When moving to real applications, experts from Digital
                    Humanities are needed to find those variants that are most adequate and lead to
                    real insights. </p>
            </div>
            <div xml:id="section09">
                <head>Acknowledgements</head>
                <p>We express our gratitude to: Uwe Springmann for his help with OCR recognition of
                    historic documents and the corpus derived from them. We also thank Stefanie
                    Schneider for the provision of the lyrics corpus. Part of the results described
                    in this paper were obtained during the stay of the third author at LMU for which
                    he has received funding from the People Programme (Marie Curie Actions) of the
                    European Union's Seventh Framework Programme (FP7/2007--2013) under REA grant
                    agreement 625160.</p>

            </div>
        </body>
        <back>
            <listBibl>
                <bibl xml:id="blumer1987" label="Blumer et al. 1987">Blumer, A., Blumer, J.,
                    Haussler, D., McConnell, R., and Ehrenfeucht, A.<title rend="quotes">Complete
                        inverted files for efficient text retrieval and analysis</title>. <title
                        rend="italic">Journal of the ACM (JACM)</title> 34 (1987): 578-595.</bibl>

                <bibl xml:id="büchler2012" label="Büchler et al. 2012">Büchler, M., Crane, G.,
                    Moritz, M., and Babeu, A. <title rend="quotes"> Increasing recall for text
                        re-use in historical documents to support research in the humanities
                    </title>. In <title rend="italic">Proceedings of 16th International Conference
                        on Theory and Practice of Digital Libraries, (tpdl 2012): </title> pp.
                    95–100 <title rend="italic">Springer Berlin Heidelberg</title>.</bibl>

                <bibl xml:id="gerdjikov2013" label="Gerdjikov et al. 2013">Gerdjikov, S. and Mihov,
                    S. and Nenchev, V. <title rend="quotes">Extraction of spelling variations from
                        language structure for noisy text correction</title>. In <title
                        rend="italic">Proc. Int. Conf. for Document Analysis and Recognition</title>
                    (2013): 324-328.</bibl>

                <bibl xml:id="gerdjikov2016" label="Gerdjikov and Schulz 2016">Gerdjikov, S., and
                    Schulz, K. U. <title rend="quotes">Corpus analysis without prior linguistic
                        knowledge-unsupervised mining of phrases and subphrase structure</title>.
                        <title rend="italic">ArXiv e-prints</title> (2016): 1602.05772.</bibl>

                <bibl xml:id="gusfield1997" label="Gusfield 1997">Gusfield, D. <title rend="italic"
                        >Algorithms on strings, trees and sequences: computer science and
                        computational biology</title>. Cambridge university press, Cambridge,
                    1997.</bibl>

                <bibl xml:id="inenaga2005" label="Inenaga et al. 2005">Inenaga, S., Hoshino, H.,
                    Shinohara, A., Takeda, M., Arikawa, S., Mauri, G., and Pavesi, G.<title
                        rend="quotes">On-line construction of compact directed acyclic word
                        graphs</title>. <title rend="italic">Discrete Applied Mathematics</title>
                    146 (2005): 156-179. </bibl>

                <bibl xml:id="mccreight1976" label="McCreight 1976">McCreight, Edward M.<title
                        rend="quotes">A space-economical suffix tree construction algorithm</title>.
                        <title rend="italic">Journal of the ACM (JACM)</title> 23 (1976): 262-272. </bibl>

                <bibl xml:id="mitankin2014" label="Mitankin et al. 2014">Mitankin, P. and Gerdjikov,
                    S. and Mihov, S. <title rend="quotes"> An approach to unsupervised historical
                        text normalization </title>. In <title rend="italic">Proceedings of the
                        First International Conference on Digital Access to Textual Cultural
                        Heritage: </title> (2014) 29-34.</bibl>

                <bibl xml:id="needleman1970" label="Needleman and Wunsch 1970">Needleman, S. B., and
                    Wunsch, C. D.<title rend="quotes">A general method applicable to the search for
                        similarities in the amino acid sequence of two proteins.</title>. <title
                        rend="italic">Journal of molecular biology</title> 48 (1970): 443-453. </bibl>


                <bibl xml:id="okanohara2009" label="Okanohara and Tsujii 2009">Okanohara, Daisuke
                    and Tsujii, Jun'ichi<title rend="quotes">Text categorization with all substring
                        features</title>. In <title rend="italic">Proceedings of the 2009 SIAM
                        International Conference on Data Mining: </title> (2009) 839-846.</bibl>

                <bibl xml:id="sariev2014" label="Sariev et al. 2014">Sariev, Andrei and Nenchev,
                    Vladislav and Gerdjikov, Stefan and Mitankin, Petar and Ganchev, Hristo and
                    Mihov, Stoyan and Tinchev, Tinko<title rend="quotes">Flexible noisy text
                        correction</title>. In <title rend="italic">Proceedings of Document Analysis
                        Systems: </title> (2014)</bibl>

                <bibl xml:id="schütze1993" label="Schütze and Pedersen 1993">Schütze, H., and
                    Pedersen, J.<title rend="quotes"> A vector model for syntagmatic and
                        paradigmatic relatedness </title>. In <title rend="italic">Proceedings of
                        the 9th Annual Conference of the UW Centre for the New OED and Text
                        Research, (oed 1993): </title> pp. 104–113.</bibl>

                <bibl xml:id="storjohann2010" label="Storjohann 2010">Storjohann, P. (Ed.) <title
                        rend="italic">Lexical-semantic relations: theoretical and practical
                        perspectives (Vol. 28)</title>. John Benjamins Publishing, Cambridge,
                    2010.</bibl>

                <bibl xml:id="ukkonen95" label="Ukkonen 1995">Ukkonen, Esko. <title rend="quotes"
                        >On-line construction of suffix trees</title>. <title rend="italic"
                        >Algorithmica</title>14 (1995): 249-260. </bibl>

                <bibl xml:id="weiner1973" label="Weiner 1973">Weiner, P. <title rend="quotes">Linear
                        pattern matching algorithms</title>. In <title rend="italic">Proceedings of
                        14th Annual Symposium on Switching and Automata Theory, (swat 1973):
                    </title> pp. 1–11 <title rend="italic">IEEE</title>.</bibl>


            </listBibl>

        </back>
    </text>
</TEI>
