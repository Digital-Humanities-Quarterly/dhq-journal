<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>[PREVIEW] DHQ: Digital Humanities Quarterly: </title>
      <link href="../../common/css/dhq.css" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_screen.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_print.css" media="print" type="text/css" rel="stylesheet" /><style type="text/css">
        #mainContent {
          float: none;
          padding-top: 2em;
          padding-left: 4em;
          padding-right: 4em;
          margin-left: 225px;
           
        }</style></head>
   <body>
      <div id="mainContent">
         <div class="DHQarticle">
            <div id="pubInfo">Preview<br />Volume 014 Number 4
            </div>
            <div class="toolbar">
               <form id="taporware" action="get">
                  <div><a href="//preview/index.html">Preview</a>
                      | 
                     <a rel="external" href="//vol/14/4/000533.xml">XML</a>
                     
                     | 
                     		   Discuss
                     			(<a href="/dhq/vol/14/4/000533/000533.html#disqus_thread" data-disqus-identifier="000533">
                        				Comments
                        			</a>)
                     
                  </div>
               </form>
            </div>
            
            <div class="DHQheader">
               
               
               
               
               <h1 class="articleTitle lang en">Playing With Unicorns: <span class="hi italic">AI
                     Dungeon</span> and Citizen NLP
               </h1>
               
               
               <div class="author"><span style="color: grey">Rita Raley
                     </span></div>
               
               <div class="author"><span style="color: grey">Minh Hua
                     </span></div>
               
               
               
               
               
               
               
               <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Playing%20With%20Unicorns%3A%20AI%20Dungeon%20and%20Citizen%20NLP&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=&amp;rft.volume=014&amp;rft.issue=4&amp;rft.aulast=Raley&amp;rft.aufirst=Rita&amp;rft.au=Rita%20Raley&amp;rft.au=Minh%20Hua"> </span></div>
            
            <div id="DHQtext">
               
               
               <div id="abstract">
                  <h2>Abstract</h2>
                  
                  
                  <p><cite class="title italic">AI Dungeon 2</cite> is an indie text adventure game that caught
                     traction within the gaming and hobbyist machine learning communities for its promise
                     of “infinite” customizable adventures, which are generated and narrated by
                     GPT-2, OpenAI’s 1.5 billion parameter language model. Samples of gameplay illustrate
                     AID’s remarkable linguistic competence and domain knowledge, as well as its capacity
                     for what can only be described as wackiness. More striking are AID’s innovative
                     gameplay mechanics, which reimagine how we interact with large language models. Game
                     play entails a procedural and incremental process of engaging with GPT-2 that opens
                     up the possibility of developing a holistic and interdisciplinary framework for
                     meaningful qualitative evaluation of language models that does not have commercial
                     use as its necessary endgame. With respect to both evaluation and writing itself,
                     AID
                     situates human players inextricably “in the loop” as necessary partners with
                     autonomous systems. Our article thus reads AID both as an example of current hobbyist
                     relations with machine learning and as a responsible model for future human-AI
                     collaborative creative practices.
                  </p>
                  
               </div>
               
               
               
               
               
               <div class="epigraph">
                  
                  <blockquote>
                     <p class="ptext">Over the years, you have trained yourself to understand the
                        human language. — AI Dungeon 2
                     </p>
                  </blockquote>
                  
               </div>
               
               <div class="div div0">
                  
                  <h1 class="head">1: Magical Unicorn Blood</h1>
                  
                  <div class="counter"><a href="#p1">1</a></div>
                  <div class="ptext" id="p1">AI Dungeon 2 was a minor sensation almost immediately after it was released as a
                     Google Colab notebook on December 5, 2019. In the weeks prior, designer Nick Walton,
                     then a student at BYU, had teased the launch of the “magical world,” but it was
                     only once people could themselves play that the AI text adventure game truly caught
                     fire [<a class="ref" href="#walton2019c">Walton 2019c</a>]. An independent subreddit began the very next day;
                     gaming journalists and tech bloggers picked it up; exuberant reactions and
                     playthroughs circulated widely on social media; and within a week the game had
                     100,000 players. So spirited was the hype of this weird game, so insistent the
                     recommendations, that the data egress charges for the notebook reached an
                     unsustainable $50,000 within three days, and BYU’s Perception, Control and Cognition
                     Lab, which had provided the support, had to shut it down. Particularly striking, and
                     apposite for the story that we will tell in this article, was the response from the
                     nascent AID community, which developed a peer-to-peer hosting solution within 12
                     hours of the take-down. But for a more sustainable path forward, and in order to
                     expand the user base beyond those who could work with Colab notebooks, Walton and
                     his
                     startup company needed a browser implementation and mobile apps, which were made
                     possible with Cortex, an open-source tool for building the infrastructural support
                     to
                     deploy machine learning models [<a class="ref" href="#walton2020">Walton 2020</a>]. By mid-February, then,
                     there were upwards of 1,000,000 players writing millions of stories in collaboration
                     with a language model that had been fine-tuned on the archive of
                     choose-your-own-adventure stories, Chooseyourstory.com, and an entire game universe,
                     complete with animations and reenactments, was underway, with Patreon subscriptions
                     soon to follow.<a class="noteRef" href="#d4e217">[1]</a>
                     
                  </div>
                  
                  <div class="counter"><a href="#p2">2</a></div>
                  <div class="ptext" id="p2">The success of AI Dungeon 2 is partly attributable to its underlying language model:
                     OpenAI’s GPT-2.<a class="noteRef" href="#d4e228">[2]</a> Language models
                     perform probabilistic calculations of word sequences based on training data; such
                     calculations are now baked into our communication environments, from predictive text
                     to application features such as Google’s Smart Compose. GPT-2 was pronounced as
                     different — “better” but potentially dangerous — because
                     of the size and scope of its training corpus (40GB of English-language data) as well
                     as its parameters (1.5 billion) [<a class="ref" href="#openai2019a">OpenAI 2019a</a>]. In the fanfare and
                     documentation attending its partial release in February 2019, GPT-2 was said to
                     perform almost too well, thus necessitating the withholding of the full parameter
                     model and securing its mystique as a black box too powerful and risky for public
                     use.<a class="noteRef" href="#d4e239">[3]</a> The model’s capability could thus only be assessed through the
                     company’s reported “synthetic text samples of unprecedented
                     quality,” the most famous of which narrated the discovery of a herd of
                     unicorns in the Andes Mountains [<a class="ref" href="#openai2019a">OpenAI 2019a</a>]. Both skeptical and
                     enthusiastic experimentation to assess whether GPT-2 was indeed as advertised a
                     “better model” began almost immediately. Gwern, for example, retrained the
                     smallest 117 million parameter model on the Project Gutenberg poetry corpus; David
                     (Jhave) Johnston initiated a collaborative writing project entitled <cite class="title italic">ReRites</cite> after fine-tuning the medium-sized model on a custom
                     poetry corpus; and Adam King’s “Talk to Transformer” site
                     invited everyone to try the model at different stages of the release with text
                     prompts of their choosing [<a class="ref" href="#branwen2019">Branwen 2019</a>]
                     [<a class="ref" href="#johnston2019">Johnston 2019</a>]. Walton entered the fray with AI Dungeon, which he
                     built during a hackathon in March 2019 [<a class="ref" href="#walton2019b">Walton 2019b</a>]. If as Walton
                     noted of the first iteration, there was “still a ways to go
                     before AI will be your group’s dungeon master”, the full release of GPT-2
                     made it possible to abandon pre-generated and cached actions, and the truly open and
                     unscripted AI Dungeon 2 debuted one month later [<a class="ref" href="#walton2019a">Walton 2019a</a>].<a class="noteRef" href="#d4e272">[4]</a> This then is our object of study in a nutshell: a 1.5
                     billion parameter language-model-turned-game distributed across one of the biggest
                     cloud computing infrastructures in the world, Amazon Web Services Cloud.<a class="noteRef" href="#d4e279">[5]</a>
                     
                  </div>
                  
                  <div class="counter"><a href="#p3">3</a></div>
                  <div class="ptext" id="p3">As with the now-renowned species, Ovid’s Unicorn, the proof of concept is in the text
                     samples, so we will begin with a darker version of the story, revealing what might
                     have happened had the Americans arrived in the valley before Dr. Jorge Pérez and his
                     team (<a href="#figure01">Figure 1</a>). 
                  </div>
                  
                  <div id="figure01" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure01.png" rel="external"><img src="resources/images/figure01.png" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 1. </div>Sample <span class="hi italic">AI Dungeon 2</span> game play (“custom”
                        adventure)
                     </div>
                  </div>
                  
                  <div class="counter"><a href="#p4">4</a></div>
                  <div class="ptext" id="p4">What you have just read is a sample of a custom AID adventure, which we initialized
                     with the same seed text the OpenAI team used to generate their report of “Ovid’s Unicorn” for GPT-2’s public debut.<a class="noteRef" href="#d4e314">[6]</a> Although
                     “custom” in this context means the game can build a choose-your-own-adventure
                     story around any starting prompt, “custom” is also an appropriate description
                     for the nonlinear mode of playing. Our playthrough was not the first thing the game
                     generated in response to OpenAI’s unicorn prompt. In a shocking finding, rumblings
                     of
                     a herd of English-speaking unicorns were at first met with an explorer who decided
                     to
                     massacre them all! Since the game runs incrementally and depends on player input,
                     every line the game generates or the player inputs can be undone using the
                     “revert” command. Therefore, whenever the story started to devolve into
                     nonsense, instead of generating a new story, and risk losing our progress, all we
                     had
                     to do was revert back a few lines and continue in a different direction. We next
                     tried (and failed) to roleplay as the lone surviving unicorn seeking revenge against
                     the explorer. As a last-ditch effort, we used the “alter” command to directly
                     incorporate the fact that the explorer was talking to a unicorn into the story, but
                     the game had a difficult time recognizing us, the second-person addressee, as
                     anything other than human, so we had to walk all the way back to the beginning
                     prompt, which then led to our sample playthrough.<a class="noteRef" href="#d4e335">[7]</a>
                     Compare our line-by-line rewriting to OpenAI’s “meta-cherry-picking” the story
                     of “Ovid’s Unicorn” from a set of generated samples, and
                     you begin to get a sense of the real possibilities of AID’s mechanics [<a class="ref" href="#openai2019a">OpenAI 2019a</a>]. 
                  </div>
                  
                  <div class="counter"><a href="#p5">5</a></div>
                  <div class="ptext" id="p5">The allure of AID is palpable through our own and the community’s experimentation
                     with the game. But the source of the appeal, AID’s novelty, is not necessarily the
                     structure of an AI-driven text adventure — after all, a PhD student had earlier
                     implemented the partial language model as “GPT Adventure” to little fanfare [<a class="ref" href="#whitmore2019">Whitmore 2019</a>].<a class="noteRef" href="#d4e354">[8]</a> From the start the centerpiece of popular reaction has been, as a
                     <cite class="title italic">Daily Beast</cite> journalist remarked, AID’s “capacity to slip into grim, hilarious, or bluntly surreal
                     terrain” — the seemingly limitless expanse that opens up for each player
                     with each game [<a class="ref" href="#hitt2019">Hitt 2019</a>]. Not only does it offer players the
                     opportunity to work with genre stories, but it also allows them to script
                     “custom” scenarios about weaponizing unicorn blood, which goes some way
                     toward fulfilling its marketing promise: “Anything is possible. Literally
                     anything.” Thus was it conceivable for <cite class="title italic">The Verge</cite>’s
                     Adi Robertson to write metafiction by getting the game to write about writing about
                     the game, for <span class="hi italic">Medium</span>’s Seb Chan to roleplay as a worker at an
                     art museum, and author Janelle Shane to become a dragon and eat the moon [<a class="ref" href="#vincent2019">Vincent 2019</a>]
                     [<a class="ref" href="#chan2019">Chan 2019</a>]
                     [<a class="ref" href="#shane2019">Shane 2019</a>]. Shane’s assertion that “the real gold
                     is the custom adventure prompt” underscores the point that AID might have
                     been a flash in the pan — another momentarily fun, but ultimately minor and
                     forgettable adaptation of GPT-2 — had it not been for Walton’s decision to add the
                     custom option and innovative gameplay mechanics that reimagine how we interact with
                     and assess language models [<a class="ref" href="#shane2019">Shane 2019</a>]. 
                  </div>
                  
                  <div class="counter"><a href="#p6">6</a></div>
                  <div class="ptext" id="p6">It is worth underscoring the extent to which players can build and manipulate to
                     their own specifications a multitude of game universes. Because AID’s inferences
                     about our world are only those that GPT-2 has gleaned from its 40GB training data
                     (and the subsequent fine-tuning with the choose-your-story corpus), the game cannot
                     completely replicate Newtonian physics; thus players can experience, and exploit,
                     absurdly malleable environments, the distinction between each one perhaps hinging
                     solely on the edibility of the moon.<a class="noteRef" href="#d4e400">[9]</a> It is difficult
                     to imagine a more enticing sandbox than one that allows players not just to build
                     within it but to remake the thing itself. The migration of player preference from
                     popular genres such as fantasy and mystery to a more open, “sandbox,” literary
                     mode, is evinced not only by the growing archive of custom stories on the AID site
                     but also by all the formal means by which people communicate enjoyment now, from the
                     vernacular idioms of social media to screams of delight during a video
                     stream.<a class="noteRef" href="#d4e409">[10]</a> What players are clearly riveted by is the surreal and
                     the absurd, paradoxically presented as lexical sense, as well as the game engine or
                     entity’s range of knowledge and linguistic competence.<a class="noteRef" href="#d4e414">[11]</a> Not only does it make correct use of the
                     past subjunctive, but it seems to know a great deal about popular culture, Internet
                     trivia, and obscure Japanese animated serials, and it can more than plausibly engage
                     the subject of coronaviruses.<a class="noteRef" href="#d4e437">[12]</a> In this
                     respect, the game is also an application in that it has demonstrated, in its
                     pantological ability to complete software code, top ten lists, and how-to tutorials,
                     its legacy as an application built on top of and driven by an all-purpose
                     text-completion algorithm. The content that AID can output is expansive and made even
                     more so by the game’s constant updates and changing player preferences, its capacity
                     for linguistic fluidity somewhat belied by its appearance as a basic command-line
                     text-adventure game.<a class="noteRef" href="#d4e441">[13]</a> We might thus say
                     that “custom” is an apposite classification for AID as a whole: a
                     build-your-own-world text adventure game, general purpose text generator, and
                     collaborative writing platform. 
                  </div>
                  
                  <div class="counter"><a href="#p7">7</a></div>
                  <div class="ptext" id="p7">Both the procedural and the unstructured mode of playing lay bare a gap in our
                     understanding of the game, and, by extension, the language model running in the
                     backend. Our research questions, then, are these: by what means, with what critical
                     toolbox or with which metrics, can AID, as a paradigmatic computational artifact,
                     be
                     qualitatively assessed, and which communities of evaluators ought to be involved in
                     the process? Parsing the code would be an integral aspect of any assessment exercise,
                     but technical analysis alone is not adequate, as we will suggest. An internal study
                     of a language model, which regardless would be counter-intuitive because of the
                     nature of its design, does not necessarily enable prediction of its decision-making
                     [<a class="ref" href="#kurzweil2012">Kurzweil 2012</a>, 160]
                     [<a class="ref" href="#knight2017">Knight 2017</a>]. Moreover, as we shall see, understanding the functioning
                     of a language model is not the same as knowing it.<a class="noteRef" href="#d4e465">[14]</a> Certainly one can read the generated stories in an ordinary sense, to
                     determine their formal properties and evaluate their aesthetic merits. Our
                     presupposition, however, is that it is not by itself sufficient to bring to bear on
                     the textual output of a machine learning system the apparatus of critical judgment
                     as
                     it has been honed over centuries in relation to language art as a putatively human
                     practice. What is striking even now is the extent to which humanistic evaluation in
                     the domain of language generation is situated as a Turing decision: <span class="hi italic">bot or not</span>. We do not however need tales of unicorns to remind us that
                     passable text is itself no longer a unicorn. And, as we will suggest, the current
                     evaluative paradigm of benchmarking generated text samples — comparing output to the
                     target data to assess its likeness — falls short when the source for generated
                     samples is neither stable nor fully knowable. 
                  </div>
                  
                  <div class="counter"><a href="#p8">8</a></div>
                  <div class="ptext" id="p8">It would seem that to reach an understanding of AID is to venture into the deep dark
                     caves of the giant itself, and to proceed with an ever-present awareness that its
                     corridors are constantly changing, perhaps even all different. It would be best to
                     bring a friend along, and to heed the warnings and sign posts erected by adventurers
                     that have preceded you. They are a crucial part of your exploration, offering field
                     knowledge to which the most expensive maps by the best cartographers cannot compare.
                     Dramatization aside, our suggestion will be that the best path towards a holistic
                     evaluation of AID is to do a different kind of code studies, different because the
                     object of inquiry is no longer code alone, but rather statistical distribution as
                     well as sociotechnical assemblage. Our challenge will be to articulate the scalar,
                     technological, and epistemological differences that AID presents, while still
                     allowing for its unstable, virtually <em class="term">ungrokkable</em>, quality, an attribute
                     the game shares with the content it outputs.<a class="noteRef" href="#d4e480">[15]</a> Our
                     premise is that the fast-growing AID presents an opportunity for researchers to study
                     language models in part through the lens of the experiences of its players, who
                     together form a dedicated, distributed community whose enthusiastic engagement
                     reskins the real work happening in the background: the training and assessment of
                     a
                     machine learning system by ordinary users.<a class="noteRef" href="#d4e489">[16]</a> This
                     engagement does not contest or seek to displace the current paradigm of scholarly
                     assessment of language models, but rather functions as a supplement to the
                     sought-after automated, yet qualitative, scheme of evaluating natural language
                     generation. 
                  </div>
                  
                  <div class="counter"><a href="#p9">9</a></div>
                  <div class="ptext" id="p9">There is no shortage of material endeavoring to explain language models and machine
                     learning for general audiences, from blog posts (e.g. <span class="error"><a href="#alamar2019">Alammar [2019]</a></span>) to podcasts and instructional videos. Although this
                     material is indisputably effective — as we can ourselves attest — it is an open
                     question as to whether a more interactive, hands-on, and targeted approach is more
                     instructive, even more enjoyable, for budding machine learning
                     practitioners.<a class="noteRef" href="#d4e501">[17]</a> Our contention then will be that AID provides different means
                     and modes of explaining Natural Language Processing (NLP) that are all the more
                     powerful for their activation of a communal sensibility and a spirit of play. What
                     AID affords is not unlike the “SimCity effect” that Noah
                     Wardrip-Fruin outlines in Expressive Processing, for it too helps its players to
                     understand complex software processes [<a class="ref" href="#wardrip2012">Wardrip-Fruin 2012</a>, 310]. And if
                     there is to be an “AID effect” with respect to a game built on top of a neural
                     network, it would be a prying open of the proverbial “black boxes” of machine
                     learning, and a summons not just to experience them firsthand, but also to affect
                     their decision making at the command line, a site where human language practice is
                     undergoing radical transformation.<a class="noteRef" href="#d4e519">[18]</a> As large language models continue to grow
                     in complexity and necessitate compute resources not readily available to ordinary
                     users, we can look to a GPT-2 implementation such as AID for the charting of a more
                     accessible and even responsible direction for user-oriented, <span class="hi italic">citizen NLP</span>. 
                  </div>
                  
               </div>
               
               <div class="div div0">
                  
                  <h1 class="head">2. How to understand large language models</h1>
                  
                  <div class="counter"><a href="#p10">10</a></div>
                  <div class="ptext" id="p10">In order to articulate how <span class="hi italic">AI Dungeon 2 </span>reimagines the
                     parameters of our relationship with machine learning, we must first establish a
                     current picture of the means by which experts and non-experts alike engage with and
                     attempt to understand language models (LMs).<a class="noteRef" href="#d4e552">[19]</a> We begin then with a basic description by
                     way of the Jorge Luis Borges fable, “The Library of
                     Babel,” the once-fictional and now-actual analog for digital text. How else
                     to explain AID’s promise of “infinite adventures” than
                     with the idea of a Library (universe) that contains books of all possible
                     combinations of 25 orthographic symbols — a library in which the vast majority of
                     books are gibberish but in which there must also exist every permutational
                     possibility, from copies of “Sonnet 18” not written by
                     Shakespeare to versions of the <cite class="title italic">Odyssey</cite> without Odysseus
                     as the hero? 
                  </div>
                  
                  <div class="counter"><a href="#p11">11</a></div>
                  <div class="ptext" id="p11">Language modeling is a subtask of natural language processing that aims to predict
                     the ‘next step’ in a sequence of words by calculating the maximum likelihood of the
                     next word given the previous ones, with the maximum likelihood subject to a
                     probability distribution learned from the training corpus: Wikipedia, Project
                     Gutenberg, or in the case of GPT-2, WebText, a corpus of some 8 million web pages
                     scraped from Reddit posts with a minimal number of karma points.<a class="noteRef" href="#d4e573">[20]</a> For language models at their current scale, Wikipedia
                     and Gutenberg are too small, delimited, and paradoxically singular, their
                     relationship to language too proprietary and protocological. WebText, by contrast,
                     buries any trace of a source text and results in non-indexical output, language that
                     does not point back to a discrete place of origin.<a class="noteRef" href="#d4e579">[21]</a> As researchers have shown, what is particularly
                     counter-intuitive is that the highest quality GPT-2 samples result from a degree of
                     randomness rather than maximum likelihood, as one would expect to be the case for
                     predictive text [<a class="ref" href="#holtzman2019">Holtzman et al. 2019</a>]. Adhering to rules and patterns is a
                     common strategy of maximal probability, so the less probable the move, the greater
                     the surprise.<a class="noteRef" href="#d4e590">[22]</a> (Another way in which GPT-2, as well as RNNs, are
                     distinct from early autocomplete models, is that the predicted tokens are fed back
                     into the model as input for future calculations.<a class="noteRef" href="#d4e596">[23]</a>) 
                  </div>
                  
                  <div class="counter"><a href="#p12">12</a></div>
                  <div class="ptext" id="p12">Given that language models are material entities — after all, neural networks are
                     collections of data points (often numbers) that are manipulated and stored via
                     computer code — it seems that we simply need to read, analyze, and study the code
                     in
                     order to understand these models.<a class="noteRef" href="#d4e607">[24]</a> Here we invoke Critical Code Studies (CCS), a reading
                     practice that has emerged from the humanistic disciplinary formations of textual
                     analysis and cultural studies [<a class="ref" href="#marino2006">Marino 2006</a>]
                     [<a class="ref" href="#marino2020">Marino 2020</a>].<a class="noteRef" href="#d4e625">[25]</a> The premise of CCS is that
                     computational literacy is empowering: if applied to language models, the argument
                     would be that prying open the black box and facilitating an elementary understanding
                     of some of the technical aspects of deep learning (e.g. Jupyter notebooks, Python,
                     linear algebra) may enable the transfer of this understanding to other contexts and
                     help illuminate some of the logics of choice and decision making.<a class="noteRef" href="#d4e664">[26]</a> With Software Studies and Platform Studies now
                     fully established as fields of inquiry, it can be taken as a given that code is a
                     “cultural text,” that it can be made “knowable,” and that, for example, examining a single line of
                     BASIC can, like its object, itself generate a labyrinthine world [<a class="ref" href="#montfort2012">Montfort et al. 2012</a>, 5, 6]. But for this new moment, or new situation, of
                     deep learning, which generally presents less interpretable problems and has sparked
                     the important field of interpretability studies, CCS may not on its own be sufficient
                     as a means of evaluating large language models.<a class="noteRef" href="#d4e678">[27]</a> Mechanistic explanations for
                     their operations are not unimportant and indeed the evolving scholarly conversation
                     on the architecture of neural networks, learning rules, and loss functions indicates
                     the extent to which what we might call a grammar of machine learning has already
                     emerged.<a class="noteRef" href="#d4e684">[28]</a> But absent an analysis of the relations between these
                     components or objects and the training datasets — and absent an analysis of these
                     systems in the wild, as they are used — then the study could really only be
                     statistical and functional.<a class="noteRef" href="#d4e693">[29]</a> This then raises the question of what it
                     means to understand a machine learning system: we can understand their operations
                     in
                     a technical or grammatical sense <span class="hi italic">in silico</span>, but CCS implicitly
                     relies upon a notion of understanding — drawing as it does on an Enlightenment
                     discourse of what is entailed in “study,” as a practice that accounts for and
                     systematizes the material properties of discrete entities — that is not available
                     for
                     machine learning systems, if for no other reason the fact that we do not yet have
                     a
                     consensus about either understanding neural networks or the meaning of
                     interpretability (cf. <a href="#lillicrap2019">Lillicrap and Kording
                        [2019]</a>). 
                  </div>
                  
                  <div class="counter"><a href="#p13">13</a></div>
                  <div class="ptext" id="p13">More plainly, CCS has historically worked with a fundamentally different
                     understanding of code: one that is <em class="emph">programmed</em> rather than
                     <em class="emph">trained</em>. The academic study <cite class="title italic">10 PRINT</cite> (in
                     shorthand) remains the gold standard for code studies, not least because of its
                     modeling of collective authorship [<a class="ref" href="#montfort2012">Montfort et al. 2012</a>]. And precisely
                     because of its field-defining status, it allows for a heuristic with which we can
                     mark this moment, and AID, as different: compare a one-line program that contains
                     and
                     generates multitudes (10 PRINT will not stop drawing mazes unless it is interrupted)
                     and multitudes (training data, compute resources, parameters, lines of code)
                     synthesized by an application so subject to continual variability that it cannot be
                     stabilized as an artifact, except insofar as it is made a “thing” by brand
                     identity and common use.<a class="noteRef" href="#d4e723">[30]</a> On the one hand we have a determinist model, the
                     notion that a computer program’s next state can be predicted via its previous state,
                     and on the other, an autoregressive language model, the training of which entails
                     stochastic and parallel processes that open up a variety of possible configurations
                     in which the model could exist. Add to this the continual retraining cycle and the
                     capricious human component across all domains of play, from unit inputs and player
                     discussion to “custom” stories, and it becomes clear that studying the code of
                     AID alone would not be especially revelatory, which reinforces the need for new
                     critical frameworks and methods.<a class="noteRef" href="#d4e732">[31]</a>
                     
                  </div>
                  
                  <div class="counter"><a href="#p14">14</a></div>
                  <div class="ptext" id="p14">It is then an understatement to say that the language models that increasingly inform
                     and populate our computational environments are no longer subject to the simple
                     input-output relations of something like Tristan Tzara’s “Dadaist
                     poem.” They have evolved to encompass interconnected parts and switches
                     with asynchronous mechanics both multifaceted and complex, and they are themselves
                     plugged into processing engines and distributed platforms more complex by orders of
                     magnitude.<a class="noteRef" href="#d4e742">[32]</a> However, to simply declare that
                     language models are too complex to understand is in our view an abdication of
                     critical responsibility, particularly in light of growing recognition of their
                     susceptibility to adversarial training and weight poisoning — more broadly, their
                     potential for misuse [<a class="ref" href="#alzantot2018">Alzantot et al. 2018</a>]
                     [<a class="ref" href="#viswanathan2020">Viswanathan 2020</a>]. If a complete mode of understanding is as-yet
                     unachievable, then evaluation is the next best thing, insofar as we take evaluation,
                     i.e. scoring the model’s performance, to be a suitable proxy for gauging and knowing
                     its capabilities. In this endeavor, the General Language Understanding Evaluation
                     benchmark (GLUE), a widely-adopted collection of nine datasets designed to assess
                     a
                     language model’s skills on elementary language operations, remains the standard for
                     the evaluation of GPT-2 and similar transfer learning models [<a class="ref" href="#wang2018">Wang et al. 2018</a>]
                     [<a class="ref" href="#radford2019">Radford et al. 2019</a>].<a class="noteRef" href="#d4e759">[33]</a> GLUE aggregates and displays a model’s
                     performance across all nine tasks on a public leaderboard, which was quickly
                     dominated by the Sesame Street Transformer models (ERNIE and copious variations of
                     BERT) that beat even the human baselines (a woeful rank 12 out of 33), thus
                     engendering the creation of SuperGLUE, an even harder benchmark that featured more
                     challenging and diverse tasks [<a class="ref" href="#wang2019">Wang et al. 2019</a>].
                  </div>
                  
                  <div class="counter"><a href="#p15">15</a></div>
                  <div class="ptext" id="p15">Especially striking, and central to our analysis, are two points: a model’s
                     performance on GLUE is binary (it either succeeds in the task or it does not) and
                     GPT-2 is notably absent from the public leaderboards (although the original GPT was
                     also beaten by Google’s BERT on GLUE).<a class="noteRef" href="#d4e775">[34]</a> The absence follows from the model’s primary talent: text generation,
                     the evaluation of which is a bit more muddled.<a class="noteRef" href="#d4e780">[35]</a>
                     Historically, the work of evaluating free-form text generation has been done by
                     expert human evaluators and is considered costly, labor-intensive and susceptible
                     to
                     subjectivity, motivating first the use of the crowdsourcing platform Mechanical Turk
                     and then the search for an automated scheme for evaluation. N-gram metrics such as
                     BLEU, ROGUE, and METEOR automate lexical matching exercises via different scoring
                     formulas, although it can be, and has been, argued that these metrics pale in
                     comparison to human evaluation [<a class="ref" href="#novikova2017">Novikova et al 2017</a>].<a class="noteRef" href="#d4e785">[36]</a>
                     Furthermore, although these metrics fall under the umbrella of NLG, they are used
                     for
                     specific tasks, with BLEU and METEOR used to evaluate machine translation and ROGUE
                     used for summary evaluation [<a class="ref" href="#see2019">See 2019</a>]. In a blog citing the
                     limitations of a metric-based evaluation, computer scientist Ehud Reiter remarks that
                     “we ultimately care about whether an NLG system produces
                     high-quality texts, not what its BLEU score is,” which is to say that
                     scoring may have no necessary relation to the more abstract, intangible, and even
                     incalculable quality, which is “quality” itself [<a class="ref" href="#reiter2017">Reiter 2017</a>]. Because metric-based evaluations of NLG can only function
                     as surrogate endpoints — a measuring of what practically can be measured — Reiter
                     goes on to advise that these evaluations be verified with “human-based study” and that researchers take care to curate a dataset of
                     “multiple high-quality reference texts” for
                     benchmarking [<a class="ref" href="#reiter2017">Reiter 2017</a>]. What then are the reference texts that
                     inform AID?
                  </div>
                  
                  <div class="counter"><a href="#p16">16</a></div>
                  <div class="ptext" id="p16">There are numerous dedicated language models, from the emulative Obama-RNN to “Deep-speare,” which was trained to produce Shakespearean
                     sonnets the crowdworking evaluators attributed to the bard himself with 50% accuracy
                     [<a class="ref" href="#hanlau2018">Han Lau et al. 2018</a>]. The efficacy and aesthetic capacity of such models
                     can thus be evaluated with the benchmarks of the original, i.e. if the speech sounds
                     as if it could belong to President Obama’s archive or if the quatrains read like a
                     newly discovered 17th-century manuscript, then the model can be said to work. But
                     if
                     the training corpus is not univocal — if there is no single voice or style, which
                     is
                     to say no single benchmark — because of its massive size, it is as yet unclear how
                     best to score the model. Along the same lines, given the generic templates for much
                     of AID’s game play, it is also possible to assess whether it is producing, for
                     example, good or bad mystery, even strong or weak fantasy, with an accounting for
                     the
                     formal elements of its output, as different structural analyses of narrative might
                     guide us to do (cf. Vladimir Propp, Claude Lévi-Strauss, Roland Barthes).<a class="noteRef" href="#d4e817">[37]</a> We might even
                     try to assess the similarities and differences between the output of AID and the
                     story corpus used in the fine-tuning and devise a formula for calculating the match
                     percentage.<a class="noteRef" href="#d4e820">[38]</a> But if a model might be said to
                     succeed or fail simply on the basis of imitation (<span class="hi italic">imago</span>, or
                     “<span class="hi italic">image</span>”), a concept that preserves not only the
                     copy but also the referent, the thing that is being copied, then a new mode and
                     manner of critical judgment is required when neither source nor target is either
                     stable or fully knowable. It would seem that much work in NLG evaluation operates
                     with the assumption that there must be so-termed model texts with which to compare
                     a
                     model’s output, yet AID’s genre-bending capacity complicates the exercise, as does
                     its community’s constantly-changing practices. 
                  </div>
                  
                  <div class="counter"><a href="#p17">17</a></div>
                  <div class="ptext" id="p17">Readers for whom the benchmarking exercise is new information might well have heard
                     in this account of textual imitation echoes of another Borges story, “Pierre Menard, Author of the Quixote,” and found themselves
                     wondering if one of its central lessons — that reading and writing are fundamentally
                     historical — has been forgotten. What of the insight that materially identical works
                     can have different aesthetic properties because they were produced by different
                     authors in different moments, which is to say that the quality of artworks cannot
                     be
                     determined apart from socio-cultural context? This question among others highlights
                     for us the need for more direct humanistic engagement in the development of language
                     models, from idea to artifact, and from training to evaluation. Humanists, we
                     maintain, should not be content to function as end-stage participants in advanced
                     NLP
                     research, appearing on the scene simply to judge the quality of output from a
                     language model as if judging entries for a creative writing award. AID, as an
                     experiment with GPT-2, provides a model for how humanists might more meaningfully
                     and
                     synergistically contribute to the project of qualitative assessment going forward,
                     and to do so in a manner not reducible to accreditation or legitimation. If
                     humanistic scholarship in the domains of science and technology has generally tended
                     toward an explanation of scientific phenomena and practices for other humanists, what
                     AID offers is a means by which humanistic techniques, concepts, and modes of thought
                     can be fed back into a machine learning system, and by extension into the research
                     domains of science and technology. 
                  </div>
                  
               </div>
               
               <div class="div div0">
                  
                  <h1 class="head">3. Experimenting with GPT-2</h1>
                  
                  <div class="counter"><a href="#p18">18</a></div>
                  <div class="ptext" id="p18">NLP was said to have achieved its “ImageNet moment” once language modeling, like
                     computer vision, embarked on the “pre-train first, fine-tune later” phase of
                     work.<a class="noteRef" href="#d4e854">[39]</a> Indeed, soon after the full
                     release of GPT-2, a Google Colab notebook allowed for free and easy fine-tuning, and
                     the work of updating a neural network’s weights became akin to a few presses of a
                     button [<a class="ref" href="#ruder2018">Ruder 2018</a>]
                     [<a class="ref" href="#woolf2019">Woolf 2019</a>]. What resulted was a remarkable creative burst from people
                     able to tweak their own copy of the model to generate, for example, “Ghost Flights” for NaNoGenMo [<a class="ref" href="#goodwin2019">Goodwin 2019</a>],
                     and in Walton’s case, to gamify the language model. Although fine-tuning did not
                     fundamentally alter GPT-2’s architecture, it did allow for an embodied understanding
                     of the language model itself. 
                  </div>
                  
                  <div class="counter"><a href="#p19">19</a></div>
                  <div class="ptext" id="p19">In this same spirit, we eagerly conducted our own fine-tuning experiments as part
                     of
                     the process of thinking through our research questions.<a class="noteRef" href="#d4e874">[40]</a> To start, we wondered, if GPT-2 were
                     fed nonsense, would it generate more nonsense? Using an excerpt from the online
                     implementation of Borges’ The Library of Babel (<a href="https://libraryofbabel.info" onclick="window.open('https://libraryofbabel.info'); return false" class="ref">https://libraryofbabel.info</a>) for
                     fine-tuning led to the generation of what can only be called garbage and thus taught
                     us the concept of overfitting, which is a model’s tendency to overmatch a limited
                     training dataset. We also used our nonsense dataset to study the precedence of
                     fine-tuning over pre-training — in other words, given that GPT-2 was pre-trained
                     using almost 40GB of putatively sensical English-language data, could one hour of
                     training it on gibberish make it forget all of its training? In a shocking finding,
                     we found that this was indeed possible, and we were able to coax the 355 million
                     parameter model to generate nonsense even when prompted with sense. For another
                     experiment, we wanted to see how GPT-2 manipulated and preserved semantic structure,
                     so we fed GPT-2 samples of visual poetry from George Herbert and Lewis Carroll to
                     Lorna Dee Cervantes’ “Valentine” and found that GPT-2 was
                     able to preserve the look and structure of a visual poem with new semantic content
                     (<a href="#figure02">Figure 2</a>).<a class="noteRef" href="#d4e904">[41]</a> (A failure to get GPT-2 to produce its own version of Carroll’s “Jabberwocky” made us aware of how much data a language model
                     needs to function properly; for this purpose, a much larger corpus of nonsense
                     literature would be required.) These experiments, which are admittedly not
                     groundbreaking, were nonetheless valuable to us as exercises and thus key to the
                     matter at hand. The true lesson, then, was that the missing tool from our evaluative
                     toolbox was actual, hands-on practice and play, which is precisely what AID, a
                     gamified language model, affords. 
                  </div>
                  
                  <div id="figure02" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure02.png" rel="external"><img src="resources/images/figure02.png" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 2. </div>Perturbing Shakespeare’s plays by shifting each line one space further to the
                        right allowed us to coax GPT-2 to generate new plays that reflected this same
                        visual structure.
                     </div>
                  </div>
                  
                  <div class="counter"><a href="#p20">20</a></div>
                  <div class="ptext" id="p20">We will not be the first to observe that this is the era of accessible machine
                     learning, but we can make this observation more precise by noting that in one hour,
                     in mid-2019, it was possible to retrain a 5GB language model on the cloud to generate
                     any text one chose, with no charge beyond now-baseline compute resources.<a class="noteRef" href="#d4e924">[42]</a> Such capability has truly
                     opened the door for amateurs, hobbyists, and autodidacts who want to study machine
                     learning and NLP and led to the emergence of an extra-institutional culture of
                     expertise. Telling the full story of this phenomenon is beyond the scope of this
                     article, but we can point to the exponential growth of the arXiv repository, along
                     with the collapse of the Courseware industry and the concomitant rise of YouTube as
                     a
                     learning center that substitutes on-demand access of multiple domain “how to”
                     videos for sequential instruction.<a class="noteRef" href="#d4e932">[43]</a> The shift to a more open culture of
                     machine learning can further be attributed to the Python programming language
                     (because of its readability and widespread use), Jupyter notebooks, APIs, deep
                     learning frameworks such as TensorFlow, and the public release of pre-trained
                     learning models that necessitate minimal fine-tuning and updating is necessary in
                     order to achieve good performance. We can recall AID’s origins as a collaborative
                     student hackathon project and now grasp the technological, economic, and cultural
                     conditions that made the game possible, while at the same time understanding it to
                     be
                     part of a fairly long-term tradition of amateur and hobbyist experimentation with
                     computational technologies and techniques, from the Homebrew Computer Club to the
                     <a href="https://creativecodecollective.github.io" onclick="window.open('https://creativecodecollective.github.io'); return false" class="ref">Creative Code
                        Collective</a>.
                  </div>
                  
               </div>
               
               <div class="div div0">
                  
                  <h1 class="head">4. AI Dungeon as case study</h1>
                  
                  <div class="counter"><a href="#p21">21</a></div>
                  <div class="ptext" id="p21">Underlying the different affective reactions to AID is a remarkably consistent,
                     almost-formulaic mode of analysis: commentators explain the game and how it works,
                     describe a few noteworthy playthroughs (with an emphasis on the aforementioned <span class="hi italic">surrealness</span>), and then perhaps offer some reflections on
                     collaborative writing and artificial intelligence more generally (see, e.g., <a href="#ars2020">Ars [2020]</a>). This template for the game’s reception, a
                     paradoxically non-formalized but uniform exercise of critical judgement, opens a
                     window onto the means by which AI enthusiasts — a category that names hobbyists and
                     supposed non-experts — have endeavored to assess novel technological artifacts such
                     as AID. More specifically, the template tells a story about how machine learning is
                     understood and evaluated by audiences outside the labs. There are two significant
                     motifs that we can detect in the otherwise MacGyvered disciplinary hodgepodge of
                     statistical model evaluation, media analysis, narratology, and game studies. First,
                     because GPT-2 in particular was from the start mystified as a black box, too mad and
                     dangerous to know, there is a sense that people wanted to pry it open, to get under
                     the proverbial hood and exploit its flaws and capabilities. 
                  </div>
                  
                  <div class="counter"><a href="#p22">22</a></div>
                  <div class="ptext" id="p22">In an interview with Walton, <cite class="title italic">Gamasutra</cite>’s John Harris
                     indirectly raises the black box problem with questions about “how
                     [the game] works” and the “data massage needed to
                     produce usable input and/or output”
                     [<a class="ref" href="#harris2020">Harris 2020</a>]. There are many such questions in what is evolving to
                     become a discourse on the game, with much of the activity playing out on the
                     r/aidungeon subreddit.<a class="noteRef" href="#d4e975">[44]</a> Begun on December 6, a day after the game’s
                     release and unbeknownst to Walton, the Reddit community boasts 31,000 members as of
                     this writing.<a class="noteRef" href="#d4e982">[45]</a> Although wacky
                     playthroughs dominate the forum’s top posts (and themselves constitute a mode of
                     evaluation), the frequently asked questions list pinned to the top of the page is
                     particularly instructive and demonstrates the community’s systematic process of
                     collaboratively discovering the game’s — and the language model’s — quirks. A simple
                     search within the subreddit for permutations of the phrase “how does <span class="hi italic">x</span> work” returns a plethora of game mechanics-related
                     questions and a corresponding laundry list of answers; even more significant is the
                     game’s presence on other Reddit communities such as r/learnmachinelearning. As we
                     will outline in this section, AID’s mechanics make a compelling contribution to the
                     theory and practice of explainable machine learning because they allow players to
                     interact with, and subsequently understand and exploit, the underlying language model
                     in nontrivial ways. 
                  </div>
                  
                  <div class="counter"><a href="#p23">23</a></div>
                  <div class="ptext" id="p23">As might be expected, playing has itself been a crucial part of understanding the
                     game.<a class="noteRef" href="#d4e997">[46]</a> There is a clear parallel here between the
                     engagement of language models via gameplay and Colin Milburn’s research on play as
                     a
                     means by which amateurs apprehend, and become participants in, the research domain
                     of
                     nanotechnology. As he argues in <cite class="title italic">Mondo Nano</cite>, “play is a form of engagement, a manner of learning, experiencing,
                     and experimenting from the bottom up, little by little, bit by bit...[W]hen it is
                     no longer possible to imagine sufficient mastery of anything, having fun becomes a
                     significant alternative to having formal expertise, an alternative to being
                     totally on top of things”
                     [<a class="ref" href="#milburn2015">Milburn 2015</a>, 294]. Fundamental to Milburn’s analysis, and indeed
                     to AID, is the notion that “the play’s the thing” — in
                     other words, players may profess an interest in the game rather than laboratory
                     research, but gameplay in fact serves as a mask for the real work of model training,
                     evaluation, and improvement.<a class="noteRef" href="#d4e1015">[47]</a> The
                     extent to which OpenAI has itself constructed the stage here should not be
                     overlooked. Although OpenAI did partner with institutional entities to perform
                     post-release analysis, their decision to make GPT-2 available to the public points
                     to
                     the value, and indeed necessity, of amateur participation for machine learning
                     research.<a class="noteRef" href="#d4e1024">[48]</a>Technical model evaluation cannot of course
                     fully anticipate how the model will perform and be used — racist Twitter bots might
                     be Exhibit A here<a class="noteRef" href="#d4e1031">[49]</a> — so public release clearly benefits
                     researchers, but at the same time helps to develop the general intellect, that
                     techno-social formation that animates production. While we do not seek in this
                     article to formalize a method for extra-institutional evaluation, we nonetheless wish
                     to highlight AID gameplay as an assessment practice that extends well beyond the
                     control of a small number of data scientists and in this regard participates in the
                     larger realignment of experts and amateurs vis-à-vis applied research.<a class="noteRef" href="#d4e1045">[50]</a>
                     
                  </div>
                  
                  <div class="counter"><a href="#p24">24</a></div>
                  <div class="ptext" id="p24">AID’s free, user-friendly, point-and-click web interface (it is not necessary to
                     download a model or to install programming distributions) contributes to the game’s
                     accessibility, but the true invitation to participate is extended by the mechanics
                     themselves. The “custom” scenarios option further frees players from the need to
                     be proficient, or even familiar, with the canonical text adventure genres as a
                     prerequisite for engagement. Indeed, all it takes is imaginative seed text to
                     experience the game as, for example, a crazed inventor weaponizing a unicorn’s blood,
                     as Aragon on his journey from <cite class="title italic">The Lord of the Rings</cite>, or
                     even as a livestreamer who has hit a bit of bad luck.<a class="noteRef" href="#d4e1060">[51]</a> Even then, AID’s unstructured mode of playing ensures that the underlying
                     language model is never locked into any one mode of content generation, effectively
                     expanding the picture of GPT-2’s supposed ceiling of fine-tuning [<a class="ref" href="#radford2019">Radford et al. 2019</a>, 9]. By allowing players to play with the language
                     model not only through a text adventure game, but also through conversation, coaxing
                     it for example to describe non-existent memes and whatever future forms of content
                     they might imagine, Walton is thus indirectly helping OpenAI benchmark GPT-2’s
                     capabilities, albeit in a less formalized fashion.<a class="noteRef" href="#d4e1068">[52]</a> In this
                     respect, it can take its place alongside the puzzle game Borderlands Science, the
                     playing of which contributes to the mapping of the gut microbiome. 
                  </div>
                  
                  <div class="counter"><a href="#p25">25</a></div>
                  <div class="ptext" id="p25">If the end goal of NLG evaluation is to produce high-quality text that benefits the
                     end user, then AID is a model of personalized content generation that ensures the
                     user is in direct control of the generation. This creative writing process, and
                     latent evaluative process, is developed by an array of advanced commands that reward
                     discovery and experimentation and at the same time discretize the process of neural
                     text generation. These commands, which used to take the archaic form of console
                     commands but have now been replaced by user-friendly buttons, give players direct
                     control of both text and world generation.<a class="noteRef" href="#d4e1075">[53]</a> But they also directly invite player feedback, criticism,
                     and ideas for improvements, and it is on this basis that we can claim that Walton
                     and
                     his team are indirectly prototyping models of automated evaluation, human-machine
                     collaboration, and ethical machine learning research. 
                  </div>
                  
                  <div class="counter"><a href="#p26">26</a></div>
                  <div class="ptext" id="p26">To start, the “revert” command allows players to undo and return to any previous
                     instance of the ongoing narrative, effectively partitioning the collaborative writing
                     process into unit utterances, as opposed to a traditional input-output pipeline. In
                     this sense, AID emphasizes processes of revision and serves as a compelling model
                     of
                     an ethical approach to Artificial Intelligence, one that prioritizes means over
                     outcomes. Stuart Russell makes the case for a reorientation of the field of AI on
                     this basis, the necessity of which becomes starkly apparent if one considers that
                     a
                     hypothetical problem such as “solve global warming” would
                     not preclude a strategy of “killing all the humans” in
                     order to achieve that goal [<a class="ref" href="#russell2019">Russell 2019</a>]. In that AID shifts the focus
                     away from a final revelation or resolution and instead foregrounds step-by-step
                     moves, plays, and utterances that can be revoked, it similarly takes an incremental
                     rather than ends approach to machine learning. It is also meaningfully collaborative:
                     helping the system learn what is good and what works requires that players
                     continually think about the criteria they are using for model evaluation and about
                     what they want from the text generator. 
                  </div>
                  
                  <div class="counter"><a href="#p27">27</a></div>
                  <div class="ptext" id="p27">AID’s availability for responsible machine learning is further evinced by the memory
                     feature. An experimental command of AID’s, rather than OpenAI’s innovation,
                     “remember” allows users to specify bits of information that are continually fed into
                     GPT-2 at each step of the prediction, effectively forcing the language model to
                     always remember. Our test story of Ovid’s Blood is again instructive. In another
                     round of play, we committed to memory the identity of the player as a unicorn and
                     were subsequently able to prompt the language model to generate text that plausibly
                     assumed a nonhuman subject of the story (<a href="#figure03">Figure 3</a>).
                     Although research on implementing memory for neural networks is not novel [<a class="ref" href="#weston2014">Weston et al. 2014</a>] and the “remember” command does not actually change
                     GPT-2’s architecture, nonetheless, it is at the very least reimagining how we
                     interact with the language model. That “remember” should be a hobbyist solution
                     to one of machine learning’s more pressing concerns speaks to the value of <span class="hi italic">citizen NLP</span> and validates OpenAI’s indeed-open model of
                     research. It is not difficult to see the science-fictional possibilities in
                     “remember” — imagine committing Isaac Asimov’s Three Laws to memory — but in
                     practical and concrete terms it does shift the Overton window on our expectations
                     of
                     machine learning, which a game like AID is training us to understand as a more
                     deliberate, responsive, and collaborative research activity.
                  </div>
                  
                  <div id="figure03" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure03.png" rel="external"><img src="resources/images/figure03.png" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 3. </div>Playthrough of Ovid’s Blood as a unicorn (subject position established with
                        “remember” command)
                     </div>
                  </div>
                  
                  <div class="counter"><a href="#p28">28</a></div>
                  <div class="ptext" id="p28">Even more on point is the “alter” command, which allows the players to directly
                     edit the textual output and guide the narrative forward in whichever manner or
                     direction is desirable. While line edits might seem initially as another version of
                     the fork-in-the-road structure of a traditional text adventure game — if the story
                     does not take you where you want to go, you return to a control point and make
                     another decision — what is at stake with this mechanic goes well beyond syntactic
                     sense and narratological completion, as we learned while working on our story of
                     Ovid’s Blood.<a class="noteRef" href="#d4e1130">[54]</a> From the
                     start, without any gender specified, AID assumed the American inventor was male, and
                     thus provided a textbook instance of the doctor : man :: nurse : woman bias problem
                     [<a class="ref" href="#buonocore2019">Buonocore 2019</a>]. To remedy this, we altered the pronoun in the
                     output line, “The inventor succeeds, but unfortunately <span class="hi italic">his</span> invention,” from male to female and were then
                     able to coax the model to independently generate the subsequent line, “After several years, the inventor finally announces that
                     <em class="emph">she</em> has bred the first unicorn calves” (<a href="#figure04">Figure 4</a>). Although we are under no illusions about our
                     ability to redress the underlying language model’s biases comprehensively, it is not
                     insignificant that a human can both explicitly revise a machine learning decision
                     and
                     implicitly train a system to (appear to) think differently.<a class="noteRef" href="#d4e1166">[55]</a> What “alter”
                     makes apparent is that NLG processes do not need to be closed to the public and that
                     automation need not entail the exclusion of humans. It reminds us then that we have
                     the capacity to intervene and shape machinic text <span class="hi italic">in actual
                        collaboration</span> with machines. It is up to players to determine what the
                     process of writing with a language model should involve, whether that be concession
                     to a machine decision or substantive revision. And, to return to the figure of the
                     ouroboros, what results is a hybrid corpus of high quality machine-human text that
                     can be further regressively used for training.<a class="noteRef" href="#d4e1181">[56]</a>
                     
                  </div>
                  
                  <div id="figure04" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure04.png" rel="external"><img src="resources/images/figure04.png" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 4. </div>Sample <cite class="title italic">AI Dungeon 2</cite> game play (gender bias
                        correction using “alter” command) 
                     </div>
                  </div>
                  
                  <div class="counter"><a href="#p29">29</a></div>
                  <div class="ptext" id="p29"> Apart from its multiplayer mode, the collaborative aspect of AID is perhaps nowhere
                     more apparent than in its contributor studio, through which players can provide
                     feedback on the game.<a class="noteRef" href="#d4e1202">[57]</a> (Popups during gameplay additionally ask players to
                     evaluate the game’s performance in its current state, albeit with a limited set of
                     descriptors, e.g. “great” and “offensive,” from which to choose). Through
                     the studio, players can also importantly create labels for quests, characters, and
                     action difficulty. Such labels help the narrator identify quests that organically
                     spawn during play, maintain dossiers on non-player characters, and even begin to
                     tighten AID’s outlaw system of physics. It must be acknowledged that the addition
                     of
                     labeling is symptomatic of the ongoing fetishization of unsupervised learning, and
                     it
                     also buys into the tacit quid-pro-quo contract that lies behind social media: free
                     use in exchange for labor and data.<a class="noteRef" href="#d4e1213">[58]</a> Nonetheless, the labeling
                     feature attests to the open, distributed, and relatively accessible culture of NLP
                     research and makes an implicit but strong case for continuing down the path of the
                     hackathon rather than the closed lab.
                  </div>
                  
                  <div class="counter"><a href="#p30">30</a></div>
                  <div class="ptext" id="p30">All very interesting as an exercise in distributed and crowdsourced machine learning
                     research, the skeptic might protest, but is the writing any good in the end? It is
                     this question that led us to consider the extent to which the tools and paradigms
                     of
                     qualitative evaluative judgment from the scientific and humanistic disciplines alike
                     might fall short in relation to an artifact such as AID. A technical analysis of the
                     model’s internals, albeit necessary, looks only at the building blocks and
                     hypothesizes its use cases. And to simply assess the output in relation to benchmarks
                     is to overlay a static, even mechanical, in-out, copy-original structure on top of
                     a
                     machine learning system with internal data flows taking the form of a byzantine
                     network of zigzagging numbers in a state of continuous transformation.<a class="noteRef" href="#d4e1223">[59]</a> Add to this the complexity of a
                     game that is itself evolving by the day, leading to ever deeper entanglements between
                     human and machine writers, and it becomes clear that a binary evaluation (good story,
                     bad story) can tell us little about the material circumstances of the text’s
                     production. 
                  </div>
                  
                  <div class="counter"><a href="#p31">31</a></div>
                  <div class="ptext" id="p31">It turns out then that the best evaluation is done by and with AID itself. If
                     human-based studies and the qualitative metrics currently in use in NLG research —
                     readability, likeability, utility — can only ever be subjective, thus necessitating
                     the forging of a kind of consensus through crowdsourcing, an even more powerful and
                     persuasive evaluative scheme can be found in a game that gives players the tools not
                     only to shape the very content they will consume, and thus implicitly assess, but
                     also to train and modify the system that is producing that same content. AID
                     crystallizes for us the potential of an open model of machine learning research: an
                     exponential number of people are able to create new knowledge, and in some cases,
                     be
                     legitimized by the very institutions that granted them access, as with OpenAI
                     recognizing Gwern and AID. But what such a mutable and mobile culture of NLP demands
                     is an evaluation scheme that can scale and keep pace — in other words, a unicorn.
                     
                  </div>
                  
               </div>
               
               <div class="div div0">
                  
                  <h1 class="head">5. GPT-3 and beyond</h1>
                  
                  <div class="counter"><a href="#p32">32</a></div>
                  <div class="ptext" id="p32">When we began this article, speculations about GPT-3 were simply that, speculations.
                     The speed of machine learning research should surprise no one, but on May 28, 2020,
                     GPT-3 surprised us nonetheless, not simply with its size but also with its text
                     samples of (again) “unprecedented quality,” the most
                     startling of which must surely be its continuation of Trurl’s Electronic Bard,
                     prompted by but not fine-tuned on Stanislaw Lem [<a class="ref" href="#openai2019a">OpenAI 2019a</a>]
                     [<a class="ref" href="#branwen2020">Branwen 2020</a>]. The model, which was announced without public release,
                     crystallized for us, and for the researchers themselves, the ongoing problem of
                     interpretability and training data bias [<a class="ref" href="#brown2020">Brown et al. 2020</a>, 34]. But we
                     took particular note of the departure from the fine-tuning paradigm, given our
                     advocacy for accessibility and experimentation by end users, and found our investment
                     in AID’s mechanics as models for more responsible machine learning affirmed [<a class="ref" href="#openai2020">OpenAI 2020</a>]. After all, the initial training data for GPT-2 and GPT-3
                     is “ours” — and we therefore have a significant stake in how this archive is
                     modified, curated, and used to model normative language processes.<a class="noteRef" href="#d4e1254">[60]</a> We have a stake as well in
                     training, evaluating, and collaborating with the autonomous systems that will
                     continue to speak and write on our behalf. Part of the purpose of this article has
                     been to describe a site in which this work is already well underway. 
                  </div>
                  
                  <div class="counter"><a href="#p33">33</a></div>
                  <div class="ptext" id="p33">Central to our thesis is the claim that citizen NLP is fundamental to maintaining
                     public purchase on the dizzying pace of the <em class="emph">development</em> and subsequent
                     <em class="emph">deployment</em> of machine learning models. Indirect support for this
                     claim came from Chief Facebook AI scientist Yann LeCun, in a speech on our campus,
                     the University of California, Santa Barbara. Riffing on Richard Feynman, LeCun
                     professed that “you don’t really understand something until you
                     build it yourself” and directly called for engineers and tinkerers alike to
                     continue to build the models that will inform the theory of artificial intelligence
                     [LeCun 2018]. This is precisely the lens through which to view the remarkable
                     creative exploits of AID: as procedural literacy practices that enable the transfer
                     of human decisions to machine learning systems and help us to build worlds, from the
                     command line to the moon. 
                  </div>
                  
               </div>
               
               
               
               
               
            </div>
            
            <div id="notes">
               <h2>Notes</h2>
               <div class="endnote" id="d4e217"><span class="noteRef lang en">[1]  To the best of our knowledge, there has to date been just one
                     description of AID in humanities scholarship. In his overview of the game, Mark
                     Sample proposed it as “a perfect object of study for so many
                     disciplines in the humanities”
                     [<a class="ref" href="#sample2020">Sample 2020</a>]. Our article shows why that is indeed the case.</span></div>
               <div class="endnote" id="d4e228"><span class="noteRef lang en">[2] GPT is short for “Generative Pretrained Transformer.” The
                     model was trained on a massive quantity of linguistic data to predict the next
                     token in a sequence; this learning was unsupervised, which means the data was
                     unlabeled and the model discovered within it the rules, patterns, and statistical
                     features that then determined the generation of tokens. </span></div>
               <div class="endnote" id="d4e239"><span class="noteRef lang en">[3] In August 2019, two graduate students replicated the 1.5b parameter
                     model (as did others), and OpenAI soon thereafter did its 50% release (774m
                     parameters). In November 2019, they released the full model, citing an only
                     marginally better credibility score assigned to its output, after which it became
                     possible for the public to verify the claims for GPT-2’s capability. Throughout
                     our text, “GPT-2” refers to the full 1.5b model unless otherwise
                     noted.</span></div>
               <div class="endnote" id="d4e272"><span class="noteRef lang en">[4] <cite class="title italic">AI Dungeon 2</cite> is hereafter abbreviated
                     “AID.”</span></div>
               <div class="endnote" id="d4e279"><span class="noteRef lang en">[5]  Cf.
                     <a href="#bogost2015">Bogost (2015)</a> on Google as a “confluence of physical, virtual, computational, and
                     non-computational stuffs.”</span></div>
               <div class="endnote" id="d4e314"><span class="noteRef lang en">[6] Text preceded
                     by “&gt;” is our input and the game’s responses follow after the paragraph
                     breaks, although the observation that it is difficult to differentiate between our
                     writing and that of AID is apropos. Hereafter, our experimentation with this seed
                     text is identified as “Ovid’s Blood.”</span></div>
               <div class="endnote" id="d4e335"><span class="noteRef lang en">[7]  The game assumes the player
                     is a human male unless otherwise specified, as we will discuss below.</span></div>
               <div class="endnote" id="d4e354"><span class="noteRef lang en">[8]  The idea of a narrative generating system that
                     could learn from previously written stories, and thus has theoretically limitless
                     potential, has been realized as “Scheherazade-IF”
                     [<a class="ref" href="#guzdial2015">Guzdial 2015</a>]. Natural language researchers have also used text
                     adventure games to train machine learning systems [<a class="ref" href="#yang2017">Yang et al. 2017</a>].</span></div>
               <div class="endnote" id="d4e400"><span class="noteRef lang en">[9] As <a href="#marcus2018">Marcus (2018, 11)</a> explains, deep learning models can only approximate
                     physical laws because they are learned rather than encoded.</span></div>
               <div class="endnote" id="d4e409"><span class="noteRef lang en">[10] “AIPD” on Twitch is a streaming channel dedicated to playing
                     and streaming AID. </span></div>
               <div class="endnote" id="d4e414"><span class="noteRef lang en">[11] It is unclear whether the
                     “Eliza effect,” the “illusion that an interactive
                     system is more ‘intelligent’ (or substantially more complex and capable)
                     than it actually is,” pertains in the instance of an unsupervised
                     learning model like GPT-2 [<a class="ref" href="#wardrip2012">Wardrip-Fruin 2012</a>, 25]. If a non-trivial
                     aspect of the “Eliza effect” is test subjects’ tacit willingness to overlook
                     obvious conceptual and syntactic errors in order to believe in the intelligence of
                     an agent, perhaps we need a new critical vocabulary to account for the hedging we
                     must now do on the question of actual, as opposed to illusory intelligence.
                     Regardless of whether or not GPT-2 understands in the full sense the symbols it is
                     processing, it is indisputable that it “has [untaught]
                     faculties... specific skills, that require a certain precision of
                     thought,” as the Slate Star Codex blogger delineates [<a class="ref" href="#alexander2019">Alexander 2019</a>]. </span></div>
               <div class="endnote" id="d4e437"><span class="noteRef lang en">[12] In the Spring of COVID-19, the game introduced
                     weekly scenarios on quarantine and Tiger King that reflected the zeitgeist of the
                     moment. These adventures now appear as archived genre options. </span></div>
               <div class="endnote" id="d4e441"><span class="noteRef lang en">[13]  If interactive fiction as evinced most notably by <cite class="title italic">Adventure</cite> and <cite class="title italic">Zork</cite> relies on
                     the structure of the puzzle to control the unfolding of the narrative, AID, both
                     in its generic template and “custom” modes, offers what might be generally
                     characterized as free play [<a class="ref" href="#montfort2003">Montfort 2003</a>]. The difference is most
                     stark at AID’s command line, where input is not constrained by pre-scripted
                     actions, allowing players’ flights of fancy to translate more or less seamlessly
                     into the game world. Narrative progression thus depends less on puzzle solving and
                     critical thinking and more on the players’ own writing.</span></div>
               <div class="endnote" id="d4e465"><span class="noteRef lang en">[14] If we only do a rules-based
                     evaluation, either statistical or linguistic, in order to try to understand a
                     large language model, we risk missing what is happening at the level of rhetoric
                     (for translator Gayatri Spivak, rhetoric is the plane or dimension of language
                     that one has to access in order to know and sense the voice of a text in a
                     different language; it is what makes it possible to inhabit someone else’s
                     umwelt). A purely technical analysis would also sideline the element of social
                     contract and reduce language to a set of rules only. As we will later note with
                     respect to its probability distributions, what makes GPT-2 work are the moments
                     when it breaks with the rules of grammar and logic and becomes rhetorical, the
                     best example of which is “Ovid’s unicorn.”
                     </span></div>
               <div class="endnote" id="d4e480"><span class="noteRef lang en">[15] The release of GPT-3, the next
                     iteration of the model, on May 28, 2020, when we were in the end stages of writing
                     this article, has made us even more acutely conscious of the difficulties of
                     stabilizing our object of inquiry. Six months on, regular AID gameplay is still
                     limited to GPT-2, but GPT-3 has been made available for some creative
                     experimentation (e.g. <a href="#branwen2020">Branwen [2020]</a>) and can now
                     be accessed as a “Dragon model” with an AID premium subscription. </span></div>
               <div class="endnote" id="d4e489"><span class="noteRef lang en">[16] GPT-2, and Transformer models more
                     generally, are examples of <em class="emph">deep</em> machine learning, the operations of
                     which are generally held to be less interpretable than supervised learning models
                     with algorithms such as k-nearest neighbors and linear regression. </span></div>
               <div class="endnote" id="d4e501"><span class="noteRef lang en">[17] See <a href="#yang2019">Yang et al. (2019)</a> for an
                     argument for making machine learning models accessible and interactive, albeit not
                     playable. </span></div>
               <div class="endnote" id="d4e519"><span class="noteRef lang en">[18] As befits its history as a fundamental
                     concept for cybernetics [<a class="ref" href="#ashby1957">Ashby 1957</a>], the “black box” metaphor
                     is ubiquitous in discussions of artificial intelligence and often used as a
                     shorthand for the problems of explainability and interpretability [<a class="ref" href="#adadi2018">Adadi and Berrada 2018</a>]
                     [<a class="ref" href="#russell2019">Russell 2019</a>]. It is interesting to consider the relations between
                     this notion of obscuration and the more sinister, political usages of the concept
                     in, for example, <cite class="title italic">The Black Box Society</cite>
                     [<a class="ref" href="#pasquale2016">Pasquale 2016</a>]. </span></div>
               <div class="endnote" id="d4e552"><span class="noteRef lang en">[19]  Our article was written before the
                     publication of [<a class="ref" href="#mcgillivray2020">McGillivray et al. 2020</a>], but it aligns with their call for
                     more collaborations and connections between the Natural Language Processing and
                     Digital Humanities communities. </span></div>
               <div class="endnote" id="d4e573"><span class="noteRef lang en">[20] If prior
                     training data from Project Gutenberg and Wikipedia tacitly suggested, in T.S.
                     Eliot’s language, “the common word exact without
                     vulgarity,” which is to say standard English, with all the notions of
                     the proper and the correct that implies, the WebText corpus suggests instead that
                     there is no common word. It is training for a language model that does not itself
                     model communication.</span></div>
               <div class="endnote" id="d4e579"><span class="noteRef lang en">[21] We note that GPT-3 is so
                     large that OpenAI had to guard against an ouroboros problem by vetting its
                     training data to ensure that datasets used for evaluation were not themselves
                     incorporated into the training data [<a class="ref" href="#brown2020">Brown et al. 2020</a>, 30]. This
                     indicates the extent to which language models perform exponentially better as the
                     datasets become more comprehensive [<a class="ref" href="#halevy2009">Halevy et al. 2009</a>]
                     [<a class="ref" href="#banko2001">Banko and Brill 2001</a>].</span></div>
               <div class="endnote" id="d4e590"><span class="noteRef lang en">[22] The uncanny liveliness of AID’s writing about magical unicorn
                     blood, then, results not only from its adherence to genre templates, but also from
                     its slight break from the obvious and the expected. One conclusion to draw from
                     this: humans may seem to display a preference for appropriation, mimesis, and
                     memetic expression — everyone is always copying everyone else — but in actual
                     linguistic practice, turbulent distribution is the mark of an authentic
                     “human” style.</span></div>
               <div class="endnote" id="d4e596"><span class="noteRef lang en">[23] On autoregression, see <a href="#karpathy2015">Karpathy (2015)</a>. When it was released, the game
                     fed GPT-2 up to the last eight pairs of player input and game response for
                     prediction, but this has since been expanded [<a class="ref" href="#walton2019d">Walton 2019d</a>]. The
                     game also allows players to pin certain lines to the language model’s memory
                     context, which are always fed into the model at each prediction step. </span></div>
               <div class="endnote" id="d4e607"><span class="noteRef lang en">[24]  Work by <a href="#bengio2003">Bengio et
                        al. (2003)</a> and <a href="#xu2000">Xu and Rudnicky (2000)</a> has
                     seen LMs in recent years take the form of a neural network [<a class="ref" href="#jing2019">Jing and Xu 2019</a>], and work by <span class="error"><a href="#vaswani2017">Vaswani et al. (2017)</a></span> has seen
                     the network architecture (or type) of the best LMs at present to be
                     Transformers.</span></div>
               <div class="endnote" id="d4e625"><span class="noteRef lang en">[25] Mark Marino’s initial articulation of “Critical
                     Code Studies,” which synthesized a range of practices and conversations
                     about “codework” and how the humanities ought to think about programming
                     languages, proposed “that we no longer speak of the code as a
                     text in metaphorical terms, but that we begin to analyze and explicate code as
                     a text, as a sign system with its own rhetoric, as verbal communication that
                     possesses significance in excess of its functional utility”
                     [<a class="ref" href="#marino2006">Marino 2006</a>]. In the book form of the argument, the call to “read code the way we read poetry,” which summons the
                     entire critical apparatus of textual studies, semiotics, deconstruction, critical
                     theory, and cultural studies for this purpose, is presented in the form of the
                     manifesto [<a class="ref" href="#marino2020">Marino 2020</a>, 31]. Marino is on this point following
                     Alexander Galloway’s articulation of computers as “fundamentally a textual medium...based on a technological language called
                     code”
                     [<a class="ref" href="#galloway2004">Galloway 2004</a>, xxiii–xxiv]. So, too, Dennis Tenen encourages
                     those who might regard themselves as mere users of computational technology “to apply the same critical acuity they employ in the close
                     reading of prose and poetry to the understanding of code and machine”
                     [<a class="ref" href="#tenen2017">Tenen 2017</a>, 21]. Foundational for this vein of thought is
                     Michael Mateas’ concept of “procedural literacy,” which
                     he defines as “the ability to read and write processes, to
                     engage procedural representation and aesthetics, to understand the interplay
                     between the culturally-embedded practices of human meaning-making and
                     technically-mediated processes”
                     [<a class="ref" href="#mateas2005">Mateas 2005</a>, 101]. </span></div>
               <div class="endnote" id="d4e664"><span class="noteRef lang en">[26] One of the
                     most influential versions of this literacy argument is made by Noah Wardrip-Fruin
                     in his aforementioned inaugural work of software studies [<a class="ref" href="#wardrip2012">Wardrip-Fruin 2012</a>].</span></div>
               <div class="endnote" id="d4e678"><span class="noteRef lang en">[27] For a general catalog of
                     research on the epistemological problem of interpretable machine learning, see
                     <a href="#we1s2020">WE1S (2020)</a>. </span></div>
               <div class="endnote" id="d4e684"><span class="noteRef lang en">[28] One field of study that works toward a technical understanding of
                     NLP operations is “BERTology,” which investigates large Transformer-based
                     language models like BERT and GPT-2. Common research in this field attempts to
                     interpret how a model processes data while revealing their inner representation
                     (parameters, weights, hidden states) (e.g <a href="#tenney2019">Tenney et al.
                        [2019]</a>). </span></div>
               <div class="endnote" id="d4e693"><span class="noteRef lang en">[29] David Berry makes the additional point that complex
                     math itself presents a high bar, thus necessitating analogies and explanatory
                     models whose aesthetics or metaphorical functioning will also require examination
                     [<a class="ref" href="#berry2018">Berry 2018</a>]. </span></div>
               <div class="endnote" id="d4e723"><span class="noteRef lang en">[30] As of this writing, there are 446 forks of AID’s GitHub
                     repository, the most notable of which are cloveranon and thadunge2, the two most
                     popular unofficial releases of the game that implemented their own features.
                     Additionally, an app- and ad-based copycat of the game (“The
                     Infinite Story”) has prompted a debate within the community about IP and
                     AID’s open-source model. </span></div>
               <div class="endnote" id="d4e732"><span class="noteRef lang en">[31] Fixing the random seed of a specific
                     instantiation of GPT-2, and sampling only the most probable sequence, will result
                     in reproducible results. Because a trained neural network is still necessarily
                     deterministic by its algorithmic design, it would in fact be possible to perform a
                     limited close reading of a specific instantiation of GPT-2 or AID, but this would
                     be to miss the forest for a tree branch.</span></div>
               <div class="endnote" id="d4e742"><span class="noteRef lang en">[32] It is on this basis that we suggest that examining a language
                     model necessarily requires considering it both as a statistical distribution and a
                     sociotechnical assemblage, with the recognition, as Tarleton Gillespie argues,
                     that this runs the risk of obscuring the “people involved at
                     every point: people debating the models, cleaning the training data, designing
                     the algorithms, tuning the parameters, deciding on which algorithms to depend
                     on in which context”
                     [<a class="ref" href="#gillespie2016">Gillespie 2016</a>, 22]. </span></div>
               <div class="endnote" id="d4e759"><span class="noteRef lang en">[33] The benchmarking tasks range from linguistic
                     acceptability (determining whether a sentence makes linguistic sense) to
                     coreference inference (reading a sentence with a pronoun and choosing the correct
                     referent from a list, akin to the Winograd Schema Challenge). GLUE results from
                     the paradigm shift from single, task-specific language models to transfer learning
                     models that have demonstrated a general understanding of a “broad range” of “canonical and fine-grained
                     linguistic tasks”
                     [<a class="ref" href="#mccormick2019">McCormick and Ryan 2019</a>].</span></div>
               <div class="endnote" id="d4e775"><span class="noteRef lang en">[34] Fine-tuning on GLUE was delegated as
                     future work in the conclusion of the GPT-2 paper [<a class="ref" href="#radford2019">Radford et al. 2019</a>].</span></div>
               <div class="endnote" id="d4e780"><span class="noteRef lang en">[35] We take text generation to mean
                     content generation, i.e. news articles, narratives, software code.</span></div>
               <div class="endnote" id="d4e785"><span class="noteRef lang en">[36] Recently, the
                     Google team released a new BERT-based metric that achieved results closer to human
                     performance. Aptly named BLEURT, the metric was pre-trained like BERT and then
                     fine-tuned on an NLG evaluation dataset [<a class="ref" href="#sellam2020">Sellam et al 2020</a>]. </span></div>
               <div class="endnote" id="d4e817"><span class="noteRef lang en">[37] The
                     use of AID to produce descriptions of hypothetical memes brings a provocative
                     question for future research to the fore: what would a formalization for good
                     versus bad memes look like? An institutional decision not to evaluate non-formal
                     textual outputs might, we anticipate, be made on the basis of sociocultural value,
                     which would presume a greater significance for news reports or code completions
                     than for memes. Part of the significance of AID, however, is that it reminds us
                     (again) how arbitrary such distinctions truly are, and not simply because of the
                     vernacular content of the story archive used for fine tuning.</span></div>
               <div class="endnote" id="d4e820"><span class="noteRef lang en">[38] It is possible to do a limited evaluation of AID in terms of
                     interactive fiction benchmarks, in the vein of scholarship on the believability of
                     autonomous agents; for example, one could consider sample AID playthroughs in
                     terms of Emily Short’s guidelines for conversation model design [<a class="ref" href="#short2007">Short 2007</a>]. As we will demonstrate in Section 4, however, AID has
                     only a family resemblance to parser adventure stories, so using IF as a benchmark
                     would necessarily be a limited exercise. </span></div>
               <div class="endnote" id="d4e854"><span class="noteRef lang en">[39] The process involves initializing the language model’s weights by the
                     pre-training corpus; in more basic terms, the model first learns the syntactic and
                     grammatical nuances of language [<a class="ref" href="#ruder2018">Ruder 2018</a>]
                     [<a class="ref" href="#sarkar2018">Sarkar 2018</a>], which are then updated accordingly by a fine-tuning
                     corpus. Fine-tuning here means shaping the model’s output toward a specific mode
                     or genre of writing, e.g. computer code, recipes, Chinese classical poetry, video
                     game walkthroughs, or Reddit submission titles.</span></div>
               <div class="endnote" id="d4e874"><span class="noteRef lang en">[40] We used Woolf’s (2019)
                     simplification of GPT-2 to conduct our experiments, fine-tuning the 355m parameter
                     model with its parameters’ factory settings. The kernel of the work was the
                     formulation of our speculative queries — for example, “if we fine-tuned GPT-2 on
                     <span class="hi italic">x</span> and gave it input <span class="hi italic">y</span>, would
                     it generate <span class="hi italic">z</span>?” — and the formatting of our training
                     data accordingly. So that our work can be verified and developed further, we refer
                     readers to our Google Colab notebook (<a href="https://colab.research.google.com/drive/1obL0qdJRyF9KQYiDkRCwjKWhTnwYBrhd?usp=sharing" onclick="window.open('https://colab.research.google.com/drive/1obL0qdJRyF9KQYiDkRCwjKWhTnwYBrhd?usp=sharing'); return false" class="ref">https://colab.research.google.com/drive/1obL0qdJRyF9KQYiDkRCwjKWhTnwYBrhd?usp=sharing</a>)
                     for the exact parameters used in the experiment represented in <a href="#figure02">Figure 2</a>.</span></div>
               <div class="endnote" id="d4e904"><span class="noteRef lang en">[41] We were guided here by Shawn
                     Presser’s heuristic for forcing stanzaic line breaks, via <span class="error"><a class="ref" href="#gwern2019">#gwern2019</a></span>. </span></div>
               <div class="endnote" id="d4e924"><span class="noteRef lang en">[42] As an
                     example of the financial and compute resources required to pre-train a large
                     language model, OpenAI reports that the pre-training of GPT-3, its 175B parameter
                     model, cost $4.6 million, and would have taken 335 years without advanced
                     computing [<a class="ref" href="#brown2020">Brown et al. 2020</a>, 46]. </span></div>
               <div class="endnote" id="d4e932"><span class="noteRef lang en">[43] With a specific focus on authorship, Aarthi
                     Vadde provides an account of the phenomenon of “mass
                     amateurization” in the “critical, creative, and
                     communicative arts, allowing amateurs to bypass the gatekeeping practices of
                     specific institutions”
                     [<a class="ref" href="#vadde2017">Vadde 2017</a>, 27].</span></div>
               <div class="endnote" id="d4e975"><span class="noteRef lang en">[44] Players can also seek explanations of AID through its
                     community on the Discord server, via gameplay itself, and the “Help” section. </span></div>
               <div class="endnote" id="d4e982"><span class="noteRef lang en">[45] For perspective on the scale of the user base, we note that in May
                     2020, the AID subreddit had approximately the same number of subscribers as the
                     subreddit for the Democratic presidential candidate, Vice President Joe Biden. For
                     up-to-date statistics for r/AIDungeon, see <a href="https://subredditstats.com/r/aidungeon" onclick="window.open('https://subredditstats.com/r/aidungeon'); return false" class="ref">https://subredditstats.com/r/aidungeon</a>.</span></div>
               <div class="endnote" id="d4e997"><span class="noteRef lang en">[46] Posts on the game’s social media communities are disproportionately
                     dominated by screen captures of gameplay, with players trying to outdo each
                     other’s weirdness with posts of novel outputs, from the mildly amusing to the
                     shockingly hilarious. Competitive creativity has by no means been absent from the
                     journalistic coverage of the game either, with the discussion almost resembling
                     teams of scientists trying to outdo each other’s findings: Shane “discovered”
                     that you can roleplay as a nonhuman character, Robertson pushed the game towards
                     the meta, and almost everyone playing has soon learned for themselves that the
                     game’s AI is quite depraved.</span></div>
               <div class="endnote" id="d4e1015"><span class="noteRef lang en">[47] Consider in this regard how AID allows players to
                     tweak the language model’s randomness in the settings, or, players are able to
                     tune one of many of GPT-2’s hyperparameters, all without needing further machine
                     learning knowledge. That “temperature” is advertised as “randomness” is
                     just the start of how AID gamifies working with language models. </span></div>
               <div class="endnote" id="d4e1024"><span class="noteRef lang en">[48] OpenAI’s report of GPT-2 cites [<a class="ref" href="#branwen2019">Branwen 2019</a>] as a
                     literary implementation and AID as a gaming implementation of GPT-2 [<a class="ref" href="#openai2019b">OpenAI 2019b</a>]. </span></div>
               <div class="endnote" id="d4e1031"><span class="noteRef lang en">[49] Partnering with the University of Oregon, OpenAI claims to be
                     developing a battery of “bias probes” or “input[s] to a model designed to elucidate the model’s disposition
                     towards producing certain kinds of outputs” in order to map GPT-2’s
                     racial, gender, and even “conspiracy theories” biases
                     [<a class="ref" href="#openai2019b">OpenAI 2019b</a>].</span></div>
               <div class="endnote" id="d4e1045"><span class="noteRef lang en">[50] On
                     informal, hands-on, or experiential forms of expertise, also see <a href="#collins2007">Collins and Evans (2007)</a>.</span></div>
               <div class="endnote" id="d4e1060"><span class="noteRef lang en">[51]  For an archive, see the
                     subreddit’s custom prompt megathread at <a href="https://www.reddit.com/r/AIDungeon/comments/e82ia5/custom_prompt_megathread/" onclick="window.open('https://www.reddit.com/r/AIDungeon/comments/e82ia5/custom_prompt_megathread/'); return false" class="ref">https://www.reddit.com/r/AIDungeon/comments/e82ia5/custom_prompt_megathread/</a>.
                     </span></div>
               <div class="endnote" id="d4e1068"><span class="noteRef lang en">[52] It is striking that players
                     use AID to test GPT-2’s ability to generate content distinct from text adventures,
                     which suggests that it is not simply genre that engages and retains users. This
                     line of thought is underscored by the fact that King’s Talk to Transformer
                     implementation remains available, yet most of the experimentation with GPT-2
                     continues to be performed and documented on AID’s platform.</span></div>
               <div class="endnote" id="d4e1075"><span class="noteRef lang en">[53] Because AID seems to have evolved
                     almost by the hour throughout the first half of 2020, our analysis of its
                     features, modes, and commands should be read with a date-timestamp. We can though
                     speak to that class of tools that allow for editing and revision because their
                     function has been continuous and they are integral to our argument about AID as an
                     model of and for citizen NLP. Future research can focus on new developments such
                     as a scripting feature that allows users to write custom JavaScript code to modify
                     the game’s logic.</span></div>
               <div class="endnote" id="d4e1130"><span class="noteRef lang en">[54] Many aspects of AID evoke the legacy of IF, most notably its
                     command line aesthetic and generic templates. In actual practice, however, AID is
                     markedly different, because of both the lack of restrictions on player input and
                     the mechanics, particularly “alter,” which is experienced as a writing
                     <em class="emph">with</em> rather than <em class="emph">against</em> the game. Although a strict
                     comparative schema for each is outside of our purview here, we can still point to
                     AID as a model for a potential future of IF in its offering of “a more profound and responsive type of systematic world,”
                     as <a href="#montfort2003">Montfort (2003)</a> puts it. </span></div>
               <div class="endnote" id="d4e1166"><span class="noteRef lang en">[55] For attempts at
                     solving bias in NLP see <a href="#openai2019b">OpenAI (2019b)</a> and <a href="#bender2018">Bender and Friedman (2018)</a>.</span></div>
               <div class="endnote" id="d4e1181"><span class="noteRef lang en">[56] We might remark as well on the
                     extent to which the WebText corpus is already a human-machine hybrid, given the
                     array of algorithmic writing assistants now in common use.</span></div>
               <div class="endnote" id="d4e1202"><span class="noteRef lang en">[57] Walton has claimed that the team has a variety of metrics
                     derived from player engagement, including explicit feedback and user behavior,
                     that are used to determine whether a particular iteration of GPT-2 is working [<a class="ref" href="#aws2020">AWS 2020</a>].</span></div>
               <div class="endnote" id="d4e1213"><span class="noteRef lang en">[58] In 2018, GPT-1 fell under the broad category
                     of semi-supervised learning, in which the model was pre-trained in an unsupervised
                     manner but later fine-tuning saw influences from supervised learning [<a class="ref" href="#radford2018">Radford et al. 2018</a>]. Fast forward two years and GPT-3 does away with the
                     supervised learning portion, with researchers decrying the difficulty of obtaining
                     high-quality fine-tuning datasets [<a class="ref" href="#brown2020">Brown et al. 2020</a>, 3]. The vision
                     for the team was text generation without the need for fine-tuning, or at least
                     with very limited fine-tuning, but AID’s model demonstrates that there is still
                     value in gathering user feedback. After all, as we have noted, the language models
                     of today are not standalone text generators, but consumer products, the revision
                     and improvement of which has material value.</span></div>
               <div class="endnote" id="d4e1223"><span class="noteRef lang en">[59] To sum up
                     the argument against using IF as a benchmark: AID is not a goal-oriented game that
                     can be won or lost but rather an experimental sandbox that can produce not just
                     stories but also code, recipes, and music.</span></div>
               <div class="endnote" id="d4e1254"><span class="noteRef lang en">[60] The OpenAI
                     team extends its gratitude to “the millions of people who
                     created content that was used in the training of the model, and to those who
                     were involved in indexing or upvoting the content (in the case of
                     WebText)”
                     [<a class="ref" href="#brown2020">Brown et al. 2020</a>, 40] but a meaningful contrast can be drawn between
                     this bracketing of citizen participation and AID’s inviting of meaningful and
                     continuous evaluation from its players.</span></div>
            </div>
            <div id="worksCited">
               <h2>Works Cited</h2>
               <div class="bibl"><span class="ref" id="aws2020">
                     <!-- close -->AWS 2020</span> “The Digital
                  Download.” Amazon Web Services Game Tech (May 20, 2020). <a href="https://aws.amazon.com/gametech/events/digital-download-online/" onclick="window.open('https://aws.amazon.com/gametech/events/digital-download-online/'); return false" class="ref">https://aws.amazon.com/gametech/events/digital-download-online/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="adadi2018">
                     <!-- close -->Adadi and Berrada 2018</span> Adadi, A. and M. Berrada. “Peeking Inside the Black-Box: A Survey on Explainable Artificial
                  Intelligence (XAI).”
                  <cite class="title italic">IEEE Access</cite> 6 (2018). <a href="https://ieeexplore.ieee.org/document/8466590" onclick="window.open('https://ieeexplore.ieee.org/document/8466590'); return false" class="ref">https://ieeexplore.ieee.org/document/8466590</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="alammar2019">
                     <!-- close -->Alammar 2019</span> Alammar, J. “The
                  Illustrated GPT-2 (Visualizing Transformer Language Models).”
                  <cite class="title italic">Jay Alammar Blog</cite> (August 2019). <a href="http://jalammar.github.io/illustrated-gpt2/" onclick="window.open('http://jalammar.github.io/illustrated-gpt2/'); return false" class="ref">http://jalammar.github.io/illustrated-gpt2/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="alexander2019">
                     <!-- close -->Alexander 2019</span> Alexander, S. “GPT-2 As Step Toward General Intelligence.”
                  <cite class="title italic">Slate Star Codex</cite> (February 19, 2019). <a href="https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/" onclick="window.open('https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/'); return false" class="ref">https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="alzantot2018">
                     <!-- close -->Alzantot et al. 2018</span> Alzantot, M. et al. “Generating Natural Language Adversarial Examples.”
                  <cite class="title italic">Proceedings of the 2018 Conference on Empirical Methods in
                     Natural Language Processing</cite> (October-November 2018). <a href="https://www.aclweb.org/anthology/D18-1316.pdf" onclick="window.open('https://www.aclweb.org/anthology/D18-1316.pdf'); return false" class="ref">https://www.aclweb.org/anthology/D18-1316.pdf</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="ars2020">
                     <!-- close -->Ars 2020</span> Ars Staff. “The machines are
                  whispering: We tested <cite class="title italic">AI Dungeon 2</cite> and cannot stop
                  laughing.”
                  <cite class="title italic">Ars Technica</cite> (January 20, 2020). <a href="https://arstechnica.com/gaming/2020/01/we-test-ai-dungeon-2-a-text-adventure-that-creates-itself-with-your-help/" onclick="window.open('https://arstechnica.com/gaming/2020/01/we-test-ai-dungeon-2-a-text-adventure-that-creates-itself-with-your-help/'); return false" class="ref">https://arstechnica.com/gaming/2020/01/we-test-ai-dungeon-2-a-text-adventure-that-creates-itself-with-your-help/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="ashby1957">
                     <!-- close -->Ashby 1957</span> Ashby, R. <cite class="title italic">An
                     Introduction to Cybernetics</cite>. Chapman &amp; Hall, London (1957). 
               </div>
               <div class="bibl"><span class="ref" id="banko2001">
                     <!-- close -->Banko and Brill 2001</span> Banko, M. and E. Brill. “Scaling to very very large corpora for natural language
                  disambiguation.”
                  <cite class="title italic">ACL '01: Proceedings of the 39th Annual Meeting on Association
                     for Computational Linguistics </cite>(July 2001), pp. 26–33.
               </div>
               <div class="bibl"><span class="ref" id="bender2018">
                     <!-- close -->Bender and Friedman 2018</span> Bender, E. and B. Friedman.
                  “Data Statements for Natural Language Processing: Toward
                  Mitigating System Bias and Enabling Better Science.”
                  <cite class="title italic">Transactions of the Association for Computational
                     Linguistics</cite> 6 (2018): pp. 587–604. <a href="https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00041" onclick="window.open('https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00041'); return false" class="ref">https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00041</a>. 
               </div>
               <div class="bibl"><span class="ref" id="bengio2003">
                     <!-- close -->Bengio et al. 2003</span> Bengio, Y., et al. “A neural probabilistic language model.”
                  <cite class="title italic">Journal of Machine Learning Research</cite>, 3 (2003), pp.
                  1137–1155.
               </div>
               <div class="bibl"><span class="ref" id="berry2018">
                     <!-- close -->Berry 2018</span> Berry, D. “Explainable
                  Aesthetics.”
                  <cite class="title italic">Stunlaw</cite> (October 2, 2018). <a href="http://stunlaw.blogspot.com/2018/10/explainable-aesthetics.html" onclick="window.open('http://stunlaw.blogspot.com/2018/10/explainable-aesthetics.html'); return false" class="ref">http://stunlaw.blogspot.com/2018/10/explainable-aesthetics.html</a>. 
               </div>
               <div class="bibl"><span class="ref" id="bogost2015">
                     <!-- close -->Bogost 2015</span> Bogost, I. “The
                  Cathedral of Computation.”
                  <cite class="title italic">The Atlantic</cite> (January 15, 2015). <a href="https://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/" onclick="window.open('https://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/'); return false" class="ref">https://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="branwen2019">
                     <!-- close -->Branwen 2019</span> Branwen, G. “GPT-2
                  Neural Network Poetry.”
                  <cite class="title italic">Gwern.net</cite> (March 2019). <a href="https://www.gwern.net/GPT-2" onclick="window.open('https://www.gwern.net/GPT-2'); return false" class="ref">https://www.gwern.net/GPT-2</a>. 
               </div>
               <div class="bibl"><span class="ref" id="branwen2020">
                     <!-- close -->Branwen 2020</span> Branwen, G. “GPT-3
                  Creative Fiction.”
                  <cite class="title italic">Gwern.net</cite> (June 2020). <a href="https://www.gwern.net/GPT-3" onclick="window.open('https://www.gwern.net/GPT-3'); return false" class="ref">https://www.gwern.net/GPT-3</a>. 
               </div>
               <div class="bibl"><span class="ref" id="brown2020">
                     <!-- close -->Brown et al. 2020</span> Brown, T.B., et al. “Language Models are Few-Shot Learners.” arXiv repository
                  (2020). <a href="https://arxiv.org/abs/2005.14165" onclick="window.open('https://arxiv.org/abs/2005.14165'); return false" class="ref">https://arxiv.org/abs/2005.14165</a>. 
               </div>
               <div class="bibl"><span class="ref" id="buonocore2019">
                     <!-- close -->Buonocore 2019</span> Buonocore, T. “Man is to Doctor as Woman is to Nurse: the Gender Bias of Word
                  Embeddings.” Towards Data Science (March 8, 2019). <a href="https://towardsdatascience.com/gender-bias-word-embeddings-76d9806a0e17" onclick="window.open('https://towardsdatascience.com/gender-bias-word-embeddings-76d9806a0e17'); return false" class="ref">https://towardsdatascience.com/gender-bias-word-embeddings-76d9806a0e17</a>. 
               </div>
               <div class="bibl"><span class="ref" id="chan2019">
                     <!-- close -->Chan 2019</span> Chan, S.“ AI Dungeon 2:
                  generative Cattelan &amp; the art museum.”
                  <cite class="title italic">Medium </cite>(December 2019). <a href="https://medium.com/@sebchan/ai-dungeon-2-generative-cattelan-the-art-museum-af16eac989ec" onclick="window.open('https://medium.com/@sebchan/ai-dungeon-2-generative-cattelan-the-art-museum-af16eac989ec'); return false" class="ref">https://medium.com/@sebchan/ai-dungeon-2-generative-cattelan-the-art-museum-af16eac989ec</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="collins2007">
                     <!-- close -->Collins and Evans 2007</span> Collins, H. and R. Evans.
                  <cite class="title italic">Rethinking Expertise</cite>. University of Chicago Press,
                  Chicago (2007).
               </div>
               <div class="bibl"><span class="ref" id="galloway2004">
                     <!-- close -->Galloway 2004</span> Galloway, A. <cite class="title italic">Protocol: How Control Exists After Decentralization</cite>. MIT Press, Cambridge
                  (2004).
               </div>
               <div class="bibl"><span class="ref" id="gillespie2016">
                     <!-- close -->Gillespie 2016</span> Gillespie, T. “Algorithm.” In B. Peters (ed), <cite class="title italic">Digital Keywords: A
                     Vocabulary of Information Society and Culture</cite>, Princeton UP, Princeton
                  (2016), pp. 18–30. 
               </div>
               <div class="bibl"><span class="ref" id="goodwin2019">
                     <!-- close -->Goodwin 2019</span> Goodwin, R. “Ghost
                  Flights.” GitHub repository (2019). <a href="https://github.com/NaNoGenMo/2019/issues/46" onclick="window.open('https://github.com/NaNoGenMo/2019/issues/46'); return false" class="ref">https://github.com/NaNoGenMo/2019/issues/46</a>. 
               </div>
               <div class="bibl"><span class="ref" id="guzdial2015">
                     <!-- close -->Guzdial 2015</span> Guzdial, M., et al. “Crowdsourcing Open Interactive Narrative.”
                  <a href="https://www.cc.gatech.edu/~riedl/pubs/guzdial-fdg15.pdf" onclick="window.open('https://www.cc.gatech.edu/~riedl/pubs/guzdial-fdg15.pdf'); return false" class="ref">https://www.cc.gatech.edu/~riedl/pubs/guzdial-fdg15.pdf</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="halevy2009">
                     <!-- close -->Halevy et al. 2009</span> Halevy, A. et al. “The Unreasonable Effectiveness of Data.”
                  <cite class="title italic">IEEE Intelligent Systems</cite> (2009), vol. 24, no. 02, pp.
                  8–12. 
               </div>
               <div class="bibl"><span class="ref" id="hanlau2018">
                     <!-- close -->Han Lau et al. 2018</span> Han Lau, J. et al. <cite class="title italic">Deep-speare: A joint neural model of poetic language, meter and
                     rhyme.</cite>
                  <cite class="title italic">Proceedings of the 56th Annual Meeting of the Association for
                     Computational Linguistics (Long Papers)</cite> (2018), pp. 1948–1958.
               </div>
               <div class="bibl"><span class="ref" id="harris2020">
                     <!-- close -->Harris 2020</span> Harris, J. “Creating
                  the ever-improvising text adventures of AI Dungeon 2.”
                  <cite class="title italic">Gamasutra</cite> (January 2020). <a href="https://www.gamasutra.com/view/news/356305/Creating_the_everimprovising_text_adventures_of_AI_Dungeon_2.php" onclick="window.open('https://www.gamasutra.com/view/news/356305/Creating_the_everimprovising_text_adventures_of_AI_Dungeon_2.php'); return false" class="ref">https://www.gamasutra.com/view/news/356305/Creating_the_everimprovising_text_adventures_of_AI_Dungeon_2.php</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="hitt2019">
                     <!-- close -->Hitt 2019</span> Hitt, T. “Meet the Mormon
                  College Student Behind the Viral A.I. Game That Took Dungeons &amp; Dragons
                  Online.”
                  <cite class="title italic">Daily Beast </cite>(December 2019). <a href="https://www.thedailybeast.com/meet-the-mormon-college-student-behind-viral-artificial-intelligence-game-ai-dungeon" onclick="window.open('https://www.thedailybeast.com/meet-the-mormon-college-student-behind-viral-artificial-intelligence-game-ai-dungeon'); return false" class="ref">https://www.thedailybeast.com/meet-the-mormon-college-student-behind-viral-artificial-intelligence-game-ai-dungeon</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="holtzman2019">
                     <!-- close -->Holtzman et al. 2019</span> Holtzman, A., et al. “The Curious Case of Neural Text <cite class="title italic">De</cite>generation.” arXiv Preprint (April 2019). <a href="https://arxiv.org/abs/1904.09751" onclick="window.open('https://arxiv.org/abs/1904.09751'); return false" class="ref">https://arxiv.org/abs/1904.09751</a>. 
               </div>
               <div class="bibl"><span class="ref" id="jing2019">
                     <!-- close -->Jing and Xu 2019</span> Jing, K. and Xu J. “A Survey on Neural Network Language Models.” arXiv repository (2019). <a href="https://arxiv.org/abs/1906.03591" onclick="window.open('https://arxiv.org/abs/1906.03591'); return false" class="ref">https://arxiv.org/abs/1906.03591</a>. 
               </div>
               <div class="bibl"><span class="ref" id="johnston2019">
                     <!-- close -->Johnston 2019</span> Johnston, D. <cite class="title italic">ReRites</cite>. <cite class="title italic">Glia: Digital Poetry</cite> (2019). <a href="http://glia.ca/rerites/" onclick="window.open('http://glia.ca/rerites/'); return false" class="ref">http://glia.ca/rerites/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="karpathy2015">
                     <!-- close -->Karpathy 2015</span> Karpathy, A. “The
                  Unreasonable Effectiveness of Recurrent Neural Networks.” Andrej Karpathy
                  Blog (May 21, 2015). <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" onclick="window.open('https://karpathy.github.io/2015/05/21/rnn-effectiveness/'); return false" class="ref">https://karpathy.github.io/2015/05/21/rnn-effectiveness/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="knight2017">
                     <!-- close -->Knight 2017</span> Knight, W. “The Dark
                  Secret at the Heart of AI.”
                  <cite class="title italic">MIT Technology Review</cite> (April 11, 2017). <a href="https://www.technologyreview.com/2017/04/11/5113/the-dark-secret-at-the-heart-of-ai/" onclick="window.open('https://www.technologyreview.com/2017/04/11/5113/the-dark-secret-at-the-heart-of-ai/'); return false" class="ref">https://www.technologyreview.com/2017/04/11/5113/the-dark-secret-at-the-heart-of-ai/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="kurzweil2012">
                     <!-- close -->Kurzweil 2012</span> Kurzweil, R. <cite class="title italic">How
                     to Create a Mind: The Secret of Human Thought Revealed</cite>. Viking Penguin,
                  New York (2012). 
               </div>
               <div class="bibl"><span class="ref" id="lecun2018">
                     <!-- close -->LeCun 2018</span> Yann, L. “Self-Supervised Learning.” Distinguished Lecture Series in Data Science,
                  UC Santa Barbara (November 8, 2018).
               </div>
               <div class="bibl"><span class="ref" id="lillicrap2019">
                     <!-- close -->Lillicrap and Kording 2019</span> Lillicrap, T. and K.
                  Kording. “What Does It Mean to Understand a Neural
                  Network?” arXiv preprint (July 2019). <a href="https://arxiv.org/abs/1907.06374" onclick="window.open('https://arxiv.org/abs/1907.06374'); return false" class="ref">https://arxiv.org/abs/1907.06374</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="marcus2018">
                     <!-- close -->Marcus 2018</span> Marcus, G. “Deep
                  Learning: A Critical Appraisal.” arXiv preprint (January 2018). <a href="https://arxiv.org/abs/1801.00631" onclick="window.open('https://arxiv.org/abs/1801.00631'); return false" class="ref">https://arxiv.org/abs/1801.00631</a>. 
               </div>
               <div class="bibl"><span class="ref" id="marino2006">
                     <!-- close -->Marino 2006</span> Marino, M. “Critical
                  Code Studies.”
                  <cite class="title italic">Electronic Book Review</cite> 4 (December 4, 2006). <a href="http://www.electronicbookreview.com/thread/electropoetics/codology/" onclick="window.open('http://www.electronicbookreview.com/thread/electropoetics/codology/'); return false" class="ref">http://www.electronicbookreview.com/thread/electropoetics/codology/</a>.
               </div>
               <div class="bibl"><span class="ref" id="marino2020">
                     <!-- close -->Marino 2020</span> Marino, M. <cite class="title italic">Critical
                     Code Studies</cite>. MIT Press, Cambridge (2020).
               </div>
               <div class="bibl"><span class="ref" id="mateas2005">
                     <!-- close -->Mateas 2005</span> Mateas, M. “Procedural
                  Literacy: Educating the New Media Practitioner.”
                  <cite class="title italic">On the Horizon</cite> 13.2 (2005), pp. 101–111.
               </div>
               <div class="bibl"><span class="ref" id="mccormick2019">
                     <!-- close -->McCormick and Ryan 2019</span> McCormick, C. and N. Ryan.
                  “GLUE Explained: Understanding BERT Through
                  Benchmarks.” Chris McCormick Blog (November 5, 2019). <a href="https://mccormickml.com/2019/11/05/GLUE/" onclick="window.open('https://mccormickml.com/2019/11/05/GLUE/'); return false" class="ref">https://mccormickml.com/2019/11/05/GLUE/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="mcgillivray2020">
                     <!-- close -->McGillivray et al. 2020</span> McGillivray, B., et al.
                  “Digital Humanities and Natural Language Processing: ‘Je
                  t’aime... Moi non plus.’”
                  <cite class="title italic">Digital Humanities Quarterly</cite>, 14.2 (2020). <a href="http://www.digitalhumanities.org/dhq/vol/14/2/000454/000454.html" onclick="window.open('http://www.digitalhumanities.org/dhq/vol/14/2/000454/000454.html'); return false" class="ref">http://www.digitalhumanities.org/dhq/vol/14/2/000454/000454.html</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="milburn2015">
                     <!-- close -->Milburn 2015</span> Milburn, C. <cite class="title italic">Mondo
                     Nano: Fun and Games in the World of Digital Matter</cite>. Duke UP, Durham
                  (2015).
               </div>
               <div class="bibl"><span class="ref" id="montfort2003">
                     <!-- close -->Montfort 2003</span> Montfort, N. <cite class="title italic">Twisty Little Passages: An Approach to Interactive Fiction</cite>. MIT Press,
                  Cambridge (2003).
               </div>
               <div class="bibl"><span class="ref" id="montfort2012">
                     <!-- close -->Montfort et al. 2012</span> Montfort, N., et al. <cite class="title italic">10 PRINT CHR$(205.5+RND(1));:GOTO 10</cite>. MIT Press, Cambridge
                  (2012).
               </div>
               <div class="bibl"><span class="ref" id="novikova2017">
                     <!-- close -->Novikova et al 2017</span> Novikova, J. “Why We Need New Evaluation Metrics for NLG.” Proceedings of
                  the 2017 Conference on Empirical Methods in Natural Language Processing, pp.
                  2241–2252 Copenhagen, Denmark, (September 2017). <a href="https://nld.ict.usc.edu/cs644-spring2020/discussions/novikova-etal-emnlp2017.pdf" onclick="window.open('https://nld.ict.usc.edu/cs644-spring2020/discussions/novikova-etal-emnlp2017.pdf'); return false" class="ref">https://nld.ict.usc.edu/cs644-spring2020/discussions/novikova-etal-emnlp2017.pdf</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="openai2019a">
                     <!-- close -->OpenAI 2019a</span> “Better Language
                  Models and Their Implications.”
                  <cite class="title italic">OpenAI Blog</cite> (February 2019). <a href="https://openai.com/blog/better-language-models/" onclick="window.open('https://openai.com/blog/better-language-models/'); return false" class="ref">https://openai.com/blog/better-language-models/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="openai2019b">
                     <!-- close -->OpenAI 2019b</span> “Release Strategies
                  and the Social Impacts of Language Models.” arXiv preprint (November 2019).
                  <a href="https://arxiv.org/pdf/1908.09203.pdf" onclick="window.open('https://arxiv.org/pdf/1908.09203.pdf'); return false" class="ref">https://arxiv.org/pdf/1908.09203.pdf</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="openai2020">
                     <!-- close -->OpenAI 2020</span> “OpenAI API.”
                  (June 2020). <a href="https://openai.com/blog/openai-api/" onclick="window.open('https://openai.com/blog/openai-api/'); return false" class="ref">https://openai.com/blog/openai-api/</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="pasquale2016">
                     <!-- close -->Pasquale 2016</span> Pasquale, F. <cite class="title italic">The
                     Black Box Society: The Secret Algorithms That Control Money and
                     Information</cite>. Harvard UP, Cambridge (2016).
               </div>
               <div class="bibl"><span class="ref" id="radford2018">
                     <!-- close -->Radford et al. 2018</span> Radford, A. “Improving Language Understanding by Generative Pre-Training.”
                  <cite class="title italic">OpenAI Blog</cite> (2018). <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" onclick="window.open('https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf'); return false" class="ref">https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="radford2019">
                     <!-- close -->Radford et al. 2019</span> Radford, A. “Language Models are Unsupervised Multitask Learners.”
                  <cite class="title italic">OpenAI Blog</cite> (2019). <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" onclick="window.open('https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf'); return false" class="ref">https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="reiter2017">
                     <!-- close -->Reiter 2017</span> Reiter, E. “How to do
                  an NLG Evaluation: Metrics.”
                  <cite class="title italic">Ehud Reiter’s Blog</cite> (May 3, 2017). <a href="https://ehudreiter.com/2017/05/03/metrics-nlg-evaluation/" onclick="window.open('https://ehudreiter.com/2017/05/03/metrics-nlg-evaluation/'); return false" class="ref">https://ehudreiter.com/2017/05/03/metrics-nlg-evaluation/</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="ruder2018">
                     <!-- close -->Ruder 2018</span> Ruder, S. “NLP’s
                  ImageNet moment has arrived.”
                  <cite class="title italic">Sebastian Ruder Blog</cite> (July 12, 2018). <a href="https://ruder.io/nlp-imagenet/" onclick="window.open('https://ruder.io/nlp-imagenet/'); return false" class="ref">https://ruder.io/nlp-imagenet/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="russell2019">
                     <!-- close -->Russell 2019</span> Russell, S. <cite class="title italic">Human
                     Compatible: Artificial Intelligence and the Problem of Control</cite>. Viking, NY
                  (2019). 
               </div>
               <div class="bibl"><span class="ref" id="sample2020">
                     <!-- close -->Sample 2020</span> Sample, M. “AI Dungeon
                  and Creativity.”
                  <cite class="title italic">SAMPLE REALITY</cite> (January 2020). <a href="https://www.samplereality.com/2020/01/28/ai-dungeon-and-creativity/" onclick="window.open('https://www.samplereality.com/2020/01/28/ai-dungeon-and-creativity/'); return false" class="ref">https://www.samplereality.com/2020/01/28/ai-dungeon-and-creativity/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="sarkar2018">
                     <!-- close -->Sarkar 2018</span> Sarkar, D. “A
                  Comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in
                  Deep Learning.”
                  <cite class="title italic">towards data science</cite> (November 14, 2018). <a href="https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a" onclick="window.open('https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a'); return false" class="ref">https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="see2019">
                     <!-- close -->See 2019</span> See, A. “Natural Language
                  Generation.” CS224N/Ling 284: Natural Language Processing with Deep
                  Learning (2019). <a href="https://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture15-nlg.pdf" onclick="window.open('https://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture15-nlg.pdf'); return false" class="ref">https://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture15-nlg.pdf</a>. 
               </div>
               <div class="bibl"><span class="ref" id="sellam2020">
                     <!-- close -->Sellam et al 2020</span> Sellam, T. et al. “BLEURT: Learning Robust Metrics for Text Generation.” arXiv
                  preprint (May 2020). <a href="https://arxiv.org/abs/2004.04696" onclick="window.open('https://arxiv.org/abs/2004.04696'); return false" class="ref">https://arxiv.org/abs/2004.04696</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="shane2019">
                     <!-- close -->Shane 2019</span> Shane, J. “Play AI
                  Dungeon 2. Become a dragon. Eat the moon.”
                  <cite class="title italic">AI Weirdness</cite> (December 2019). <a href="https://aiweirdness.com/post/189511103367/play-ai-dungeon-2-become-a-dragon-eat-the-moon" onclick="window.open('https://aiweirdness.com/post/189511103367/play-ai-dungeon-2-become-a-dragon-eat-the-moon'); return false" class="ref">https://aiweirdness.com/post/189511103367/play-ai-dungeon-2-become-a-dragon-eat-the-moon</a>. 
               </div>
               <div class="bibl"><span class="ref" id="short2007">
                     <!-- close -->Short 2007</span> Short, E. “Conversation.”
                  <cite class="title italic">Emily Short’s Interactive Storytelling</cite> (2007). <a href="http://emshort.wordpress.com/writing-if/my-articles/conversation/" onclick="window.open('http://emshort.wordpress.com/writing-if/my-articles/conversation/'); return false" class="ref">http://emshort.wordpress.com/writing-if/my-articles/conversation/</a>.
               </div>
               <div class="bibl"><span class="ref" id="tenen2017">
                     <!-- close -->Tenen 2017</span> Tenen, D. <cite class="title italic">Plain Text:
                     The Poetics of Computation</cite>. Columbia UP, New York (2017). 
               </div>
               <div class="bibl"><span class="ref" id="tenney2019">
                     <!-- close -->Tenney et al. 2019</span> Tenney, I., et al. “BERT Rediscovers the Classical NLP Pipeline.”
                  <cite class="title italic">Proceedings of the 57th Annual Meeting of the Association for
                     Computational Linguistics</cite> (2019): pp. 4593–4601.
               </div>
               <div class="bibl"><span class="ref" id="vadde2017">
                     <!-- close -->Vadde 2017</span> Vadde, A. “Amateur
                  Creativity: Contemporary Literature and the Digital Publishing Scene.”
                  <cite class="title italic">New Literary History</cite>, 48.1 (Winter 2017): 27–51. 
               </div>
               <div class="bibl"><span class="ref" id="vincent2019">
                     <!-- close -->Vincent 2019</span> Vincent, J. “This AI
                  text adventure game has pretty much infinite possibilities.”
                  <cite class="title italic">The Verge</cite> (December 2019). <a href="https://www.theverge.com/tldr/2019/12/6/20998993/ai-dungeon-2-choose-your-own-adventure-game-text-nick-walton-gpt-machine-learning" onclick="window.open('https://www.theverge.com/tldr/2019/12/6/20998993/ai-dungeon-2-choose-your-own-adventure-game-text-nick-walton-gpt-machine-learning'); return false" class="ref">https://www.theverge.com/tldr/2019/12/6/20998993/ai-dungeon-2-choose-your-own-adventure-game-text-nick-walton-gpt-machine-learning</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="viswanathan2020">
                     <!-- close -->Viswanathan 2020</span> Viswanathan, S. “Beware of Weight Poisoning in Transfer Learning.”
                  <cite class="title italic">Towards Data Science</cite> (May 4, 2020). <a href="https://towardsdatascience.com/beware-of-weight-poisoning-in-transfer-learning-4c09b63f8353" onclick="window.open('https://towardsdatascience.com/beware-of-weight-poisoning-in-transfer-learning-4c09b63f8353'); return false" class="ref">https://towardsdatascience.com/beware-of-weight-poisoning-in-transfer-learning-4c09b63f8353</a>. 
               </div>
               <div class="bibl"><span class="ref" id="we1s2020">
                     <!-- close -->WE1S 2020</span> WE1S. “Bibliography –
                  Interpretability and Explainability.” WE1S: A 4Humanities Project (2020).
                  <a href="https://we1s.ucsb.edu/research/we1s-bibliography/bibliography-interpretability-and-explainability/" onclick="window.open('https://we1s.ucsb.edu/research/we1s-bibliography/bibliography-interpretability-and-explainability/'); return false" class="ref">https://we1s.ucsb.edu/research/we1s-bibliography/bibliography-interpretability-and-explainability/</a>. 
               </div>
               <div class="bibl"><span class="ref" id="walton2019a">
                     <!-- close -->Walton 2019a</span> Walton, N. “About
                  <cite class="title italic">AI Dungeon</cite>.”
                  <a href="http://ai-adventure.appspot.com/about.html" onclick="window.open('http://ai-adventure.appspot.com/about.html'); return false" class="ref">http://ai-adventure.appspot.com/about.html</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="walton2019b">
                     <!-- close -->Walton 2019b</span> Walton, N. “AI
                  Dungeon 2: Creating Infinitely Generated Text Adventures with Deep Learning
                  Language Models.”
                  <cite class="title italic">Perception, Control, Cognition</cite> (November 21, 2019). <a href="https://pcc.cs.byu.edu/2019/11/21/ai-dungeon-2-creating-infinitely-generated-text-adventures-with-deep-learning-language-models/" onclick="window.open('https://pcc.cs.byu.edu/2019/11/21/ai-dungeon-2-creating-infinitely-generated-text-adventures-with-deep-learning-language-models/'); return false" class="ref">https://pcc.cs.byu.edu/2019/11/21/ai-dungeon-2-creating-infinitely-generated-text-adventures-with-deep-learning-language-models/</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="walton2019c">
                     <!-- close -->Walton 2019c</span> Walton, N. Twitter post, November 23,
                  2019. <a href="https://twitter.com/nickwalton00/status/1198295331449888768" onclick="window.open('https://twitter.com/nickwalton00/status/1198295331449888768'); return false" class="ref">https://twitter.com/nickwalton00/status/1198295331449888768</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="walton2019d">
                     <!-- close -->Walton 2019d</span> Walton, N. “AI-Dungeon.” GitHub
                  repository (2019). <a href="https://github.com/AIDungeon/AIDungeon" onclick="window.open('https://github.com/AIDungeon/AIDungeon'); return false" class="ref">https://github.com/AIDungeon/AIDungeon</a>. 
               </div>
               <div class="bibl"><span class="ref" id="walton2020">
                     <!-- close -->Walton 2020</span> Walton, N. “How we
                  scaled AI Dungeon 2 to support over 1,000,000 users.”
                  <cite class="title italic">Medium</cite> (February 11, 2020). <a href="https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9" onclick="window.open('https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9'); return false" class="ref">https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="wang2018">
                     <!-- close -->Wang et al. 2018</span> Wang, A., et al. “GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language
                  Understanding.”
                  <cite class="title italic">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing
                     and Interpreting Neural Networks for NLP</cite> (November 1, 2018), pp. 353–355.
                  <a href="https://www.aclweb.org/anthology/W18-5446.pdf" onclick="window.open('https://www.aclweb.org/anthology/W18-5446.pdf'); return false" class="ref">https://www.aclweb.org/anthology/W18-5446.pdf</a>. 
               </div>
               <div class="bibl"><span class="ref" id="wang2019">
                     <!-- close -->Wang et al. 2019</span> Wang, A., et al. “SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding
                  Systems.” arXiv preprint (May 2019). <a href="https://arxiv.org/abs/1905.00537" onclick="window.open('https://arxiv.org/abs/1905.00537'); return false" class="ref">https://arxiv.org/abs/1905.00537</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="wardrip2012">
                     <!-- close -->Wardrip-Fruin 2012</span> Wardrip-Fruin, N. <cite class="title italic">Expressive Processing: Digital Fictions, Computer Games, and
                     Software Studies</cite>. MIT Press, Cambridge (2012).
               </div>
               <div class="bibl"><span class="ref" id="weston2014">
                     <!-- close -->Weston et al. 2014</span> Weston, J., et al. “Memory Networks.” arXiv preprint (2014). <a href="https://arxiv.org/abs/1410.3916" onclick="window.open('https://arxiv.org/abs/1410.3916'); return false" class="ref">https://arxiv.org/abs/1410.3916</a>. 
               </div>
               <div class="bibl"><span class="ref" id="whitmore2019">
                     <!-- close -->Whitmore 2019</span> Whitmore, N. “GPT2
                  Adventure.” Google Colaboratory Notebook (2019). <a href="https://colab.research.google.com/drive/1khUaPex-gyk1wXXLuqcopiWmHmcKl4UP" onclick="window.open('https://colab.research.google.com/drive/1khUaPex-gyk1wXXLuqcopiWmHmcKl4UP'); return false" class="ref">https://colab.research.google.com/drive/1khUaPex-gyk1wXXLuqcopiWmHmcKl4UP</a>.
               </div>
               <div class="bibl"><span class="ref" id="woolf2019">
                     <!-- close -->Woolf 2019</span> Woolf, M. “How To Make
                  Custom AI-Generated Text With GPT-2.”
                  <cite class="title italic">Max Woolf’s Blog</cite> (September 4, 2019). <a href="https://minimaxir.com/2019/09/howto-gpt2/" onclick="window.open('https://minimaxir.com/2019/09/howto-gpt2/'); return false" class="ref">https://minimaxir.com/2019/09/howto-gpt2/</a>.
               </div>
               <div class="bibl"><span class="ref" id="xu2000">
                     <!-- close -->Xu and Rudnicky 2000</span> Xu, and Rudnicky. “Language Modeling for Dialog System.”
                  <cite class="title italic">Sixth International Conference on Spoken Language
                     Processing</cite> (ICSLP 2000). <a href="https://www.isca-speech.org/archive/icslp_2000/i00_1118.html" onclick="window.open('https://www.isca-speech.org/archive/icslp_2000/i00_1118.html'); return false" class="ref">https://www.isca-speech.org/archive/icslp_2000/i00_1118.html</a>. 
               </div>
               <div class="bibl"><span class="ref" id="yang2017">
                     <!-- close -->Yang et al. 2017</span> Yang, Z. “Mastering
                  the Dungeon: Grounded Language Learning by Mechanical Turker Descent.”
                  arXiv preprint (November 2017). <a href="https://arxiv.org/abs/1711.07950" onclick="window.open('https://arxiv.org/abs/1711.07950'); return false" class="ref">https://arxiv.org/abs/1711.07950</a>
                  
               </div>
               <div class="bibl"><span class="ref" id="yang2019">
                     <!-- close -->Yang et al. 2019</span> Yang, Y., et al. “A
                  Study on Interaction in Human-in-the-Loop Machine Learning for Text
                  Analytics.”
                  <cite class="title italic">IUI Workshops 2019</cite> (March 2019). <a href="http://ceur-ws.org/Vol-2327/IUI19WS-ExSS2019-9.pdf" onclick="window.open('http://ceur-ws.org/Vol-2327/IUI19WS-ExSS2019-9.pdf'); return false" class="ref">http://ceur-ws.org/Vol-2327/IUI19WS-ExSS2019-9.pdf</a>. 
               </div>
            </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
         </div>
      </div>
   </body>
</html>