<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>[PREVIEW] DHQ: Digital Humanities Quarterly: </title>
      <link href="../../common/css/dhq.css" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_screen.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_print.css" media="print" type="text/css" rel="stylesheet" />
      <style type="text/css">
        #mainContent {
          float: none;
          padding-top: 2em;
          padding-left: 4em;
          padding-right: 4em;
          margin-left: 225px;
           
        }</style>
   </head>
   <body>
      <div id="mainContent">
         <div class="DHQarticle">
            <div id="pubInfo">Preview<br />Volume  Number </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            	
            <div class="DHQheader">
               		
               			
               				
               				
               <h1 class="articleTitle lang en">Cross-codex Learning for Reliable Scribe Identification in
                  					Medieval Manuscripts</h1>
               				
               				
               <div class="author"><span style="color: grey">Julius Weißmann
                     					</span> &lt;<a href="mailto:weissmann_dot_julius_at_gmail_dot_com" onclick="javascript:window.location.href='mailto:'+deobfuscate('weissmann_dot_julius_at_gmail_dot_com'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('weissmann_dot_julius_at_gmail_dot_com'); return false;">weissmann_dot_julius_at_gmail_dot_com</a>&gt;, Media and Digital Technologies, St. Pölten University of Applied
                  						Sciences</div>
               				
               <div class="author"><span style="color: grey">Markus Seidl
                     					</span> &lt;<a href="mailto:markus_dot_seidl_at_fhstp_dot_ac_dot_at" onclick="javascript:window.location.href='mailto:'+deobfuscate('markus_dot_seidl_at_fhstp_dot_ac_dot_at'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('markus_dot_seidl_at_fhstp_dot_ac_dot_at'); return false;">markus_dot_seidl_at_fhstp_dot_ac_dot_at</a>&gt;, Media and Digital Technologies, St. Pölten University of Applied
                  						Sciences</div>
               				
               <div class="author"><span style="color: grey">Anya Dietrich
                     					</span> &lt;<a href="mailto:a_dot_dietrich_at_med_dot_uni-frankfurt_dot_de" onclick="javascript:window.location.href='mailto:'+deobfuscate('a_dot_dietrich_at_med_dot_uni-frankfurt_dot_de'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('a_dot_dietrich_at_med_dot_uni-frankfurt_dot_de'); return false;">a_dot_dietrich_at_med_dot_uni-frankfurt_dot_de</a>&gt;, MEG Unit, Brain Imaging Center</div>
               				
               <div class="author"><span style="color: grey">Martin Haltrich
                     					</span> &lt;<a href="mailto:m_dot_haltrich_at_stift-klosterneuburg_dot_at" onclick="javascript:window.location.href='mailto:'+deobfuscate('m_dot_haltrich_at_stift-klosterneuburg_dot_at'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('m_dot_haltrich_at_stift-klosterneuburg_dot_at'); return false;">m_dot_haltrich_at_stift-klosterneuburg_dot_at</a>&gt;, Library, Klosterneuburg Abbey</div>
               			
               			
               			
               		
               		
               		
               		
               	<span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Cross-codex%20Learning%20for%20Reliable%20Scribe%20Identification%20in%20Medieval%20Manuscripts&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=&amp;rft.volume=&amp;rft.issue=&amp;rft.aulast=Weißmann&amp;rft.aufirst=Julius&amp;rft.au=Julius%20Weißmann&amp;rft.au=Markus%20Seidl&amp;rft.au=Anya%20Dietrich&amp;rft.au=Martin%20Haltrich"> </span></div>
            	
            <div id="DHQtext">
               		
               			
               <div id="abstract">
                  <h2>Abstract</h2>
                  				
                  <p>Historic scribe identification is a substantial task for obtaining information about
                     the
                     					past. Uniform script styles, such as the Carolingian minuscule, make it a difficult
                     task
                     					for classification to focus on meaningful features. Therefore, we demonstrate
                     in this
                     					paper the importance of cross-codex training data for CNN based text-independent
                     off-line
                     					scribe identification, to overcome codex dependent overfitting. We report three
                     main
                     					findings: First, we found that preprocessing with masked grayscale images instead
                     of RGB
                     					images clearly increased the F1-score of the classification results. Second,
                     we trained
                     					different neural networks on our complex data, validating time and accuracy differences
                     in
                     					order to define the most reliable network architecture. With AlexNet, the network
                     with the
                     					best trade-off between F1-score and time, we achieved for individual classes
                     F1-scores of
                     					up to 0,96 on line level and up to 1.0 on page level in classification. Third,
                     we could
                     					replicate the finding that the CNN output can be further improved by implementing
                     a reject
                     					option, giving more stable results. We present the results on our large scale
                     open source
                     					dataset – the Codex Claustroneoburgensis database (CCl-DB) – containing a significant
                     					number of writings from different scribes in several codices. We demonstrate
                     for the first
                     					time on a dataset with such a variety of codices that paleographic decisions
                     can be
                     					reproduced automatically and precisely with CNNs. This gives manifold new and
                     fast
                     					possibilities for paleographers to gain insights into unlabeled material, but
                     also to
                     					develop further hypotheses.</p>
                  			</div>
               			
               		
               		
               			
               <div class="div div0">
                  				
                  <h1 class="head">1 Introduction</h1>
                  				
                  <div class="counter"><a href="#p1">1</a></div>
                  <div class="ptext" id="p1">In recent years, there has been a notable surge in the digitization of historical
                     					documents, allowing for machine processing and providing unprecedented opportunities
                     for
                     					researchers, including palaeographers. A pivotal challenge lies in the identification
                     of
                     					scribes, recognizing the hands responsible for manuscript creation. However,
                     this task is
                     					inherently time-intensive for researchers like palaeographers and codicologists,
                     					constraining its scope.</div>
                  				
                  <div class="counter"><a href="#p2">2</a></div>
                  <div class="ptext" id="p2">Simultaneously, the differentiation and recognition of scribal hands represent an
                     essential
                     					methodology. This capability facilitates the determination of dates, specific
                     scribal
                     					hands, or the geographic origins, enabling the formulation of insights into the
                     					trajectories of medieval scribes across diverse monasteries and scriptoria. Such
                     					information contributes significantly to our understanding of dating, place of
                     origin, and
                     					insights into the scribes themselves and their organizational structures (Kluge
                     2019),
                     					(Landau 2004), (Powitz 2007).</div>
                  				
                  <div class="counter"><a href="#p3">3</a></div>
                  <div class="ptext" id="p3">In European scriptoria the script Carolingian minuscule was used until the second
                     half of
                     					12th century for writing and copying books (codices). This Latin script was the
                     first
                     					standardized script in the medieval period. Although codices typically lack specific
                     					notations regarding which scribe wrote particular sections, the identification
                     of scribes
                     					across various codices is invaluable for understanding scriptoria organization
                     and the
                     					movement of codices and scribes between monasteries.</div>
                  				
                  <div class="counter"><a href="#p4">4</a></div>
                  <div class="ptext" id="p4">The historic auxiliary science of paleography addresses, among other aspects, the
                     					identification of scribes based on distinct, scribe-typical features in their
                     writing.
                     					However, given the sheer volume of codex pages, this task remains tedious and
                     					time-consuming, demanding a high level of domain expertise. Automation through
                     machines
                     					holds promise for expediting and enhancing the assignment of scribal hands, thereby
                     					relieving palaeographers from laborious and repetitive tasks, making the process
                     faster
                     					and more comprehensive.</div>
                  				
                  <div class="counter"><a href="#p5">5</a></div>
                  <div class="ptext" id="p5">For instance, the library of Stift Klosterneurburg, amassed over the past 900 years,
                     					boasting nearly 300,000 copies. This remarkable collection, dating back to the
                     12th
                     					century, exemplifies the potential of automated techniques in efficiently identifying
                     					scribes within the vast repository of codex pages (Haltrich 2014).</div>
                  				
                  <div class="counter"><a href="#p6">6</a></div>
                  <div class="ptext" id="p6">Consequently, only a limited amount of medieval codices has been investigated with
                     a focus
                     					on scribe identification. The automation utilizing pattern recognition and machine
                     					learning allows for larger amounts of material. However, to the best of our knowledge
                     data
                     					of most automation-based approaches are either limited to even only one (De Stefano
                     et al.
                     					2011), (Cilia et al. 2020<span class="hi italic">a</span>,<span class="hi italic">b</span>) or a few
                     					different codices or include material from way larger time periods (e.g. (Fiel
                     et al.
                     					2017), (Chammas et al. 2020)).</div>
                  				
                  <div class="counter"><a href="#p7">7</a></div>
                  <div class="ptext" id="p7">To overcome these shortcomings, we investigate automated scribe identification on
                     a large
                     					dataset we compiled: The CCl-DB (Seidl et al. 2014). This dataset contains 51
                     individual
                     					codices with a total amount of 17071 pages. These codices originate from the
                     library of
                     					Klosterneuburg Abbey and were written in the late 12th century in Carolingian
                     minuscule
                     					(Schneider 2014), (Bischoff 2004). The scarcity of information about the scribes
                     					underscores the significant value of this new dataset and its associated processing
                     					capabilities.</div>
                  				
                  <div class="counter"><a href="#p8">8</a></div>
                  <div class="ptext" id="p8">We are aiming to answer two central questions: <span class="hi italic">a) Can the scribe
                        						assignments coming from decades of work by paleographic experts </span>(Haidinger 1983,
                     					1991), (Lackner 2012) <span class="hi italic">be successfully modelled and predicted? </span>and
                     					b) <span class="hi italic">If so, can we use the models to predict scribes for codex pages that
                        						have unclear scribe assignments or no scribe assignments at all? </span>A substantial
                     					potential data specific risk seen in work by others that could render our work
                     useless is
                     					that we could model not only script specific features but also book specific
                     features such
                     					as the parchment and page margins. To mitigate this risk, we identified scribes
                     that have
                     					been found in at least 3 codices. The subset we use contains 25200<a class="noteRef" href="#d3e292">[1]</a> random lines uniformly distributed over 7 scribes in 31 different
                     					historic codices, in order to train the models to recognize the scribe without
                     codex
                     					specific features.</div>
                  				
                  <div class="counter"><a href="#p9">9</a></div>
                  <div class="ptext" id="p9">In the last decade, convolutional neural networks<a class="noteRef" href="#d3e297">[2]</a> (CNNs) have proven to efficiently
                     					classify writers in modern and historic context and other tasks such as segmentation
                     					(Oliveira et al. 2018), optical character recognition (Islam et al. 2016), and
                     writer
                     					identification (Xing &amp; Qiao 2016), (De Stefano et al. 2011).</div>
                  				
                  <div class="counter"><a href="#p10">10</a></div>
                  <div class="ptext" id="p10">For our classification model we compared several general purpose object and</div>
                  				
                  <div class="counter"><a href="#p11">11</a></div>
                  <div class="ptext" id="p11">
                     					
                     <div class="figure">
                        						
                        						<a href="resources/images/figure01.jpeg" rel="external"><img src="resources/images/figure01.jpeg" style="" alt="" /></a>
                        					</div>Figure. 1: Examples from the CCl-DB (Seidl et al. 2014) of three lines of
                     					different codices from one scribe. The ink and parchment appearance differs,
                     although it’s
                     					written from the same scribe (class A 30) (Haidinger 1991), (Lackner 2012). Top:
                     CCl 206,
                     					middle: CCl 197, bottom: CCl 217.concept detection CNNs as well as specific architectures
                     					for scribe identification (see Table 3). Surprisingly, the classic AlexNet (Krizhevsky
                     et
                     					al. 2012) provided the best trade-off between F1-score and time. We show that
                     we can
                     					distinguish the scribes described by paleographic experts and even identify potential
                     					wrong scribe assignments. Furthermore, in combination with the reject option
                     introduced by
                     					Cilia et al. (2020<span class="hi italic">a</span>) we demonstrate that we can reliably predict
                     					the scribes for codices with unclear or missing scribe assignments.</div>
                  				
                  <div class="counter"><a href="#p12">12</a></div>
                  <div class="ptext" id="p12">In this paper, we focus on three major issues:</div>
                  				
                  <div class="ptext">
                     <ul class="list bulleted">
                        <li class="item">the importance of cross-codex based training data for automatic scribe
                           						identification</li>
                        <li class="item">the feasibility of training a model based on scribe assignments by the paleographers
                           						Haidinger (2010, 1983, 1991) and Lackner (2012)</li>
                        <li class="item">the necessity of exploiting the confidence in scribe predictions to reveal
                           						uncertainties in the dataset.</li>
                     </ul>
                  </div>
                  				
                  <div class="counter"><a href="#p13">13</a></div>
                  <div class="ptext" id="p13">The latter is a central requirement, as there is no objective ground truth for scribe
                     					assignments for the medieval codices we are using. Our contribution in this paper
                     is
                     					threefold:</div>
                  				
                  <div class="counter"><a href="#p14">14</a></div>
                  <div class="ptext" id="p14">Firstly, we demonstrate the necessity of book independent training of scribe models,
                     which
                     					has been neglected in other studies. Secondly, we demonstrate that contrary to
                     the results
                     					of Xing &amp; Qiao (2016) standard architectures are sufficiently accurate to reliably
                     					identify medieval scribes in a classification pipeline. Thirdly, our work consequently
                     					facilitates comprehensive and convincing studies on large datasets and allows
                     new insights
                     					into the historic monastic life and the relationships between the monasteries.<a class="noteRef" href="#d3e331">[3]</a>
                     				</div>
                  				
                  <div class="counter"><a href="#p15">15</a></div>
                  <div class="ptext" id="p15">The paper is structured as follows: after an overview about related work in section
                     2 we
                     					outline the dataset in section 3. In section 4 we explain the applied methods
                     for scribe
                     					identification. We show and discuss the results in section 5 and finally conclude
                     the
                     					paper in section 6.</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  <h1 class="head">2 Related work</h1>
                  				
                  <div class="counter"><a href="#p16">16</a></div>
                  <div class="ptext" id="p16">Computer-aided historic handwritten document analysis includes segmentation, text
                     					recognition, dating and writer identification as well as verification. Segmentation
                     					usually separates the written or drawn content from the carrier material (such
                     as
                     					parchment or paper) (Oliveira et al. 2018), (Tensmeyer et al. 2017). Based on
                     this, a
                     					possible next step is handwritten text recognition (HTR) (Chammas et al. 2018).
                     Either the
                     					segments or the written content alone or a combination of both modalities allow
                     further
                     					investigations like dating, writer verification (Shaikh et al. 2020), (Dey et
                     al. 2017)
                     					and identification (Chammas et al. 2020), (Xing &amp; Qiao 2016), (Fiel et al. 2017).</div>
                  				
                  <div class="counter"><a href="#p17">17</a></div>
                  <div class="ptext" id="p17">Different processes for scribe identification can be used, such as text-dependent
                     and
                     					text-independent. Text-dependent (Said et al. 1998) methods allow identifying
                     the writer
                     					on particular characters or words, whereas text-independent (Yang et al. 2016)
                     approaches
                     					can be applied on new unseen content. Two kinds of handwritten text patterns
                     can be used:
                     					on-line and offline writer identification. On-line (Yang et al. 2016) systems
                     work with
                     					time series of the formation process, while off-line (Xing &amp; Qiao 2016) solutions
                     are
                     					limited to the images of the written text document.</div>
                  				
                  <div class="counter"><a href="#p18">18</a></div>
                  <div class="ptext" id="p18">Writer identification is a strong topic in document analysis and therefore much discussed.
                     					In the last years, a variety of solutions have been provided. These methods can
                     be grouped
                     					into codebook-based and codebook-free methods. Codebook-based refer to a codebook
                     that
                     					serves as a background model. This model is based on statistical features like
                     in (Maaten
                     					&amp; Postma 2005). The codebook-free methods include for example the width of ink
                     traces,
                     					which was used from Brink et al. (2012) to predict the writer in medieval and
                     modern
                     					handwritten documents, or the hinge feature provided by (He &amp; Schomaker 2014)
                     in order
                     					to identify writers in handwritten English text in the IAM-dataset (Marti &amp; Bunke
                     					2002). Further, there have been strong results in using the Scale-Invariant Feature
                     					Transform (SIFT) for writer identification (Xiong et al. 2015), (Fiel &amp; Sablatnig
                     					2012), (Wu et al. 2014).</div>
                  				
                  <div class="counter"><a href="#p19">19</a></div>
                  <div class="ptext" id="p19">In recent years, the number of Deep Learning<a class="noteRef" href="#d3e349">[4]</a> (DL) based studies in document
                     					analysis increased drastically (Chammas et al. 2020), (Cilia et al. 2020<span class="hi italic">b</span>), (Xing &amp; Qiao 2016). As mentioned in the introduction, the interest in
                     					using such techniques is due to their ability to provide powerful state-of-the-art
                     					solutions in an efficient and reliable way. During the training, the DL model
                     learns the
                     					best fitting features for the classification. Therefore, no handcrafted features
                     are
                     					required.</div>
                  				
                  <div class="counter"><a href="#p20">20</a></div>
                  <div class="ptext" id="p20">In Fiel &amp; Sablatnig (2015) presented the strong performance of CNN’s for scribe
                     					identification on modern data sets.</div>
                  				
                  <div class="counter"><a href="#p21">21</a></div>
                  <div class="ptext" id="p21">Xing &amp; Qiao (2016) performed a writer identification on the modern IAM and the HWDB1.1
                     					dataset. They developed a special multi-stream CNN architecture based on AlexNet
                     and
                     					outperformed previous approaches on handcrafted features.</div>
                  				
                  <div class="counter"><a href="#p22">22</a></div>
                  <div class="ptext" id="p22">Table 1: Subset of the CCl-DB</div>
                  				
                  <div class="table">
                     <table class="table">
                        <tr class="row">
                           						
                           <td valign="top" class="cell">Class</td>
                           						
                           <td valign="top" class="cell">Training codices (<span class="hi italic">test A </span>and <span class="hi italic">B</span>)</td>
                           						
                           <td valign="top" class="cell">Separate codices (<span class="hi italic">test B </span>only)</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell"></td>
                           						
                           <td valign="top" class="cell">Lines per codex</td>
                           						
                           <td valign="top" class="cell">#Codices</td>
                           						
                           <td valign="top" class="cell">Codices</td>
                           						
                           <td valign="top" class="cell">Lines per codex</td>
                           						
                           <td valign="top" class="cell">#Codices</td>
                           						
                           <td valign="top" class="cell">Codices</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell">A 30</td>
                           						
                           <td valign="top" class="cell">450</td>
                           						
                           <td valign="top" class="cell">8</td>
                           						
                           <td valign="top" class="cell">
                              							
                              <div class="counter"><a href="#p23">23</a></div>
                              <div class="ptext" id="p23">30, 31, 197, 206,</div>
                              							
                              <div class="counter"><a href="#p24">24</a></div>
                              <div class="ptext" id="p24">226, 246, 256, 257</div>
                              						</td>
                           						
                           <td valign="top" class="cell">1500</td>
                           						
                           <td valign="top" class="cell">2</td>
                           						
                           <td valign="top" class="cell">32, 217</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell">A 259</td>
                           						
                           <td valign="top" class="cell">1200</td>
                           						
                           <td valign="top" class="cell">3</td>
                           						
                           <td valign="top" class="cell">209, 259, 949</td>
                           						
                           <td valign="top" class="cell">1754</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">706</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell">B 259</td>
                           						
                           <td valign="top" class="cell">720</td>
                           						
                           <td valign="top" class="cell">5</td>
                           						
                           <td valign="top" class="cell">
                              							
                              <div class="counter"><a href="#p25">25</a></div>
                              <div class="ptext" id="p25">259, 622, 706, 212,</div>
                              							
                              <div class="counter"><a href="#p26">26</a></div>
                              <div class="ptext" id="p26">671</div>
                              						</td>
                           						
                           <td valign="top" class="cell">1439</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">246</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell">A 20</td>
                           						
                           <td valign="top" class="cell">1200</td>
                           						
                           <td valign="top" class="cell">3</td>
                           						
                           <td valign="top" class="cell">21, 28, 39</td>
                           						
                           <td valign="top" class="cell">3000</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">20</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell">B 20</td>
                           						
                           <td valign="top" class="cell">900</td>
                           						
                           <td valign="top" class="cell">4</td>
                           						
                           <td valign="top" class="cell">22, 195, 216, 764</td>
                           						
                           <td valign="top" class="cell">119</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">20</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell">A 215</td>
                           						
                           <td valign="top" class="cell">1200</td>
                           						
                           <td valign="top" class="cell">3</td>
                           						
                           <td valign="top" class="cell">215, 219, 703</td>
                           						
                           <td valign="top" class="cell">3000</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">245</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell">A 258</td>
                           						
                           <td valign="top" class="cell">1800</td>
                           						
                           <td valign="top" class="cell">2</td>
                           						
                           <td valign="top" class="cell">258, 707</td>
                           						
                           <td valign="top" class="cell">3000</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">203</td>
                           					</tr>
                     </table>
                     <div class="caption-no-label">
                        <div class="label">Table 1. </div>
                     </div>
                  </div>
                  				
                  <div class="counter"><a href="#p27">27</a></div>
                  <div class="ptext" id="p27">The dataset for our experiments is a subset of the seven common scribes of the CCl-DB
                     					(Seidl et al. 2014). We generated a dataset, with two groups of codices – the
                     <span class="hi italic">training codices </span>and the <span class="hi italic">separate codices</span>.
                     					From the <span class="hi italic">training codices </span>we choose for every class 3600 random
                     					lines, that are uniformly distributed over all books. In total these are 25200
                     lines that
                     					are separated into training, validation and test data (<span class="hi italic">test A</span>)
                     					according to the ratio of 60 %, 20 % and 20 % respectively. The separate books
                     are used
                     					for an extra test set <span class="hi italic">test B</span>. There are up to 3000 lines of one
                     					class, depending on the codex-size.</div>
                  				
                  <div class="counter"><a href="#p28">28</a></div>
                  <div class="ptext" id="p28">Cilia et al. (2020<span class="hi italic">a</span>) demonstrated a comparison between deep learning
                     					and handcrafted features on the Avila Bible that is written in <span class="hi italic">Carolingian minuscule</span>. These classical features, as Cilia et al. call them, are
                     					handcrafted features, that have been developed in cooperation with paleographers.
                     The
                     					results of their studies emphasize the effectiveness of deep learning features
                     in contrast
                     					to the handcrafted features.</div>
                  				
                  <div class="counter"><a href="#p29">29</a></div>
                  <div class="ptext" id="p29">In our research, we investigate <span class="hi italic">scribe </span>identification in contrast to
                     						<span class="hi italic">writer </span>identification, since the specific individual of the
                     					writing is generally not known for our material. Scribe identification is discussed
                     in a
                     					medieval context only in a very limited range, like at the International Conference
                     on
                     					Document Analysis and Recognition (ICDAR) competitions (Fiel et al. 2017) or
                     in
                     					conjunction with the Avila bible (Cilia et al. 2020<span class="hi italic">a</span>). However, the
                     					aforementioned datasets are of limited use for our goals. The Avila bible is
                     literally
                     					only one codex and consequently does not allow cross-codex scribe identification.
                     The
                     					datasets used in the historical ICDAR competitions (Fiel et al. 2017), (Christlein
                     et al.
                     					2019) span time periods of many centuries, and hence include different scripts
                     and carrier
                     					materials. Thus, scribe identification in the large amounts of medieval codices
                     in
                     					Europe’s libraries is still a challenge and our approach allows novel insights
                     as it
                     					focuses on a wide range of codices of several scribes in the short period of
                     the late 12th
                     					century.</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  <h1 class="head">3 Dataset</h1>
                  				
                  <div class="counter"><a href="#p30">30</a></div>
                  <div class="ptext" id="p30">We perform experiments on a subset (see Table 1) of seven scribes provided by the
                     CCl-DB
                     					(Seidl et al. 2014). We selected the scribes which have contributed</div>
                  				
                  <div class="counter"><a href="#p31">31</a></div>
                  <div class="ptext" id="p31">
                     					
                     <div class="figure">
                        						
                        						<a href="resources/images/figure02.jpeg" rel="external"><img src="resources/images/figure02.jpeg" style="" alt="" /></a>
                        					</div>Figure. 2: Image data of the CCl-DB (Seidl et al. 2014) (CCl 20, S. 3r, hand A 20
                     					(Haidinger 1983)). The CCl-DB provides the codices page by page (left) and on
                     line-level
                     					(right-top). The line-level images are produced automatically by the segmentation
                     of
                     					Transkribus (Kahle et al. 2017). The neural network classification works with
                     squared
                     					images, therefore we cropped the line images into squares and resized them into
                     the
                     					network input size. to as many books as possible to allow cross-codex evaluation.
                     Samples
                     					in the dataset were handwritten on parchment in <span class="hi italic">Carolingian minuscule
                        					</span>(see Figure 1 and 2) on one- and two-column pages. These codices have been written
                     					down in the scriptorium of Klosterneuburg in the last third of the 12th century.
                     The data
                     					is provided by the Scribe ID AI<a class="noteRef" href="#d3e599">[5]</a> project and has been labelled by paleographic experts based on the activity of the
                     					paleographers Haidinger (2010, 1983, 1991) and Lackner (2012). 52 labelled codices
                     are
                     					provided in the CCl-DB. This database enables new possibilities within document
                     analysis
                     					and especially in handwriting recognition.</div>
                  				
                  <div class="counter"><a href="#p32">32</a></div>
                  <div class="ptext" id="p32">To the best of our knowledge, there is no comparable database available that provides
                     the
                     					workings of many medieval scribes in various codices and in such a short period
                     of
                     					time.</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  <h1 class="head">4 Methods for Scribe Identification</h1>
                  				
                  <div class="counter"><a href="#p33">33</a></div>
                  <div class="ptext" id="p33">This section will introduce the pipeline of our line-based scribe identification approach.
                     					The pipeline is grouped into three main parts (see Figure 3). In the first part
                     – the
                     					image preprocessing – we focus on providing the following network input images
                     that are
                     					reduced to their scribe specific information. The second part presents the neural
                     network
                     					classification approach. Here we compare different CNNs as image classifiers
                     for scribe
                     					identification. Finally, the third part covers the post-processing which generates
                     the
                     					final score. This is where we introduce the computation of the line score and
                     the reject
                     					option – a method to improve the prediction. All parts will be detailed in the
                     					following.</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">4.1Image preprocessing</h2>
                     					
                     <div class="counter"><a href="#p34">34</a></div>
                     <div class="ptext" id="p34">The dataset contains not only the codex pages, but also the extracted lines.</div>
                     					
                     <div class="counter"><a href="#p35">35</a></div>
                     <div class="ptext" id="p35">
                        						
                        <div class="figure">
                           							
                           							<a href="resources/images/figure03.jpeg" rel="external"><img src="resources/images/figure03.jpeg" style="" alt="" /></a>
                           						</div>Figure. 3: Overall procedure of the proposed scribe recognition system. The
                        						rounded boxes symbolize data, whereas the angular boxes show processes.The line
                        data
                        						is usually correctly extracted from the pages, however there are some small
                        snippets
                        						with no noticeable content in the dataset. As image lines are generally of wide
                        aspect
                        						ratio, we use a simple heuristic (<span class="hi italic">width/height </span>≤ 5) to skip
                        						these uninformative snippets already in the step of preprocessing.</div>
                     					
                     <div class="counter"><a href="#p36">36</a></div>
                     <div class="ptext" id="p36">
                        						
                        <div class="figure">
                           							
                           							<a href="resources/images/figure04.jpeg" rel="external"><img src="resources/images/figure04.jpeg" style="" alt="" /></a>
                           						</div>Figure. 4: Example for the preprocessing (CCl 212, S. 1r, hand B 259 (Lackner
                        						2012)). The lines of the CCl-DB (Seidl et al. 2014) are provided as RGB images
                        (top).
                        						From these, we converted the images to grayscale (middle). The masked grayscaled
                        						images are produced by removing the background from the ink.For studying the
                        optimal
                        						input image data we generated grayscale images and masked grayscale images
                        						additionally to the RGB data (see Figure 4). When we masked<a class="noteRef" href="#d3e643">[6]</a> the
                        						images we followed the example of De Stefano et al. (2018). We applied their
                        fixed
                        						threshold value, equal to 135, to separate the ink and the parchment of the
                        grayscale
                        						images (see Figure 4). In related work (Cilia et al. 2020<span class="hi italic">a</span>),
                        						(Fiel et al. 2017), (Fiel &amp; Sablatnig 2015), (Cloppet et al. 2016), binarization
                        						is often applied to text images. However, since our masking does not work reliably
                        						enough to produce meaningful binarization, we omit this step in this work.</div>
                     					
                     <div class="counter"><a href="#p37">37</a></div>
                     <div class="ptext" id="p37">As already mentioned, the lines of the CCl-DB are of different aspect ratio, but the
                        						networks we implemented are working with a fixed input size. In order to handle
                        the
                        						different lengths of the lines, we followed the patch scanning strategy of Xing
                        &amp;
                        						Qiao (2016). First, the images have been resized in height to the specific network
                        						input image height, while maintaining the aspect ratio of the line. Afterwards,
                        we
                        						cropped the lines from left to right into patches (see Figure 2). This sliding
                        window
                        						comprises the network specific input image width. Due to the large dataset (see
                        Table
                        						1), there is no need for data augmentation<a class="noteRef" href="#d3e651">[7]</a>. Hence, we
                        						generated patches with no overlap. Only one overlap occurs at the last image
                        of each
                        						line, as the last patch of the line is generated by positioning the sliding
                        window at
                        						the end of the line. Finally, we scaled and normalized the patches.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">4.2 Patch level classification</h2>
                     					
                     <div class="counter"><a href="#p38">38</a></div>
                     <div class="ptext" id="p38">Xing &amp; Qiao (2016) achieved high identification accuracies with their customized
                        						CNN’s on the line level data of the IAM (Marti &amp; Bunke 2002) dataset. They
                        						optimized AlexNet to the task of writer identification on the IAM dataset and
                        denoted
                        						the architecture Half DeepWriter. Next, they developed the DeepWriter architecture,
                        						which is an improvement of Half DeepWriter that enables the computation of two
                        						sequential image patches in a single pass with a multi-stream architecture.
                        Xing and
                        						Qiao showed that DeepWriter produces the best results on the line level data
                        of the
                        						IAM dataset. Therefore, we implemented these three auspicious architectures
                        as per
                        						description of Xing &amp; Qiao (2016), when we tested the potential of preprocessed
                        						images on our data (see Table 1).</div>
                     					
                     <div class="counter"><a href="#p39">39</a></div>
                     <div class="ptext" id="p39">Additionally, we compared several other general-purpose object and concept detection
                        						architectures in our study to find the best one suited to our specific data.
                        For this
                        						purpose, we used models provided by Torchvision (Marcel &amp; Rodriguez 2010) (see
                        						Table 3) and only adapted the input layer to the grayscale images and the output
                        layer
                        						to the seven classes.</div>
                     					
                     <div class="counter"><a href="#p40">40</a></div>
                     <div class="ptext" id="p40">As shown in different studies, pre-training and fine-tuning a CNN can lead to better
                        						results (Xing &amp; Qiao 2016), (Studer et al. 2019). Xing and Qiao (2016)
                        						demonstrated this on the IAM (Marti &amp; Bunke 2002) and the HWDB (Liu et al. 2011)
                        						dataset. Therefore, we trained the described models on the IAM dataset, fine-tuned
                        						them on our data and compared the results with the from scratch trained weights.</div>
                     					
                     <div class="counter"><a href="#p41">41</a></div>
                     <div class="ptext" id="p41">The models have been trained with a batch size of 32 over 10 epochs with a learning
                        						rate of 1∗10−5 on ADAM. The error was calculated with the cross entropy. Over
                        all ten
                        						epochs, the instance of the model that performed best on the validation data
                        has been
                        						saved for the next steps of the experiments.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">4.3 Postprocessing</h2>
                     					
                     <div class="counter"><a href="#p42">42</a></div>
                     <div class="ptext" id="p42">We pursue a patch, line and page level classification, but as already described, the
                        						network classification is on patch level. To compute the line and page score,
                        we
                        						follow the example of Xing &amp; Qiao (2016). They calculate the final score vector
                        							<span class="hi italic">f</span>i for the <span class="hi italic">jth</span> writer, of all
                        						patches <span class="hi italic">N </span>of one line . This
                        						averaged Softmax output serves as the basis for the final step of the post-processing
                        						– the reject option.</div>
                     					
                     <div class="counter"><a href="#p43">43</a></div>
                     <div class="ptext" id="p43">Cilia et al. (2020<span class="hi italic">a</span>) proposed the reject option to generate more
                        						reliable results for the writer identification on the Avila bible. They showed
                        that
                        						sometimes it is better to withdraw a precarious decision than accepting all
                        						predictions. In such a case, they reject the prediction with the reject option.</div>
                     					
                     <div class="counter"><a href="#p44">44</a></div>
                     <div class="ptext" id="p44">We used the line score as a probability distribution to check the probabilities for
                        all
                        						writers. As Cilia et al. explained, the error-reject curve shows the impact
                        of the
                        						reject rate to the wrong predictions and allows finding the optimal threshold
                        for
                        						rejecting a prediction. Our reject rate is given by the line score of one writer.
                        The
                        						reject rate corresponds to the wrong predictions.</div>
                     				</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  <h1 class="head">5 Results</h1>
                  				
                  <div class="counter"><a href="#p45">45</a></div>
                  <div class="ptext" id="p45">The purpose of this study was to train a model that classifies reliable and efficiently
                     					scribes in cross-codex data. We want to enable the automatic continuation of
                     the work of
                     					paleography experts following their example, in order to allow research in large
                     scale. In
                     					this study we would like to find a model that is not only reliable but also fast
                     in
                     					processing, as it is the basis for research on active learning.</div>
                  				
                  <div class="counter"><a href="#p46">46</a></div>
                  <div class="ptext" id="p46">In Table 2 we show the importance of cross-codex test data and the risk of overfitting.</div>
                  				
                  <div class="counter"><a href="#p47">47</a></div>
                  <div class="ptext" id="p47">In the evaluation of our scribe classification pipeline, we found:</div>
                  				
                  <div class="ptext">
                     <ul class="list numbered">
                        <li class="item">Image preprocessing plays a key role in cross-codex scribe identification. In
                           						comparison to RGB images, masked grayscale images roughly doubled the F1-score
                           in the
                           						classification task.</li>
                        <li class="item">Further, we showed that AlexNet provides very fast, and among the most reliable
                           						predictions in classifying the scribes of our data set.</li>
                        <li class="item">Contrary to expectations, pre-training the network on the IAM database leads to
                           						worse results, which is why we omitted this step.</li>
                     </ul>
                  </div>
                  				
                  <div class="counter"><a href="#p48">48</a></div>
                  <div class="ptext" id="p48">Applying the best fitting trained model, it turned out that it is very effective and
                     even
                     					indicates incorrect data.</div>
                  				
                  <div class="counter"><a href="#p49">49</a></div>
                  <div class="ptext" id="p49">Moreover, we introduce the reject option on our dataset in order to get rid of precarious
                     					classifications and found that it underlines the results.</div>
                  				
                  <div class="counter"><a href="#p50">50</a></div>
                  <div class="ptext" id="p50">Finally, we deployed the pipeline to processes open paleographic topics.</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.1 Cross-codex data</h2>
                     					
                     <div class="counter"><a href="#p51">51</a></div>
                     <div class="ptext" id="p51">The CCl-DB provides handwritings of several scribes in different codices. Therefore,
                        we
                        						compared two test sets (see Table 2) to check if the networks tend to learn
                        						codex-specific features. For this experiment we trained the architectures AlexNet,
                        						Half Deep Writer and DeepWriter. Referring to Xing &amp; Qiao (2016) these networks
                        						are suitable for handwriting identification. We found, that the test set <span class="hi italic">test B </span>which contains test samples from books which have not
                        						been used for training (see Table 1) is more comprehensive than <span class="hi italic">test
                           							A </span>because all three trained networks performed better on <span class="hi italic">test A </span>whether the input images have been RGB grayscale or masked. We
                        						conclude, that the networks learned codex-specific features in <span class="hi italic">test
                           							A</span>. Therefore, we used the test set <span class="hi italic">test B </span>for further
                        						experiments to obtain more reliable results.</div>
                     					
                     <div class="counter"><a href="#p52">52</a></div>
                     <div class="ptext" id="p52">Table 2: F1-score for image preprocessing on patch level</div>
                     					
                     <div class="table">
                        <table class="table">
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Data</td>
                              							
                              <td valign="top" class="cell">Network</td>
                              							
                              <td valign="top" class="cell">RGB</td>
                              							
                              <td valign="top" class="cell">GS</td>
                              							
                              <td valign="top" class="cell">GS mask</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Test A</td>
                              							
                              <td valign="top" class="cell">AlexNet</td>
                              							
                              <td valign="top" class="cell">0.25</td>
                              							
                              <td valign="top" class="cell">0.56</td>
                              							
                              <td valign="top" class="cell">0.64</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell"></td>
                              							
                              <td valign="top" class="cell">Deep Writer</td>
                              							
                              <td valign="top" class="cell">0.25</td>
                              							
                              <td valign="top" class="cell">0.44</td>
                              							
                              <td valign="top" class="cell">0.57</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell"></td>
                              							
                              <td valign="top" class="cell">Half Deep Writer</td>
                              							
                              <td valign="top" class="cell">0.25</td>
                              							
                              <td valign="top" class="cell">0.41</td>
                              							
                              <td valign="top" class="cell">0.54</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell"></td>
                              							
                              <td valign="top" class="cell">∅</td>
                              							
                              <td valign="top" class="cell">0.25</td>
                              							
                              <td valign="top" class="cell">0.47</td>
                              							
                              <td valign="top" class="cell">0.58</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Test B</td>
                              							
                              <td valign="top" class="cell">AlexNet</td>
                              							
                              <td valign="top" class="cell">0.30</td>
                              							
                              <td valign="top" class="cell">0.53</td>
                              							
                              <td valign="top" class="cell">0.60</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell"></td>
                              							
                              <td valign="top" class="cell">Deep Writer</td>
                              							
                              <td valign="top" class="cell">0.26</td>
                              							
                              <td valign="top" class="cell">0.32</td>
                              							
                              <td valign="top" class="cell">0.42</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell"></td>
                              							
                              <td valign="top" class="cell">Half Deep Writer</td>
                              							
                              <td valign="top" class="cell">0.35</td>
                              							
                              <td valign="top" class="cell">0.30</td>
                              							
                              <td valign="top" class="cell">0.38</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell"></td>
                              							
                              <td valign="top" class="cell">∅</td>
                              							
                              <td valign="top" class="cell">0.30</td>
                              							
                              <td valign="top" class="cell">0.38</td>
                              							
                              <td valign="top" class="cell">0.47</td>
                              						</tr>
                        </table>
                        <div class="caption-no-label">
                           <div class="label">Table 2. </div>
                        </div>
                     </div>
                     					
                     <div class="counter"><a href="#p53">53</a></div>
                     <div class="ptext" id="p53">Preprocessed input images and their impact on the classification of the test data.
                        The
                        						experiment was performed on the three different networks AlexNet, Half DeepWriter
                        and
                        						Deepwriter. As a result, the averaged F1-score is given. We provide two F1-scores
                        of
                        						separate test sets (see Table 1).</div>
                     					
                     <div class="counter"><a href="#p54">54</a></div>
                     <div class="ptext" id="p54">Table 3: Network performance on patch level</div>
                     					
                     <div class="table">
                        <table class="table">
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Network</td>
                              							
                              <td valign="top" class="cell">F1 Test B</td>
                              							
                              <td valign="top" class="cell">Time</td>
                              							
                              <td valign="top" class="cell">img. (h ∗ w)</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Densenet*</td>
                              							
                              <td valign="top" class="cell">0.61</td>
                              							
                              <td valign="top" class="cell">503</td>
                              							
                              <td valign="top" class="cell">224 ∗ 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">AlexnetNet</td>
                              							
                              <td valign="top" class="cell">0.60</td>
                              							
                              <td valign="top" class="cell">115</td>
                              							
                              <td valign="top" class="cell">227 ∗ 227</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">ResNet18*</td>
                              							
                              <td valign="top" class="cell">0.56</td>
                              							
                              <td valign="top" class="cell">164</td>
                              							
                              <td valign="top" class="cell">224 ∗ 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Inception v3*</td>
                              							
                              <td valign="top" class="cell">0.55</td>
                              							
                              <td valign="top" class="cell">683</td>
                              							
                              <td valign="top" class="cell">299 ∗ 299</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">VGG*</td>
                              							
                              <td valign="top" class="cell">0.53</td>
                              							
                              <td valign="top" class="cell">610</td>
                              							
                              <td valign="top" class="cell">224 ∗ 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">SqueezeNet*</td>
                              							
                              <td valign="top" class="cell">0.50</td>
                              							
                              <td valign="top" class="cell">135</td>
                              							
                              <td valign="top" class="cell">224 ∗ 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">MNASNet*</td>
                              							
                              <td valign="top" class="cell">0.43</td>
                              							
                              <td valign="top" class="cell">196</td>
                              							
                              <td valign="top" class="cell">224 ∗ 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">DeepWriter</td>
                              							
                              <td valign="top" class="cell">0.42</td>
                              							
                              <td valign="top" class="cell">66</td>
                              							
                              <td valign="top" class="cell">113 ∗ 226</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Half DeepWriter</td>
                              							
                              <td valign="top" class="cell">0.38</td>
                              							
                              <td valign="top" class="cell">62</td>
                              							
                              <td valign="top" class="cell">113 ∗ 113</td>
                              						</tr>
                        </table>
                        <div class="caption-no-label">
                           <div class="label">Table 3. </div>
                        </div>
                     </div>
                     					
                     <div class="counter"><a href="#p55">55</a></div>
                     <div class="ptext" id="p55">Nine different CNN architectures are trained on the data of Table 1 to compare their
                        						performance on patch level. The weighted averaged F1-Score we use, is measured
                        on <span class="hi italic">test B</span>
                        					</div>
                     					
                     <div class="counter"><a href="#p56">56</a></div>
                     <div class="ptext" id="p56">(see Table 1) and rounded to two decimal places. The training-time is given in rounded
                        						minutes. The models marked by * originate from the torchvision library. </div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.2 Classification pipeline</h2>
                     					
                     <div class="ptext">
                        <ul class="list numbered">
                           <li class="item">To find the best type of input image for the CNN classification, we preprocessed
                              							the dataset in three different ways. We compared RGB images with grayscale
                              and
                              							masked grayscale images and found that masked grayscale images produce the
                              best
                              							F1-score in the test data (see Table 2). Consequently, the following experiments
                              							are based on this powerful image preprocessing. The masking has proven to be
                              							effective enough even though we used a simple threshold-based algorithm that
                              							sometimes does not reliably distinguish between ink and parchment. Hence, we
                              could
                              							replace it in further studies by a better learning-based solution.</li>
                           <li class="item">As there are different networks available for image classification, we compare
                              							in Table 3 nine powerful architectures. AlexNet achieves with an F1-score of
                              0.60
                              							on patch level and 115 minutes training time the best trade-off between F1-score
                              							and time. Only DenseNet achieved a small improvement of 0.01 in comparison
                              to
                              							AlexNet but with a training time of 503 minutes it is much less time efficient.
                              							Even though latest state-of-the-art models performed better, with a growing
                              number
                              							of parameters, the processing time would be impractical for our purpose, and
                              as
                              							already shown (see Table 2) data-centric approaches such as masked grayscale
                              							images are more influential. Given these F1 and training time results, we claim
                              							AlexNet to be best suited for our purposes and thus used it for all further
                              							experiments.</li>
                           <li class="item">To understand whether pre-training is beneficial, we follow the example of Xing
                              							&amp; Qiao (2016). Accordingly, we pre-trained AlexNet on 301 writers of the IAM
                              							dataset and fine-tuned the model on the CCl-DB data. The pre-trained and
                              							fine-tuned model generates an F1-score of 0.58 whereas the from scratch trained
                              							model outperformed this result with an F1-score of 0.60 on page level. Because
                              of
                              							the lower F1-score of the pre-trained and finetuned model model, we assume
                              that
                              							there are not enough shared features between the CCl-DB and the IAM dataset.
                              							However, as shown by Studer et al. (2019), models in general benefit from
                              							pre-training. We assume, that larger and more comprehensive datasets than the
                              IAM
                              							handwriting database could improve our model.</li>
                        </ul>
                     </div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.3 Automatic paleographic classificaion</h2>
                     					
                     <div class="counter"><a href="#p57">57</a></div>
                     <div class="ptext" id="p57">To figure out, which reliability values can be reached by the trained AlexNet, we
                        						evaluated the data of <span class="hi italic">test B</span>. The main experiments are
                        						performed on line level (see Figure 7), but we also provide test results on
                        patch and
                        						page level (see Table 4). Furthermore, we show the confusion matrix of the same
                        test
                        						data on page level in Figure 5. We observe, that the line level classification
                        						generally reinforces the patch level results and the page level classification
                        						generally reinforces the line level results.</div>
                     					
                     <div class="counter"><a href="#p58">58</a></div>
                     <div class="ptext" id="p58">Another particularity in Table 4 and Figure 5 are the dichotomous scores. Five of
                        seven
                        						classes are predicted well, such as F1-scores up to 1.0 on page level and 0.96
                        on line
                        						level in the case of A20 (see Table 4). Only the two classes B 20 and A 215
                        seem to be
                        						less precisely predicted on the test data. We observe low F1-Scores of 0.0 on
                        page
                        						level as well as 0.24 and 0.06 on line level respectively. However, the low
                        						predictions for the two classes B 20 and A 215 strengthen the hypothesis of
                        a powerful
                        						model as investigations of our paleographic partners revealed the labelling
                        of these
                        						classes to be most probably incorrect. The paleographers actually labeled this
                        test
                        						data as several not defined classes. Thus, the classification of the two classes
                        						proposed by the network might indeed correspond to the correct scribes and could
                        						therefore give new insight. However, confirmation by future research using our
                        						approach would be needed.</div>
                     					
                     <div class="counter"><a href="#p59">59</a></div>
                     <div class="ptext" id="p59">Table 4: Results of <span class="hi italic">test B</span>
                        					</div>
                     					
                     <div class="table">
                        <table class="table">
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Scribe</td>
                              							
                              <td valign="top" class="cell">F1-p</td>
                              							
                              <td valign="top" class="cell">F1-l</td>
                              							
                              <td valign="top" class="cell">F1-pg</td>
                              							
                              <td valign="top" class="cell">#-p</td>
                              							
                              <td valign="top" class="cell">#-l</td>
                              							
                              <td valign="top" class="cell">#-pg</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">B 259</td>
                              							
                              <td valign="top" class="cell">0.60</td>
                              							
                              <td valign="top" class="cell">0.76</td>
                              							
                              <td valign="top" class="cell">0.85</td>
                              							
                              <td valign="top" class="cell">31309</td>
                              							
                              <td valign="top" class="cell">1340</td>
                              							
                              <td valign="top" class="cell">42</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">A 259</td>
                              							
                              <td valign="top" class="cell">0.79</td>
                              							
                              <td valign="top" class="cell">0.94</td>
                              							
                              <td valign="top" class="cell">0.98</td>
                              							
                              <td valign="top" class="cell">34004</td>
                              							
                              <td valign="top" class="cell">1672</td>
                              							
                              <td valign="top" class="cell">52</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">A 30</td>
                              							
                              <td valign="top" class="cell">0.62</td>
                              							
                              <td valign="top" class="cell">0.76</td>
                              							
                              <td valign="top" class="cell">0.74</td>
                              							
                              <td valign="top" class="cell">56173</td>
                              							
                              <td valign="top" class="cell">2805</td>
                              							
                              <td valign="top" class="cell">66</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">A 20</td>
                              							
                              <td valign="top" class="cell">0.90</td>
                              							
                              <td valign="top" class="cell">0.96</td>
                              							
                              <td valign="top" class="cell">1.00</td>
                              							
                              <td valign="top" class="cell">71565</td>
                              							
                              <td valign="top" class="cell">2814</td>
                              							
                              <td valign="top" class="cell">72</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">B 20</td>
                              							
                              <td valign="top" class="cell">0.05</td>
                              							
                              <td valign="top" class="cell">0.24</td>
                              							
                              <td valign="top" class="cell">0.00</td>
                              							
                              <td valign="top" class="cell">1957</td>
                              							
                              <td valign="top" class="cell">111</td>
                              							
                              <td valign="top" class="cell">3</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">A 215</td>
                              							
                              <td valign="top" class="cell">0.07</td>
                              							
                              <td valign="top" class="cell">0.06</td>
                              							
                              <td valign="top" class="cell">0.00</td>
                              							
                              <td valign="top" class="cell">65689</td>
                              							
                              <td valign="top" class="cell">2897</td>
                              							
                              <td valign="top" class="cell">92</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">A 258</td>
                              							
                              <td valign="top" class="cell">0.68</td>
                              							
                              <td valign="top" class="cell">0.79</td>
                              							
                              <td valign="top" class="cell">0.83</td>
                              							
                              <td valign="top" class="cell">67520</td>
                              							
                              <td valign="top" class="cell">2893</td>
                              							
                              <td valign="top" class="cell">96</td>
                              						</tr>
                        </table>
                        <div class="caption-no-label">
                           <div class="label">Table 4. </div>
                        </div>
                     </div>
                     					
                     <div class="counter"><a href="#p60">60</a></div>
                     <div class="ptext" id="p60">F1-score on <span class="hi italic">test B </span>(see Table 1). The F1-score is measured on
                        						patch- (p) and line- (l) and page-level (pg). The weighted averaged test data
                        are
                        						random lines of unseen books, as</div>
                     					
                     <div class="counter"><a href="#p61">61</a></div>
                     <div class="ptext" id="p61">
                        						
                        <div class="figure">
                           							
                           							<a href="resources/images/figure05.png" rel="external"><img src="resources/images/figure05.png" style="" alt="" /></a>
                           						</div>Figure. 5: Confusion matrix of the data of <span class="hi italic">test B </span>on
                        						page level (see Table 3).these lines are of various length, they result in a
                        different
                        						number of patches. Due to the image preprocessing the total of samples is slightly
                        						lower than in Table 1.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.4 Reject Option</h2>
                     					
                     <div class="counter"><a href="#p62">62</a></div>
                     <div class="ptext" id="p62">
                        						
                        <div class="figure">
                           							
                           							<a href="resources/images/figure06.png" rel="external"><img src="resources/images/figure06.png" style="" alt="" /></a>
                           						</div>Figure. 6: Error-reject curves for five different scribes on the data of <span class="hi italic">test B </span>on line level (see Table 1).To investigate whether
                        						implementing a reject option improves results we tested the five classes B 259,
                        A 259,
                        						A 30, A 20, A 258 on it. These are the classes shown previously without conflicts
                        in
                        						the test data of <span class="hi italic">test B</span>. Figure 6 shows that increasing the
                        						reject rate minimizes the error. The reject curves of Figure 6 drop quickly,
                        						indicating a strong influence of the threshold. As Cilia et al. (2020<span class="hi italic">a</span>) explained, the reject option is therefore suitable for the scribe
                        						identification on the CCl-DB. Therefore, we choose a reject option based on
                        the
                        						threshold of 40 %, as it ensures low error with high sample rate. As class B
                        20 and A
                        						215 are difficult to evaluate from the test data, the threshold is adapted to
                        60
                        						%.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.5 Into the wild: Using our model on data with unknown scribes</h2>
                     					
                     <div class="counter"><a href="#p63">63</a></div>
                     <div class="ptext" id="p63">The central aim of our approach is to contribute new insights for paleography.
                        						Therefore, we examined sections from the codices that the experts limited to
                        one
                        						scribe, although they could not determine the exact individual. As shown in
                        Figure 7
                        						the trained model contributes meaningful classifications for these parts. The
                        first
                        						plot can be considered as reference, this is the part of CCl 214 written by
                        A 30. In
                        						this example, the model recognizes class A 30 as main class. The remaining six
                        plots
                        						can be differentiated into two groups. On the one hand there are plots b, d
                        and f
                        						which give significant results that refer to one scribe class B 20, A 30 and
                        A 215
                        						respectively. On the other hand, there are plots like in c, e and g that produce
                        						diffuse classification, not focused on one class. We conclude that these less
                        						significant predictions are caused either by scribes the 
                        <div class="figure">
                           							
                           							<a href="resources/images/figure07.png" rel="external"><img src="resources/images/figure07.png" style="" alt="" /></a>
                           						</div>Figure. 7: Scribe identification on line level and with reject option. All
                        						figures are based on the parts of one scribe. These new codices are labeled
                        with one
                        						given (a) and six unknown scribes (b-g).model hasn’t learned yet or by more
                        than one
                        						scribe.</div>
                     				</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  <h1 class="head">6 Conclusion</h1>
                  				
                  <div class="counter"><a href="#p64">64</a></div>
                  <div class="ptext" id="p64">In this paper, we want to study the question of how to train a reliable and efficient
                     model
                     					that allows cross-codex scribe identification in the strongly standardized medieval
                     					Carolingian minuscule of the CCl-DB. To this aim, we first figured out the risk
                     of codex
                     					specific overfitting and showed the importance of cross-codex data to overcome
                     this issue.
                     					We also found, that the reduction of RGB-images to grayscale masked images helps
                     the
                     					network to focus on scribe specific features and leads to significantly better
                     					results.</div>
                  				
                  <div class="counter"><a href="#p65">65</a></div>
                  <div class="ptext" id="p65">After comparing several networks, AlexNet was used in our pipeline to generate a
                     					classification on patch, line and page level. Finally, we improved the final
                     score by
                     					implementing the reject option.</div>
                  				
                  <div class="counter"><a href="#p66">66</a></div>
                  <div class="ptext" id="p66">One of the limitations of the proposed method is the basic segmentation, which is
                     					challenging on the historic parchment. This limitation leads to a natural direction
                     of
                     					future work, focusing on improving the segmentation method that also allows binarization.
                     					The outcomes of these investigations currently form the foundation for advancing
                     automated
                     					scribe identification. The recognition system described in this paper has been
                     integrated
                     					into the backend of an active learning application, while concurrently, we are
                     					collaboratively developing an intuitively accessible application with continuous
                     					annotations in close cooperation with paleographers. The inclusion of a visual
                     interface
                     					will empower experts to scrutinize and refine predictions, facilitating an iterative
                     					process of retraining our model and validating it against new scribe hypotheses.
                     These
                     					findings aim to unlock novel possibilities and analytical tools, fostering a
                     more profound
                     					comprehension of diverse medieval scriptoria. Going forward, this research endeavors
                     to
                     					bring researchers closer to addressing open questions regarding the organizational
                     aspects
                     					of scriptoria in the high medieval monasteries of (Lower) Austria, with additional
                     					evidence and interpretations serving as valuable support.</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  <h1 class="head">Funding</h1>
                  				
                  <div class="counter"><a href="#p67">67</a></div>
                  <div class="ptext" id="p67">This work has received funding from the Lower Austrian FTI-Call 2018 under grant agreement
                     					No FTI18-004 (project Active Machine Learning for Automatic Scribe Identification
                     in 12th
                     					Century Manuscripts). Moreover, the work was supported by Erasmus+ from the German
                     					Academic Exchange Service (DAAD).</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  <h1 class="head">Acknowledgments</h1>
                  				
                  <div class="counter"><a href="#p68">68</a></div>
                  <div class="ptext" id="p68">We would like to thank the team of the Klosterneuburg abbey library, as well as the
                     team of
                     					the institute of Creative\Media/Technologies of the St. Polten University of
                     Applied
                     					Sciences for their help.</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  <h1 class="head">Works Cited</h1>
                  				
                  <div class="counter"><a href="#p69">69</a></div>
                  <div class="ptext" id="p69">Bischoff 2004 Bischoff, B. (2004), <span class="hi italic">Paläographie des römischen Altertums
                        						und des abendländischen Mittelalters</span>, E. Schmidt, Berlin.</div>
                  				
                  <div class="counter"><a href="#p70">70</a></div>
                  <div class="ptext" id="p70">Brink et al. 2012 Brink, A., Smit, J., Bulacu, M. &amp; Schomaker, L. (2012), ‘Writer
                     					identification using directional ink-trace width measurements’, <span class="hi italic">Pattern
                        						Recognition </span>45(1), 162–171.</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://www.sciencedirect.com/science/article/pii/S0031320311002810</h2>
                     					
                     <div class="counter"><a href="#p71">71</a></div>
                     <div class="ptext" id="p71">Chammas et al. 2018 Chammas, E., Mokbel, C. &amp; Likforman-Sulem, L. (2018),
                        						Handwriting recognition of historical documents with few labeled data, <span class="hi italic">in </span>‘2018 13th IAPR International Workshop on Document Analysis
                        						Systems (DAS)’, IEEE Computer Society, Los Alamitos, CA, USA, pp. 43–48.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://doi.ieeecomputersociety.org/10.1109/DAS.2018.15</h2>
                     					
                     <div class="counter"><a href="#p72">72</a></div>
                     <div class="ptext" id="p72">Chammas et al. 2020 Chammas, M., Makhoul, A. &amp; DEMERJIAN, J. (2020), Writer
                        						identification for historical handwritten documents using a single feature extraction
                        						method, <span class="hi italic">in </span>‘19th International Conference on Machine Learning
                        						and Applications (ICMLA 2020)’, Miami (on line), United States. URL: <span class="hi italic">https://hal.archives-ouvertes.fr/hal-03017586</span>
                        					</div>
                     					
                     <div class="counter"><a href="#p73">73</a></div>
                     <div class="ptext" id="p73">Christlein et al. 2019 Christlein, V., Nicolaou, A., Seuret, M., Stutzmann, D. &amp;
                        						Maier, A. (2019), Icdar 2019 competition on image retrieval for historical handwritten
                        						documents, pp. 1505–1509.</div>
                     					
                     <div class="counter"><a href="#p74">74</a></div>
                     <div class="ptext" id="p74">Cilia et al. 2020a Cilia, N. D., De Stefano, C., Fontanella, F., Marrocco, C.,
                        						Molinara, M. &amp; Freca, A. S. d. (2020<span class="hi italic">a</span>), ‘An experimental
                        						comparison between deep learning and classical machine learning approaches for
                        writer
                        						identification in medieval documents’, <span class="hi italic">Journal of Imaging
                           						</span>6(9).</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://www.mdpi.com/2313-433X/6/9/89</h2>
                     					
                     <div class="counter"><a href="#p75">75</a></div>
                     <div class="ptext" id="p75">Cilia et al. 2020b Cilia, N., De Stefano, C., Fontanella, F., Marrocco, C., Molinara,
                        						M. &amp; Freca, A. (2020<span class="hi italic">b</span>), ‘An end-to-end deep learning system
                        						for medieval writer identification’, <span class="hi italic">Pattern Recognition Letters
                           						</span>129, 137–143.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://www.sciencedirect.com/science/article/pii/S0167865519303460</h2>
                     					
                     <div class="counter"><a href="#p76">76</a></div>
                     <div class="ptext" id="p76">Cloppet et al. 2016 Cloppet, F., Eglin, V., Kieu, V. C., Stutzmann, D. &amp; Vincent,
                        						N. (2016), Icfhr2016 competition on the classification of medieval handwritings
                        in
                        						latin script, <span class="hi italic">in </span>‘2016 15th International Conference on
                        						Frontiers in Handwriting Recognition (ICFHR)’, pp. 590–595.</div>
                     					
                     <div class="counter"><a href="#p77">77</a></div>
                     <div class="ptext" id="p77">De Stefano et al. 2011 De Stefano, C., Fontanella, F., Maniaci, M. &amp; Scotto di
                        						Freca, A. (2011), ‘A method for scribe distinction in medieval manuscripts using
                        page
                        						layout features’, pp. 393–402.</div>
                     					
                     <div class="counter"><a href="#p78">78</a></div>
                     <div class="ptext" id="p78">De Stefano et al. 2018 De Stefano, C., Maniaci, M., Fontanella, F. &amp; Scotto di
                        						Freca, A. (2018), ‘Layout measures for writer identification in mediaeval documents’,
                        							<span class="hi italic">Measurement </span>127, 443–452.</div>
                     					
                     <div class="counter"><a href="#p79">79</a></div>
                     <div class="ptext" id="p79">URL: <a href="https://www.sciencedirect.com/science/article/pii/S0263224118305359" onclick="window.open('https://www.sciencedirect.com/science/article/pii/S0263224118305359'); return false" class="ref"><span class="hi italic">https://www.sciencedirect.com/science/article/pii/S0263224118305359</span></a>
                        					</div>
                     					
                     <div class="counter"><a href="#p80">80</a></div>
                     <div class="ptext" id="p80">Dey et al. 201 Dey, S., Dutta, A., Toledo, J., Ghosh, S., Llados, J. &amp; Pal, U.
                        						(2017), ‘Signet: Convolutional siamese network for writer independent offline
                        						signature verification’, <span class="hi italic">CoRR</span> abs/1707.02131. URL: <span class="hi italic">http://arxiv.org/abs/1707.02131</span>
                        					</div>
                     					
                     <div class="counter"><a href="#p81">81</a></div>
                     <div class="ptext" id="p81">Fiel et al. 2017 Fiel, S., Kleber, F., Diem, M., Christlein, V., Louloudis, G., Nikos,
                        						S. &amp; Gatos, B. (2017), Icdar 2017 competition on historical document writer
                        						identification (historical-wi), <span class="hi italic">in </span>‘2017 14th IAPR
                        						International Conference on Document Analysis and Recognition (ICDAR)’, Vol.
                        01, IEEE,
                        						pp. 1377– 1382.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://ieeexplore.ieee.org/abstract/document/8270156</h2>
                     					
                     <div class="counter"><a href="#p82">82</a></div>
                     <div class="ptext" id="p82">Fiel &amp; Sablatnig 2012 Fiel, S. &amp; Sablatnig, R. (2012), ‘Writer retrieval and
                        						writer identification using local features’, <span class="hi italic">Proceedings - 10th IAPR
                           							International Workshop on Document Analysis Systems, DAS 2012</span>.</div>
                     					
                     <div class="counter"><a href="#p83">83</a></div>
                     <div class="ptext" id="p83">Fiel &amp; Sablatnig 2015 Fiel, S. &amp; Sablatnig, R. (2015), Writer identification
                        						and retrieval using a convolutional neural network, <span class="hi italic">in </span>G.
                        						Azzopardi &amp; N. Petkov, eds, ‘Computer Analysis of Images and Patterns’, Springer,
                        						Springer International Publishing, Cham, pp. 26–37.</div>
                     					
                     <div class="counter"><a href="#p84">84</a></div>
                     <div class="ptext" id="p84">Haidinger 1983 Haidinger, A. (1983), <span class="hi italic">Katalog der Handschriften des
                           							Augustiner Chorherrenstiftes Klosterneuburg</span>, Vol. 2 of <span class="hi italic">Veröffentlichungen der Kommission für Schrift- und Buchwesen des
                           							Mittelalters</span>, Wien.</div>
                     					
                     <div class="counter"><a href="#p85">85</a></div>
                     <div class="ptext" id="p85">Haidinger 1991 Haidinger, A. (1991), <span class="hi italic">Katalog der Handschriften des
                           							Augustiner Chorherrenstiftes Klosterneuburg</span>, Vol. 2 of <span class="hi italic">Veröffentlichungen der Kommission für Schrift- und Buchwesen des
                           							Mittelalters</span>, Wien.</div>
                     					
                     <div class="counter"><a href="#p86">86</a></div>
                     <div class="ptext" id="p86">Haidinger 2010 Haidinger, A. (2010), ‘manuscripta.at – ein webportal zu
                        						mittelalterlichen handschriften in österreichischen bibliotheken’, <span class="hi italic">Schriften der Vereinigung Österreichischer Bibliothekarinnen und Bibliothekare
                           							(VÖB)</span> pp. 53–61. URL: <a href="https://manuscripta.at/" onclick="window.open('https://manuscripta.at/'); return false" class="ref"><span class="hi italic">https://manuscripta.at/</span></a>
                        					</div>
                     					
                     <div class="counter"><a href="#p87">87</a></div>
                     <div class="ptext" id="p87">Haltich 2014 Haltich M. (2014), “Die Stiftsbibliothek”, in: Das Stift Klosterneuburg
                        :
                        						wo sich Himmel und Erde begegnen. Hrsg. von Wolfgang Huber. Doessel: Janos Stekovics
                        						Verlag, 2014, p. 216–229.</div>
                     					
                     <div class="counter"><a href="#p88">88</a></div>
                     <div class="ptext" id="p88">He &amp; Schomaker 2014 He, S. &amp; Schomaker, L. (2014), Delta-n hinge:
                        						Rotation-invariant features for writer identification, <span class="hi italic">in </span>‘2014
                        						22nd International Conference on Pattern Recognition’, pp. 2023–2028.</div>
                     					
                     <div class="counter"><a href="#p89">89</a></div>
                     <div class="ptext" id="p89">Islam et al. 2016 Islam, N., Islam, Z. &amp; Noor, N. (2016), ‘A survey on optical
                        						character recognition system’, <span class="hi italic">ITB Journal of Information and
                           							Communication Technology</span>.</div>
                     					
                     <div class="counter"><a href="#p90">90</a></div>
                     <div class="ptext" id="p90">Kahle et al. 2017 Kahle, P., Colutto, S., Hackl, G. &amp; Mühlberger, G. (2017),
                        						Transkribus - a service platform for transcription, recognition and retrieval
                        of
                        						historical documents, <span class="hi italic">in </span>‘2017 14th IAPR International
                        						Conference on Document Analysis and Recognition (ICDAR)’, Vol. 04, pp. 19–24.</div>
                     					
                     <div class="counter"><a href="#p91">91</a></div>
                     <div class="ptext" id="p91">Kluge 2019 Kluge M. (2019), Handschriften des Mittelalters: Grundwissen Kodikologie
                        und
                        						Paläographie. Thorbecke Jan Verlag. URL:
                        						https://books.google.de/books?id=unFHwgEACAAJ.</div>
                     					
                     <div class="counter"><a href="#p92">92</a></div>
                     <div class="ptext" id="p92">Krizhevsky et al. 2012 Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. (2012),
                        						Imagenet classification with deep convolutional neural networks, <span class="hi italic">in
                           						</span>F. Pereira, C. J. C. Burges, L. Bottou &amp; K. Q. Weinberger, eds, ‘Advances in
                        						Neural Information Processing Systems’, Vol. 25, Curran Associates, Inc. URL:
                        						https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c
                        						Paper.pdf</div>
                     					
                     <div class="counter"><a href="#p93">93</a></div>
                     <div class="ptext" id="p93">Lackner 2012 Lackner, F. (2012), <span class="hi italic">Katalog der Handschriften des
                           							Augustiner Chorherrenstiftes Klosterneuburg</span>, Vol. 2 of <span class="hi italic">Veröffentlichungen der Kommission für Schrift- und Buchwesen des
                           							Mittelalters</span>, Wien.</div>
                     					
                     <div class="counter"><a href="#p94">94</a></div>
                     <div class="ptext" id="p94">Landau 2004 Landau P. (2004), Die Lex Baiuvariorum. Entstehungszeit, Entstehungsort
                        und
                        						Charakter von Bayerns ältester Rechts- und Geschichtsquelle; vorgetragen in
                        der
                        						Gesamtsitzung vom 6. Juni 2003. München. URL:
                        						http://publikationen.badw.de/de/019366060.</div>
                     					
                     <div class="counter"><a href="#p95">95</a></div>
                     <div class="ptext" id="p95">Liu et al. 2011 Liu, C.-L., Yin, F., Wang, D.-H. &amp; Wang, Q.-F. (2011), Casia online
                        						and offline chinese handwriting databases, pp. 37 – 41.</div>
                     					
                     <div class="counter"><a href="#p96">96</a></div>
                     <div class="ptext" id="p96">Maaten &amp; Postma 2005 Maaten, L. V. D. &amp; Postma, E. (2005), Improving automatic
                        						writer identification, <span class="hi italic">in </span>‘PROC. OF 17TH BELGIUM-NETHERLANDS
                        						CONFERENCE ON ARTIFICIAL INTELLIGENCE (BNAIC 2005’, pp. 260–266.</div>
                     					
                     <div class="counter"><a href="#p97">97</a></div>
                     <div class="ptext" id="p97">Marcel &amp; Rodriguez 2010 Marcel, S. &amp; Rodriguez, Y. (2010), Torchvision the
                        						machine-vision package of torch, <span class="hi italic">in </span>‘Proceedings of the 18th
                        						ACM International Conference on Multimedia’, MM ’10, Association for Computing
                        						Machinery, New York, NY, USA, p. 1485–1488.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://doi.org/10.1145/1873951.1874254</h2>
                     					
                     <div class="counter"><a href="#p98">98</a></div>
                     <div class="ptext" id="p98">Marti &amp; Bunke 2002 Marti, U. &amp; Bunke, H. (2002), ‘The iam-database: an english
                        						sentence database for offline handwriting recognition’, <span class="hi italic">International Journal on Document Analysis and Recognition </span>5(1), 39–46.</div>
                     					
                     <div class="counter"><a href="#p99">99</a></div>
                     <div class="ptext" id="p99">Oliveira et al. 2018 Oliveira, S. A., Seguin, B. &amp; Kaplan, F. (2018), ‘dhsegment:
                        A
                        						generic deeplearning approach for document segmentation’, <span class="hi italic">2018 16th
                           							International Conference on Frontiers in Handwriting Recognition (ICFHR) </span>pp.
                        						7–12.</div>
                     					
                     <div class="counter"><a href="#p100">100</a></div>
                     <div class="ptext" id="p100">Powitz 2007 Powitz G. (2007), “Was vermag Paläographie?”, in: Urkundensprachen im
                        						germanisch-romanischen Grenzgebiet: Beiträge zum Kolloquium am 5./6. Oktober
                        1995 in
                        						Trier, hrsg. von K. Gärtner und G. Holtus (Trierer historische Forschungen,
                        35), p.
                        						223–251.</div>
                     					
                     <div class="counter"><a href="#p101">101</a></div>
                     <div class="ptext" id="p101">Said et al. 1998 Said, H., Baker, K. &amp; Tan, T. (1998), ‘Personal identification
                        						based on handwriting’, <span class="hi italic">Proceedings. Fourteenth International
                           							Conference on Pattern Recognition (Cat. No.98EX170) </span>2, 1761–1764.</div>
                     					
                     <div class="counter"><a href="#p102">102</a></div>
                     <div class="ptext" id="p102">Schneider 2014 Schneider, K. (2014), <span class="hi italic">Paläographie und
                           							Handschriftenkunde für Germanisten</span>, De Gruyter, Berlin/Boston.</div>
                     					
                     <div class="counter"><a href="#p103">103</a></div>
                     <div class="ptext" id="p103">Seidl &amp; Haltrich 2014 Seidl, M., Haltrich, M. (2014), ‘Codex
                        						claustroneoburgensis-datenbank (ccl-db)’. URL: <a href="https://phaidra.fhstp.ac.at/view/o:4631" onclick="window.open('https://phaidra.fhstp.ac.at/view/o:4631'); return false" class="ref">https://phaidra.fhstp.ac.at/view/o:4631</a>
                        					</div>
                     					
                     <div class="counter"><a href="#p104">104</a></div>
                     <div class="ptext" id="p104">Shaikh et al. 2020 Shaikh, M. A., Duan, T., Chauhan, M. &amp; Srihari, S. N. (2020),
                        						‘Attention based writer independent verification’, <span class="hi italic">2020 17th
                           							International Conference on Frontiers in Handwriting Recognition (ICFHR) </span>pp.
                        						373–379.</div>
                     					
                     <div class="counter"><a href="#p105">105</a></div>
                     <div class="ptext" id="p105">Studer et al. 2019 Studer, L., Alberti, M., Pondenkandath, V., Goktepe, P., Kolonko,
                        						T., Fischer, A., Liwicki, M. &amp; Ingold, R. (2019), ‘A comprehensive study of
                        						imagenet pre-training for historical document image analysis’, <span class="hi italic">2019
                           							International Conference on Document Analysis and Recognition (ICDAR) </span>pp.
                        						720–725.</div>
                     					
                     <div class="counter"><a href="#p106">106</a></div>
                     <div class="ptext" id="p106">Tensmeyer et al. 2017 Tensmeyer, C., Davis, B., Wigington, C., Lee, I. &amp; Barrett,
                        						B. (2017), Pagenet: Page boundary extraction in historical handwritten documents,
                        <span class="hi italic">in </span>‘Proceedings of the 4th International Workshop on Historical
                        						Document Imaging and Processing’, HIP2017, Association for Computing Machinery,
                        New
                        						York, NY, USA, p. 59–64.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://doi.org/10.1145/3151509.3151522</h2>
                     					
                     <div class="counter"><a href="#p107">107</a></div>
                     <div class="ptext" id="p107">Wu et al. 2014 Wu, X., Tang, Y. &amp; Bu, W. (2014), ‘Offline text-independent writer
                        						identification based on scale invariant feature transform’, <span class="hi italic">Information Forensics and Security, IEEE Transactions on </span>9, 526–536.</div>
                     					
                     <div class="counter"><a href="#p108">108</a></div>
                     <div class="ptext" id="p108">Xing &amp; Qiao 2016 Xing, L. &amp; Qiao, Y. (2016), Deepwriter: A multi-stream deep
                        						cnn for textindependent writer identification, <span class="hi italic">in </span>‘2016 15th
                        						International Conference on Frontiers in Handwriting Recognition (ICFHR)’, IEEE
                        						Computer Society, Los Alamitos, CA, USA, pp. 584–589.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://doi.ieeecomputersociety.org/10.1109/ICFHR.2016.0112</h2>
                     					
                     <div class="counter"><a href="#p109">109</a></div>
                     <div class="ptext" id="p109">Xiong et al. 2015 Xiong, Y.-J., Wen, Y., Wang, P. S. P. &amp; Lu, Y. (2015),
                        						Text-independent writer identification using sift descriptor and contour-directional
                        						feature, <span class="hi italic">in </span>‘2015 13th International Conference on Document
                        						Analysis and Recognition (ICDAR)’, pp. 91–95.</div>
                     					
                     <div class="counter"><a href="#p110">110</a></div>
                     <div class="ptext" id="p110">Yang et al. 2016 Yang, W., Jin, L. &amp; Liu, M. (2016), ‘Deepwriterid: An end-to-end
                        						online text-independent writer identification system’, <span class="hi italic">IEEE
                           							Intelligent Systems </span>31(2), 45–53.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">URL: https://doi.org/10.1109/MIS.2016.22</h2>
                     				</div>
                  			</div>
               		
               		
               			
               		
               	</div>
            
            <div id="notes">
               <h2>Notes</h2>
               <div class="endnote" id="d3e292"><span class="noteRef lang en">[1]  A typical single
                     						column page contains 31 or 32 lines. The vast majority of our books is in single
                     						column layout, hence we can roughly estimate that the 25200 lines correspond
                     to 800
                     						pages.</span></div>
               <div class="endnote" id="d3e297"><span class="noteRef lang en">[2]  Recently, artificial neural
                     						networks have demonstrated remarkable efficiency in handling unstructured data,
                     						including images, text, and speech. Convolutional Neural Networks (CNNs), as
                     a
                     						specialized architecture, have proven highly beneficial in image processing
                     by adeptly
                     						learning spatial hierarchies of features.</span></div>
               <div class="endnote" id="d3e331"><span class="noteRef lang en">[3]  The
                     						code for the experiments is publicly accessible:
                     						https://gitlab.rlp.net/studiengang-digitale-methodik/abschlussarbeiten/ma-repo/-/tree/main/experiments</span></div>
               <div class="endnote" id="d3e349"><span class="noteRef lang en">[4]  Deep learning is a subset of machine
                     						learning that involves neural networks with multiple layers (deep neural networks)
                     to
                     						model and process complex patterns in data.</span></div>
               <div class="endnote" id="d3e599"><span class="noteRef lang en">[5]  See: <a href="https://research.fhstp.ac.at/en/projects/scribe-id-ai" onclick="window.open('https://research.fhstp.ac.at/en/projects/scribe-id-ai'); return false" class="ref">https://research.fhstp.ac.at/en/projects/scribe-id-ai</a>
                     					</span></div>
               <div class="endnote" id="d3e643"><span class="noteRef lang en">[6]  Image masking is a
                     							technique of selectively concealing or revealing specific portions of an image.
                     In
                     							this example, masking is done by removing the parchment/background in the image,
                     							to focus the model's attention on the features of the handwriting.</span></div>
               <div class="endnote" id="d3e651"><span class="noteRef lang en">[7]  Data augmentation can be used to
                     							enlarge the dataset. In image classification it involves applying various
                     							transformations (such as rotation, flipping, and scaling) to the existing training
                     							dataset to create additional diverse samples, enhancing the model's ability
                     to
                     							generalize to different variations of the input images.</span></div>
            </div>
            <div id="worksCited">
               <h2>Works Cited</h2>
               <div class="bibl"><span class="ref" id="d3e1578"><!-- close --></span></div>
            </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            <div class="license"><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
               </div>
         </div>
      </div>
   </body>
</html>