<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>[PREVIEW] DHQ: Digital Humanities Quarterly: </title>
      <link href="../../common/css/dhq.css" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_screen.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_print.css" media="print" type="text/css" rel="stylesheet" />
      <style type="text/css">
        #mainContent {
          float: none;
          padding-top: 2em;
          padding-left: 4em;
          padding-right: 4em;
          margin-left: 225px;
           
        }</style>
   </head>
   <body>
      <div id="mainContent">
         <div class="DHQarticle">
            <div id="pubInfo">Preview<br />Volume  Number </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            	
            <div class="DHQheader">
               		
               			
               				
               				
               <h1 class="articleTitle lang en">Cross-codex Learning for Reliable Scribe Identification in Medieval
                  					Manuscripts</h1>
               				
               				
               <div class="author"><span style="color: grey">Julius Weißmann
                     					</span> &lt;<a href="mailto:weissmann_dot_julius_at_gmail_dot_com" onclick="javascript:window.location.href='mailto:'+deobfuscate('weissmann_dot_julius_at_gmail_dot_com'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('weissmann_dot_julius_at_gmail_dot_com'); return false;">weissmann_dot_julius_at_gmail_dot_com</a>&gt;, Media and Digital Technologies, St. Pölten University of Applied Sciences</div>
               				
               <div class="author"><span style="color: grey">Markus Seidl
                     					</span> &lt;<a href="mailto:markus_dot_seidl_at_fhstp_dot_ac_dot_at" onclick="javascript:window.location.href='mailto:'+deobfuscate('markus_dot_seidl_at_fhstp_dot_ac_dot_at'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('markus_dot_seidl_at_fhstp_dot_ac_dot_at'); return false;">markus_dot_seidl_at_fhstp_dot_ac_dot_at</a>&gt;, Media and Digital Technologies, St. Pölten University of Applied Sciences</div>
               				
               <div class="author"><span style="color: grey">Anya Dietrich
                     					</span> &lt;<a href="mailto:a_dot_dietrich_at_med_dot_uni-frankfurt_dot_de" onclick="javascript:window.location.href='mailto:'+deobfuscate('a_dot_dietrich_at_med_dot_uni-frankfurt_dot_de'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('a_dot_dietrich_at_med_dot_uni-frankfurt_dot_de'); return false;">a_dot_dietrich_at_med_dot_uni-frankfurt_dot_de</a>&gt;, MEG Unit, Brain Imaging Center</div>
               				
               <div class="author"><span style="color: grey">Martin Haltrich
                     					</span> &lt;<a href="mailto:m_dot_haltrich_at_stift-klosterneuburg_dot_at" onclick="javascript:window.location.href='mailto:'+deobfuscate('m_dot_haltrich_at_stift-klosterneuburg_dot_at'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('m_dot_haltrich_at_stift-klosterneuburg_dot_at'); return false;">m_dot_haltrich_at_stift-klosterneuburg_dot_at</a>&gt;, Library, Klosterneuburg Abbey</div>
               			
               			
               			
               		
               		
               		
               		
               	<span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Cross-codex%20Learning%20for%20Reliable%20Scribe%20Identification%20in%20Medieval%20Manuscripts&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=&amp;rft.volume=&amp;rft.issue=&amp;rft.aulast=Weißmann&amp;rft.aufirst=Julius&amp;rft.au=Julius%20Weißmann&amp;rft.au=Markus%20Seidl&amp;rft.au=Anya%20Dietrich&amp;rft.au=Martin%20Haltrich"> </span></div>
            	
            <div id="DHQtext">
               		
               			
               <div id="abstract">
                  <h2>Abstract</h2>
                  				
                  <p>Historic scribe identification is a substantial task for obtaining information about
                     the past. Uniform script
                     					styles, such as the Carolingian minuscule, make it a difficult task for classification
                     to focus on meaningful
                     					features. Therefore, we demonstrate in this paper the importance of cross-codex
                     training data for CNN based
                     					text-independent off-line scribe identification, to overcome codex dependent
                     overfitting. We report three main
                     					findings: First, we found that preprocessing with masked grayscale images instead
                     of RGB images clearly
                     					increased the F1-score of the classification results. Second, we trained different
                     neural networks on our
                     					complex data, validating time and accuracy differences in order to define the
                     most reliable network
                     					architecture. With AlexNet, the network with the best trade-off between F1-score
                     and time, we achieved for
                     					individual classes F1-scores of up to 0,96 on line level and up to 1.0 on page
                     level in classification. Third,
                     					we could replicate the finding that the CNN output can be further improved by
                     implementing a reject option,
                     					giving more stable results. We present the results on our large scale open source
                     dataset – the Codex
                     					Claustroneoburgensis database (CCl-DB) – containing a significant number of writings
                     from different scribes in
                     					several codices. We demonstrate for the first time on a dataset with such a variety
                     of codices that
                     					paleographic decisions can be reproduced automatically and precisely with CNNs.
                     This gives manifold new and
                     					fast possibilities for paleographers to gain insights into unlabeled material,
                     but also to develop further
                     					hypotheses.</p>
                  			</div>
               			
               		
               		
               			
               <div class="div div0">
                  				
                  <h1 class="head">1 Introduction</h1>
                  				
                  <div class="counter"><a href="#p1">1</a></div>
                  <div class="ptext" id="p1">In recent years, there has been a notable surge in the digitization of historical
                     documents, allowing for
                     					machine processing and providing unprecedented opportunities for researchers,
                     including palaeographers. A
                     					pivotal challenge lies in the identification of scribes, recognizing the hands
                     responsible for manuscript
                     					creation. However, this task is inherently time-intensive for researchers like
                     palaeographers and
                     					codicologists, constraining its scope.</div>
                  				
                  <div class="counter"><a href="#p2">2</a></div>
                  <div class="ptext" id="p2">Simultaneously, the differentiation and recognition of scribal hands represent an
                     essential methodology. This
                     					capability facilitates the determination of dates, specific scribal hands, or
                     the geographic origins, enabling
                     					the formulation of insights into the trajectories of medieval scribes across
                     diverse monasteries and
                     					scriptoria. Such information contributes significantly to our understanding of
                     dating, place of origin, and
                     					insights into the scribes themselves and their organizational structures [<a class="ref" href="#kluge2019">Kluge 2019</a>], [<a class="ref" href="#landau2004">Landau 2004</a>], [<a class="ref" href="#powitz2007">Powitz 2007</a>].</div>
                  				
                  <div class="counter"><a href="#p3">3</a></div>
                  <div class="ptext" id="p3">In European scriptoria the script <em class="term">Carolingian minuscule</em> was used until the second half of 12th
                     					century for writing and copying books (codices). This Latin script was the first
                     standardized script in the
                     					medieval period. Although codices typically lack specific notations regarding
                     which scribe wrote particular
                     					sections, the identification of scribes across various codices is invaluable
                     for understanding scriptoria
                     					organization and the movement of codices and scribes between monasteries.</div>
                  				
                  <div class="counter"><a href="#p4">4</a></div>
                  <div class="ptext" id="p4">The historic auxiliary science of paleography addresses, among other aspects, the
                     identification of scribes
                     					based on distinct, scribe-typical features in their writing. However, given the
                     sheer volume of codex pages,
                     					this task remains tedious and time-consuming, demanding a high level of domain
                     expertise. Automation through
                     					machines holds promise for expediting and enhancing the assignment of scribal
                     hands, thereby relieving
                     					palaeographers from laborious and repetitive tasks, making the process faster
                     and more comprehensive.</div>
                  				
                  <div class="counter"><a href="#p5">5</a></div>
                  <div class="ptext" id="p5">For instance, the library of Stift Klosterneurburg, amassed over the past 900 years,
                     boasting nearly 300,000
                     					copies. This remarkable collection, dating back to the 12th century, exemplifies
                     the potential of automated
                     					techniques in efficiently identifying scribes within the vast repository of codex
                     pages [<a class="ref" href="#haltich2014">Haltich 2014</a>].</div>
                  				
                  <div class="counter"><a href="#p6">6</a></div>
                  <div class="ptext" id="p6">Consequently, only a limited amount of medieval codices has been investigated with
                     a focus on scribe
                     					identification. The automation utilizing pattern recognition and machine learning
                     allows for larger amounts of
                     					material. However, to the best of our knowledge data of most automation-based
                     approaches are either limited to
                     					even only one [<a class="ref" href="#destefano_etal2011">De Stefano et al 2011</a>], [<a class="ref" href="#cilia_etal2020a">Cilia et al 2020a</a>], [<a class="ref" href="#cilia_etal2020b">Cilia et al 2020b</a>] or a few different codices or include material from way larger time periods
                     					(e.g. [<a class="ref" href="#fiel_etal2017">Fiel et al 2017</a>], [<a class="ref" href="#chammas_etal2020">Chammas et al 2020</a>]).</div>
                  				
                  <div class="counter"><a href="#p7">7</a></div>
                  <div class="ptext" id="p7">To overcome these shortcomings, we investigate automated scribe identification on
                     a large dataset we
                     					compiled: The CCl-DB [<a class="ref" href="#seidl_etal2014">Seidl and Haltrich 2014</a>]. This dataset contains 51 individual codices with a total
                     					amount of 17071 pages. These codices originate from the library of Klosterneuburg
                     Abbey and were written in
                     					the late 12th century in Carolingian minuscule [<a class="ref" href="#schneider2014">Schneider 2014</a>], [<a class="ref" href="#bischoff2004">Bischoff 2004</a>].
                     					The scarcity of information about the scribes underscores the significant value
                     of this new dataset and its
                     					associated processing capabilities.</div>
                  				
                  <div class="counter"><a href="#p8">8</a></div>
                  <div class="ptext" id="p8">We are aiming to answer two central questions:
                     <ol class="list">
                        <li class="item">Can the scribe assignments coming from decades of work by paleographic experts [<a class="ref" href="#haidinger1983">Haidinger 1983</a>], [<a class="ref" href="#haidinger1991">Haidinger 1991</a>], [<a class="ref" href="#lackner2012">Lackner 2012</a>] be successfully
                           							modelled and predicted?</li>
                        <li class="item">If so, can we use the models to predict scribes for codex pages that have unclear
                           scribe assignments
                           							or no scribe assignments at all?</li>
                     </ol>A substantial potential data specific risk seen in work by others that could render
                     our work useless is
                     					that we could model not only script specific features but also book specific
                     features such as the parchment
                     					and page margins. To mitigate this risk, we identified scribes that have been
                     found in at least 3 codices. The
                     					subset we use contains 25200<a class="noteRef" href="#d3e338">[1]</a> random lines uniformly distributed over 7 scribes in 31 different historic codices,
                     in order
                     					to train the models to recognize the scribe without codex specific features (<a href="#figure01">see
                        						Figure 1</a>).</div>
                  				
                  <div class="counter"><a href="#p9">9</a></div>
                  <div class="ptext" id="p9">In the last decade, convolutional neural networks<a class="noteRef" href="#d3e346">[2]</a> (CNNs) have proven to efficiently classify writers
                     					in modern and historic context and other tasks such as segmentation [<a class="ref" href="#oliveira_etal2018">Oliveira et al 2018</a>],
                     					optical character recognition [<a class="ref" href="#islam_etal2016">Islam et al 2016</a>], and writer identification [<a class="ref" href="#xing_etal2016">Xing and Qiao 2016</a>], [<a class="ref" href="#destefano_etal2011">De Stefano et al 2011</a>].</div>
                  				
                  <div class="counter"><a href="#p10">10</a></div>
                  <div class="ptext" id="p10">For our classification model we compared several general purpose object and concept
                     detection CNNs as well as
                     					specific architectures for scribe identification (<a href="#table03">see Table 3</a>). Surprisingly, the
                     					classic AlexNet [<a class="ref" href="#krizhevsky_etal2012">Krizhevsky et al 2012</a>] provided the best trade-off between F1-score and time. We
                     					show that we can distinguish the scribes described by paleographic experts and
                     even identify potential wrong
                     					scribe assignments. Furthermore, in combination with the reject option introduced
                     by Cilia et al. (<a href="#cilia_etal2020a">2020a</a>) we demonstrate that we can reliably predict the scribes for codices
                     					with unclear or missing scribe assignments.</div>
                  				
                  <div id="figure01" class="figure">
                     					
                     					
                     <div class="ptext"><a href="resources/images/figure01.jpg" rel="external"><img src="resources/images/figure01.jpg" style="" alt="Three differing lines of handwritten Carolingian miniscule" /></a></div>
                     					
                     				
                     <div class="caption">
                        <div class="label">Figure 1. </div>Examples from the CCl-DB [<a class="ref" href="#seidl_etal2014">Seidl and Haltrich 2014</a>] of three lines of different codices from one
                        						scribe. The ink and parchment appearance differs, although it’s written from
                        the same scribe (class A 30)
                        							[<a class="ref" href="#haidinger1991">Haidinger 1991</a>], [<a class="ref" href="#lackner2012">Lackner 2012</a>]. Top: CCl 206, middle: CCl 197, bottom: CCl
                        						217.</div>
                  </div>
                  				
                  <div class="counter"><a href="#p11">11</a></div>
                  <div class="ptext" id="p11">In this paper, we focus on three major issues:</div>
                  				
                  <div class="ptext">
                     <ul class="list">
                        <li class="item">the importance of cross-codex based training data for automatic scribe identification</li>
                        <li class="item">the feasibility of training a model based on scribe assignments by the paleographers
                           Haidinger (<a href="#haidinger2010">2010</a>, <a href="#haidinger1983">1983</a>, <a href="#haidinger1991">1991</a>) and Lackner (<a href="#lackner2012">2012</a>)</li>
                        <li class="item">the necessity of exploiting the confidence in scribe predictions to reveal uncertainties
                           in the
                           						dataset.</li>
                     </ul>
                  </div>
                  				
                  <div class="counter"><a href="#p12">12</a></div>
                  <div class="ptext" id="p12">The latter is a central requirement, as there is no objective ground truth for scribe
                     assignments for the
                     					medieval codices we are using. Our contribution in this paper is threefold:</div>
                  				
                  <div class="counter"><a href="#p13">13</a></div>
                  <div class="ptext" id="p13">Firstly, we demonstrate the necessity of book independent training of scribe models,
                     which has been neglected
                     					in other studies. Secondly, we demonstrate that contrary to the results of Xing
                     and Qiao (<a href="#xing_etal2016">2016</a>) standard architectures are sufficiently accurate to reliably identify
                     					medieval scribes in a classification pipeline. Thirdly, our work consequently
                     facilitates comprehensive and
                     					convincing studies on large datasets and allows new insights into the historic
                     monastic life and the
                     					relationships between the monasteries.<a class="noteRef" href="#d3e416">[3]</a>
                     				</div>
                  				
                  <div class="counter"><a href="#p14">14</a></div>
                  <div class="ptext" id="p14">The paper is structured as follows: after an overview about related work in <a href="#section02">Section
                        						2</a> we outline the dataset in <a href="#section03">Section 3</a>. In <a href="#section04">Section 4</a> we explain the applied methods for scribe identification. We show and discuss the
                     results
                     					in <a href="#section05">Section 5</a> and finally conclude the paper in <a href="#section06">Section
                        						6</a>.</div>
                  			</div>
               			
               <div id="section02" class="div div0">
                  				
                  <h1 class="head">2 Related work</h1>
                  				
                  <div class="counter"><a href="#p15">15</a></div>
                  <div class="ptext" id="p15">Computer-aided historic handwritten document analysis includes segmentation, text
                     recognition, dating and
                     					writer identification as well as verification. Segmentation usually separates
                     the written or drawn content
                     					from the carrier material (such as parchment or paper) [<a class="ref" href="#oliveira_etal2018">Oliveira et al 2018</a>], [<a class="ref" href="#tensmeyer_etal2017">Tensmeyer et al 2017</a>]. Based on this, a possible next step is handwritten text recognition (HTR)
                     						[<a class="ref" href="#chammas_etal2018">Chammas et al 2018</a>]. Either the segments or the written content alone or a combination of both
                     					modalities allow further investigations like dating, writer verification [<a class="ref" href="#shaikh_etal2020">Shaikh et al 2020</a>],
                     						[<a class="ref" href="#dey_etal2017">Dey et al 2017</a>] and identification [<a class="ref" href="#chammas_etal2020">Chammas et al 2020</a>], [<a class="ref" href="#xing_etal2016">Xing and Qiao 2016</a>], [<a class="ref" href="#fiel_etal2017">Fiel et al 2017</a>].</div>
                  				
                  <div class="counter"><a href="#p16">16</a></div>
                  <div class="ptext" id="p16">Different processes for scribe identification can be used, such as text-dependent
                     and text-independent.
                     					Text-dependent [<a class="ref" href="#said_etal1998">Said et al 1998</a>] methods allow identifying the writer on particular characters or
                     					words, whereas text-independent [<a class="ref" href="#yang_etal2016">Yang et al 2016</a>] approaches can be applied on new unseen
                     					content. Two kinds of handwritten text patterns can be used: on-line and offline
                     writer identification.
                     					On-line [<a class="ref" href="#yang_etal2016">Yang et al 2016</a>] systems work with time series of the formation process, while off-line
                     						[<a class="ref" href="#xing_etal2016">Xing and Qiao 2016</a>] solutions are limited to the images of the written text document.</div>
                  				
                  <div class="counter"><a href="#p17">17</a></div>
                  <div class="ptext" id="p17">Writer identification is a strong topic in document analysis and therefore much discussed.
                     In the last years,
                     					a variety of solutions have been provided. These methods can be grouped into
                     codebook-based and codebook-free
                     					methods. Codebook-based refer to a codebook that serves as a background model.
                     This model is based on
                     					statistical features like in [<a class="ref" href="#maaten_etal2005">Maaten and Postma 2005</a>]. The codebook-free methods include for example
                     					the width of ink traces, which was used from Brink et al. (<a href="#brink_etal2012">2021</a>) to
                     					predict the writer in medieval and modern handwritten documents, or the hinge
                     feature provided by [<a class="ref" href="#he_etal2014">He and Schomaker 2014</a>] in order to identify writers in handwritten English text in the IAM-dataset [<a class="ref" href="#marti_etal2002">Marti and Bunke 2002</a>]. Further, there have been strong results in using the Scale-Invariant Feature
                     					Transform (SIFT) for writer identification [<a class="ref" href="#xiong_etal2015">Xiong et al 2015</a>], [<a class="ref" href="#fiel_etal2012">Fiel and Sablatnig 2012</a>],
                     						[<a class="ref" href="#wu_etal2014">Wu et al 2014</a>].</div>
                  				
                  <div class="counter"><a href="#p18">18</a></div>
                  <div class="ptext" id="p18">In recent years, the number of Deep Learning<a class="noteRef" href="#d3e497">[4]</a> (DL) based studies in document analysis increased drastically [<a class="ref" href="#chammas_etal2020">Chammas et al 2020</a>], [<a class="ref" href="#cilia_etal2020b">Cilia et al 2020b</a>], [<a class="ref" href="#xing_etal2016">Xing and Qiao 2016</a>]. As mentioned in the introduction, the
                     					interest in using such techniques is due to their ability to provide powerful
                     state-of-the-art solutions in an
                     					efficient and reliable way. During the training, the DL model learns the best
                     fitting features for the
                     					classification. Therefore, no handcrafted features are required. For example,
                     Fiel and Sablatnig (<a href="#fiel_etal2015">2015</a>) demonstrated the strong performance of DL by employing CNNs for scribe
                     					identification on modern datasets. Xing and Qiao (<a href="#xing_etal2016">2016</a>) performed a writer
                     					identification on the modern IAM and the HWDB1.1 dataset. They developed a special
                     multi-stream CNN
                     					architecture based on AlexNet and outperformed previous approaches on handcrafted
                     features. Cilia et al. (<a href="#cilia_etal2020a">2020a</a>) demonstrated a comparison between deep learning and handcrafted
                     					features on the Avila Bible that is written in <em class="term">Carolingian minuscule</em>. These classical features,
                     					as Cilia et al. call them, are handcrafted features, that have been developed
                     in cooperation with
                     					paleographers. The results of their studies emphasize the effectiveness of deep
                     learning features in contrast
                     					to the handcrafted features.</div>
                  				
                  <div class="counter"><a href="#p19">19</a></div>
                  <div class="ptext" id="p19">In our research, we investigate <em class="term">scribe</em> identification in contrast to <em class="emph">writer</em>
                     					identification, since the specific individual of the writing is generally not
                     known for our material. Scribe
                     					identification is discussed in a medieval context only in a very limited range,
                     like at the International
                     					Conference on Document Analysis and Recognition (ICDAR) competitions [<a class="ref" href="#fiel_etal2017">Fiel et al 2017</a>] or in
                     					conjunction with the Avila bible [<a class="ref" href="#cilia_etal2020a">Cilia et al 2020a</a>]. However, the aforementioned datasets are of
                     					limited use for our goals. The Avila bible is literally only one codex and consequently
                     does not allow
                     					cross-codex scribe identification. The datasets used in the historical ICDAR
                     competitions [<a class="ref" href="#fiel_etal2017">Fiel et al 2017</a>], [<a class="ref" href="#christlein_etal2019">Christlein et al 2019</a>] span time periods of many centuries, and
                     					hence include different scripts and carrier materials. Thus, scribe identification
                     in the large amounts of
                     					medieval codices in Europe’s libraries is still a challenge and our approach
                     allows novel insights as it
                     					focuses on a wide range of codices of several scribes in the short period of
                     the late 12th century.</div>
                  			</div>
               			
               <div id="section03" class="div div0">
                  				
                  <h1 class="head">3 Dataset</h1>
                  				
                  <div class="counter"><a href="#p20">20</a></div>
                  <div class="ptext" id="p20">We perform experiments on a subset (<a href="#table01">see Table 1</a>) of seven scribes provided by
                     					the CCl-DB [<a class="ref" href="#seidl_etal2014">Seidl and Haltrich 2014</a>]. We selected the scribes which have contributed to as many books as
                     					possible to allow cross-codex evaluation. Samples in the dataset were handwritten
                     on parchment in
                     						<em class="term">Carolingian minuscule</em> (see <a href="#figure01">Figure 1</a> and <a href="#figure02">Figure 2</a>) on one- and two-column pages. These codices have been written down in the scriptorium
                     of
                     					Klosterneuburg in the last third of the 12th century. The data is provided by
                     the Scribe ID AI<a class="noteRef" href="#d3e556">[5]</a> project and has been labelled by paleographic experts based on the activity of the
                     paleographers
                     					Haidinger (<a href="#haidinger2010">2010</a>, <a href="#haidinger1983">1983</a>, <a href="#haidinger1991">1991</a>) and Lackner (<a href="#lackner2012">2012</a>). 52 labelled codices
                     					are provided in the CCl-DB. This database enables new possibilities within document
                     analysis and especially in
                     					handwriting recognition.</div>
                  				
                  <div id="table01" class="table">
                     <table class="table">
                        <tr class="row label">
                           						
                           <td valign="top" class="cell" rowspan="2">Class</td>
                           						
                           <td valign="top" class="cell" colspan="3">Training codices (Test A and Test B)</td>
                           						
                           <td valign="top" class="cell" colspan="3">Separate codices (Test B only)</td>
                           					</tr>
                        <tr class="row label">
                           						
                           <td valign="top" class="cell">Lines per codex</td>
                           						
                           <td valign="top" class="cell">#Codices</td>
                           						
                           <td valign="top" class="cell">Codices</td>
                           						
                           <td valign="top" class="cell">Lines per codex</td>
                           						
                           <td valign="top" class="cell">#Codices</td>
                           						
                           <td valign="top" class="cell">Codices</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell label">A 30</td>
                           						
                           <td valign="top" class="cell">450</td>
                           						
                           <td valign="top" class="cell">8</td>
                           						
                           <td valign="top" class="cell">30, 31, 197, 206, 226, 246, 256, 257</td>
                           						
                           <td valign="top" class="cell">1500</td>
                           						
                           <td valign="top" class="cell">2</td>
                           						
                           <td valign="top" class="cell">32217</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell label">A 259</td>
                           						
                           <td valign="top" class="cell">1200</td>
                           						
                           <td valign="top" class="cell">3</td>
                           						
                           <td valign="top" class="cell">209, 259, 949</td>
                           						
                           <td valign="top" class="cell">1754</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">706</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell label">B 259</td>
                           						
                           <td valign="top" class="cell">720</td>
                           						
                           <td valign="top" class="cell">5</td>
                           						
                           <td valign="top" class="cell">259, 622, 706, 212, 671</td>
                           						
                           <td valign="top" class="cell">1439</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">246</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell label">A 20</td>
                           						
                           <td valign="top" class="cell">1200</td>
                           						
                           <td valign="top" class="cell">3</td>
                           						
                           <td valign="top" class="cell">21, 28, 39</td>
                           						
                           <td valign="top" class="cell">3000</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">20</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell label">B 20</td>
                           						
                           <td valign="top" class="cell">900</td>
                           						
                           <td valign="top" class="cell">4</td>
                           						
                           <td valign="top" class="cell">22, 195, 216, 764</td>
                           						
                           <td valign="top" class="cell">119</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">20</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell label">A 215</td>
                           						
                           <td valign="top" class="cell">1200</td>
                           						
                           <td valign="top" class="cell">3</td>
                           						
                           <td valign="top" class="cell">215, 219, 703</td>
                           						
                           <td valign="top" class="cell">3000</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">245</td>
                           					</tr>
                        <tr class="row">
                           						
                           <td valign="top" class="cell label">A 258</td>
                           						
                           <td valign="top" class="cell">1800</td>
                           						
                           <td valign="top" class="cell">2</td>
                           						
                           <td valign="top" class="cell">258, 707</td>
                           						
                           <td valign="top" class="cell">3000</td>
                           						
                           <td valign="top" class="cell">1</td>
                           						
                           <td valign="top" class="cell">203</td>
                           					</tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 1. </div>Subset of the CCl-DB. The dataset for our experiments is a subset of the seven common
                        scribes of the
                        						CCl-DB [<a class="ref" href="#seidl_etal2014">Seidl and Haltrich 2014</a>]. We generated a dataset, with two groups of codices – the “Training
                        							Codices” and the “Separate Codices”. From the “Training Codices” we choose for every class
                        						3600 random lines, that are uniformly distributed over all books. In total these
                        are 25200 lines that are
                        						separated into training, validation and test data (Test A) according to the
                        ratio of 60%, 20% and 20%
                        						respectively. The separate books are used for an extra test set Test B. There
                        are up to 3000 lines of one
                        						class, depending on the codex-size.</div>
                  </div>
                  				
                  <div id="figure02" class="figure">
                     					
                     					
                     <div class="ptext"><a href="resources/images/figure02.jpeg" rel="external"><img src="resources/images/figure02.jpeg" style="" alt="A page of text divided into lines, then into individual glyphs" /></a></div>
                     					
                     				
                     <div class="caption">
                        <div class="label">Figure 2. </div>Image data of the CCl-DB [<a class="ref" href="#seidl_etal2014">Seidl and Haltrich 2014</a>] (CCl 20, S. 3r, hand A 20 [<a class="ref" href="#haidinger1983">Haidinger 1983</a>]). The CCl-DB provides the codices page by page (left) and on line-level
                        						(right-top). The line-level images are produced automatically by the segmentation
                        of Transkribus [<a class="ref" href="#kahle_etal2017">Kahle et al 2017</a>]. The neural network classification works with squared images, therefore we
                        						cropped the line images into squares and resized them into the network input
                        size.</div>
                  </div>
                  				
                  <div class="counter"><a href="#p21">21</a></div>
                  <div class="ptext" id="p21">To the best of our knowledge, there is no comparable database available that provides
                     the workings of many
                     					medieval scribes in various codices and in such a short period of time.</div>
                  			</div>
               			
               <div id="section04" class="div div0">
                  				
                  <h1 class="head">4 Methods for Scribe Identification</h1>
                  				
                  <div class="counter"><a href="#p22">22</a></div>
                  <div class="ptext" id="p22">This section will introduce the pipeline of our line-based scribe identification approach.
                     The pipeline is
                     					grouped into three main parts (<a href="#figure03">see Figure 3</a>). In the first part – the image
                     					preprocessing – we focus on providing the following network input images that
                     are reduced to their scribe
                     					specific information. The second part presents the neural network classification
                     approach. Here we compare
                     					different CNNs as image classifiers for scribe identification. Finally, the third
                     part covers the
                     					post-processing which generates the final score based on line- and page-level.
                     This is where we introduce the
                     					computation of the line score and the reject option – a method to improve the
                     prediction. All parts will be
                     					detailed in the following.</div>
                  				
                  <div id="figure03" class="figure">
                     					
                     					
                     <div class="ptext"><a href="resources/images/figure03.jpeg" rel="external"><img src="resources/images/figure03.jpeg" style="" alt="Flowchart of image processing steps resulting in page and line scores" /></a></div>
                     					
                     				
                     <div class="caption">
                        <div class="label">Figure 3. </div>Overall procedure of the proposed scribe recognition system. The rounded boxes symbolize
                        data, whereas
                        						the angular boxes show processes.</div>
                  </div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">4.1 Image preprocessing</h2>
                     					
                     <div class="counter"><a href="#p23">23</a></div>
                     <div class="ptext" id="p23">The dataset contains not only the codex pages, but also the extracted lines. The line
                        data is usually
                        						correctly extracted from the pages, however there are some small snippets with
                        no noticeable content in the
                        						dataset. As image lines are generally of wide aspect ratio, we use a simple
                        heuristic (\(\text{width}/\text{height}\leq5\)) to skip these uninformative
                        						snippets already in the step of preprocessing.</div>
                     					
                     <div class="counter"><a href="#p24">24</a></div>
                     <div class="ptext" id="p24">For studying the optimal input image data we generated grayscale images and masked
                        grayscale images
                        						additionally to the RGB data (<a href="#figure04">see Figure 4</a>). When we masked<a class="noteRef" href="#d3e804">[6]</a> the images we followed the example of De Stefano et al. (<a href="#destefano_etal2018">2018</a>). We applied their fixed threshold value, equal to 135, to
                        						separate the ink and the parchment of the grayscale images (<a href="#figure04">see Figure 4</a>). In
                        						related work [<a class="ref" href="#cilia_etal2020a">Cilia et al 2020a</a>], [<a class="ref" href="#fiel_etal2017">Fiel et al 2017</a>], [<a class="ref" href="#fiel_etal2015">Fiel and Sablatnig 2015</a>], [<a class="ref" href="#cloppet_etal2016">Cloppet et al 2016</a>], binarization is often applied to text images. However, since our
                        						masking does not work reliably enough to produce meaningful binarization, we
                        omit this step in this
                        						work.</div>
                     					
                     <div id="figure04" class="figure">
                        						
                        						
                        <div class="ptext"><a href="resources/images/figure04.jpeg" rel="external"><img src="resources/images/figure04.jpeg" style="" alt="The three-step preprocessing sequence for scribe identification" /></a></div>
                        						
                        					
                        <div class="caption">
                           <div class="label">Figure 4. </div>Example for the preprocessing (CCl 212, S. 1r, hand B 259 [<a class="ref" href="#lackner2012">Lackner 2012</a>]). The lines of
                           							the CCl-DB [<a class="ref" href="#seidl_etal2014">Seidl and Haltrich 2014</a>] are provided as RGB images (top). From these, we converted the
                           							images to grayscale (middle). The masked grayscaled images are produced by
                           removing the background from
                           							the ink.</div>
                     </div>
                     					
                     <div class="counter"><a href="#p25">25</a></div>
                     <div class="ptext" id="p25">As already mentioned, the lines of the CCl-DB are of different aspect ratio, but the
                        networks we
                        						implemented are working with a fixed input size. In order to handle the different
                        lengths of the lines, we
                        						followed the patch scanning strategy of Xing and Qiao (<a href="#xing_etal2016">2016</a>). First, the
                        						images have been resized in height to the specific network input image height,
                        while maintaining the aspect
                        						ratio of the line. Afterwards, we cropped the lines from left to right into
                        patches (<a href="#figure02">see Figure 2</a>). This sliding window comprises the network specific input image width. Due to the
                        						large dataset (<a href="#table01">see Table 1</a>), there is no need for data augmentation.<a class="noteRef" href="#d3e847">[7]</a> Hence, we generated patches with no overlap. Only one overlap occurs at the last
                        						image of each line, as the last patch of the line is generated by positioning
                        the sliding window at the end
                        						of the line. Finally, we scaled and normalized the patches.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">4.2 Patch level classification</h2>
                     					
                     <div class="counter"><a href="#p26">26</a></div>
                     <div class="ptext" id="p26">Xing and Qiao (<a href="#xing_etal2016">2016</a>) achieved high identification accuracies with their
                        						customized CNN’s on the line level data of the IAM [<a class="ref" href="#marti_etal2002">Marti and Bunke 2002</a>] dataset. They optimized
                        						AlexNet to the task of writer identification on the IAM dataset and denoted
                        the architecture Half
                        						DeepWriter. Next, they developed the DeepWriter architecture, which is an improvement
                        of Half DeepWriter
                        						that enables the computation of two sequential image patches in a single pass
                        with a multi-stream
                        						architecture. Xing and Qiao showed that DeepWriter produces the best results
                        on the line level data of the
                        						IAM dataset. Therefore, we implemented these three auspicious architectures
                        as per description of Xing and
                        						Qiao (<a href="#xing_etal2016">2016</a>), when we tested the potential of preprocessed images on our
                        						data (<a href="#table01">see Table 1</a>).</div>
                     					
                     <div class="counter"><a href="#p27">27</a></div>
                     <div class="ptext" id="p27">Additionally, we compared several other general-purpose object and concept detection
                        architectures in our
                        						study to find the best one suited to our specific data. For this purpose, we
                        used models provided by
                        						Torchvision [<a class="ref" href="#marcel_etal2010">Marcel and Rodriguez 2010</a>] (<a href="#table03">see Table 3</a>) and only adapted the
                        						input layer to the grayscale images and the output layer to the seven classes.</div>
                     					
                     <div class="counter"><a href="#p28">28</a></div>
                     <div class="ptext" id="p28">As shown in different studies, pre-training and fine-tuning a CNN can lead to better
                        results [<a class="ref" href="#xing_etal2016">Xing and Qiao 2016</a>] , [<a class="ref" href="#studer_etal2019">Studer et al 2019</a>]. Xing and Qiao (<a href="#xing_etal2016">2016</a>) demonstrated this on the IAM [<a class="ref" href="#marti_etal2002">Marti and Bunke 2002</a>] and the HWDB [<a class="ref" href="#liu_etal2011">Liu et al 2011</a>] dataset. Therefore, we trained the described models on the IAM dataset,
                        						fine-tuned them on our data and compared the results with the from scratch trained
                        weights.</div>
                     					
                     <div class="counter"><a href="#p29">29</a></div>
                     <div class="ptext" id="p29">The models have been trained with a batch size of 32 over 10 epochs with a learning
                        rate of \(1∗10^{−5}\) on ADAM. The error was calculated with the cross
                        						entropy. Over all ten epochs, the instance of the model that performed best
                        on the validation data has been
                        						saved for the next steps of the experiments.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">4.3 Postprocessing</h2>
                     					
                     <div class="counter"><a href="#p30">30</a></div>
                     <div class="ptext" id="p30">We pursue a patch, line and page level classification, but as already described, the
                        network classification
                        						is on patch level. To compute the line and page score, we follow the example
                        of Xing and Qiao (<a href="#xing_etal2016">2016</a>). They calculate the final score vector \(f_i\) for the \(j^{th}\) writer,
                        						of all patches \(N\) of one line: \(f_i=\frac{1}{N}\sum{^N_{i=1}}f_{ij}\). This averaged Softmax output serves as
                        						the basis for the final step of the post-processing – the reject option.</div>
                     					
                     <div class="counter"><a href="#p31">31</a></div>
                     <div class="ptext" id="p31">Cilia et al. (<a href="#cilia_etal2020a">2020a</a>) proposed the reject option to generate more
                        						reliable results for the writer identification on the Avila bible. They showed
                        that sometimes it is better
                        						to withdraw a precarious decision than accepting all predictions. In such a
                        case, they reject the prediction
                        						with the reject option.</div>
                     					
                     <div class="counter"><a href="#p32">32</a></div>
                     <div class="ptext" id="p32">We used the line score as a probability distribution to check the probabilities for
                        all writers. As Cilia
                        						et al. explained, the error-reject curve shows the impact of the reject rate
                        to the wrong predictions and
                        						allows finding the optimal threshold for rejecting a prediction. Our reject
                        rate is given by the line score
                        						of one writer. The reject rate corresponds to the wrong predictions.</div>
                     				</div>
                  			</div>
               			
               <div id="section05" class="div div0">
                  				
                  <h1 class="head">5 Results</h1>
                  				
                  <div class="counter"><a href="#p33">33</a></div>
                  <div class="ptext" id="p33">The purpose of this study was to train a model that classifies reliable and efficiently
                     scribes in
                     					cross-codex data. We want to enable the automatic continuation of the work of
                     paleography experts following
                     					their example, in order to allow research in large scale. In this study we would
                     like to find a model that is
                     					not only reliable but also fast in processing, as it is the basis for research
                     on active learning.</div>
                  				
                  <div class="counter"><a href="#p34">34</a></div>
                  <div class="ptext" id="p34">In <a href="#table02">Table 2</a> we show the importance of cross-codex test data and the risk of
                     					overfitting.</div>
                  				
                  <div class="counter"><a href="#p35">35</a></div>
                  <div class="ptext" id="p35">In the evaluation of our scribe classification pipeline, we found: 
                     <ol class="list">
                        <li class="item">Image preprocessing plays a key role in cross-codex scribe identification. In comparison
                           to RGB
                           							images, masked grayscale images roughly doubled the F1-score in the classification
                           task.</li>
                        <li class="item">Further, we showed that AlexNet provides very fast, and among the most reliable predictions
                           in
                           							classifying the scribes of our data set.</li>
                        <li class="item">Contrary to expectations, pre-training the network on the IAM database leads to worse
                           results, which
                           							is why we omitted this step.</li>
                     </ol>
                  </div>
                  				
                  <div class="counter"><a href="#p36">36</a></div>
                  <div class="ptext" id="p36">Applying the best fitting trained model, it turned out that it is very effective and
                     even indicates incorrect
                     					data.</div>
                  				
                  <div class="counter"><a href="#p37">37</a></div>
                  <div class="ptext" id="p37">Moreover, we introduce the reject option on our dataset in order to get rid of precarious
                     classifications and
                     					found that it underlines the results.</div>
                  				
                  <div class="counter"><a href="#p38">38</a></div>
                  <div class="ptext" id="p38">Finally, we deployed the pipeline to processes open paleographic topics.</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.1 Cross-codex data</h2>
                     					
                     <div class="counter"><a href="#p39">39</a></div>
                     <div class="ptext" id="p39">The CCl-DB provides handwritings of several scribes in different codices. Therefore,
                        we compared two test
                        						sets (<a href="#table02">see Table 2</a>) to check if the networks tend to learn codex-specific
                        						features. For this experiment we trained the architectures AlexNet, Half Deep
                        Writer and DeepWriter.
                        						Referring to Xing and Qiao (<a href="#xing_etal2016">2016</a>) these networks are suitable for
                        						handwriting identification. We found, that the test set Test B which contains
                        test samples from books which
                        						have not been used for training (<a href="#table01">see Table 1</a>) is more comprehensive than Test A
                        						because all three trained networks performed better on Test A whether the input
                        images have been RGB
                        						grayscale or masked. We conclude, that the networks learned codex-specific features
                        in Test A. Therefore, we
                        						used the test set Test B for further experiments to obtain more reliable results.</div>
                     					
                     <div id="table02" class="table">
                        <table class="table">
                           <tr class="row label">
                              							
                              <td valign="top" class="cell">Data</td>
                              							
                              <td valign="top" class="cell">Network</td>
                              							
                              <td valign="top" class="cell">RGB</td>
                              							
                              <td valign="top" class="cell">GS</td>
                              							
                              <td valign="top" class="cell">GS mask</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label" rowspan="4">Test A</td>
                              							
                              <td valign="top" class="cell">AlexNet</td>
                              							
                              <td valign="top" class="cell">0.25</td>
                              							
                              <td valign="top" class="cell">0.56</td>
                              							
                              <td valign="top" class="cell">0.64</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Deep Writer</td>
                              							
                              <td valign="top" class="cell">0.25</td>
                              							
                              <td valign="top" class="cell">0.44</td>
                              							
                              <td valign="top" class="cell">0.57</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Half Deep Writer</td>
                              							
                              <td valign="top" class="cell">0.25</td>
                              							
                              <td valign="top" class="cell">0.41</td>
                              							
                              <td valign="top" class="cell">0.54</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">∅</td>
                              							
                              <td valign="top" class="cell">0.25</td>
                              							
                              <td valign="top" class="cell">0.47</td>
                              							
                              <td valign="top" class="cell">0.58</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label" rowspan="4">Test B</td>
                              							
                              <td valign="top" class="cell">AlexNet</td>
                              							
                              <td valign="top" class="cell">0.30</td>
                              							
                              <td valign="top" class="cell">0.53</td>
                              							
                              <td valign="top" class="cell">0.60</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Deep Writer</td>
                              							
                              <td valign="top" class="cell">0.26</td>
                              							
                              <td valign="top" class="cell">0.32</td>
                              							
                              <td valign="top" class="cell">0.42</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">Half Deep Writer</td>
                              							
                              <td valign="top" class="cell">0.35</td>
                              							
                              <td valign="top" class="cell">0.30</td>
                              							
                              <td valign="top" class="cell">0.38</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell">∅</td>
                              							
                              <td valign="top" class="cell">0.30</td>
                              							
                              <td valign="top" class="cell">0.38</td>
                              							
                              <td valign="top" class="cell">0.47</td>
                              						</tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 2. </div>F1-score for image preprocessing on patch level. Preprocessed input images and their
                           impact on the
                           							classification of the test data. The experiment was performed on the three
                           different networks AlexNet,
                           							Half DeepWriter and Deepwriter. As a result, the averaged F1-score is given.
                           We provide two F1-scores of
                           							separate test sets (<a href="#table01">see Table 1</a>).</div>
                     </div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.2 Classification pipeline</h2>
                     					
                     <div class="counter"><a href="#p40">40</a></div>
                     <div class="ptext" id="p40"> To find the best type of input image for the CNN classification, we preprocessed
                        the dataset in three
                        						different ways. We compared RGB images with grayscale and masked grayscale images
                        and found that masked
                        						grayscale images produce the best F1-score in the test data (<a href="#table02">see Table 2</a>).
                        						Consequently, the following experiments are based on this powerful image preprocessing.
                        The masking has
                        						proven to be effective enough even though we used a simple threshold-based algorithm
                        that sometimes does not
                        						reliably distinguish between ink and parchment. Hence, we could replace it in
                        further studies by a better
                        						learning-based solution.</div>
                     					
                     <div id="table03" class="table">
                        <table class="table">
                           <tr class="row label">
                              							
                              <td valign="top" class="cell">Network</td>
                              							
                              <td valign="top" class="cell">F1 Test B</td>
                              							
                              <td valign="top" class="cell">Time</td>
                              							
                              <td valign="top" class="cell">Image (height, width)</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">Densenet*</td>
                              							
                              <td valign="top" class="cell">0.61</td>
                              							
                              <td valign="top" class="cell">503</td>
                              							
                              <td valign="top" class="cell">224, 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">AlexnetNet</td>
                              							
                              <td valign="top" class="cell"><span class="hi bold">0.60</span></td>
                              							
                              <td valign="top" class="cell"><span class="hi bold">115</span></td>
                              							
                              <td valign="top" class="cell">227, 227</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">ResNet18*</td>
                              							
                              <td valign="top" class="cell">0.56</td>
                              							
                              <td valign="top" class="cell">164</td>
                              							
                              <td valign="top" class="cell">224, 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">Inception v3*</td>
                              							
                              <td valign="top" class="cell">0.55</td>
                              							
                              <td valign="top" class="cell">683</td>
                              							
                              <td valign="top" class="cell">299, 299</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">VGG*</td>
                              							
                              <td valign="top" class="cell">0.53</td>
                              							
                              <td valign="top" class="cell">610</td>
                              							
                              <td valign="top" class="cell">224, 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">SqueezeNet*</td>
                              							
                              <td valign="top" class="cell">0.50</td>
                              							
                              <td valign="top" class="cell">135</td>
                              							
                              <td valign="top" class="cell">224, 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">MNASNet*</td>
                              							
                              <td valign="top" class="cell">0.43</td>
                              							
                              <td valign="top" class="cell">196</td>
                              							
                              <td valign="top" class="cell">224, 224</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">DeepWriter</td>
                              							
                              <td valign="top" class="cell">0.42</td>
                              							
                              <td valign="top" class="cell">66</td>
                              							
                              <td valign="top" class="cell">113, 226</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">Half DeepWriter</td>
                              							
                              <td valign="top" class="cell">0.38</td>
                              							
                              <td valign="top" class="cell">62</td>
                              							
                              <td valign="top" class="cell">113, 113</td>
                              						</tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 3. </div>Network performance on patch level. Nine different CNN architectures are trained on
                           the data of <a href="#table01">Table 1</a> to compare their performance on patch level. The weighted averaged
                           							F1-Score we use, is measured on Test B (<a href="#table01">see Table 1</a>) and rounded to two
                           							decimal places. The training-time is given in rounded minutes. The models marked
                           by * originate from the
                           							torchvision library.</div>
                     </div>
                     					
                     <div class="counter"><a href="#p41">41</a></div>
                     <div class="ptext" id="p41">As there are different networks available for image classification, we compare in
                        <a href="#table03">Table 3</a> nine powerful architectures. AlexNet achieves with an F1-score of 0.60 on patch level
                        and
                        						115 minutes training time the best trade-off between F1-score and time. Only
                        DenseNet achieved a small
                        						improvement of 0.01 in comparison to AlexNet but with a training time of 503
                        minutes it is much less time
                        						efficient. Even though latest state-of-the-art models performed better, with
                        a growing number of parameters,
                        						the processing time would be impractical for our purpose, and as already shown
                        (<a href="#table02">see
                           							Table 2</a>) data-centric approaches such as masked grayscale images are more influential. Given
                        these
                        						F1 and training time results, we claim AlexNet to be best suited for our purposes
                        and thus used it for all
                        						further experiments.</div>
                     					
                     <div class="counter"><a href="#p42">42</a></div>
                     <div class="ptext" id="p42">To understand whether pre-training is beneficial, we follow the example of Xing and
                        Qiao (<a href="#xing_etal2016">2016</a>). Accordingly, we pre-trained AlexNet on 301 writers of the IAM dataset
                        						and fine-tuned the model on the CCl-DB data. The pre-trained and fine-tuned
                        model generates an F1-score of
                        						0.58 whereas the from scratch trained model outperformed this result with an
                        F1-score of 0.60 on page level.
                        						Because of the lower F1-score of the pre-trained and finetuned model model,
                        we assume that there are not
                        						enough shared features between the CCl-DB and the IAM dataset. However, as shown
                        by Studer et al. (<a href="#studer_etal2019">2019</a>), models in general benefit from pre-training. We assume, that larger
                        						and more comprehensive datasets than the IAM handwriting database could improve
                        our model.</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.3 Automatic paleographic classification</h2>
                     					
                     <div class="counter"><a href="#p43">43</a></div>
                     <div class="ptext" id="p43">To figure out, which reliability values can be reached by the trained AlexNet, we
                        evaluated the data of
                        						Test B. The main experiments are performed on line level (<a href="#figure07">see Figure 7</a>), but
                        						we also provide test results on patch and page level (<a href="#table04">see Table 4</a>).
                        						Furthermore, we show the confusion matrix of the same test data on page level
                        in <a href="#figure05">Figure 5</a>. We observe, that the line level classification generally reinforces the patch level
                        						results and the page level classification generally reinforces the line level
                        results.</div>
                     					
                     <div class="counter"><a href="#p44">44</a></div>
                     <div class="ptext" id="p44">Another particularity in <a href="#table04">Table 4</a> and <a href="#figure05">Figure 5</a>
                        						are the dichotomous scores. Five of seven classes are predicted well, such as
                        F1-scores up to 1.0 on page
                        						level and 0.96 on line level in the case of A20 (<a href="#table04">see Table 4</a>). Only the two
                        						classes B 20 and A 215 seem to be less precisely predicted on the test data.
                        We observe low F1-Scores of 0.0
                        						on page level as well as 0.24 and 0.06 on line level respectively. However,
                        the low predictions for the two
                        						classes B 20 and A 215 strengthen the hypothesis of a powerful model as investigations
                        of our paleographic
                        						partners revealed the labelling of these classes to be most probably incorrect.
                        The paleographers actually
                        						labeled this test data as several not defined classes. Thus, the classification
                        of the two classes proposed
                        						by the network might indeed correspond to the correct scribes and could therefore
                        give new insight. However,
                        						confirmation by future research using our approach would be needed.</div>
                     					
                     <div id="table04" class="table">
                        <table class="table">
                           <tr class="row label">
                              							
                              <td valign="top" class="cell">Scribe</td>
                              							
                              <td valign="top" class="cell">F1-p</td>
                              							
                              <td valign="top" class="cell">F1-l</td>
                              							
                              <td valign="top" class="cell">F1-pg</td>
                              							
                              <td valign="top" class="cell">#-p</td>
                              							
                              <td valign="top" class="cell">#-l</td>
                              							
                              <td valign="top" class="cell">#-pg</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">B 259</td>
                              							
                              <td valign="top" class="cell">0.60</td>
                              							
                              <td valign="top" class="cell">0.76</td>
                              							
                              <td valign="top" class="cell">0.85</td>
                              							
                              <td valign="top" class="cell">31309</td>
                              							
                              <td valign="top" class="cell">1340</td>
                              							
                              <td valign="top" class="cell">42</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">A 259</td>
                              							
                              <td valign="top" class="cell">0.79</td>
                              							
                              <td valign="top" class="cell">0.94</td>
                              							
                              <td valign="top" class="cell">0.98</td>
                              							
                              <td valign="top" class="cell">34004</td>
                              							
                              <td valign="top" class="cell">1672</td>
                              							
                              <td valign="top" class="cell">52</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">A 30</td>
                              							
                              <td valign="top" class="cell">0.62</td>
                              							
                              <td valign="top" class="cell">0.76</td>
                              							
                              <td valign="top" class="cell">0.74</td>
                              							
                              <td valign="top" class="cell">56173</td>
                              							
                              <td valign="top" class="cell">2805</td>
                              							
                              <td valign="top" class="cell">66</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">A 20</td>
                              							
                              <td valign="top" class="cell">0.90</td>
                              							
                              <td valign="top" class="cell">0.96</td>
                              							
                              <td valign="top" class="cell">1.00</td>
                              							
                              <td valign="top" class="cell">71565</td>
                              							
                              <td valign="top" class="cell">2814</td>
                              							
                              <td valign="top" class="cell">72</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">B 20</td>
                              							
                              <td valign="top" class="cell">0.05</td>
                              							
                              <td valign="top" class="cell">0.24</td>
                              							
                              <td valign="top" class="cell">0.00</td>
                              							
                              <td valign="top" class="cell">1957</td>
                              							
                              <td valign="top" class="cell">111</td>
                              							
                              <td valign="top" class="cell">3</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">A 215</td>
                              							
                              <td valign="top" class="cell">0.07</td>
                              							
                              <td valign="top" class="cell">0.06</td>
                              							
                              <td valign="top" class="cell">0.00</td>
                              							
                              <td valign="top" class="cell">65689</td>
                              							
                              <td valign="top" class="cell">2897</td>
                              							
                              <td valign="top" class="cell">92</td>
                              						</tr>
                           <tr class="row">
                              							
                              <td valign="top" class="cell label">A 258</td>
                              							
                              <td valign="top" class="cell">0.68</td>
                              							
                              <td valign="top" class="cell">0.79</td>
                              							
                              <td valign="top" class="cell">0.83</td>
                              							
                              <td valign="top" class="cell">67520</td>
                              							
                              <td valign="top" class="cell">2893</td>
                              							
                              <td valign="top" class="cell">96</td>
                              						</tr>
                        </table>
                        <div class="caption">
                           <div class="label">Table 4. </div>Results of Test B. F1-score on Test B(<a href="#table01">see Table 1</a>). The F1-score is
                           							measured on patch- (p) and line- (l) and page-level (pg). The weighted averaged
                           test data are random lines
                           							of unseen books, as these lines are of various length, they result in a different
                           number of patches. Due
                           							to the image preprocessing the total of samples is slightly lower than in <a href="#table01">Table
                              								1</a>.</div>
                     </div>
                     					
                     <div class="counter"><a href="#p45">45</a></div>
                     <div class="ptext" id="p45"></div>
                     					
                     <div id="figure05" class="figure">
                        						
                        						
                        <div class="ptext"><a href="resources/images/figure05.png" rel="external"><img src="resources/images/figure05.png" style="" alt="a matrix showing truth vs prediction where light colors represent higher scores" /></a></div>
                        						
                        					
                        <div class="caption">
                           <div class="label">Figure 5. </div>Confusion matrix of the data of Test B on page level (<a href="#table03">see Table
                              							3</a>).</div>
                     </div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.4 Reject Option</h2>
                     					
                     <div class="counter"><a href="#p46">46</a></div>
                     <div class="ptext" id="p46"> To investigate whether implementing a reject option improves results we tested the
                        five classes (B 259, A
                        						259, A 30, A 20, A 258) on it. These are the classes shown previously without
                        conflicts in the test data of
                        						Test B. <a href="#figure06">Figure 6</a> shows that increasing the reject rate minimizes the error.
                        						The reject curves of <a href="#figure06">Figure 6</a> drop quickly, indicating a strong influence of
                        						the threshold. As Cilia et al. (<a href="#cilia_etal2020a">2020a</a>) explained, the reject option is
                        						therefore suitable for the scribe identification on the CCl-DB. Therefore, we
                        choose a reject option based
                        						on the threshold of 40 %, as it ensures low error with high sample rate. As
                        class B 20 and A 215 are
                        						difficult to evaluate from the test data, the threshold is adapted to 60%.</div>
                     					
                     <div id="figure06" class="figure">
                        						
                        						
                        <div class="ptext"><a href="resources/images/figure06.png" rel="external"><img src="resources/images/figure06.png" style="" alt="a line graph where high steady y-values drop sharply after 40%" /></a></div>
                        						
                        					
                        <div class="caption">
                           <div class="label">Figure 6. </div>Error-reject curves for five different scribes on the data of Test B on line level
                           (<a href="#table01">see Table 1</a>).</div>
                     </div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">5.5 Into the wild: Using our model on data with unknown scribes</h2>
                     					
                     <div class="counter"><a href="#p47">47</a></div>
                     <div class="ptext" id="p47">The central aim of our approach is to contribute new insights for paleography. Therefore,
                        we examined
                        						sections from the codices that the experts limited to one scribe, although they
                        could not determine the
                        						exact individual. As shown in <a href="#figure07">Figure 7</a> the trained model contributes
                        						meaningful classifications for these parts. The first plot can be considered
                        as reference, this is the part
                        						of CCl 214 written by A 30. In this example, the model recognizes class A 30
                        as main class. The remaining
                        						six plots can be differentiated into two groups. On the one hand there are plots
                        b, d and f which give
                        						significant results that refer to one scribe class B 20, A 30 and A 215 respectively.
                        On the other hand,
                        						there are plots like in c, e and g that produce diffuse classification, not
                        focused on one class. We
                        						conclude that these less significant predictions are caused either by scribes
                        the model hasn’t learned yet
                        						or by more than one scribe.</div>
                     					
                     <div id="figure07" class="figure">
                        						
                        						
                        <div class="ptext"><a href="resources/images/figure07.png" rel="external"><img src="resources/images/figure07.png" style="" alt="7 comparative bar graphs where the &#34;reject option&#34; yields more favorable results" /></a></div>
                        						
                        					
                        <div class="caption">
                           <div class="label">Figure 7. </div>Scribe identification on line level and with reject option. All figures are based
                           on the parts of one
                           							scribe. These new codices are labeled with one given (a) and six unknown scribes
                           (b-g).</div>
                     </div>
                     				</div>
                  			</div>
               			
               <div id="section06" class="div div0">
                  				
                  <h1 class="head">6 Conclusion</h1>
                  				
                  <div class="counter"><a href="#p48">48</a></div>
                  <div class="ptext" id="p48">In this paper, we want to study the question of how to train a reliable and efficient
                     model that allows
                     					cross-codex scribe identification in the strongly standardized medieval Carolingian
                     minuscule of the CCl-DB.
                     					To this aim, we first figured out the risk of codex specific overfitting and
                     showed the importance of
                     					cross-codex data to overcome this issue. We also found, that the reduction of
                     RGB-images to grayscale masked
                     					images helps the network to focus on scribe specific features and leads to significantly
                     better results.</div>
                  				
                  <div class="counter"><a href="#p49">49</a></div>
                  <div class="ptext" id="p49">After comparing several networks, AlexNet was used in our pipeline to generate a classification
                     on patch,
                     					line and page level. Finally, we improved the final score by implementing the
                     reject option.</div>
                  				
                  <div class="counter"><a href="#p50">50</a></div>
                  <div class="ptext" id="p50">One of the limitations of the proposed method is the basic segmentation, which is
                     challenging on the historic
                     					parchment. This limitation leads to a natural direction of future work, focusing
                     on improving the segmentation
                     					method that also allows binarization. The outcomes of these investigations currently
                     form the foundation for
                     					advancing automated scribe identification. The recognition system described in
                     this paper has been integrated
                     					into the backend of an active learning application, while concurrently, we are
                     collaboratively developing an
                     					intuitively accessible application with continuous annotations in close cooperation
                     with paleographers. The
                     					inclusion of a visual interface will empower experts to scrutinize and refine
                     predictions, facilitating an
                     					iterative process of retraining our model and validating it against new scribe
                     hypotheses. These findings aim
                     					to unlock novel possibilities and analytical tools, fostering a more profound
                     comprehension of diverse
                     					medieval scriptoria. Going forward, this research endeavors to bring researchers
                     closer to addressing open
                     					questions regarding the organizational aspects of scriptoria in the high medieval
                     monasteries of (Lower)
                     					Austria, with additional evidence and interpretations serving as valuable support.</div>
                  			</div>
               			
               <div class="div div0">
                  				
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">Funding</h2>
                     					
                     <div class="counter"><a href="#p51">51</a></div>
                     <div class="ptext" id="p51">This work has received funding from the Lower Austrian FTI-Call 2018 under grant agreement
                        No FTI18-004
                        						(project Active Machine Learning for Automatic Scribe Identification in 12th
                        Century Manuscripts). Moreover,
                        						the work was supported by Erasmus+ from the German Academic Exchange Service
                        (DAAD).</div>
                     				</div>
                  				
                  <div class="div div1">
                     					
                     <h2 class="head">Acknowledgments</h2>
                     					
                     <div class="counter"><a href="#p52">52</a></div>
                     <div class="ptext" id="p52">We would like to thank the team of the Klosterneuburg abbey library, as well as the
                        team of the institute
                        						of Creative\Media/Technologies of the St. Polten University of Applied Sciences
                        for their help.</div>
                     				</div>
                  			</div>
               		
               		
               			
               		
               	</div>
            
            <div id="notes">
               <h2>Notes</h2>
               <div class="endnote" id="d3e338"><span class="noteRef lang en">[1] A typical single column page contains 31 or 32 lines. The vast majority of
                     						our books is in single column layout, hence we can roughly estimate that the
                     25200 lines correspond to 800
                     						pages.</span></div>
               <div class="endnote" id="d3e346"><span class="noteRef lang en">[2] Recently, artificial neural networks have demonstrated
                     						remarkable efficiency in handling unstructured data, including images, text,
                     and speech. Convolutional
                     						Neural Networks (CNNs), as a specialized architecture, have proven highly beneficial
                     in image processing by
                     						adeptly learning spatial hierarchies of features.</span></div>
               <div class="endnote" id="d3e416"><span class="noteRef lang en">[3] The code for the experiments is publicly accessible: <a href="https://gitlab.rlp.net/studiengang-digitale-methodik/abschlussarbeiten/ma-repo/-/tree/main/experiments" onclick="window.open('https://gitlab.rlp.net/studiengang-digitale-methodik/abschlussarbeiten/ma-repo/-/tree/main/experiments'); return false" class="ref">https://gitlab.rlp.net/studiengang-digitale-methodik/abschlussarbeiten/ma-repo/-/tree/main/experiments</a></span></div>
               <div class="endnote" id="d3e497"><span class="noteRef lang en">[4] Deep learning is a subset of machine learning that involves
                     						neural networks with multiple layers (deep neural networks) to model and process
                     complex patterns in
                     						data.</span></div>
               <div class="endnote" id="d3e556"><span class="noteRef lang en">[5] See: <a href="https://research.fhstp.ac.at/en/projects/scribe-id-ai" onclick="window.open('https://research.fhstp.ac.at/en/projects/scribe-id-ai'); return false" class="ref">https://research.fhstp.ac.at/en/projects/scribe-id-ai</a>
                     					</span></div>
               <div class="endnote" id="d3e804"><span class="noteRef lang en">[6] Image masking
                     							is a technique of selectively concealing or revealing specific portions of
                     an image. In this example,
                     							masking is done by removing the parchment/background in the image, to focus
                     the model's attention on the
                     							features of the handwriting.</span></div>
               <div class="endnote" id="d3e847"><span class="noteRef lang en">[7] Data
                     							augmentation can be used to enlarge the dataset. In image classification it
                     involves applying various
                     							transformations (such as rotation, flipping, and scaling) to the existing training
                     dataset to create
                     							additional diverse samples, enhancing the model's ability to generalize to
                     different variations of the
                     							input images.</span></div>
            </div>
            <div id="worksCited">
               <h2>Works Cited</h2>
               <div class="bibl"><span class="ref" id="bischoff2004"><!-- close -->Bischoff 2004</span>  Bischoff, B. (2004) <cite class="title italic">Paläographie des
                     						römischen Altertums und des abendländischen Mittelalters</cite>, E. Schmidt, Berlin.</div>
               <div class="bibl"><span class="ref" id="brink_etal2012"><!-- close -->Brink et al 2012</span>  Brink, A., Smit, J., Bulacu, M. and Schomaker, L. (2012)
                  						“Writer identification using directional ink-trace width measurements”, <cite class="title italic">Pattern Recognition</cite> 45(1), 162–171. Available at: <a href="https://www.sciencedirect.com/science/article/pii/S0031320311002810" onclick="window.open('https://www.sciencedirect.com/science/article/pii/S0031320311002810'); return false" class="ref">https://www.sciencedirect.com/science/article/pii/S0031320311002810</a>.</div>
               <div class="bibl"><span class="ref" id="chammas_etal2018"><!-- close -->Chammas et al 2018</span>  Chammas, E., Mokbel, C. and Likforman-Sulem, L.
                  					(2018) “Handwriting recognition of historical documents with few labeled data”, in
                  						<cite class="title italic">2018 13th IAPR International Workshop on Document Analysis Systems (DAS)</cite>, IEEE
                  					Computer Society, Los Alamitos, CA, USA, pp. 43–48. Available at: <a href="https://doi.ieeecomputersociety.org/10.1109/DAS.2018.15" onclick="window.open('https://doi.ieeecomputersociety.org/10.1109/DAS.2018.15'); return false" class="ref">https://doi.ieeecomputersociety.org/10.1109/DAS.2018.15</a>.</div>
               <div class="bibl"><span class="ref" id="chammas_etal2020"><!-- close -->Chammas et al 2020</span>  Chammas, M., Makhoul, A. and DEMERJIAN, J. (2020)
                  						“Writer identification for historical handwritten documents using a single feature
                  						extraction method”, in <cite class="title italic">19th International Conference on Machine Learning and
                     						Applications (ICMLA 2020)</cite>, Miami (on line), United States. Available at: <a href="https://hal.archives-ouvertes.fr/hal-03017586" onclick="window.open('https://hal.archives-ouvertes.fr/hal-03017586'); return false" class="ref">https://hal.archives-ouvertes.fr/hal-03017586</a>.</div>
               <div class="bibl"><span class="ref" id="christlein_etal2019"><!-- close -->Christlein et al 2019</span>  Christlein, V., Nicolaou, A., Seuret, M.,
                  					Stutzmann, D. and Maier, A. (2019) “Icdar 2019 competition on image retrieval for
                  						historical handwritten documents”, in <cite class="title italic">2019 International Conference on Document
                     						Analysis and Recognition</cite>. IEEE, pp. 1505–1509.</div>
               <div class="bibl"><span class="ref" id="cilia_etal2020a"><!-- close -->Cilia et al 2020a</span>  Cilia, N. D., De Stefano, C., Fontanella, F.,
                  					Marrocco, C., Molinara, M. and Freca, A. S. d. (2020a), “An experimental comparison
                  						between deep learning and classical machine learning approaches for writer identification
                  in medieval
                  						documents”, <cite class="title italic">Journal of Imaging</cite> 6(9). Available at: <a href="https://www.mdpi.com/2313-433X/6/9/89" onclick="window.open('https://www.mdpi.com/2313-433X/6/9/89'); return false" class="ref">https://www.mdpi.com/2313-433X/6/9/89</a>.</div>
               <div class="bibl"><span class="ref" id="cilia_etal2020b"><!-- close -->Cilia et al 2020b</span>  Cilia, N., De Stefano, C., Fontanella, F., Marrocco,
                  					C., Molinara, M. and Freca, A. (2020b), “An end-to-end deep learning system for medieval
                  						writer identification”, <cite class="title italic">Pattern Recognition Letters</cite> 129, 137–143.
                  					Available at: <a href="https://www.sciencedirect.com/science/article/pii/S0167865519303460" onclick="window.open('https://www.sciencedirect.com/science/article/pii/S0167865519303460'); return false" class="ref">https://www.sciencedirect.com/science/article/pii/S0167865519303460</a>.</div>
               <div class="bibl"><span class="ref" id="cloppet_etal2016"><!-- close -->Cloppet et al 2016</span>  Cloppet, F., Eglin, V., Kieu, V. C., Stutzmann, D.
                  					and Vincent, N. (2016) “Icfhr2016 competition on the classification of medieval
                  						handwritings in latin script”, in <cite class="title italic">2016 15th International Conference on
                     						Frontiers in Handwriting Recognition (ICFHR)</cite>, pp. 590–595.</div>
               <div class="bibl"><span class="ref" id="destefano_etal2011"><!-- close -->De Stefano et al 2011</span>  De Stefano, C., Fontanella, F., Maniaci, M. and
                  					Scotto di Freca, A. (2011) “A method for scribe distinction in medieval manuscripts using
                  						page layout features”, in <cite class="title italic">Image Analysis and Processing–ICIAP 2011: 16th
                     						International Conference Proceedings</cite>, pp. 393–402.</div>
               <div class="bibl"><span class="ref" id="destefano_etal2018"><!-- close -->De Stefano et al 2018</span>  De Stefano, C., Maniaci, M., Fontanella, F. and
                  					Scotto di Freca, A. (2018) “Layout measures for writer identification in mediaeval
                  						documents”, <cite class="title italic">Measurement</cite> 127, 443–452. Available at: <a href="https://www.sciencedirect.com/science/article/pii/S0263224118305359" onclick="window.open('https://www.sciencedirect.com/science/article/pii/S0263224118305359'); return false" class="ref">https://www.sciencedirect.com/science/article/pii/S0263224118305359</a>.</div>
               <div class="bibl"><span class="ref" id="dey_etal2017"><!-- close -->Dey et al 2017</span>  Dey, S., Dutta, A., Toledo, J., Ghosh, S., Llados, J. and
                  					Pal, U. (2017) “Signet: Convolutional siamese network for writer independent offline
                  						signature verification”, <cite class="title italic">CoRR</cite> abs/1707.02131. Available at: <a href="http://arxiv.org/abs/1707.02131" onclick="window.open('http://arxiv.org/abs/1707.02131'); return false" class="ref">http://arxiv.org/abs/1707.02131</a>.</div>
               <div class="bibl"><span class="ref" id="fiel_etal2012"><!-- close -->Fiel and Sablatnig 2012</span>  Fiel, S. and Sablatnig, R. (2012) “Writer retrieval and writer identification using local features”, <cite class="title italic">Proceedings - 10th IAPR International Workshop on Document Analysis Systems, DAS 2012</cite>.</div>
               <div class="bibl"><span class="ref" id="fiel_etal2015"><!-- close -->Fiel and Sablatnig 2015</span>  Fiel, S. and Sablatnig, R. (2015) <cite class="title">Writer
                     						identification and retrieval using a convolutional neural network</cite>, in G. Azzopardi and N. Petkov,
                  					eds, <cite class="title italic">Computer Analysis of Images and Patterns</cite>, Springer, Springer International
                  					Publishing, Cham, pp. 26–37.</div>
               <div class="bibl"><span class="ref" id="fiel_etal2017"><!-- close -->Fiel et al 2017</span>  Fiel, S., Kleber, F., Diem, M., Christlein, V., Louloudis,
                  					G., Nikos, S. and Gatos, B. (2017) “Icdar 2017 competition on historical document writer
                  						identification (historical-wi)”, in <cite class="title italic">2017 14th IAPR International Conference on
                     						Document Analysis and Recognition (ICDAR)</cite>, Vol. 01, IEEE, pp. 1377– 1382. Available at: <a href="https://ieeexplore.ieee.org/abstract/document/8270156" onclick="window.open('https://ieeexplore.ieee.org/abstract/document/8270156'); return false" class="ref">https://ieeexplore.ieee.org/abstract/document/8270156</a>.</div>
               <div class="bibl"><span class="ref" id="haidinger1983"><!-- close -->Haidinger 1983</span>  Haidinger, A. (1983) <cite class="title italic">Katalog der
                     						Handschriften des Augustiner Chorherrenstiftes Klosterneuburg</cite>, Vol. 2 of <cite class="title italic">Veröffentlichungen der Kommission für Schrift- und Buchwesen des Mittelalters</cite>, Wien.</div>
               <div class="bibl"><span class="ref" id="haidinger1991"><!-- close -->Haidinger 1991</span>  Haidinger, A. (1991) <cite class="title italic">Katalog der
                     						Handschriften des Augustiner Chorherrenstiftes Klosterneuburg</cite>, Vol. 2 of <cite class="title italic">Veröffentlichungen der Kommission für Schrift- und Buchwesen des Mittelalters</cite>, Wien.</div>
               <div class="bibl"><span class="ref" id="haidinger2010"><!-- close -->Haidinger 2010</span>  Haidinger, A. (2010) “manuscripta.at –
                  						ein webportal zu mittelalterlichen handschriften in österreichischen bibliotheken”, <cite class="title italic">Schriften der Vereinigung Österreichischer Bibliothekarinnen und Bibliothekare (VÖB)</cite>
                  					pp. 53–61. Available at: <a href="https://manuscripta.at/" onclick="window.open('https://manuscripta.at/'); return false" class="ref">https://manuscripta.at/</a>.</div>
               <div class="bibl"><span class="ref" id="haltich2014"><!-- close -->Haltich 2014</span>  Haltich M. (2014) “Die
                  						Stiftsbibliothek”, in: <cite class="title italic">Das Stift Klosterneuburg : wo sich Himmel und Erde
                     						begegnen</cite>. Hrsg. von Wolfgang Huber. Doessel: Janos Stekovics Verlag, 2014, p. 216–229.</div>
               <div class="bibl"><span class="ref" id="he_etal2014"><!-- close -->He and Schomaker 2014</span>  He, S. and Schomaker, L. (2014) “Delta-n hinge: Rotation-invariant features for writer identification”, in <cite class="title italic">2014
                     						22nd International Conference on Pattern Recognition</cite>, pp. 2023–2028.</div>
               <div class="bibl"><span class="ref" id="islam_etal2016"><!-- close -->Islam et al 2016</span>  Islam, N., Islam, Z. and Noor, N. (2016) “A survey on optical character recognition system”, <cite class="title italic">ITB Journal of
                     						Information and Communication Technology</cite>.</div>
               <div class="bibl"><span class="ref" id="kahle_etal2017"><!-- close -->Kahle et al 2017</span>  Kahle, P., Colutto, S., Hackl, G. and Mühlberger, G.
                  					(2017) “Transkribus - a service platform for transcription, recognition and retrieval of
                  						historical documents”, in <cite class="title italic">2017 14th IAPR International Conference on Document
                     						Analysis and Recognition (ICDAR)</cite>, Vol. 04, pp. 19–24.</div>
               <div class="bibl"><span class="ref" id="kluge2019"><!-- close -->Kluge 2019</span>  Kluge M. (2019) <cite class="title italic">Handschriften des
                     						Mittelalters: Grundwissen Kodikologie und Paläographie</cite>. Thorbecke Jan Verlag. Available at: <a href="https://books.google.de/books?id=unFHwgEACAAJ" onclick="window.open('https://books.google.de/books?id=unFHwgEACAAJ'); return false" class="ref">https://books.google.de/books?id=unFHwgEACAAJ</a>.</div>
               <div class="bibl"><span class="ref" id="krizhevsky_etal2012"><!-- close -->Krizhevsky et al 2012</span>  Krizhevsky, A., Sutskever, I. and Hinton, G.
                  					E. (2012) “Imagenet classification with deep convolutional neural networks”, in F.
                  					Pereira, C. J. C. Burges, L. Bottou and K. Q. Weinberger, eds, <cite class="title italic">Advances in Neural
                     						Information Processing Systems</cite>, Vol. 25, Curran Associates, Inc. Available at: <a href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68cPaper.pdf" onclick="window.open('https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68cPaper.pdf'); return false" class="ref">https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68cPaper.pdf</a>.</div>
               <div class="bibl"><span class="ref" id="lackner2012"><!-- close -->Lackner 2012</span>  Lackner, F. (2012) <cite class="title italic">Katalog der
                     						Handschriften des Augustiner Chorherrenstiftes Klosterneuburg</cite>, Vol. 2 of <cite class="title italic">Veröffentlichungen der Kommission für Schrift- und Buchwesen des Mittelalters</cite>, Wien.</div>
               <div class="bibl"><span class="ref" id="landau2004"><!-- close -->Landau 2004</span>  Landau P. (2004) “Die Lex Baiuvariorum.
                  						Entstehungszeit, Entstehungsort und Charakter von Bayerns ältester Rechts- und
                  Geschichtsquelle”;
                  						<cite class="title itlaic">vorgetragen in der Gesamtsitzung</cite> vom 6. Juni 2003. München. Available at: <a href="http://publikationen.badw.de/de/019366060" onclick="window.open('http://publikationen.badw.de/de/019366060'); return false" class="ref">http://publikationen.badw.de/de/019366060</a>.</div>
               <div class="bibl"><span class="ref" id="liu_etal2011"><!-- close -->Liu et al 2011</span>  Liu, C.-L., Yin, F., Wang, D.-H. and Wang, Q.-F. (2011)
                  						“Casia online and offline chinese handwriting databases”, pp. 37 – 41.</div>
               <div class="bibl"><span class="ref" id="maaten_etal2005"><!-- close -->Maaten and Postma 2005</span>  Maaten, L. V. D. and Postma, E. (2005) “Improving automatic writer identification”, in <cite class="title italic">PROC. OF 17TH
                     						BELGIUM-NETHERLANDS CONFERENCE ON ARTIFICIAL INTELLIGENCE (BNAIC 2005</cite>, pp. 260–266.</div>
               <div class="bibl"><span class="ref" id="marcel_etal2010"><!-- close -->Marcel and Rodriguez 2010</span>  Marcel, S. and Rodriguez, Y. (2010) “Torchvision the machine-vision package of torch”, in <cite class="title italic">Proceedings
                     						of the 18th ACM International Conference on Multimedia</cite>, MM ’10, Association for Computing Machinery,
                  					New York, NY, USA, p. 1485–1488. Available at: <a href="https://doi.org/10.1145/1873951.1874254" onclick="window.open('https://doi.org/10.1145/1873951.1874254'); return false" class="ref">https://doi.org/10.1145/1873951.1874254</a>.</div>
               <div class="bibl"><span class="ref" id="marti_etal2002"><!-- close -->Marti and Bunke 2002</span>  Marti, U. and Bunke, H. (2002) “The iam-database: an english sentence database for offline handwriting recognition”, <cite class="title italic">International Journal on Document Analysis and Recognition</cite> 5(1), 39–46.</div>
               <div class="bibl"><span class="ref" id="oliveira_etal2018"><!-- close -->Oliveira et al 2018</span>  Oliveira, S. A., Seguin, B. and Kaplan, F. (2018)
                  						“dhsegment: A generic deeplearning approach for document segmentation”, <cite class="title italic">2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR)</cite> pp.
                  					7–12.</div>
               <div class="bibl"><span class="ref" id="powitz2007"><!-- close -->Powitz 2007</span>  Powitz G. (2007) “Was vermag Paläographie?”, in: Urkundensprachen
                  					im germanisch-romanischen Grenzgebiet: Beiträge zum Kolloquium am 5./6. Oktober
                  1995 in Trier, hrsg. von K.
                  					Gärtner und G. Holtus (Trierer historische Forschungen, 35), p. 223–251.</div>
               <div class="bibl"><span class="ref" id="said_etal1998"><!-- close -->Said et al 1998</span>  Said, H., Baker, K. and Tan, T. (1998) “Personal identification based on handwriting”, <cite class="title italic">Proceedings.
                     						Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)</cite> 2, 1761–1764.</div>
               <div class="bibl"><span class="ref" id="schneider2014"><!-- close -->Schneider 2014</span>  Schneider, K. (2014) <cite class="title italic">Paläographie und
                     						Handschriftenkunde für Germanisten</cite>, De Gruyter, Berlin/Boston.</div>
               <div class="bibl"><span class="ref" id="seidl_etal2014"><!-- close -->Seidl and Haltrich 2014</span>  Seidl, M., Haltrich, M. (2014) “Codex claustroneoburgensis-datenbank (ccl-db)”. Available at: <a href="https://phaidra.fhstp.ac.at/view/o:4631" onclick="window.open('https://phaidra.fhstp.ac.at/view/o:4631'); return false" class="ref">https://phaidra.fhstp.ac.at/view/o:4631</a>.</div>
               <div class="bibl"><span class="ref" id="shaikh_etal2020"><!-- close -->Shaikh et al 2020</span>  Shaikh, M. A., Duan, T., Chauhan, M. and Srihari, S.
                  					N. (2020) “Attention based writer independent verification”, <cite class="title italic">2020 17th International Conference on Frontiers in Handwriting Recognition (ICFHR)</cite> pp.
                  					373–379.</div>
               <div class="bibl"><span class="ref" id="studer_etal2019"><!-- close -->Studer et al 2019</span>  Studer, L., Alberti, M., Pondenkandath, V., Goktepe,
                  					P., Kolonko, T., Fischer, A., Liwicki, M. and Ingold, R. (2019) “A comprehensive study of
                  						imagenet pre-training for historical document image analysis”, <cite class="title italic">2019
                     						International Conference on Document Analysis and Recognition (ICDAR)</cite> pp. 720–725.</div>
               <div class="bibl"><span class="ref" id="tensmeyer_etal2017"><!-- close -->Tensmeyer et al 2017</span>  Tensmeyer, C., Davis, B., Wigington, C., Lee, I.
                  					and Barrett, B. (2017) “Pagenet: Page boundary extraction in historical handwritten
                  						documents”, in <cite class="title italic">Proceedings of the 4th International Workshop on Historical
                     						Document Imaging and Processing</cite>, HIP2017, Association for Computing Machinery, New York, NY, USA, p.
                  					59–64. Available at: <a href="https://doi.org/10.1145/3151509.3151522" onclick="window.open('https://doi.org/10.1145/3151509.3151522'); return false" class="ref">https://doi.org/10.1145/3151509.3151522</a>.</div>
               <div class="bibl"><span class="ref" id="wu_etal2014"><!-- close -->Wu et al 2014</span>  Wu, X., Tang, Y. and Bu, W. (2014) “Offline text-independent writer identification based on scale invariant feature transform”, <cite class="title italic">Information Forensics and Security, IEEE Transactions on 9</cite>, pp. 526–536.</div>
               <div class="bibl"><span class="ref" id="xing_etal2016"><!-- close -->Xing and Qiao 2016</span>  Xing, L. and Qiao, Y. (2016) “Deepwriter: A Multi-stream Deep CNN for Text-Independent Writer Identification”, in <cite class="title italic">2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)</cite>,
                  					IEEE Computer Society, Los Alamitos, CA, USA, pp. 584–589. Available at: <a href="https://doi.ieeecomputersociety.org/10.1109/ICFHR.2016.0112" onclick="window.open('https://doi.ieeecomputersociety.org/10.1109/ICFHR.2016.0112'); return false" class="ref">https://doi.ieeecomputersociety.org/10.1109/ICFHR.2016.0112</a>.</div>
               <div class="bibl"><span class="ref" id="xiong_etal2015"><!-- close -->Xiong et al 2015</span>  Xiong, Y.-J., Wen, Y., Wang, P. S. P. and Lu, Y. (2015)
                  						“Text-independent writer identification using sift descriptor and contour-directional
                  						feature”, in <cite class="title italic">2015 13th International Conference on Document Analysis and
                     						Recognition (ICDAR)</cite>, pp. 91–95.</div>
               <div class="bibl"><span class="ref" id="yang_etal2016"><!-- close -->Yang et al 2016</span>  Yang, W., Jin, L. and Liu, M. (2016) “Deepwriterid: An end-to-end online text-independent writer identification system”, <cite class="title italic">IEEE Intelligent Systems</cite> 31(2), 45–53. Available at: <a href="https://doi.org/10.1109/MIS.2016.22" onclick="window.open('https://doi.org/10.1109/MIS.2016.22'); return false" class="ref">https://doi.org/10.1109/MIS.2016.22</a>.</div>
            </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            <div class="license"><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
               </div>
         </div>
      </div>
   </body>
</html>