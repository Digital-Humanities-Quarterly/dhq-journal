<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>[PREVIEW] DHQ: Digital Humanities Quarterly: </title>
      <link href="../../common/css/dhq.css" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_screen.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_print.css" media="print" type="text/css" rel="stylesheet" />
      <style type="text/css">
        #mainContent {
          float: none;
          padding-top: 2em;
          padding-left: 4em;
          padding-right: 4em;
          margin-left: 225px;
           
        }</style>
   </head>
   <body>
      <div id="mainContent">
         <div class="DHQarticle">
            <div id="pubInfo">Preview<br />Volume 015 Number 4</div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            
            <div class="DHQheader">
               
               
               
               <h1 class="articleTitle lang en">Character Recognition Of Seventeenth-Century Spanish American Notary Records Using
                  Deep Learning</h1>
               
               
               <div class="author"><span style="color: grey">Nouf Alrasheed
                     </span> &lt;<a href="mailto:nalrasheed_at_mail_dot_umkc_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('nalrasheed_at_mail_dot_umkc_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('nalrasheed_at_mail_dot_umkc_dot_edu'); return false;">nalrasheed_at_mail_dot_umkc_dot_edu</a>&gt;, Department of Computer Science. &amp; Electrical Engineering. University of Missouri-Kansas
                  City</div>
               
               <div class="author"><span style="color: grey">Praveen Rao
                     </span> &lt;<a href="mailto:praveen_dot_rao_at_missouri_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('praveen_dot_rao_at_missouri_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('praveen_dot_rao_at_missouri_dot_edu'); return false;">praveen_dot_rao_at_missouri_dot_edu</a>&gt;, Department of Health Management &amp; Informatics, Department of Electrical Engineering
                  &amp; Computer Science. University of Missouri-Columbia</div>
               
               <div class="author"><span style="color: grey">Viviana Grieco
                     </span> &lt;<a href="mailto:griecov_at_umkc_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('griecov_at_umkc_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('griecov_at_umkc_dot_edu'); return false;">griecov_at_umkc_dot_edu</a>&gt;, Department of History. University of Missouri-Kansas City</div>
               
               
               
               
               
               
               
               <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Character%20Recognition%20Of%20Seventeenth-Century%20Spanish%20American%20Notary%20Records%20Using%20Deep%20Learning&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=&amp;rft.volume=015&amp;rft.issue=4&amp;rft.aulast=Alrasheed&amp;rft.aufirst=Nouf&amp;rft.au=Nouf%20Alrasheed&amp;rft.au=Praveen%20Rao&amp;rft.au=Viviana%20Grieco"> </span></div>
            
            <div id="DHQtext">
               
               
               <div id="abstract">
                  <h2>Abstract</h2>
                  
                  <p>Handwritten character recognition is a challenging
                     pattern recognition problem due to the inconsistency of the handwritten scripts and
                     the lack of accurate labeled data. Historical documents written in cursive are even
                     more challenging as characters have unique and varying shapes. Frequently, words are
                     linked by lines and ornamental doodles. When historical documents are digitized, the
                     images contain various types of noise and degradation, which further complicates the
                     recognition of characters. In this paper, we present an empirical study of how well
                     state-of-the-art convolutional neural networks (CNNs) for image classification
                     perform for the task of recognizing handwritten characters in seventeenth-century
                     Spanish American notarial scripts. Professional historians, paleography experts and
                     trained labelers were involved in preparing the labeled dataset of Spanish
                     characters for training the CNNs. The
                     labeled dataset used in this experiment was created from the manuscripts written by
                     one of the multiple scribes that contributed to the collection of approximately
                     220,000 digitized images of notary records housed at the
                     <cite class="title italic">Archivo General de la Nación Argentina </cite>(National
                     Archives). We removed the noise in these images by applying standard image
                     processing techniques. After training different CNNs, we computed the classification
                     accuracy for all the characters. We observed that ResNet-50 achieved a promising
                     accuracy of 97.08% compared to InceptionResnet-V2, Inception-V3, and VGG-16, which
                     achieved 96.66%, 96.33% and 70.91%, respectively.</p>
                  </div>
               
               
               
               
               <div class="div div0">
                  
                  <h1 class="head">I. INTRODUCTION <a class="noteRef" href="#d4e212">[1]</a></h1>
                  
                  <div class="counter"><a href="#p1">1</a></div>
                  <div class="ptext" id="p1">Notary records contain a wealth of information for understanding different aspects
                     of
                     the human experience. For that reason, historians specialized in different regions
                     and time periods employ them in writing social, economic, political, and cultural
                     histories. The seventeenth-century Spanish American notarial scripts housed in the
                     National Archives of Argentina are among the most challenging collections, as they
                     were written by multiple hands, for an audience of experts, and at a time the
                     written Spanish language underwent significant transformations [<a class="ref" href="#silvaprada2001">Silva Prada 2001</a>] [<a class="ref" href="#wasserman2018">Wasserman 2018</a>]
                     .<a class="noteRef" href="#d4e224">[2]</a> Consequently, it takes years of training
                     and practice in seventeenth-century Spanish paleography to become proficient in
                     reading and analyzing these notarial scripts (Fig.1). On an average, it takes expert
                     Spanish speaking readers about one hour to read a four to five pages long notarized
                     deed. The task is even more daunting for non-native Spanish speakers. </div> 
                  
                  
                  
                  <div class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/Figure_1.png" rel="external"><img src="resources/images/Figure_1.png" style="" alt="Screenshot of two different styles of handwriting" /></a></div>
                     
                     
                     <div class="caption">
                        <div class="label">Figure 1. </div>Samples of different handwriting styles present in the collection of
                        seventeenth-century notarial scripts used for this study</div>
                  </div>
                  
                  
                  <div class="counter"><a href="#p2">2</a></div>
                  <div class="ptext" id="p2">Digitization significantly aided in the preservation of these records and made them
                     relatively more accessible primarily by enabling their duplication without damaging
                     the originals. However, despite the quantity and variety of documents this
                     collection compiles, these records are still waiting to be fully utilized in
                     scholarly endeavors. To this day, researchers and students rely on traditional, time
                     consuming, and expensive methods of archival research to access these documents and
                     archival discovery primarily depends on the skill, patience and luck of the scholar.
                     The development of a system capable of storing, reading, querying, and analyzing
                     this historical collection is crucial as it will make these manuscripts accessible
                     to a broader community of researchers without requiring extensive and expensive
                     paleography training. Character recognition is the first step in the development of
                     such a system.</div>
                  
                  <div class="counter"><a href="#p3">3</a></div>
                  <div class="ptext" id="p3">Today, using optical character recognition (OCR), we can automatically convert
                     printed or handwritten text into machine-readable, editable, and searchable text.
                     For that reason, OCR is regarded as the heart of many document analysis systems.
                     Unlike the recognition of printed text, historical handwritten text presents unique
                     challenges. Written in cursive, historical scripts usually employ irregular
                     characters and capitalization, abbreviations, archaic spelling, and linked words
                     (Fig. 2).
                     <a class="noteRef" href="#d4e241">[3]</a> Additionally, the scans contain different types of noise
                     including discoloration, stains, as well as ink bleeds and smudges. In order to
                     enable OCR tasks, researchers applied different methods including Support Vector
                     Machine (SVM) [<a class="ref" href="#vellingiriraj2016">Vellingiriraj et al. 2016</a>], K-NN [<a class="ref" href="#chammas2018">Chammas et al. 2018</a>], and deep
                     learning [<a class="ref" href="#granell2018">Granell et al. 2018</a>]. </div> 
                  
                  
                  
                  <div class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/Figure2.png" rel="external"><img src="resources/images/Figure2.png" style="" alt="Screenshot of two different styles of handwriting, annotated" /></a></div>
                     
                     
                     <div class="caption">
                        <div class="label">Figure 2. </div>Example of some of the challenges
                        present in the manuscripts utilized for this study. On average, one
                        page has 24 lines. The variations showed in this short paragraph are
                        standard throughout the deeds.</div>
                  </div>
                  
                  
                  
                  <div class="counter"><a href="#p4">4</a></div>
                  <div class="ptext" id="p4">The challenges of converting Spanish American historical texts into machine-readable
                     text have been pointed out by Hannah Alpert-Abrams. She used <a href="https://icebergnlp.github.io/" onclick="window.open('https://icebergnlp.github.io/'); return false" class="ref">Ocular</a>, the OCR tool developed by
                     Taylor Berg-Kirkpatrick, to machine read the <cite class="title italic">Primeros Libros</cite>,
                     a sixteenth-century, printed, bilingual (Spanish and Nahuatl) text [<a class="ref" href="#alpertabrams2016">Alpert-Abrams 2016</a>]. Her experiments
                     delivered not only dirty OCR but also linguistic errors that could lead to
                     inaccuracies in cultural translation. We experimented with <a href="https://transkribus.eu/Transkribus/" onclick="window.open('https://transkribus.eu/Transkribus/'); return false" class="ref">Transkribus</a>, another popular
                     tool, which also yielded an inaccurate output for our collection of
                     seventeenth-century, handwritten, Spanish American notarial records. However, in
                     recent years, deep learning has achieved remarkable success for image understanding
                     and classification, image segmentation, speech recognition, and natural language
                     processing. In this work, we explore if deep learning, and more specifically CNNs,
                     can enable accurate recognition of characters in Spanish American notarial scripts.
                     </div>
                  
                  <div class="counter"><a href="#p5">5</a></div>
                  <div class="ptext" id="p5">Deep learning techniques perform better and achieve higher accuracy when large
                     labeled datasets are available (e.g., ImageNet, MS COCO) [<a class="ref" href="#deng2009">Deng et al. 2009</a>] [<a class="ref" href="#lin2014">Lin et al. 2014</a>].
                     However, there is no readily available labeled dataset for
                     seventeenth-century historical texts. Although data labeling is an expensive,
                     error-prone, and time-consuming task, with the help of professional historians and
                     paleography experts, we manually prepared a labeled dataset. Additionally,
                     historical texts have various kinds of noises and degradation and the uneven
                     scanning quality of the images pose additional challenges for image preprocessing
                     and cleaning as it has to be performed without losing any of the essential features
                     that define each of the characters.</div>
                  
                  <div class="counter"><a href="#p6">6</a></div>
                  <div class="ptext" id="p6">In this paper, we present an empirical study of how well state-of-the-art CNNs
                     perform for the task of recognizing handwritten characters in seventeenth-century
                     Spanish American notarial scripts. To the best of our knowledge, this is the first
                     effort towards automatically recognizing characters in seventeenth-century Spanish
                     American notarial scripts. </div>
                  
                  <div class="counter"><a href="#p7">7</a></div>
                  <div class="ptext" id="p7"><span class="hi bold">The key contributions of our work are the following:</span></div>
                  
                  <div class="ptext">
                     <ul class="list">
                        <li class="item">With the assistance of professional historians as well as labelers proficient in
                           Spanish and trained in paleography, we prepared the training dataset in two steps.
                           Firstly, we collected from our labelers 250 unique samples of each of the characters
                           present on the manuscripts. Secondly, we augmented the dataset and generated
                           additional characters by applying random distortions and rotations to the original
                           ones. For quality control, before training CNNs on the generated dataset, our
                           professional historians verified that the expanded characters resembled the original
                           ones. There are certain characters that are rare in both, the Spanish language and
                           the notarial scripts. For those characters we had fewer labels.</li>
                        <li class="item"> We selected four state-of-the-art CNNs, namely, Inception-v3
                           [<a class="ref" href="#szegedy2015">Szegedy et al. 2015</a>] [<a class="ref" href="#szegedy2016">Szegedy et al. 2016</a>], ResNet-50 [<a class="ref" href="#he2016">He et al. 2016</a>], VGG-16 [<a class="ref" href="#simonyan2014">Simonyan and Zisserman 2014</a>] and
                           InceptionResNet-v2
                           [<a class="ref" href="#szegedy2017">Szegedy et al. 2017</a>] to
                           recognize high frequency characters as well as rare characters (i.e., x and z). We
                           trained these networks by configuring the hyperparameters to
                           achieve the best classification accuracy. Our experiments showed that ResNet-50
                           achieved the best classification accuracy of 97.08% whereas other networks achieved
                           lower accuracy with VGG-16 being the poorest.</li>
                        <li class="item">For broader use by the academic community and to foster new research in
                           transcribing historical texts, our labeled dataset and software are publicly
                           available on GitHub via <a href="https://github.com/UMKC-BigDataLab/DeepLearningSpanishAmerican" onclick="window.open('https://github.com/UMKC-BigDataLab/DeepLearningSpanishAmerican'); return false" class="ref">https://github.com/UMKC-BigDataLab/DeepLearningSpanishAmerican</a>.</li>
                     </ul>
                  </div>
                  
                  <div class="counter"><a href="#p8">8</a></div>
                  <div class="ptext" id="p8">This paper is organized as follows. Section II discusses the relevant related works
                     and the motivation for this study. Section III presents the methodology we employed
                     and discusses our evaluation results. Finally, we conclude in Section IV and outline
                     our future work.</div> </div>
               
               <div class="div div0">
                  
                  
                  <h1 class="head">II. RELATED WORK &amp; MOTIVATION</h1>
                  
                  <div class="counter"><a href="#p9">9</a></div>
                  <div class="ptext" id="p9">Deep learning approaches have been widely used for handwritten text recognition of
                     many modern languages. CNNs
                     [<a class="ref" href="#krizhevsky2012">Krizhevsky et al. 2012</a>] are
                     among the most popular deep learning methods and have a proven record of outstanding
                     performance when applied to image recognition tasks. Additionally, CNNs have shown
                     an outstanding success when applied to the MNIST dataset [<a class="ref" href="#lechun1998">LeCun et al. 1998</a>].
                     Ashiquzzaman et al. proposed a CNN-based model using ReLU activation function and
                     dropout as a regularization layer that has achieved 97.4% accuracy [<a class="ref" href="#ashiquzzaman2017">Ashiquzzaman and Tushar 2017</a>].
                     Tsai investigated various convolutional neural network architectures
                     for handwritten Japanese character recognition and created a model with a 96.1%
                     recognition rate for character classification [<a class="ref" href="#tsai2016">Tsai 2016</a>]. Another CNN-based model
                     has been proposed by Rabby et al. to classify Bangla handwriting characters. A
                     95.71% validation accuracy was achieved for the BanglaLekha-Isolated dataset [<a class="ref" href="#rabby2018">Rabby et al. 2018</a>].</div>
                  
                  <div class="counter"><a href="#p10">10</a></div>
                  <div class="ptext" id="p10">However, applying these methods to historical documents present unique challenges
                     due
                     to the quality of the scanned images, writing style variations, and the lack of
                     labeled data. Consequently, only a few studies have taken this path. For instance,
                     Kölsch et al. used a Fully Convolutional Neural Network (FCNN)-based approach for
                     historic German documents, which achieved 95.6% accuracy [<a class="ref" href="#kolsch2018">Kolsch et al. 2018</a>].
                     Clanuwat et al. proposed a KuroNet model that jointly recognizes an entire page of
                     text by using a residual U-Net architecture and predicts the location and identity
                     of all characters on a given page. Additionally, their proposed system was able to
                     successfully recognize a significant fraction of pre-modern Japanese documents
                     [<a class="ref" href="#clanuwat2019">Clanuwat</a>].</div>
                  
                  <div class="counter"><a href="#p11">11</a></div>
                  <div class="ptext" id="p11">Researchers tend to combine CNNs with recurrent neural networks (RNNs) to further
                     improve accuracy. That was the case for Granell et al. who proposed a handwritten
                     text recognition system to transcribe a corpus of Spanish medieval scrips based on
                     a
                     CNN and RNN [<a class="ref" href="#granell2018">Granell et al. 2018</a>]. The authors showed that deep learning
                     approaches outperform the traditional machine learning models such as Hidden Markov
                     Model-based systems. Dona Valy et al. evaluated different deep learning approaches
                     for character recognition that have been constructed from Khmer palm leaf
                     manuscripts [<a class="ref" href="#valy2018">Valy et al. 2018</a>]. The authors showed that the combination of CNN and
                     RNN-based architectures achieves better results with a 5.01% error rate. Finally,
                     Chammas et al. presented a CRNN system for text- line recognition of historical
                     documents [<a class="ref" href="#chammas2018">Chammas et al. 2018</a>]. They showed how to train the system with only 10%
                     manually labeled text-line data from the READ 2017 dataset.</div>
                  
                  <div class="counter"><a href="#p12">12</a></div>
                  <div class="ptext" id="p12">Next, we describe the salient features of four recent CNNs that we used in our
                     study.</div>
                  
                  <div class="ptext">
                     <ol class="list">
                        <li class="item">
                           <div class="ptext">VGG</div>
                           
                           <div class="ptext">In 2014, Karen Simonyan and Andrew Zisserman (2014) proposed the VGGNet for the Large
                              Scale Visual Recognition Challenge (ILSVRC2014). The key contribution from this
                              model was to increase the depth of the architecture by using a 3x3 convolutional
                              filters to achieve higher performance. The VGG model achieved 92.7% top-5 accuracy
                              on the ImageNet dataset and won the ILSVRC2014 challenge. For our experimental
                              study, we chose VGG-16 as a representative of the VGGNet due to its smaller number
                              of parameters compared to VGG19.</div>
                        </li>
                        <li class="item">
                           <div class="ptext">Inception</div>
                           
                           
                           <div class="ptext">Inception architecture was first proposed in 2014 by Szegedy et al. The authors
                              claimed that deeper networks are more prone to overfitting and consume computational
                              resources. They solved that challenge by moving from fully connected to sparsely
                              connected architectures. They introduced the inception layer, which is a combination
                              of three different convolutional layers (1x1 convolutional layer, 3x3 convolutional
                              layer, and 5x5 convolutional layer) with a max pooling layer that operates at the
                              same level. Their outputs are concatenated to be the input of the next layer. This
                              architecture has been updated to increase the accuracy further and proved that any
                              convolution with kernel size more substantial than 3x3 could be represented
                              efficiently with a series of smaller convolutions. In our experimental study, we
                              used Inception- V3 [<a class="ref" href="#szegedy2015">Szegedy et al. 2015</a>] [<a class="ref" href="#szegedy2017">Szegedy et al. 2017</a>].</div>
                        </li>
                        <li class="item">
                           <div class="ptext">ResNet</div>
                           
                           
                           <div class="ptext">He et al. introduced the deep residual neural network (ResNet) architecture and won
                              the first place in the ILSVRC 2015 classification competition. ResNet introduces the
                              idea of identity connections that skip one or more layers to train deeper neural
                              networks. This resolved the vanishing gradient problem by allowing the gradients to
                              flow directly through the skipped connections backward from later layers to the
                              initial filter. For our experimental study, we used ResNet-50 as a representative
                              [<a class="ref" href="#he2016">He et al. 2016</a>].</div>
                        </li>
                        <li class="item">
                           <div class="ptext">InceptionResNet</div>
                           
                           
                           <div class="ptext">Inception-ResNet is a convolutional neural network proposed by Szegedy et al. in
                              2016. It was trained on more than one million images from the ImageNet database and
                              achieved a 3.08% top-5 error on the test set of the ImageNet classification (CLS)
                              challenge [<a class="ref" href="#szegedy2017">Szegedy et al. 2017</a>] The success of residual connections in training
                              very deep architectures and the performance of the Inception-V3 inspired the authors
                              to replace the Inception filter concatenation step with residual connections. This
                              combination allows Inception to obtain all the advantages of the residual approach
                              but with the preservation of its computational efficiency. We used
                              InceptionResNet-v2 as a representative for our experimental study.</div>
                        </li>
                     </ol>
                  </div>
                  
                  
                  
                  <div class="counter"><a href="#p21">21</a></div>
                  <div class="ptext" id="p21">Despite these advances, to this day, there is a lack of end-to-end systems capable
                     of
                     managing and analyzing historical documents in general and those in Spanish in
                     particular. This gap, coupled with the professional training needs of 21st century
                     humanities scholars, draw our attention and
                     drives our experimentation efforts to make these manuscripts accessible to a broader
                     community of researchers without requiring extensive and expensive paleography
                     training. Our effort is the first step in this direction and will open up a wide
                     range of research opportunities for others in the academic community.</div>
               </div>
               
               
               <div class="div div0">   
                  
                  
                  <h1 class="head">III. METHODOLOGY</h1>
                  
                  <div class="counter"><a href="#p22">22</a></div>
                  <div class="ptext" id="p22">In this section, we present the methodology for conducting this empirical study. The
                     overall steps are illustrated in Figure 3. There are four main stages: (a)
                     pre-processing, (b) dataset preparation, (c) training and validation (to tune the
                     hyperparameters), and (d) testing the accuracy of character recognition.</div> 
                  
                  
                  
                  <div class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/Figure3.png" rel="external"><img src="resources/images/Figure3.png" style="" alt="Image of a flowchart" /></a></div>
                     
                     
                     <div class="caption">
                        <div class="label">Figure 3. </div>Overall
                        steps involved in character recognition of seventeenth-century
                        Spanish American notarial scripts</div>
                  </div>
                  
                  
                  
                  
                  <div class="div div1">
                     <h2 class="head">a) Pre-processing:</h2> 
                     <div class="counter"><a href="#p23">23</a></div>
                     <div class="ptext" id="p23">The manuscripts scans contained noise including spurious ink
                        markings, ink smudges and bleeds. Such noise affects the feature extraction as well
                        as the classification. Before constructing the character dataset, we reduced the
                        noise on the manuscripts images (Figure 4). The following preprocessing techniques
                        allowed us to clean the images without affecting the quality of the written content.
                        Firstly, we converted the original manuscript images into grayscale. Secondly, we
                        applied a median filter to soften the images backgrounds and remove background
                        noise. Finally, we applied image binarization to convert the grayscale images into
                        black and white ones as this technique significantly reduces the information
                        contained in an image and increases the training speed [<a class="ref" href="#chamchong2009">Chamchong and Fung 2009</a>]. </div>
                     
                     
                     <div class="figure">
                        
                        
                        <div class="ptext"><a href="resources/images/Figure4.png" rel="external"><img src="resources/images/Figure4.png" style="" alt="Two images of handwriting" /></a></div>
                        
                        
                        <div class="caption">
                           <div class="label">Figure 4. </div>An example of an original scan and its cleaned version.</div>
                     </div>
                  </div>
                  
                  
                  
                  <div class="div div1">
                     <h2 class="head">b) Dataset preparation:</h2> 
                     <div class="counter"><a href="#p24">24</a></div>
                     <div class="ptext" id="p24">We constructed the character dataset from clean images. <a href="http://www.colabeler.com/" onclick="window.open('http://www.colabeler.com/'); return false" class="ref">Colabeler</a> tool was used to annotate and
                        label the characters. The annotations were exported in JSON format along with each
                        character label and its corresponding coordinates. We ran a Python script to crop
                        and save every character in .png format. As it was difficult to keep each character
                        within square dimensions while annotating them, each one of them was padded with
                        white pixels and resized to fixed dimensions for training purposes. We considered
                        24
                        characters that comprise most of the Spanish alphabet: a, b, c, c, d, e, f, g, h,
                        i, j, l, m, n, o, p,
                        q, r, s, t, u/v, x, y, and z. Note
                        that the "u" and the "v" were interchangeable in
                        seventeenth-century Spanish, and thus, the alphabets provided by most paleography
                        manuals list them as a single character. We followed this standard and treated them
                        as single letter (u/v). Additionally,
                        characters such as "k" and "w" are infrequently used in modern Spanish
                        and were so uncommon in seventeenth-century notarial scripts that paleography
                        textbooks do not even list them on their sample alphabets.<a class="noteRef" href="#d4e442">[4]</a>
                        To build our sample dataset, we selected the hand of Nicolas de Valdibia y Brizuela
                        who, by 1650, acted as an interim notary in Buenos Aires, Argentina. As opposed to
                        those who held permanent positions, interim notaries did not receive extensive
                        training nor were they skilled scribes. Thus, the experiments we report in this
                        paper were based on very irregular and, therefore, hard to read scripts, as shown
                        in
                        Figure 2 &amp; Figure 4. </div>
                     
                     <div class="counter"><a href="#p25">25</a></div>
                     <div class="ptext" id="p25">Our labeling team labeled 250 unique samples for every character. This resulted in
                        a
                        total of 6,000 original images. As deep learning models perform well on large
                        labeled datasets, the dataset was augmented by applying random distortion and
                        rotation of +5 and -5 degrees without affecting the shape and/or the direction of
                        each character. A few examples are shown in Figure 5. </div>
                     
                     
                     
                     <div class="figure">
                        
                        
                        <div class="ptext"><a href="resources/images/Figure5.png" rel="external"><img src="resources/images/Figure5.png" style="" alt="Two images of handwriting" /></a></div>
                        
                        
                        <div class="caption">
                           <div class="label">Figure 5. </div>Example of the original characters “b”; “d” and “p”
                           b) Example of
                           augmented characters after applying random distortion and
                           rotation</div>
                     </div>
                     
                     
                     
                     
                     <div class="counter"><a href="#p26">26</a></div>
                     <div class="ptext" id="p26">For quality control, before training CNNs on the generated dataset, the professional
                        historians and paleography experts in our team verified that the expanded characters
                        resembled the original ones. Our dataset contained 1,000 samples for each character
                        out of which 250 samples were manually labeled, and 750 samples were generated. This
                        resulted in a total of 24,000 images.</div>
                  </div>
                  
                  <div class="div div1">
                     <h2 class="head">c) Training and validation:</h2> 
                     <div class="counter"><a href="#p27">27</a></div>
                     <div class="ptext" id="p27">We conducted all our experiments on a GeForce RTX 2080 Ti
                        GPU with 12GB GPU memory. Our software was implemented using Keras [<a class="ref" href="#chollet2015">Chollet et al. 2015</a>] with TensorFlow backend 
                        [<a class="ref" href="#abadi2015">Abadi et al. 2015</a>], TensorBoard,<a class="noteRef" href="#d4e481">[5]</a> and
                        OpenCV [<a class="ref" href="#bradski2000">Bradski 2000</a>].</div>
                     
                     <div class="counter"><a href="#p28">28</a></div>
                     <div class="ptext" id="p28">We trained the state-of-art CNNs using 24,000 images (1,000 images per character)
                        in
                        our labeled dataset prepared from our seventeenth-century Spanish American notary
                        scripts. For each character, we split the training set into an 80-20 split. The
                        samples not used for training were part of the testing set. The testing set
                        contained 50 samples per character and were preprocessed in the same way as the
                        training images. Data augmentation was applied to the training set to avoid
                        overfitting. As we mentioned earlier, most of the paleography manuals list the “u” and the “v” as a single character as they were
                        interchangeable in seventeenth-century Spanish. We followed the same standard and
                        treated them as a single letter (u/v).</div>
                  </div>
                  
                  <div class="counter"><a href="#p29">29</a></div>
                  <div class="ptext" id="p29">e) Test of the accuracy of character recognition: in this research, the character
                     recognition accuracy was used as the primary metric to evaluate the performance of
                     different CNNs. An empirical tuning approach has been followed to tune the
                     hyperparameters to obtain higher character recognition accuracy. To ensure a fair
                     comparison, we set a total of 150 epochs to train the models, and used the Adam
                     optimizer [<a class="ref" href="#kingma2015">Kingma and Ba 2015</a>]. Adam is a gradient descent optimization algorithm
                     that is popularly used in training deep learning models. (Using gradient descent,
                     it
                     is possible to find local minima of functions during optimization.) The performance
                     of the models with different hyperparameters values is shown in Table I and Table
                     II.</div>
                  
                  <div class="counter"><a href="#p30">30</a></div>
                  <div class="ptext" id="p30">Table I shows the recognition accuracy when we set the dropout value to 0.6.
                     ResNet-50 achieved the highest accuracy of 97.02%, followed by InceptionResnet-v2,
                     Inception-v3, and VGG-16 with a recognition accuracy of 96.33%, 93.83%, and 96.33%,
                     respectively. The performance of most of the networks improved when the batch size
                     was increased to 64 except for Inception-v3, which achieved a better recognition
                     accuracy when the batch size was 32.</div>
                  
                  <div class="counter"><a href="#p31">31</a></div>
                  <div class="ptext" id="p31">The recognition accuracy results obtained from using 0.5 dropout rate are presented
                     in Table II. The recognition accuracy decreased for most of the networks when we
                     changed the dropout rate from 0.6 to 0.5. VGG-16 was the only model where it
                     performed better on a 0.5 dropout rate.</div>
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row label">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Models</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">
                              Batch Size 32
                              </td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">
                              Batch Size 64
                              </td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">VGG-16</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">62.50%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">69.33%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Inception-V3</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94.91%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">93.83%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">ResNet-50</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">95.50%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">97.08%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">InceptionResnet-V2</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96.00%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96.33%</td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 1. </div>Recognition accuracy obtained with 0.6 dropout rate; best accuracy is shown in blue
                        and the worst in red</div>
                  </div>
                  
                  
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row label">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Models</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">
                              Batch Size 32
                              </td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">
                              Batch Size 64
                              </td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">VGG-16</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">70.33%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"> 70.91%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Inception-V3</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">93.83%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96.33%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">ResNet-50</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96.92%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">87.58%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">InceptionResnet-V2</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96.66%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94.08%</td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 2. </div>Recognition accuracy obtained with 0.5 dropout rate; best accuracy is shown in blue
                        and the worst in red</div>
                  </div>
                  
                  
                  
                  
                  <div class="counter"><a href="#p32">32</a></div>
                  <div class="ptext" id="p32">Table III shows the accuracy breakdown of each character obtained from two different
                     experiments. We labeled the best results in bold and worse results in italics. As
                     shown
                     in the table, VGG-16 fails in recognizing non-confusing characters such as "o" and
                     "u/v". However, it performs well on few characters such as “m” and “y”.</div>
                  
                  <div class="table">
                     <table class="table">
                        <tr class="row">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> </td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Batch Size
                              = 32 &amp; Dropout rate = 0.5</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> </td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> </td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> </td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Batch Size
                              = 64 &amp; Dropout rate = 0.5</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> </td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> </td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> </td>
                           </tr>
                        <tr class="row label">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"></td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">VGG</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Inception</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">ResNet</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Inception</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">VGG</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Inception</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">ResNet</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">Inception</td>
                           </tr>
                        <tr class="row label">
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"></td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">16</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">v3</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">50</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> Resnet v2</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">16</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">v3</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1">50</td>
                           
                           <td valign="top" class="cell label" colspan="1" rowspan="1"> Resnet v2</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">A</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">82%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">94%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">90%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">B</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">82%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">86%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">98%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">98%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">C</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">62%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">94%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">94%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">42%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">94%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">86%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">c¸</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">76%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">74%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">D</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">74%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">74%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">76%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">E</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">36%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">84%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">90%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">84%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">46%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">90%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">76%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">86%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">F</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">38%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">86%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">88%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">92%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">60%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">94%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">G</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">22%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">98%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">32%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">88%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">68%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">68%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">H</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">74%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">68%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">78%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">I</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">64%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">64%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">44%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">J</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">88%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">86%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">L</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">76%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">70%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">80%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">M</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">96%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">96%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">N</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">90%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">76%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">92%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">56%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">78%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">O</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">82%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">82%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">P</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">88%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">94%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">98%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">98%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">98%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Q</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">74%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">78%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">R</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">58%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">98%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">44%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">90%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">S</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">74%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">94%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">94%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">92%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">58%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">90%</td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">T</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">64%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">96%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">82%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">94%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">96%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">u/v</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">68%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">64%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">X</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">52%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">62%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">92%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">90%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">66%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">90%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">84%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">90%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Y</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">94%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">88%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                        <tr class="row">
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">Z</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">72%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1">98%</td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><em class="emph">80%</em></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           
                           <td valign="top" class="cell" colspan="1" rowspan="1"><span class="hi bold">100%</span></td>
                           </tr>
                     </table>
                     <div class="caption">
                        <div class="label">Table 3. </div>Recognition accuracy per character. Best results are highlighted in bold and the worst
                        results are highlighted in italics</div>
                  </div>
                  
                  
                  
                  <div class="counter"><a href="#p33">33</a></div>
                  <div class="ptext" id="p33">Overall, VGG-16 performed the worst for most of our character datasets. Figure 6
                     gives the graphs of accuracy and loss values for the training set with respect to
                     the number of epochs. It shows that VGG-16 accuracy could have been improved if it
                     trained with more epochs.</div>
                  
                  
                  <div class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/Figure6.png" rel="external"><img src="resources/images/Figure6.png" style="" alt="Images of eight line charts" /></a></div>
                     
                     
                     <div class="caption">
                        <div class="label">Figure 6. </div>The accuracy (left) and loss (right) curves on the training set of the
                        CNN models</div>
                  </div>
                  
                  
                  
                  
                  <div class="counter"><a href="#p34">34</a></div>
                  <div class="ptext" id="p34">To further understand why some models achieved low accuracy, we generated confusion
                     matrices for all the models. Confusion matrices help us study the miss-classified
                     characters. As seen in Figure 7, confusion matrices confirm that most of the
                     confusions occur between the characters that are written similarly. For instance,
                     the character “n” is confused with “r” as shown in Figure 7(a), and “g” is confused with “q” as shown in Figure 7(b). The results
                     are not surprising as these characters generally confuse non-expert human readers
                     and, occasionally, trained paleographers. Figure 8 shows samples of these
                     characters. However, as shown on Table III, the recognition accuracy remains overall
                     strong.
                     </div>
                  
                  
                  <div class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/Figure7.png" rel="external"><img src="resources/images/Figure7.png" style="" alt="Two images of matrices" /></a></div>
                     
                     
                     <div class="caption">
                        <div class="label">Figure 7. </div>(a) ResNet-50 Confusion
                        Matrix (b) InceptionReset-v2 Confusion
                        Matrix
                        Confusion
                        matrices of selected models to show the miss-classified
                        characters</div>
                  </div>
                  
                  
                  <div class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/Figure8.png" rel="external"><img src="resources/images/Figure8.png" style="" alt="Two images of handwriting" /></a></div>
                     
                     
                     <div class="caption">
                        <div class="label">Figure 8. </div>a) Example of the shape similarities between the characters “r” and “n”. 
                        b) Example of the shape similarities between the characters “g,” “q,” and “y”</div>
                  </div>
                  
                  
                  </div>
               
               <div class="div div0">
                  
                  <h1 class="head">IV. CONCLUSION &amp; FUTURE WORK</h1>
                  
                  <div class="counter"><a href="#p35">35</a></div>
                  <div class="ptext" id="p35">Historical handwritten character recognition is a challenging pattern recognition
                     problem due to the inconsistency of the handwritten scripts and the lack of accurate
                     labeled data. In this paper, we presented an empirical study on how state-of-
                     the-art CNNs (developed for image classification) perform for the task of
                     recognizing handwritten characters in seventeenth-century Spanish American notarial
                     scripts. The labeled dataset employed in this study was carefully curated with the
                     help of paleography experts and professional historians. Data augmentation was
                     employed to increase the number of training samples. We observed that ResNet-50
                     achieved the promising accuracy of 97.08% compared to InceptionResnet- V2,
                     Inception-V3, and VGG-16, which achieved 96.66%, 96.33%, and 70.91%, respectively.
                     </div>
                  
                  <div class="counter"><a href="#p36">36</a></div>
                  <div class="ptext" id="p36">Our study demonstrates that recent CNNs are promising to detect characters in
                     seventeenth-century Spanish notarial scripts. Our future work will test the
                     performance of deep learning-based OCR models such as Keras-OCR, YOLO-OCR, Tesseract
                     and Kraken for the detection and recognition of handwritten words on these
                     manuscripts. Accurate word recognition will be a necessary step in the development
                     of a tool for reading, querying, and analyzing this historical collection. We plan
                     model the content of these manuscripts in a form that would make information
                     retrieval faster and better.</div>
                  
                  <div class="counter"><a href="#p37">37</a></div>
                  <div class="ptext" id="p37">The labeled dataset and software used in this study are publicly available on GitHub
                     via <a href="https://github.com/UMKC-BigDataLab/DeepLearningSpanishAmerican" onclick="window.open('https://github.com/UMKC-BigDataLab/DeepLearningSpanishAmerican'); return false" class="ref">https://github.com/UMKC-BigDataLab/DeepLearningSpanishAmerican</a>.</div>
               </div>
               
               <div class="div div0">
                  
                  <h1 class="head">ACKNOWLEDGEMENTS</h1>
                  
                  <div class="counter"><a href="#p38">38</a></div>
                  <div class="ptext" id="p38">This research was supported by the NEH Digital Humanities Advancement Grant
                     (HAA-271747-20), UMKC’s Missouri Institute for Energy and Defense (MIDE), UMKC’s
                     Funding for Excellence Program, and a Collaborative Data Science Grant from UMKC’s
                     Institute for Data Education, Analytics and Science (IDEAS). The authors would like
                     thank Ryan Rowland, Maha Alrasheed, and Vania Todorova for labeling data as well as
                     the <cite class="title italic">Archivo General de la República Argentina</cite> for granting
                     their permission to use in this study their digitized collection of notary records.
                     Dr. Martin L. E. Wasserman contributed to this project with his expertise in Spanish
                     paleography. The first author (N. A.) would like to thank UMKC’s Women’s Council
                     Graduate Assistance Fund (GAF) as well as the University of Tabuk in Saudi Arabia
                     for sponsoring her scholarship.</div>
                  </div>
               
               
               
               
               
               
               </div>
            
            <div id="notes">
               <h2>Notes</h2>
               <div class="endnote" id="d4e212"><span class="noteRef lang en">[1]  Viviana Grieco’s research focuses on Colonial Latin
                     American history and has received extensive paleography training in
                     Argentina and in Spain. She leads our labeling team which counts on the
                     expertise of Martin Wasserman and David Freeman, historians who have
                     employed in their research the collection of notary records used in this
                     study. For more information about our research team visit <a href="https://www.umkc.edu/mide/NEH-Project/" onclick="window.open('https://www.umkc.edu/mide/NEH-Project/'); return false" class="ref">https://www.umkc.edu/mide/NEH-Project/</a>
                     </span></div>
               <div class="endnote" id="d4e224"><span class="noteRef lang en">[2]  The speed and volume of the documentary production
                     forced the scribes to link words and use an increasing number of
                     abbreviations. The office of the public notary in seventeenth century
                     Buenos Aires had a high turnover rate, which explains the large number
                     of interim notaries as well as the variety of hands present in this
                     collection.</span></div>
               <div class="endnote" id="d4e241"><span class="noteRef lang en">[3]  The Document Analysis Group at the
                     Universitat Autònoma de Barcelona has been developing a digital library
                     for the sixteenth-century <cite class="title italic">Llibres d’Esposalles</cite>
                     (marriage records). These handwritten marriage records are quite
                     challenging although each marriage license follows a regular formula and
                     the scripts are more consistent than those for the seventeenth-century
                     notary records, <a href="http://dag.cvc.uab.es/the-esposalles-database/" onclick="window.open('http://dag.cvc.uab.es/the-esposalles-database/'); return false" class="ref">http://dag.cvc.uab.es/the-esposalles-database/</a>
                     </span></div>
               <div class="endnote" id="d4e442"><span class="noteRef lang en">[4]  N.
                     Silva-Prada, Manual de paleografía y diplomática hispanoamericana,
                     siglos XVI, XVII y XVIII. Libros de texto, manuales de prácticas y
                     antologías. Universidad Autónoma Metropolitana, Unidad Iztapalapa, 2001.
                     <a href="https://paleografi.hypotheses.org/el-manual-de-silva-prada" onclick="window.open('https://paleografi.hypotheses.org/el-manual-de-silva-prada'); return false" class="ref">https://paleografi.hypotheses.org/el-manual-de-silva-prada</a>
                     </span></div>
               <div class="endnote" id="d4e481"><span class="noteRef lang en">[5]  Tensorflow,
                     “tensorflow/tensorboard,” Apr 2020. Available: <a href="https://github.com/tensorflow/tensorboard" onclick="window.open('https://github.com/tensorflow/tensorboard'); return false" class="ref">https://github.com/tensorflow/tensorboard</a>
                     </span></div>
            </div>
            <div id="worksCited">
               <h2>Works Cited</h2>
               <div class="bibl"><span class="ref" id="abadi2015"><!-- close -->Abadi et al. 2015</span> Abadi M., Agarwal A., Barham P., Brevdo E., Chen Z., Citro C., Corrado G. S., Davis
                  A., Dean J., Devin M., Ghemawat S., Goodfellow I., Harp A., Irving G., Isard M., Jia
                  Y., Jozefowicz R., Kaiser L., Kudlur M., Levenberg J., Mané D., Monga R., Moore S.,
                  Murray D., Olah C., Schuster M., Shlens J., Steiner B., Sutskever I., Talwar K.,
                  Tucker P., Vanhoucke V., Vasudevan V., Viégas F., Vinyals O., Warden P., Wattenberg
                  M., Wicke M., Yu Y., and Zheng, X. “TensorFlow: Large-scale machine learning on
                  heterogeneous systems,” 2015, software available <a href="https://www.tensorflow.org/" onclick="window.open('https://www.tensorflow.org/'); return false" class="ref">https://www.tensorflow.org/</a>
                  </div>
               <div class="bibl"><span class="ref" id="alpertabrams2016"><!-- close -->Alpert-Abrams 2016</span> Alpert-Abrams, H., “Machine Reading the <span class="hi italic">Primeros Libros</span>,” <cite class="title italic">DHQ</cite>
                  10, no. 4, 2016.</div>
               <div class="bibl"><span class="ref" id="ashiquzzaman2017"><!-- close -->Ashiquzzaman and Tushar 2017</span> Ashiquzzaman A. and Tushar A. K., “Handwritten Arabic numeral recognition using deep
                  learning neural networks,” in 2017 IEEE International Conference on Imaging, Vision
                  &amp; Pattern Recognition (icIVPR). IEEE, 2017, pp. 1–4.</div>
               <div class="bibl"><span class="ref" id="bradski2000"><!-- close -->Bradski 2000</span> Bradski G., “The OpenCV Library,” <cite class="title italic">Dr. Dobb’s Journal of Software Tools</cite>, 2000.</div>
               <div class="bibl"><span class="ref" id="chamchong2009"><!-- close -->Chamchong and Fung 2009</span> Chamchong R. and Fung C. C., “Comparing background elimination approaches for
                  processing of ancient Thai manuscripts on palm leaves,” in 2009 International
                  Conference on Machine Learning and Cybernetics, vol. 6. IEEE, 2009, pp.
                  3436–3441.</div>
               <div class="bibl"><span class="ref" id="chammas2018"><!-- close -->Chammas et al. 2018</span> Chammas E., Mokbel C., and Likforman-Sulem L., “Handwriting recognition of historical
                  documents with few labeled data,” in 2018 13th IAPR International Workshop on
                  Document Analysis Systems (DAS). IEEE, 2018, pp. 43–48.</div>
               <div class="bibl"><span class="ref" id="chollet2015"><!-- close -->Chollet et al. 2015</span> Chollet F. et al., “Keras,” <a href="https://github.com/fchollet/keras" onclick="window.open('https://github.com/fchollet/keras'); return false" class="ref">https://github.com/fchollet/keras</a>, 2015.</div>
               <div class="bibl"><span class="ref" id="clanuwat2019"><!-- close -->Clanuwat</span> Clanuwat T., Lamb A., and. Kitamoto A, “Kuronet: Pre-modern Japanese Kuzushiji
                  character recognition with deep learning,” arXiv preprint arXiv:1910.09433,
                  2019.</div>
               <div class="bibl"><span class="ref" id="deng2009"><!-- close -->Deng et al. 2009</span> Deng J., Dong W., Socher R., Kai Li L. Li, and Li Fei-Fei, “Imagenet: A large-scale
                  hierarchical image database,” in 2009 IEEE Conference on Computer Vision and Pattern
                  Recognition, 2009, pp. 248–255.</div>
               <div class="bibl"><span class="ref" id="granell2018"><!-- close -->Granell et al. 2018</span> Granell E., Chammas E., Likforman-Sulem L., Martíınez-Hinarejos C.-D., Mokbel C.,
                  and
                  Cîrstea B.-I., “Transcription of Spanish historical handwritten documents with deep
                  neural networks,” <cite class="title italic">Journal of Imaging</cite>, vol. 4, no. 1, p. 15, 2018.</div>
               <div class="bibl"><span class="ref" id="he2016"><!-- close -->He et al. 2016</span> He K., Zhang X., Ren S., and Sun J., “Deep residual learning for image recognition,”
                  in Proceedings of the IEEE conference on computer vision and pattern recognition,
                  2016, pp. 770–778.</div>
               <div class="bibl"><span class="ref" id="kingma2015"><!-- close -->Kingma and Ba 2015</span> Kingma, Diederik P. and Ba, Jimmy, “Adam: A Method for
                  Stochastic Optimization,” arxiv:1412.6980, published as a conference paper at
                  the 3rd International Conference for Learning Representations, San Diego,
                  2015.</div>
               <div class="bibl"><span class="ref" id="kolsch2018"><!-- close -->Kolsch et al. 2018</span> Kölsch A., Mishra A., Varshneya S., Afzal M.Z., and Liwicki M., “Recognizing
                  challenging handwritten annotations with fully convolutional networks,” in 2018 16th
                  International Conference on Frontiers in Handwriting Recognition (ICFHR). IEEE,
                  2018, pp. 25–31.</div>
               <div class="bibl"><span class="ref" id="krizhevsky2012"><!-- close -->Krizhevsky et al. 2012</span> Krizhevsky A., Sutskever I., and Hinton G. E., “Imagenet classification with deep
                  convolutional neural networks,” in <cite class="title italic">Advances in neural infor- mation processing
                     systems</cite>, 2012, pp. 1097–1105.</div>
               <div class="bibl"><span class="ref" id="lechun1998"><!-- close -->LeCun et al. 1998</span> LeCun Y., Bottou L., Bengio Y., and Haffner P., “Gradient-based learning applied to
                  document recognition,” Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2324,
                  1998.</div>
               <div class="bibl"><span class="ref" id="lin2014"><!-- close -->Lin et al. 2014</span> Lin, T-Y., Maire M., S. Belongie, J. Hays, Perona P., Ramanan D., Dollár P., and.
                  Zitnick C. L, “Microsoft coco: Common objects in con- text,” in Computer Vision –
                  ECCV 2014, D. Fleet, T. Pajdla, B. Schiele, and T. Tuytelaars, Eds. Cham: Springer
                  International Publishing, 2014, pp. 740–755.</div>
               <div class="bibl"><span class="ref" id="rabby2018"><!-- close -->Rabby et al. 2018</span> Rabby A. S. A., Haque S., Islam S., Abujar S., and Hossain S. A., “Bornonet: Bangla
                  handwritten characters recognition using convolutional neural network,” Procedia
                  computer science, vol. 143, pp. 528– 535, 2018.</div>
               <div class="bibl"><span class="ref" id="silvaprada2001"><!-- close -->Silva Prada 2001</span> Silva Prada, N. “Paleografías americanas,” <a href="https://www.openedition.org/21549" onclick="window.open('https://www.openedition.org/21549'); return false" class="ref">https://www.openedition.org/21549</a>, 2001.r
                  </div>
               <div class="bibl"><span class="ref" id="simonyan2014"><!-- close -->Simonyan and Zisserman 2014</span> Simonyan K. and Zisserman A., “Very deep convolutional networks for large-scale image
                  recognition,” arXiv preprint arXiv:1409.1556, 2014.</div>
               <div class="bibl"><span class="ref" id="szegedy2015"><!-- close -->Szegedy et al. 2015</span> Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke
                  V., and Rabinovich A., “Going deeper with convolutions,” in Proceedings of the IEEE
                  conference on computer vision and pattern recognition, 2015, pp. 1–9. </div>
               <div class="bibl"><span class="ref" id="szegedy2016"><!-- close -->Szegedy et al. 2016</span> Szegedy C., Vanhoucke V., Ioffe S., Shlens J., and. Wojna Z, “Rethinking the
                  inception architecture for computer vision,” in Proceedings of the IEEE conference
                  on computer vision and pattern recognition, 2016, pp. 2818–2826.</div>
               <div class="bibl"><span class="ref" id="szegedy2017"><!-- close -->Szegedy et al. 2017</span> Szegedy C., Ioffe S., Vanhoucke V., and Alemi A. A., “Inception-v4, inception-resnet
                  and the impact of residual connections on learning,” in Thirty-first AAAI conference
                  on artificial intelligence, 2017.</div>
               <div class="bibl"><span class="ref" id="tsai2016"><!-- close -->Tsai 2016</span> Tsai C., “Recognizing handwritten Japanese characters using deep convolutional neural
                  networks,” 2016.</div>
               <div class="bibl"><span class="ref" id="valy2018"><!-- close -->Valy et al. 2018</span> Valy D., Verleysen M., Chhun S., and Burie J.-C., “Character and text recognition of
                  Khmer historical palm leaf manuscripts,” in 2018 16th International Conference on
                  Frontiers in Handwriting Recognition (ICFHR). IEEE, 2018, pp. 13–18.</div>
               <div class="bibl"><span class="ref" id="vellingiriraj2016"><!-- close -->Vellingiriraj et al. 2016</span> Vellingiriraj E., Balamurugan M., and Balasubramanie P., “Information extraction and
                  text mining of ancient vattezhuthu characters in historical documents using image
                  zoning,” in 2016 International Conference on Asian Language Processing (IALP). IEEE,
                  2016, pp. 37–40.</div>
               <div class="bibl"><span class="ref" id="wasserman2018"><!-- close -->Wasserman 2018</span> Wasserman, M.L.E., “La escritura paleográfica Iberoamericana: letras procesales y
                  encadenadas,” in <cite class="title italic">Introducción a la Paleografía. Herramientas para la Lectura y
                     Anáisis de Documentos Antiguos</cite>, ed. Rosana Vassallo (La Plata: Facultad de
                  Humanidades y Ciencias de la Educación, 2018)</div>
            </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            <div class="license"><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
               </div>
         </div>
      </div>
   </body>
</html>