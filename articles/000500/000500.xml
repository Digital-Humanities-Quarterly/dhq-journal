<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
   xmlns:mml="http://www.w3.org/1998/Math/MathML">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <!--Author should supply the title and personal information-->
            <title type="article" xml:lang="en">Methods and Advanced Tools for the Analysis of Film
               Colors in Digital Humanities</title>
            <!--Add a <title> with appropriate @xml:lang for articles in languages other than English-->
            <dhq:authorInfo>
               <!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>Barbara <dhq:family>Flueckiger</dhq:family>
               </dhq:author_name>
               <dhq:affiliation>University of Zurich</dhq:affiliation>
               <email>baflueckiger@gmail.com</email>
               <dhq:bio>
                  <p>Barbara Flueckiger has been professor for film studies at the University of
                     Zurich since 2007. Before her studies in film theory and history, she worked
                     internationally as a film professional. Her research focuses on the interaction
                     between technology and aesthetics. She published two standard text books,
                        <title rend="italic">Sound Design</title> and <title rend="italic">Visual
                        Effects</title>. Since 2001 she has developed and led many research
                     projects. In 2015 she was awarded the prestigious Advanced Grant by the
                     European Research Council for a research project on the technology and
                     aesthetics of film colors plus in 2018 a proof of concept for the development
                     of a multispectral, versatile film scanner. <title rend="italic">Timeline of
                        Historical Film Colors</title>: <ref target="https://filmcolors.org/"
                        >https://filmcolors.org/</ref>
                  </p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>Gaudenz <dhq:family>Halter</dhq:family>
               </dhq:author_name>
               <dhq:affiliation>University of Zurich</dhq:affiliation>
               <email>N/A</email>
               <dhq:bio>
                  <p>Gaudenz Halter has been a PhD student in data science since 2020. He has been
                     the developer of the VIAN video analysis and annotation software and the VIAN
                     WebApp in collaboration with the Visualization and MultiMedia Lab at the
                     University of Zurich.</p>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <!--This information will be completed at publication-->
            <idno type="DHQarticle-id">000500</idno>
            <idno type="volume"
               >014</idno>
            <idno type="issue">4</idno>
            <date when="2020-12-20">20 December 2020</date>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND">
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref
                     target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
                     >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
            <!--add <language> with appropriate @ident for any additional languages-->
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords">
               <!--Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#authorial_keywords">
               <!--Authors may include one or more keywords of their choice-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <!--Each change should include @who and @when as well as a brief note on what was done.-->
         <change when="2020-10-09" who="jmurel">Created file</change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract>
            <!--Include a brief abstract of the article-->
            <p>Colors are one of the most difficult stylistic elements of film to analyze, but — as
               this paper elaborates — a most rewarding one too. A long-neglected topic in film
               studies, film colors have gained increasing attention over the last decade. With the
               development of database-driven analysis, deep-learning tools, and a large range of
               visualization methods the research project ERC Advanced Grant <title rend="italic"
                  >FilmColors</title> set out to provide a more comprehensive approach to analyzing
               the manifold aspects of color in film. This paper focuses on a set of strong
               theoretical and analytical concepts of film colors — including human interpretation —
               that connect the stylistic, expressive, and narrative dimensions with the development
               and evaluation of digital methods. A corpus of more than 400 films have been analyzed
               with a computer-assisted workflow that has been integrated into the video annotation
               and analysis software VIAN since 2017. VIAN is connected to the online platform VIAN
               WebApp for the evaluation of results, queries, and visualizations on segment, film
               and corpus level. Compared to traditional, mostly language-dominated approaches to
               the aesthetics, technology, and narratology of film colors, the digital humanities
               tools turn evidence created through the mapping of results into an instantly
               accessible array of visual representations. By relating detailed human annotation and
               interpretation to these visual representations, the integrated workflow consisting of
               the VIAN visual analysis software in combination with the crowdsourcing portal VIAN
               WebApp has created a comprehensive ecosystem for the investigation of film aesthetics
               and narration. It thus significantly extends established methods in film studies.</p>
         </dhq:abstract>
         <dhq:teaser>
            <!--Include a brief teaser, no more than a phrase or a single sentence-->
            <p>Examines the aesthetics, technology, and narratology of film colors through the <title rend="italic">FilmColors</title> research project</p>
         </dhq:teaser>
      </front>
      <body>
         <div xml:id="section01">
            <head>1 Introduction</head>
            <p>Film colors are one of the most difficult aspects for the analysis of film style, but
               — as this paper will elaborate — also a most rewarding one. A long neglected topic in
               film studies, film colors have gained increasing attention during the last decade.
               Following the advent of digital methods in recent years, in-depth studies about the
               history, uses, underpinning concepts and their theoretical and epistemological
               reflection in digital humanities have been published by <ref target="#stutz2016"
                  >Olivia Kristina Stutz (2016)</ref>, <ref target="#heftberger2016">Adelheid
                  Heftberger (2016</ref>, <ref target="#heftberger2018">2018</ref>), <ref
                  target="#olesen2017">Christian Gosvig Olesen (2017)</ref>. Increasingly there is a
               discourse around the development of digital approaches, methods, and tools for film
               analysis. Stutz (2016) and Olesen (2017) pay specific attention to the question of
               color analyses. <ref target="#ferguson2013">Kevin Ferguson (2013</ref> and <ref
                  target="#ferguson2015">2015</ref>), <ref target="#manovich2013">Lev Manovich
                  (2013</ref> and <ref target="#manovich2015">2015</ref>) and <ref
                  target="#reyes-garcia2014">Everardo Reyes-García (2014</ref> and <ref
                  target="#reyes-garcia2017">2017</ref>) have developed specific visualization
               methods for art works, paintings and film in particular. Pause and Walkowski’s work
               on computer-assisted color analysis is drawing on our own work <ptr
                  target="#pause2018"/>.</p>
            <p>Traditional analyses of film colors were mostly based on verbal description. They
               showed a tendency toward hermeneutical interpretation while aesthetic and affective
               dimensions were often neglected. </p>
            <p>With the development of database-driven analysis, deep-learning tools and a large
               range of visualizations the research project ERC Advanced Grant <title rend="italic"
                  >FilmColors</title> (see <ref target="#acknowledgements">Acknowledgements</ref>)
               aims at providing a more comprehensive approach to analyze the manifold aspects of
               color in film. </p>
            <p>Therefore the central argument of this paper focuses on the combination of a set of
               strong theoretical and analytical concepts including human interpretation that
               connects the various instances of film colors’ stylistic, expressive and narrative
               dimensions to the development and evaluation of digital methods. </p>
            <p>It is a widespread misconception that digital tools generate meaningful results in an
               automated fashion. Theoretically sound reasoning and the constant reflection of
               visualization methods, their epistemological and perceptual underpinnings is a
               mandatory requirement that must govern any interdisciplinary collaboration between
               film studies and computer science, see our previous papers for a more extended
               discussion of these prerequisites and their connection to experimental aesthetics
                  <ptr target="#flueckiger2011"/>
               <ptr target="#flueckiger2017"/>
               <ptr target="#flueckiger2018"/>. By contrast to the previous papers, this article
               intends to provide insights into the many methods, obstacles, advances, problems and
               lessons learned during the collaborative development of the tools. </p>
            <p>Integral part of the research projects is the <title rend="italic">Timeline of
                  Historical Film Colors</title> (<ref target="https://filmcolors.org"
                  >https://filmcolors.org</ref>) — an interactive, comprehensive web resource on
               film colors that has been created and curated by Barbara Flueckiger since 2012 <ptr
                  target="#flueckiger2012"/>. </p>
         </div>
         <div xml:id="section02">
            <head>2 Database-driven Analysis, Analytical Concepts and Evaluation</head>
            <p>Overarching goal of the research project’s interdisciplinary perspective is the
               investigation of the relationship between the aesthetics and technology of film
               colors. To this end, a large group of more than 400 films produced between 1895 and
               1995 were analyzed in a highly detailed way with a computer-assisted approach. It
               combined temporal segmentation by the video annotation tool ELAN (first released in
               2002) with a database-driven protocol consisting of a controlled vocabulary of around
               1.200 theoretical and analytical concepts for the annotation of each segment. A
               network of custom-made relational databases for the analysis, filmographic data,
               glossary and evaluation of results (see <ref target="#figure07">Figure 7</ref>) was
               programmed in FileMaker to a large extent by the PI herself with input from her team.
               Despite the fact that FileMaker has its weaknesses and limitations in terms of
               programmability and flexibility the self-sufficient adaptation and development of the
               databases according to the evolving requirements of the analyses remained the most
               significant advantage throughout the project. Increasingly, the databases were linked
               with each other by relational connections to deliver meaningful results and to
               provide instant access to a variety of evaluation methods of the data gathered (see
                  <ref target="#section03">Section 3</ref>). </p>
            <p>The team distinguished several levels of analysis, from screenshots to temporal
               segments of individual films (<quote rend="inline">micro level</quote>), individual
               films as a whole (<quote rend="inline">meso level</quote>), and over the whole corpus
               or selected sub-corpora (<quote rend="inline">macro level</quote>), see <ref
                  target="#olesen2016">Olesen (2016)</ref>.</p>
            <p>Filmographic data has been collected to represent the whole corpus of films, to
               define corpus selection and assignment to individual researchers and to keep track of
               the processing state. Corpora were selected based on research into monographs and
               articles on film colors, with each of the PhD candidates’ setting their own focus in
               the three periods1895 to 1930, 1930 to 1955, and 1955 to 1995. Guiding principles for
               selection criteria aim at a comparison between canonical works, famous for their
               elaborate or bold color design with lesser known works to form sub-groups for
               specific film color processes, genres, for individual filmmakers, cinematographers,
               color consultants, or countries. In line with historical poetics <ptr
                  target="#bordwell1989"/> and neo-formalist analysis established by the Wisconsin
               school of Kristin Thompson and David Bordwell <ptr target="#thompson1988"/>
               <ptr target="#bordwell1985"/>, the corpora should enable the <term>diachronic
                  analysis</term> of personal styles, institutional contexts — for instance changing
               professional norms, cultural preferences, notions of taste — or technological
               innovation over time, but also a <term>synchronic comparison</term> between these
               different instances at a given period.</p>
            <p> Stock identification, research into technical innovation, detailed information about
               color processes applied to each film play an important part for a better
               understanding of these connections and allow to circumvent misconceptions present in
               previous literature. These research methods are completed by scientific measurements
               of film stocks’ spectral characteristics to enable improved methods for the
               digitization and restoration of analog film colors. Such a comprehensive approach
               that connects insights into aesthetic developments with a deep investigation into
               technological innovation has been called a <quote rend="inline">technobole
                  approach</quote> by Frank Beau (2002). Contrary to technical determinism the
                  <q>technobole approach</q> that stays at the center of our method is paying
               attention to epistemological, institutional, social, cultural and economic factors
               that govern technical advances and how technology in turn feeds back into culture and
               society. This cultural perspective is investigated thoroughly in the PI’s second
               research project <hi rend="italic">Film Colors. Technologies, Cultures,
                  Institutions</hi>.</p>
            <p>A three-level model that complies with recommended metadata schemes established for
               film archives by standardization entities such as FIAF or <ref
                  target="http://www.filmstandards.org">filmstandards.org</ref> has been implemented
               into the corpus database by team member Joëlle Kost. It allows the allocation of
               individual tokens of a single film, such as DVDs, Blu-ray or various historical film
               prints and negatives inspected and documented in film archives in Europe, Japan and
               the United States and assigns a specific tri-partite item ID to each one of them.
               From the start, this database was hosted on a FileMaker server provided by the
               University of Zurich.</p>
            <p>All the films chosen for analysis were digitized and then temporally segmented with
               the video annotation tool ELAN (see <ref target="#section04">Section 4</ref> for
               approach and description). The resulting information — mostly time codes and
               numbering of the segments plus optionally basic descriptions according to a template
               — was then exported to an analysis database for close reading, which in turn was
               connected to the corpus DB for filmographic data, based on the item ID. </p>
            <figure>
               <head>Sketch of the analysis and evaluation workflow with the database
                  architecture.</head>
               <graphic url="resources/images/figure01.png"/>
            </figure>
            <p>Theoretical and analytical concepts were mostly elaborated before the start of the
               project, during the PI’s teaching and research activities in the field of color
               theory, film aesthetics, semantics and narration — with a focus on film colors in the
               last decade. Accordingly, they were already part of the research proposal. Submitted
               to the ERC. During half a year of coaching and training at the beginning of the
               project, the team members were introduced into the concepts and were given room for
               extended discussions. Some concepts evolved bottom-up during the analyses and were
               contributed by team members based on their observations. For instance, a catalogue of
               basic terms for characters’ affective or emotional states were part of the initial
               glossary, but continuously extended by postdoc researcher Bregt Lameris who focuses
               on the relationship between film colors and affects. Motifs and themes were also
               evolving bottom-up for certain standard situations — for instance ceremonies, show
               numbers, metamorphoses — or topics such as exoticism, architecture, self-reference
               etc. They were organized in a keyword database connected to the analysis DB.</p>
            <p>Eleven different registers contained a taxonomy with classes of analytical concepts,
               ranging from verbal descriptions of colors, color contrasts, image composition,
               depth-of-field, lighting, textures and patterns, surface properties and materials of
               characters, objects or environments in the diegesis including their tactile
               properties, to the materiality of films analyzed with the concept of
                  <term>faktura</term>, plus movements of camera, characters, objects, and lighting. </p>
            <p>For each temporal segment of the films — usually between 50 and 70 segments per film
               — the team went through the whole range of analytical concepts in the analysis DB and
               added up to 32 relevant screenshots into media containers.</p>
            <p>All the theoretical and analytical concepts of the controlled vocabulary — more than
               1.200 including hues — were continuously defined in a glossary database with
               references to sources, if available, and illustrated with exemplary screenshots
               gathered during the analyses.</p>
            <p>From the start we were thinking about how these concepts could be processed with
               advanced tools for automatic data extraction, and this question guides the
               development of deep learning tools to this day (see Sections 4 to 9). It goes without
               saying that not all of them can easily be solved with the current state-of-art and
               limited resources even within an ERC research project of this scope. On the other
               hand — as stated above — it is the central credo of the project’s comprehensive
               approach that it aims at a qualitative analysis that focuses on the contextualization
               of observations by human intervention and interpretation. By their very nature,
               automatic approaches to image processing are not able to identify subtle details and
               idiosyncrasies, for instance that curtains moving slightly in the wind might be a
               metaphor for the heroine’s inner turmoil as in the Japanese film Jigokumon.</p>
            <p>Narratologic concepts are especially challenging for automatic assessment.
               Point-of-view structures that operate with the concept of <term>focalization</term>
                  (<ptr target="#genette1972"/>
               <ptr target="#genette1983"/> to differentiate between instances of narration,
               so-called focalizers or filters, are possibly very hard to identify for non-human
               observers, but they are very important for the investigation of film colors,
               including characters’ mental states in dreams or hallucinations, alignment with
               characters <ptr target="#smith1995"/>, temporal organization of the narration such as
               flashbacks, summaries, mise-en-abyme, parallel montage or montage sequences,
               non-narrative situations, turning points, suspense and foreshadowing etc. </p>
            <p>Similar challenges are in operation for phenomena of higher order semantics. By
               higher order semantics we understand all forms of modification of meaning that are
               established through intra-textual relationships, intertextual and inter-medial
               references or cultural uses, such as cultural contexts, milieu, taste, sociopolitical
               markers, stereotypes, genre conventions, character relationships, race, gender,
               symbols, signals, metaphors and isotopies / rhyming. Intertextual and inter-medial
               references for connections to other films, media or art works through pastiche,
               allusion, citation, irony, parody etc. <ptr target="#genette1992"/>
               <ptr target="#jameson1991"/>
               <ptr target="#dyer2006"/>.</p>
            <figure xml:id="figure02">
               <head>Higher order semantics in color design: pastiche in Blood and Sand (USA 1941,
                  Rouben Mamoulian)(left)  and sociopolitical markers that indicate status and
                  period  in <title rend="italic">The Private Lives of Elizabeth and Essex</title>
                  (USA 1939, Michael Curtiz) (right).</head>
               <graphic url="resources/images/figure02a.png"/>
               <graphic url="resources/images/figure02b.png"/>
            </figure>
            <p>Emotions and affects relate to characters’ inner states — joy, sadness, anger, hate,
               disgust — or emotional relationships such as love, conflict, sex, but also for
               cross-modal relationships of visual representations to smell, taste or touch. In
               addition, there are basic theoretical concepts for emotional and affective responses
               such as direct affect <ptr target="#plantinga2009"/>, contagion, artefact emotion,
               mimicry, plus aesthetic categories that address the senses such as excess <ptr
                  target="#thompson1986"/>, artefact emotion <ptr target="#tan1996"/>, atmosphere,
                  <term>Stimmung</term> or mood.</p>
            <figure xml:id="figure03">
               <head>Excess in <title rend="italic">King of Jazz</title> (USA 1930, John Murray
                  Anderson; Pál Fejös) (above) and  <title rend="italic">Die bitteren Tränen der
                     Petra von Kant</title> (GER 1972, Rainer Werner Fassbinder) (below).</head>
               <graphic url="resources/images/figure03a.png"/>
               <graphic url="resources/images/figure03b.png"/>
            </figure>
            <p>In the domain of color identification, however, computer-based approaches are
               superior to human observation, even if it is necessary to stress the fact that the
               results of these analyses also need human interpretation.</p>
            <p>In our analysis DB, colors were verbally described as dominant hues for the entire
               scene, female and male protagonists and supporting characters, background and
               foreground, inter-titles and letters, including general observations on saturation,
               lightness etc. It is obvious that such verbal descriptions are very limited, they do
               not take into account the subtle shades of each color of a certain range as various
               types of hues, levels of saturation or brightness.</p>
            <p>By color schemes — often called <term>color palettes</term> — we denote the overall
               distribution of color in an image or in a temporal segment according to the
               variations of hues, saturation, warmth or lightness, such as monochrome restrictive,
               muted, gaudy, saturated etc. Types can occur simultaneously, for instance a
               monochrome color scheme can also be warm or saturated. As we will elaborate in a
               later section (see <ref target="#section07">Section 7</ref>) our methods for the
               identification of color schemes with deep learning tools are both superior, more
               refined than verbal descriptions and yield highly significant results, if, again,
               they are connected to the concepts elaborated above.</p>
            <p>Color contrasts refer to an established set defined by artist and scholar Johannes
               Itten to describe specific relationships of color harmonies, color <quote
                  rend="inline">chords,</quote> or spatial distribution, again correlated to the
               dimensions of hue, saturation and lightness as organized in Itten’s <quote
                  rend="inline">Farbstern</quote> (<term>color star</term>) <ptr target="#itten1970"
               />. For instance, the most ubiquitous color contrast in the recent decade has been
               the orange–teal combination that is both a cold–warm and complementary contrast plus
               it contains a light–dark variation since yellow is perceived as brighter than blue. </p>
            <figure xml:id="figure04">
               <head>Some exemplary screenshots for the concept <q>cold-warm contrast</q> in the
                  glossary DB.</head>
               <graphic url="resources/images/figure04_new.png"/>
            </figure>
            <p>The identification of color contrasts and color schemes has long been a field of
               computer analysis. As we will discuss (see <ref target="#section07">Section 7</ref>),
               however, most of these approaches do not comply with the demands of aesthetic
               analysis in terms of differentiation, flexibility and subtlety. Some of them were
               established for normative purposes, to identify ‘good’ uses of color harmonies for
               design, or to give a rough, albeit pleasing visualization for film geeks, such as
               MovieBarcodes.</p>
            <div xml:id="section02.1">
               <head>2.1 Problems</head>
               <p>Consistently the biggest challenge was the level of complexity for all the team
                  members working on the film analyses. Overall the process was perceived as
                  extremely time consuming. Following a first evaluation after several months into
                  the project, the concepts were separated into the most relevant ones vs. the rarer
                  ones. Team members also showed difficulties to work on such extended catalogues of
                  concepts that were only randomly ordered by relevance. Therefore they devised
                  ordered lists sorted according to thematic coherence, which helped finding the
                  checkbox in a more intuitive way. Finally we ended up establishing individual
                  layouts for each team member to take their personal focus into account. However,
                  this approach resulted in a much more complex database architecture to collect and
                  evaluate all the data.</p>
            </div>
            <div xml:id="section02.2">
               <head>2.2 Lessons learned</head>
               <p>Informed by the constantly evolving workflow and database architecture the
                  crowdsourcing platform for external users <ptr target="#flueckiger2018"/>
                  <ptr target="#halter2019"/> has been developed in a modular fashion, again by
                  Gaudenz Halter with support by Silas Weber. First, concepts are being sorted
                  according to inner relationships, for instance positive affects related to joy vs.
                  negative affects related to depression or aggression as elaborated and refined
                  during the development of the workflow and following the final evaluation. Second,
                  levels of significance of concepts and levels of complexity have been established
                  for each area of analysis, as for instance lighting or image composition. This
                  modular design will give users the possibility to select from a menu of concepts
                  not only the topics they are interested in, for instance color contrasts or
                  costume design, but also the level of complexity for each of those modules
                  individually so that the controlled vocabulary matches best their research
                  interest.</p>
            </div>
         </div>
         <div xml:id="section03">
            <head>3 Evaluation of the Data Gathered</head>
            <p>Resulting from the manual analysis was a massive quantity of data and screenshots,
               amounting to more than 17.000 segments with about 170.000 screenshots assembled in a
               master analysis DB and more than half a million of summations gathered in an
               evaluation database. This evaluation database has been connected to the glossary DB
               and the corpus DB, based on the glossary ID and the Item ID (see <ref
                  target="#figure01">Figure 1</ref>). With these identifiers we were able to then
               display the results directly in the glossary DB and corpus DB respectively by portals
               and scripts, which turned out to be the biggest advantage of the relational database
               architecture. As will be discussed in a later paragraph (see <ref
                  target="#section03.1">Section 3.1</ref>) there were also many problems and
               challenges to master.</p>
            <p>In principle the results can be accessed by three ways through the FileMaker
               architecture and in many additional, more complex ways through the analysis and
               annotation tool VIAN and the online platform VIAN WebApp. The VIAN WebApp is a
               crowdsourcing portal that currently contains all the more than 400 analyzed films for
               evaluation and visualizations on segment, film and corpus level <ptr
                  target="#flueckiger2018"/>
               <ptr target="#halter2019"/>. In the future, external users will have the possibility
               to commit their own VIAN projects. Since the database for the VIAN WebApp hosts both
               qualitative and numeric color information, the developers decided on a diploid
               database architecture for the online platform. Most of the data is hosted on a
               Postgres SQL database; for fast querying and processing numeric information they use
               a HDF5 file structure (see <ref target="#halter2019">Halter et al. 2019</ref>). Data
               are processed by cloud computing on Microsoft Azure.</p>
            <p>The offline analysis VIAN is integrated into an ecosystem (see <ref
                  target="#figure05">Figure 5</ref>). Individual projects are uploaded to the online
               platform VIAN WebApp. In return, users can download projects from the VIAN WebApp to
               adjust it to their own interests. In addition, the VIAN WebApp connects projects to
               the corresponding galleries from the <title rend="italic">Timeline of Historical Film
                  Colors</title>. Finally, the ColorMania app became an extension for visitors of
               the <title rend="italic">Color Mania</title> exhibition at Fotomuseum Winterthur (see
                  <ref target="#figure05">Figure 5</ref>).</p>
            <figure xml:id="figure05">
               <head>Increasingly VIAN became part of an ecosystem consisting of the offline tool
                  VIAN analysis and annotation software, the online platform VIAN WebApp, connected
                  to the <title rend="italic">Timeline of Historical Film Colors</title> and to the
                     <title rend="italic">ColorMania</title> exhibition app.</head>
               <graphic url="resources/images/figure05.png"/>
            </figure>
            <p>All the FileMaker DBs have been exported to the VIAN WebApp database architecture.
               Each of the individual DBs is thus mirrored in the WebApp.</p>
            <p>The corpus DB contains the results listed for each individual film, i.e. on the meso
               level. It corresponds to the project page on the VIAN WebApp. For each field the
               corpus DB lists all the occurrences within this film, including a list of all the
               comments made in the remark fields with the corresponding segment ID. This overview
               provides an instant footprint for each film and is the basis for hypotheses that lead
               to further investigations. </p>
            <figure xml:id="figure06">
               <head>VIAN WebApp project overview of the more than 400 analyzed films. Each project
                  has its own page with detailed analysis and visualizations, see screen video of
                  Paris, Texas <ref target="https://vimeo.com/396548709"
                     >https://vimeo.com/396548709</ref>.</head>
               <graphic url="resources/images/figure06.png"/>
            </figure>
            <p>From a different angle, the results are reflected in the glossary DB based on each
               individual concept, with many custom-made filters for periods, corpus assignment,
               genres, country etc. With this perspective, it is possible to get instant information
               about the dominance of a narrative, semantic or aesthetic feature, a motive or
               location on the macro level, sorted by frequency. The glossary DB corresponds to the
               concepts page on the VIAN WebApp.</p>
            <p>Finally the evaluation DB itself where all these results are stored allows the
               diachronic analysis also on the macro level across the whole corpus. It delivers
               diagrams of developments over time for the whole period spanning the first 100 years
               of film history from 1895 to 1995. For instance the development of certain lighting
               styles such as colored light, mood lighting or mixed lighting, of types of depth of
               field, of layered and complex image compositions become visible at a glance. These
               trends are then the foundation for hypotheses that have to be investigated in detail
               in the analysis DB. It is also crucial to keep in mind — as we will discuss in more
               detail in the problems section (see <ref target="#section03.1">Section 3.1</ref>) —
               that these results are not necessarily hard facts. They provide insights into
               tendencies that have then to be investigated in more detail and tested with other
               means of evaluation. But the results by far exceed previous traditional, often
               anecdotal approaches that yielded much less evidence of historical developments. </p>
            <p>In line with the goal of the research project to identify correlations between
               technical innovation and aesthetics, the identification of diachronic patterns
               through digital humanities tools is the single most important foundation for new
               insights that surpass previous findings. It displays important connections between
               the technology and stylistic forms but makes also very clear that often such causal
               connections were overstated in the past while cultural or inter-medial influences
               were largely neglected. As several recent studies have shown, careful integration of
               colorimetric visualizations into reflections on the material aesthetics of films
               yield new insights into the material aesthetics of film, for instance in a recent
               study of Len Lye’s experimental color films of the 1930s <ptr
                  target="#flueckiger2019"/>Flueckiger 2019).</p>
            <figure xml:id="figure07">
               <head>Comparison of colorimetric analysis performed in VIAN gives insights into the
                  material aesthetics of historical color films: Dufaycolor’s muted, brownish hues
                  in <title rend="italic">A Colour Box</title> (GBR 1935, Len Lye) vs. high
                  saturation and color separation in a Gasparcolor print of <title rend="italic"
                     >Colour Flight</title> (GBR 1937, Len Lye), see galleries on the <title
                     rend="italic">Timeline of Historical Film Colors</title>
                  <ref
                     target="https://filmcolors.org/filter/?_sft_ubercategory=lye&amp;post_types=gallery"
                     >https://filmcolors.org/filter/?_sft_ubercategory=lye&amp;post_types=gallery</ref>.</head>
               <graphic url="resources/images/figure07a_new.png"/>
               <graphic url="resources/images/figure07b_new.png"/>
            </figure>
            <p>Increasingly the screenshots themselves became an important part of the
               investigation. Initially only three exemplary screenshots were embedded into the
               first version of the glossary DB to illustrate the concepts. Once it turned out that
               the glossary database is also a perfect way to organize screenshots its architecture
               had to be completely refurbished to embed the screenshots dynamically via a second
               database, glossary images DB, all of which was connected to the corpus DB. With this
               database architecture it became possible to write scripts for portals and to sort
               images according to periods, corpus assignments or typology. For the VIAN WebApp, it
               is mandatory to select a sample of the most representative images for external users,
               which is done by assigning priorities to the screenshots to sort them out. Now the
               FileMaker DB architecture also allows to embed the screenshots into the corpus DB to
               provide a selection of the most significant forms of expression through color in a
               specific film.</p>
            <figure xml:id="figure08">
               <head>Glossary DB: Extract of a representative selection for the concept <q>colored
                     light,</q>  sorted according to different periods, sub-corpora or
                  typologies.</head>
               <graphic url="resources/images/figure08.png"/>
            </figure>
            <p>Since the team aims at capturing historical film prints of the analyzed films to get
               a better reference for the analyses, these photographs are then published on the
                  <title rend="italic">Timeline of Historical Film</title>. As shown in the VIAN
               Ecosystem the <title rend="italic">Timeline</title> has been integrated into the
               workflow as well. A script in FileMaker connects the corresponding galleries from the
                  <title rend="italic">Timeline</title> and displays them in a browser window
               directly in the databases to compare the photo documentation of one or more
               historical film prints with the analyzed digitization from DVDs and Blu-rays. The
               browser window enables immediate frontend tagging of the <title rend="italic"
                  >Timeline</title> photos with the thesaurus that is organizing the historical
               color film processes, the media, quotes, and galleries by a tagging system in the
                  <title rend="italic">Timeline</title> (see <ref target="#figure09">Figure
               9</ref>). Furthermore, the links to the galleries on the <title rend="italic"
                  >Timeline</title> are embedded into the project page of the VIAN WebApp.</p>
            <figure xml:id="figure09">
               <head>Glossary images DB: Comparison of DVD screenshot (left) with photograph of
                  historical film print of <title rend="italic">Salomé</title> (USA 1922, Charles
                  Bryant) from the <title rend="italic">Timeline of Historical Film Colors</title>,
                  integrated into the DB. Credit: George Eastman Museum. Photograph by Barbara
                  Flueckiger.</head>
               <graphic url="resources/images/figure09.png"/>
            </figure>
            <p>Increasingly all the facets of analysis have been integrated into the overarching eco
               system (see <ref target="#figure05">Figure 5</ref> and <ref target="#section04"
                  >Sections 4 to 9</ref>) that has guided the development of the crowd-sourcing
               platform and the implementation of all the facets of our research.</p>
            <div xml:id="section03.1">
               <head>3.1 Problems</head>
               <p>As mentioned above, resulting from this work was a massive quantity of data and
                  screenshots assembled in a master analysis DB supposed to be hosted on the
                  FileMaker server of UZH. It turned out, however, that the server was not
                  configured for such a demanding task, which necessitated that all the screenshots
                  were exported, down-sized and reimported what seemed like an unsurmountable task
                  for FileMaker due to the non-standardized nomenclature for the image files.
                  Therefore, we ultimately decided to export each screenshot into an individual
                  folder with a defined nomenclature consisting of item ID, image ID and shot ID
                  that were then processed externally by Gaudenz Halter and reimported automatically
                  with a script in FileMaker. Processing included the resizing and compression of
                  the images as well as finding the timestamps of the screenshots within the movie.
                  Since the exported screenshots did not exactly match the content of their
                  corresponding frame, due to resizing and compression earlier in the pipeline, the
                  best matching frame has been determined by application of the mean squared error.
                  This mechanism also allows to import already existing screenshots into a VIAN
                  project and assign them to the correct locus in the video.</p>
               <p>Similar problems occurred with the evaluation of the data. Scripts in FileMaker to
                  assemble the data in summations for each film became too complex and the process
                  incredibly slow and vulnerable. Even the in-house FileMaker specialists and
                  external experts could not offer solutions. Therefore, we turned to a similar
                  workflow to export all the data, process them externally in several Python scripts
                  organized in a pipeline. In a first step we had to migrate the complete dataset
                  exported from FileMaker into the VIAN WebApp database architecture. We then
                  calculated the frequencies of keywords on a per-movie basis and related
                  correlation matrices between keywords. This step was followed by a set of
                  successively performed steps to enrich the existing dataset with numeric color
                  features, including the computation of color histograms, color palettes and
                  average color values for each segment and screenshot in a figure/ground separated
                  manner. Finally the per-movie frequencies of keywords have been reimported into
                  FileMaker for the evaluation. Again due to the fact that each team member received
                  their own analysis layer organized with respect to their preferences and interests
                  there were many inconsistencies that affected minutiae such as spelling, local and
                  global concepts etc. Even complicated by the fact that the glossary was extended
                  over time there were internal inconsistencies affecting the connection between the
                  tri-partite logic of the taxonomy in the glossary consisting of classes, fields
                  and concepts, and the organization of the values in fields of the database. </p>
            </div>
            <div xml:id="section03.2">
               <head>3.2 Lessons learned</head>
               <p>To gather consistent and significant data it is mandatory to coach users as much
                  as possible and to illustrate concepts with precise visualizations from
                  screenshots. The glossary database thus contains a priority field to select the
                  most informative and clear-cut screenshots for each concept, ideally at least six
                  screenshots from different periods for each one of them. As stated before, these
                  screenshots are instantly available on the concepts page of the VIAN WebApp (see
                     <ref target="#figure10">Figure 10</ref>), so that users get a very good idea
                  what each keyword is referring to. These catalogues of screenshots might be
                  extended by short video clips taken from the corpus in case where movement or
                  other changes over time are central to the concept.</p>
            </div>
         </div>
         <figure xml:id="figure10">
            <head>VIAN WebApp concept page: collection of exemplary screenshots for the concept
                  <q>pop-out effect</q> attributed to a figure (as opposed to objects).</head>
            <graphic url="resources/images/figure10.png"/>
         </figure>
         <div xml:id="section04">
            <head>4 Development of a Visual Annotation, Analysis and Visualization Platform</head>
            <p>Based on the manual annotations executed in 2016 and 2017 with the combination of
               ELAN and the FM DBs, a set of tools for semi-automatic and automatic color analyses
               and visualization of results have been developed since 2017. These tools make use of
               computer vision and deep learning to provide meaningful results <ptr
                  target="#flueckiger2017"/>
               <ptr target="#flueckigeretal2017"/>
               <ptr target="#flueckiger2018"/>
               <ptr target="#halter2019"/>.</p>
            <p>Video annotation tools were among the first approaches to apply digital methods to
               segment and annotate films with a set of tools, see for instance <ref
                  target="#gruber2019">Gruber et al. (2009)</ref>, investigations in Giunti (<ref
                  target="#giunti2010">2010</ref>; <ref target="#giunti2014">2014</ref>), a detailed
               assessment by <ref target="#melgar2017">Melgar et al. (2017)</ref>.</p>
            <p>In 2016 we executed an extended research into all the available tools, many of which
               were not running on newer operating systems anymore, due to the termination of
               funding (see <ref target="#flueckiger2017">Flueckiger 2017</ref>). Finally we decided
               to use ELAN (see <ref target="#figure11">Figure 11</ref>), a video annotation tool
               that offers a great variety of options and is very sophisticated, but was developed
               with a focus on the analysis of language by the Max Planck Institute for
               Psycholinguistics in Nijmegen.</p>
            <figure xml:id="figure11">
               <head>Video annotation system ELAN interface and template for segmentation and
                  annotation,  <title rend="italic">Pierrot le fou</title> (FRA 1965, Jean-Luc
                  Godard).</head>
               <graphic url="resources/images/figure11.png"/>
            </figure>
            <p>To overcome the limitations of this approach and to shift focus more to the
               perspective of visual forms of expression, a new visual video annotation system VIAN
               has been developed by Gaudenz Halter. In addition to several layers of video
               segmentation and annotation it integrates advanced methods for the analysis and
               visualization of film colors and is suited for large scale classification of film
               content. </p>
            <figure>
               <head>VIAN segmentation layer with screenshot manager, <title rend="italic"
                     >Sedmikrásky</title> [<title rend="italic">Daisies</title>] (CZE 1966, Vera
                  Chytilová).</head>
               <graphic url="resources/images/figure12.png"/>
            </figure>
            <p>VIAN is a tier-based film annotation software that places emphasis on visual aspects
               of film style and its color aesthetics, allowing the user to perform general
               annotation tasks as well as numeric analysis of film material. VIAN has been
               developed to not only provide data for the crowd-sourcing tool VIAN WebApp that
               combines our developed analysis pipeline into one software, but also to be flexibly
               used in other research projects with different film-analytical topics. In essence it
               consists of several crucial ingredients: Screenshot management, classification by
               large vocabularies, a toolset for color analysis and visualizations, for a basic
               overview see several tutorials for the VIAN annotation tool: <ref
                  target="vimeo.com/user/70756694/folder/1220854"
                  >vimeo.com/user/70756694/folder/1220854</ref>.</p>
            <p>Previous annotation tools do, to the best of our knowledge, not implement a
                  <q>screenshot management system</q>, thus screenshots usually have to be exported
               and managed by the user in the file system, an obviously difficult and error prone
               task with an increasing number of screenshots. However, as stated earlier,
               screenshots play a key role in the visual assessment of films. Therefore, screenshots
               have become a central type of annotation that can be created in VIAN. Apart from
               screenshots, VIAN also provides temporal segments and vector graphic annotations. The
               latter describe annotations that can be drawn directly on screen, currently these are
               ellipses, rectangles, images, text and free-hand drawings. </p>
            <figure>
               <head>VIAN's analysis widget contains the controlled vocabulary developed during the
                  manual analyses  and defined in the glossary DB and on the concept page on the
                  VIAN WebApp. <title rend="italic"> Paris, Texas</title> (DEU / FRA 1984, Wim
                  Wenders).</head>
               <graphic url="resources/images/figure13.png"/>
            </figure>
            <p>As mentioned before (see <ref target="#section02">Section 2</ref>), our project
               included the classification of a large amount of segments by over 1.200 concepts
               using FileMaker. With respect to the VIAN WebApp crowd-sourcing tool, this
               functionality has been implemented into VIAN also. By contrast to many other film
               annotation software packages, VIAN makes a clear distinction between natural
               language-based annotation and <q>classification</q> based on vocabularies that have
               been established and tested in the manual corpus analysis. Descriptions are performed
               by simply typing the respective annotation into the temporal segment or as vector
               graphic annotation onto the screen. The latter, however, is performed within VIAN’s
               classification system. Once a user has created one or several annotations consisting
               of screenshots, temporal segments or vector graphic annotations they can be
               classified by the vocabularies defined in the glossary. VIAN also allows the user to
               define the conceptual entity, so called <q>classification objects</q> that are
               classified explicitly with one or more vocabularies. For example, the concept
                  <q>saturated</q> could target the classification object <q>male protagonist</q>
               and <q>female protagonist.</q> Color features can be extracted for an annotation to
               create visualizations that yield insights into the colorimetric context of
               screenshots, temporal segments or regions within the frame. Furthermore, VIAN
               automatically computes several measures in an evenly spaced manner for the complete
               movie to directly display the most important color features while scrubbing through
               or watching a video.</p>
            <p>Implemented in Python, we have put strong focus into the extendibility such that
               scholars can easily extend VIAN’s functionality to suit the needs of their research
               questions or using it as a Python API. </p>
            <div xml:id="section04.1">
               <head>4.1 Problems</head>
               <p>The development of VIAN has been an iterative process of development and testing
                  with the research team. Obviously, a large number of design questions arise during
                  such a process, especially when the number of requirements and tasks are as large
                  as in the case of the film colors research. Clearly, there are numerous questions
                  related to the software architecture and implementation of tools, but we have also
                  found that developing an easy to use software can be challenging. One of the major
                  difficulties regarding the architecture of VIAN has been to develop a software
                  that solves the very specific need of our research project while remaining generic
                  to be used for other projects and research topics. </p>
               <p>Another difficulty was related to the efficient storage of the data. Most
                  annotation tools use a human-readable file format such as XML or JSON to store the
                  generated data permanently. These formats have the advantage that the data can
                  easily be read even without the source tool at hand and improve interoperability.
                  However, numeric data as generated and operated by VIAN had to be stored in a
                  faster accessible file format. During the development we tried several approaches.
                  We started with a simple JSON file. Once the numeric data became too large, we
                  migrated to an SQLite database. This approach did however not scale well enough,
                  finally we implemented a hybrid system using a human-readable JSON file for the
                  annotations and project structure and an optimized HDF5 file for numeric data.</p>
            </div>
            <div xml:id="section04.2">
               <head>4.2 Lessons learned</head>
               <p>We have found that the most important part about the development is a short
                  feedback loop between the developer and the users, film scholars, students or
                  other researchers. Since there is a huge palette of statistical and analytical
                  methods that could be implemented into VIAN. It turned out that developing in a
                  user-centered fashion is favorable over implementing a large range of possible
                  features. As such we tried to create a solid architectural foundation and remain
                  generic whenever possible without introducing too much complexity. </p>
            </div>
         </div>
         <div xml:id="section05">
            <head>5 Temporal Segmentation, Extraction and Organization of Screenshots</head>
            <p>Approaches to the parsing of films vary greatly depending on a researcher’s interest:
                     <cit><quote rend="block">They can be parsed meaningfully into a hierarchy that
                     has units within units within units [...]. Within this hierarchy, some units
                     have the psychological stature of being events. That is, viewers judge them to
                     have beginnings, middles, and ends, with boundaries that are often denoted by
                     changes in time and place, and that form separable segments within the ongoing
                     audiovisual stream.</quote>
                  <ptr target="#cutting2012" loc="1"/></cit> What sounds relatively simple, turns
               out to be rather complex, especially when we consider tools for (semi-)automatic
               segmentation (Hahn 2009). Ambiguities increase when we define temporal units by the
               consistency of color schemes, which is the aim of the film colors study. Even if the
               camera angle varies or if the camera moves in tracking or crane shots the colors
               dominating the scene can vary significantly, albeit continuously. Therefore it
               becomes difficult to identify the temporal segments in a consistent way. Some montage
               patterns — such as parallel montage — require sub-segmentations that consider both
               event boundaries and temporal units conflicting with each other. While silent films
               with their intertitles and / or uniformly tinted segments often signpost their
               structural organization in a rather distinct way, more recent films have more fluidly
               overlapping scenes. The classical Hollywood continuity system, on the other hand, has
               established a number of enunciation marks that communicate scene changes or temporal
               ellipses such as dissolves, fades, or wipes. </p>
            <p>Temporal segmentation of a film by human observers — and especially those trained as
               film scholars or advanced students in film studies — take all these various,
               historically established cues into account, even if the task is connected to mainly
               the dimension of film color. On average the team identified between 50 to 70 temporal
               units with sufficiently consistent color schemes within feature-length films.</p>
            <p>To accelerate this time-consuming process, VIAN provides an auto-segmentation
               functionality that computes a temporal segmentation by means of agglomerative
               clustering of evenly spaced color histograms. The result can then be fine-tuned by
               the user using the merge and cut tool of VIAN’s timeline.</p>
            <figure>
               <head>Comparison manual (top) vs. four types of automated temporal segmentation with
                  30 to 60 segments in  <title rend="italic">Une femme est une femme</title> (FRA
                  1961, Jean-Luc Godard).</head>
               <graphic url="resources/images/figure14.png"/>
            </figure>
            <p>As elaborated above (see <ref target="#section04">Section 4</ref>), an informed
               selection of screenshots is paramount as a heuristic tool to reduce the complexity of
               the time-based video stream by picking out the most relevant moments. Therefore, it
               became mandatory to establish a fast and flexible process not only to extract
               screenshots with a simple command but also to organize them instantly in relation to
               the temporal segmentation of the film in individual bins and with consistent
               nomenclature. In ELAN, each screenshot extraction required several steps from 5 to 12
               commands plus manually naming the image files and defining the image format. VIAN, by
               contrast, treats screenshots as an integral type of annotation, their creation and
               management are therefore key functionalities. Screenshots are created with a simple
               hotkey and displayed in several ways within VIAN including temporal alignment in the
               timeline and grouped by segmentation in the screenshot manager.</p>
            <div xml:id="section05.1">
               <head>5.1 Problems</head>
               <p>Many video annotation software solutions have been established in the past that
                  fulfil basic needs. But there is a big leap to developing more sophisticated tools
                  that respond to more complex requirements. Bottom line: the devil is in the
                  details. A very fine framework that integrates several types of players for
                  different zoom-out functions is a powerful start to segment movies temporally, to
                  verbally annotate these units and to extract screenshots. How well does the
                  integrated player process diverse codecs and aspect ratios? What options does it
                  offer to adjust segmentations and to add sub-segmentations for discontinuous
                  entities such as parallel montage? How does it prevent overlapping segments or, by
                  contrast, enable them? What options are there to correct existing
                  segmentations?</p>
               <p>Automatic temporal segmentation proved to deliver surprisingly good results that
                  in certain instances challenged human approaches to subdivide the video stream
                  into consistent chunks. On the negative side, auto-segmentation seemed to be much
                  more finely grained in dark scenes and some segments were too long, especially
                  when compared to the average lengths of segments.</p>
            </div>
            <div xml:id="section05.2">
               <head>5.2 Lessons learned</head>
               <p>To develop a robust video annotation system constant user feedback from
                  experienced users is a necessary requirement. For the next step of
                  auto-segmentation we envision to take music cues and sound design into account,
                  see for instance <ref target="#burghardt2016">Burghardt et al. (2016)</ref> for a
                  very original approach to combine image and dialogue in film analysis with digital
                  tools. Very often onset or termination of diegetic music indicate shifts in locale
                  or time. Sound design is expressive of certain locations or temporal cues as
                  well.</p>
               <p>Furthermore, so-called enunciation marks such as fades to black or white,
                  cross-fadings or intertitles should be incorporated into the system of rules for
                  the parsing of units. Significant deviations in the resulting length of segments
                  compared to the average should force the system to process these extremely long or
                  short chunks again.</p>
            </div>
         </div>
         <div xml:id="section06">
            <head>6 Figure-Ground Separation</head>
            <p>Very early in the project, a figure–ground separation tool was established <ptr
                  target="#flueckiger2017"/> to extract characters from the background using a
               current, deep-learning semantic segmentation technique <ptr target="#long2015"/>
               <ptr target="#zhao2016"/>. With the rationale to assign to each frame pixel a label
               this approach indicates the most probable object it represents. It aims at
               investigating the aesthetics of color attribution through costume and set design in
               conjunction with other parameters of the mise-en-scène. In the project the method has
               been constantly improved for speed and performance and provides the basis for all the
               other color analysis tools — <term>LAB plots</term> (see <ref target="#figure18"
                  >Figures 18</ref> and <ref target="#figure21">21</ref> etc.),
                  <term>Color_dT</term> plots (see <ref target="#figure15">Figures 15</ref> and <ref
                  target="#figure17">17</ref>) — that consider characters independent from their
               backgrounds.</p>
            <p>Aesthetics of figure-ground separation varies greatly during the course of film
               history, depending on many factors such as color processes, cinematography,
               mise-en-scène including lighting, staging, materiality of costumes, objects and
               environments, but also notions of taste and professional norms. For instance strong
               figure–ground separation was a typical stylistic means to enhance instant legibility
               in the context of the so-called <q>continuity system</q> established in classical
               Hollywood films from the mid-1920s onward. </p>
            <p>In this production context there was often a hierarchy that attributed the most
               visually compelling colors to the female star and to reduce color difference between
               characters and backgrounds for supporting characters. Saturation is mostly attributed
               to female characters while male characters only wore colorful dresses when they were
               playing certain parts that were framed within cultural norms, by historical distance
               — for instance royalty or uniforms — , by certain milieus such as the entertainment
               industry or the arts, by cultural othering such as exoticism or individual
               personality traits such as queerness or non-conformist attitudes (see <ref
                  target="#bohn2000">Bohn 2000</ref>, <ref target="#vanska2017">Vänskä 2017</ref>)
               or genre conventions. Strong figure–ground separation as a trend can be observed
               again in the emerging contexts of the first auteur-centered color films in European
               and for instance Japanese productions that feature a sober modernist style.</p>
            <p>To investigate these stylistic and culturally justified changes in a clear-cut way we
               established a typology that took the following dimensions into account: strong vs.
               weak, silhouettes, figure–ground inversion, and separation by hue, saturation or
               lightness. By figure–ground inversion we denote relationships where the background is
               either more saturated or brighter than the background. </p>
            <p>These distinctions have then become the underlying concepts for the visualizations
               that came out of the figure–ground separation pipeline.</p>
            <p>Referring to the annotation and classification system explained earlier, VIAN allows
               the user to define <hi rend="italic">classification objects </hi>to express a
               conceptual entity of his or her interest, in this case <q>figure</q> and
                  <q>ground.</q> VIAN uses a deep learning based semantic segmentation to interpret
               the content of a frame (see <ref target="#figure15">Figure 15</ref>). The output of
               such a segmentation is a grayscale image, where each pixel of the input image is
               assigned to a gray value, so called <hi rend="italic">labels</hi>, which correspond
               to defined objects the model has been trained on. VIAN now allows to assign a set of
               labels to each classification object, creating a semantic link between the content of
               the frame and the classification performed by the researcher. Arnold and Tilton’s
               studies of visual culture also applied image recognition with deep learning tools
                  <ptr target="#arnold2020a"/>
               <ptr target="#arnold2020b"/>.</p>
            <figure xml:id="figure15">
               <head>Semantic segmentation performed in VIAN.</head>
               <graphic url="resources/images/figure15.png"/>
            </figure>
            <p>The results of this figure–ground pipeline are highly significant, especially when
               combined with the <hi rend="italic">Color_dT</hi> visualization (see Figure 15). An
               instant fingerprint of a film’s aesthetic development emerges when we compare the
               varying relationships between color attribution to characters vs. environment in the
               course of a film’s narrative unfolding. As will be elaborated in Section 7
               Colorimetric <hi rend="italic">Analyses and Visualizations</hi>, the resulting types
               of visualizations differ profoundly from established ones. Mapping the results still
               raises some questions for scaling. For instance, we found that humans perceive
               saturation levels attributed to characters as higher when the rest of the image is
               less saturated, a difference that cannot be rendered accurately with our current
               visualization and colorimetry methods yet.</p>
            <figure xml:id="figure16">
               <head>Figure–ground separation in VIAN, <title rend="italic">Jigokumon</title> (JAP
                  1953, Teinosuke Kinugasa).</head>
               <graphic url="resources/images/figure16.png"/>
            </figure>
            <div>
               <head>6.1 Problems</head>
               <p>While we expected this task to be very demanding it turned out that — because this
                  is one of the most important tasks in autonomous driving — deep-learning methods
                  are currently in a very dynamic state especially with regard to extracting
                  characters from backgrounds. YOLO <ptr target="#redmon2015"/> was the first object
                  recognition software applied. It provided very reliable results for the
                  identification of humans while other objects were often misinterpreted, especially
                  when they were partially occluded or cut off at the frame’s edges. </p>
               <figure xml:id="figure17">
                  <head>Object identification in YOLO: while persons are identified consistently,
                      errors occur when objects are partially occluded or fragmented.</head>
                  <graphic url="resources/images/figure17.png"/>
               </figure>
               <p>YOLO was combined with GrabCut <ptr target="#rother2004"/>. GrabCut works as
                  follows: the user initially draws a rectangle around the object to be in the
                  foreground, GrabCut will then try to directly segment the frame, and return the
                  result. The user can then iteratively optimize the result by marking regions that
                  have not been identified correctly using strokes. Performing this process for each
                  image manually would not have been feasible because of the time constraints, we
                  thus used YOLO, an object recognition neural network to draw the initial bounding
                  box and the strokes. However, this pipeline did not scale well enough for our
                  purposes, demanding a large amount of resources and time. We therefore decided to
                  use a deep-learning convolutional network to perform the pixelwise segmentation
                  directly with semantic segmentation <ptr target="#long2015"/> rather than the YOLO
                  and GrabCut based approach. </p>
            </div>
            <div xml:id="section06.2">
               <head>6.2 Lessons learned</head>
               <p>A collaborative, interdisciplinary approach that connects high levels of expertise
                  both in the domain of aesthetic analysis and computer science has proven to be
                  mandatory for the elaboration of an analysis and visualization pipeline that
                  respects both fields and connects them in a convincing manner. While such a
                  statement may seem banal, in fact the actual exchange between different
                  disciplines has been much more demanding and requires continuous adjustments from
                  both sides. Experts from the field of humanities must be able to understand the
                  requirements of informatics and to describe the task in a highly formalized
                  manner. Scientists on the other hand need to be open to integrate a sense for the
                  subtleties of aesthetic concepts to understand why minor details unexpectedly can
                  have a significant impact on the results. The resulting pipeline should produce
                  visualizations that respect the rigorous demands of science while also considering
                  instant accessibility for human observers and knowledge of aesthetic distinctions
                  at the same time.</p>
            </div>
         </div>
         <div xml:id="section07">
            <head>7 Colorimetric Analyses and Visualizations</head>
            <p>Previous approaches to visualizations of color schemes were surprisingly reduced in
               their scope and were not sophisticated enough to do justice to aesthetic subtleties
               of color design in film. </p>
            <p>Currently available tools to devise color schemes are often applying K-means <ptr
                  target="#brodbeck2011"/>
               <ptr target="#rosebrock2014"/> and thus are limited to the depiction of a fixed set
               of hues. Color schemes in VIAN, by contrast, are extracted to match spatial
               distribution and can be edited according to the needs of the color analysis for a
               certain film. Some films apply very distinct hues to their color schemes while others
               resort to minute shifts to display developments in character relationships. Color
               schemes can express a character’s inner states or personal developments, relationship
               to other characters or a given environment, again norms of taste and milieus, or
               cultural conventions. Socio-political markers indicate characters’ connection to a
               certain class or social function in a socially or culturally pre-defined way as for
               instance in uniforms.</p>
            <p>From the start, we therefore envisioned a different approach that allows for a
               flexible fine-tuning of color schemes to match the specific style of a given film. A
               second basic requirement was the representation of the spatial distribution of colors
               in a way that is instantly displaying the quantitative allocation of colors in an
               image or temporal segment. Thirdly, we aimed at visualization methods of color
               schemes that show their development in a film over time according to the temporal
               segmentation executed in the pipeline.</p>
            <p>Typical time-based representations such as movie barcodes or mosaics provide
               plenoptic overviews of films (for a discussion see <ref target="#heftberger2016"
                  >Heftberger 2016</ref>, <ref target="#stutz2016">Stutz 2016</ref>, <ref
                  target="#olesen2017">Olesen 2017</ref>, <ref target="#flueckiger2017">Flueckiger
                  2017</ref>) but they do not represent the finely grained shifts and relationships
               that are fundamental for an in-depth study of aesthetics. Frederic Brodbeck arranged
               color schemes in circles to give an overview of what he called a fingerprint of a
               film’s color scheme <ptr target="#brodbeck2011"/>. Z-projections have become a main
               part of Kevin L. Ferguson’s visualizations <ptr target="#ferguson2013"/>
               <ptr target="#ferguson2016"/> who also proposed a volumetric approach to visualize an
               entire film’s color on the time axis in 3D <ptr target="#ferguson2015"/>. James E.
               Cutting and his team at Cornell University devised many methods to visualize movies,
               among others a movie barcode that implemented color schemes from warm to cold colors
                  <ptr target="#cutting2016"/>. From 2013 onwards Lev Manovich <ptr
                  target="#manovich2013a"/>
               <ptr target="#manovich2013b"/> and his Software Studies lab applied a range of
               visualizations to Dziga Vertov’s films for Adelheid Heftberger’s research project
                  <ptr target="#heftberger2015"/>
               <ptr target="#heftberger2016"/>, some of them based on ImagePlot and ImageJ that were
               used previously for the visualizations of artworks <ptr target="#manovich2012"/>
               <ptr target="#reyes-garcia2014"/>
               <ptr target="#reyes-garcia2017"/>. ImageJ, initially introduced for bio-medical
               research <ptr target="#ross2007"/>, has since been used by several researchers for
               film analysis (<ref target="#olesen2016">Olesen 2016</ref>, <ref
                  target="#heftberger2016">Heftberger 2016</ref>, see several chapters in <ref
                  target="#hoyt2016">Hoyt et al. 2016</ref>). Casey et al. compared temporal
               segments in films based on histograms visualized in a similarity matrix <ptr
                  target="#casey2014"/>.</p>
            <p>As elaborated in Halter et al. (2019), the team defined a set of requirements for the
               visualizations. They should <list type="ordered">
                  <item>Represent visual impressions true to human perception;</item>
                  <item>Represent subtle aesthetic nuances in figure and ground separately;</item>
                  <item>Visualize the films at the micro (screenshot, temporal segment), meso
                     (individual film) and macro (corpus) levels.</item>
               </list> And in addition they should be interactive and flexible for adjustment to an
               individual researcher’s interest <ptr target="#halter2019" loc="126"/>.</p>
            <p>Therefore, as elaborated in previous papers <ptr target="#flueckiger2011"/>
               <ptr target="#flueckiger2017"/>, the relationships of colors need to be mapped into a
               perceptually uniform color space to provide visualizations that match human vision.
               In VIAN, both the screenshots and the color schemes are thus transformed into the
               perceptually uniform CIE L*a*b* (referred to as LAB in this paper) color space needed
               for meaningful representation of the color distribution in a given film. Contrary to
               most established visual representations such as image plots, z-projections, color
               palettes or barcodes, a visual representation in a perceptually uniform color space
               pays attention to the relational nature of colors with regard to the visual system.
               Chromaticity and lightness plots provide an overview of a film’s color distribution,
               see Figure 18.</p>
            <figure xml:id="figure18">
               <head>Chromaticity plots in CIE L*a*b* (LAB) for <title rend="italic">Pierrot le
                     fou</title> (FRA 1965, Jean-Luc Godard),  image plot (above) vs. palette dot
                  plot (below) The comparison shows that chroma extends much further in palette dot
                  plots without averaging effects caused by the representation of images.</head>
               <graphic url="resources/images/figure18a.png"/>
               <graphic url="resources/images/figure18b.png"/>
            </figure>
            <p>While visualizing color schemes in a strip of color patches sorted by frequency is
               generally well established and gives a good overview, they are often hard to compare
               and hide how the palette has been assembled during the clustering process. To compare
               color distribution in relation to human perception the color scheme is displayed in
               the LAB color space as a palette dot plot. With this method small changes as well as
               color contrasts within the chroma or hue between different color patches become
               directly visible (see <ref target="#figure19">Figure 19</ref>, right). The tree
               palette (<ref target="#figure19">Figure 19</ref>, above, middle) should help the user
               to understand into which final cluster the colors of the input image have been
               merged. To this end, palettes are stacked in different merge steps corresponding to
               increasing levels of granularity on top of each other and the color patches sorted
               within the palette by the order resulting from the clustering. Thus all colors merged
               into a cluster are visualized directly below it. </p>
            <figure xml:id="figure19">
               <head>Color palettes for individual shots: tree diagram with increasing levels of
                  detail (above, middle) and LAB (right); selection of 7 hues for layer palette
                  sorted by frequency (below, middle). <title rend="italic">Blade Runner
                     2049</title> (USA 2017, Denis Villeneuve),  see interactive visualization
                  methods in the screen video <ref target="https://vimeo.com/299804415"
                     >https://vimeo.com/299804415</ref>.</head>
               <graphic url="resources/images/figure19a.png"/>
               <graphic url="resources/images/figure19b.png"/>
            </figure>
            <p>Applying color-related computational methods, such as clustering or statistics on the
               raw frames of a film is often not feasible because of the sheer amount of data. It is
               thus often a necessity to extract feature vectors adequately representing the content
               through a color histogram that is regularly used within VIAN. However, color spaces
               are three-dimensional and so are their color histograms, making visualization of
               color histograms a difficult task. A naive approach would be to visualize the
               histograms as point clouds in a three-dimensional space but this method doesn’t yield
               good comparability. We therefore developed a bar-chart like representation of a color
               histogram by sorting the colors of the three-dimensional histogram into a
               one-dimensional list using a room-filling curve, namely the Hilbert curve.
               Intuitively, this room-filling curve describes a path, by which any point of a given
               space is visited, in our case the bins of the three-dimensional color histogram. By
               unraveling this curve, we can align the bins of the three-dimensional color histogram
               in a one-dimensional row. We use Hilbert curves, because this type of room-filling
               curve has shown to preserve the specific locality well, in our case this means that
               color bins which are close in the three-dimensional histogram, will also be close in
               the unraveled, one-dimensional, histogram bar plot. </p>
            <p>Color_dT is an advanced method to visualize the color development of a film over time
               on the meso level with regard to its temporal unfolding, again for figure, ground and
               whole screenshots independently. It is currently implemented for saturation
               contrasts, contrast of hue, chroma or light-dark contrast, but could also include
               cold–warm contrast. Shifts in figure–ground relationships become instantly evident,
               so do overall developments with regard to the narrative events in the course of a
               film. </p>
            <figure xml:id="figure20">
               <head>Color_dT plot development of saturation (y-axis) over time (x-axis) for figure
                  (above) and background (below) in <title rend="italic">Jigokumon</title> (JAP
                  1953, Teinosuke Kinugasa), visualization by Noyan Evirgen for ERC Advanced Grant
                     <title rend="italic">FilmColors</title>.</head>
               <graphic url="resources/images/figure20a.png"/>
               <graphic url="resources/images/figure20b.png"/>
            </figure>
            <p>One significant example is the Japanese film <title rend="italic">Jigokumon</title>,
               produced as one of the first Japanese color films shot in the then new chromogenic
               process Eastmancolor. In the first half of the film we see a pronounced figure ground
               separation with the characters, especially the female love interest standing out in
               colorfully patterned, saturated kimonos in front of subdued backgrounds. In the
               middle of the film a peripety occurs during a horse race where the two male opponents
               fight each other. This scene is set in broad daylight with conflicting colors in
               background and foreground. After this turning point, the tragedy sets in with a
               markedly different color design and mise-en-scène characterized by dark scenes in
               low-key lighting, which by its very nature reduces figure–ground separation.</p>
            <p>With early applied colors such as tinting and toning, the LAB chromaticity plots look
               decidedly different due to the mostly monochrome color schemes. As becomes evident
               from a comparison between <title rend="italic">L’Inhumaine</title> (FRA 1923, Marcel
               L'Herbier) and <title rend="italic">Das Cabinet des Dr. Caligari</title> (GER 1919,
               Robert Wiene), the digitization of <title rend="italic">L’ Inhumaine</title> differs
               substantially by the detached distribution of chroma — there is no continuity from
               the center to the higher levels — which could result from problems in digital color
               management.</p>
            <figure xml:id="figure21">
               <head>Chromaticity plots in the CIE L*a*b* space for the tinted films <title
                     rend="italic">L’Inhumaine</title> (FRA 1923, Marcel L'Herbier) (above)  and
                     <title rend="italic">Das Cabinet des Dr. Caligari</title> (GER 1919, Robert
                  Wiene).</head>
               <graphic url="resources/images/figure21a.png"/>
               <graphic url="resources/images/figure21b.png"/>
            </figure>
            <figure xml:id="figure22">
               <head>Color_dT plot development of saturation (y-axis) over time (x-axis)  for the
                  tinted film <title rend="italic">L’Inhumaine</title> (FRA 1923, Marcel L'Herbier),
                  a tinted film.</head>
               <graphic url="resources/images/figure22.png"/>
            </figure>
            <div>
               <head>Features Tool</head>
               <p>Correlations between concepts are displayed in two ways. The <hi rend="italic"
                     >features tool</hi> enables users to select the concepts from the menu.
                  Consequently the occurrence of these concepts are then displayed over time related
                  to the segments where they occur. Connected to the exemplary screenshots this type
                  of visualization instantly builds the foundation to establish and test
                  hypotheses.</p>
               <p>The correlation between different keywords within a project or corpus-wide can be
                  investigated using the co-occurrence matrix plots, which indicates how often every
                  combination of keywords occurs within the scope.</p>
               <figure xml:id="figure23">
                  <head>VIAN features tool visualizes co-occurrences of concepts organized on the
                     time axis with regard to the temporal segmentation in <title rend="italic">Do
                        the Right Thing</title> (USA 1989, Spike Lee), see screen video <ref
                        target="https://vimeo.com/292861139"
                     >https://vimeo.com/292861139</ref>.</head>
                  <graphic url="resources/images/figure23.png"/>
               </figure>
               <p>In the screen video the features tool is tested with Spike Lee’s Do the Right
                  Thing. Several typical features of this film have been selected in this
                  visualization. In addition to the leitmotif that establishes the dominant red
                  spectrum of the film and associates it to the topic of heat in its double sense as
                  a temperature and as a metaphor for the rising racial tensions, the film’s
                  aesthetics is informed by a dichotomy between the private sphere and the public
                  space. The private sphere in interiors is often shown suffused in atmospheric
                  diffusion again associated to the hazy damp caused by the heat in warm monochrome
                  red tones with shafts of light filling the room, all of which are associated to a
                  romantic tradition dating back to the early 19th century. By contrast, the
                  aesthetics of the film’s public sphere follows a much more sober style connected
                  to traditions of social realism with extended depth of field in wide-angle shots
                  that show the characters in relationship to each other and to their environment.
                  In terms of color design, the film makes use of what we call socio-political
                  markers, culturally established conventions to denote certain social strata or
                  official functions. For instance the protagonist played by Spike Lee himself is a
                  pizza delivery boy and wears clothes in the colors of the Italian
                     <term>tricolore</term>, white, green and red. His encounters are also defined
                  by the central topic of race that is connected to the various ethnic groups, the
                  Puerto Ricans, the Jamaican, the Koreans, the Italians, and the Afro-Americans,
                  each of which is associated to different sets of hues by socio-political markers.
                  Such a pattern of color aesthetics and meaning can easily be confirmed or further
                  elaborated with the <hi rend="italic">features tool</hi> (<ref target="#figure23"
                     >Figure 23</ref>).</p>
            </div>
            <div xml:id="section07.1">
               <head>7.1 Problems</head>
               <p>Image plots are fantastic tools for visualizations when a researcher aims at
                  keeping the connection to the source material. By zooming into the plots, users
                  can look at the screenshots and see where and why a certain screenshot is present
                  in the plot and how it is related to the film. However, because image plots’
                  colorimetric values are calculated based on the average of the screenshot’s color
                  distribution, monochrome color schemes distort the visualization by being too
                  dominant. Screenshots with more than one hue or a multitude of hues aggregate at
                  the center of the LAB visualization or at the bottom of a <term>Color_dT</term>
                  plot. Therefore, this type of visualization is best suited for early applied
                  colors such as tinting and toning with their monochrome color distribution or for
                  films with stark color designs in mostly one dominant hue per segment such as for
                  instance Suspiria or Slawomir Idziak’s camerawork whose signature style often
                  applies colored illumination and monochrome or graduated lens filters.</p>
            </div>
            <div xml:id="section07.2">
               <head>7.2 Lessons learned</head>
               <p>For many films that are not rendered well in image plots we devised an alternative
                  solution by consecrating the full image rendition and separated the individual
                  color values (comparison see <ref target="#figure18">Figure 18</ref>). That is,
                  instead of using the average color values, we computed the color palette for a
                  given screenshot and visualize it in the AB plane of the LAB color space. A jitter
                  effect is applied to add some noise, making the amount of a specific hue visible
                  within the color space. These palette dot plot visualizations now show the color
                  schemes represented by dots for each of the colors present in a screenshot. We had
                  to devise a method to include the spatial percentage into the dot plots. Dot plots
                  have also become a means to show color schemes in a different way than with the
                  typical color bars, see <ref target="#figure19">Figure 19</ref>. Different methods
                  to scale and distribute colors in visualizations are offered such as zoom
                  functions or range adjustments. Rotation is crucial for visualizations related to
                  the L axis in the LAB space to show the distribution of hues in a meaningful way.
                  While palette dot plots display a film’s color distribution in an intuitive way,
                  they do not take the relative incidence into account. Therefore yet another type
                  of visualization was introduced: heat maps that show the color distribution by
                  means of levels of transparency corresponding to the incidence (<ref
                     target="#figure24">Figure 24</ref>). </p>
            </div>
         </div>
         <figure xml:id="figure24">
            <head>Palette dot plots (left) vs. heat maps (right): while palette dot plots visualize
               the occurrence of a certain color, heat maps indicate the incidence by different
               levels of transparency. VIAN WebApp query <q>disgust.</q></head>
            <graphic url="resources/images/figure24.png"/>
         </figure>
         <div xml:id="section08">
            <head>8 Visualizations, Concepts and Correlations on the Macro Level</head>
            <p>One of the biggest gains of our investigation is the massive dataset created by the
               analysis team. As written above, (see <ref target="#section03">Section 3</ref>) it
               amounts to more than 17.000 segments with more than 170.000 screenshots for more than
               400 films, each of which are connected to the meticulous manual analysis and
               annotation presented in detail in the previous sections of this paper (see <ref
                  target="#section02">Sections 2</ref> to <ref target="#section05">5</ref>).</p>
            <p>One way to display the amount of associations between different keywords within a
               dataset this large and complex, is to follow a network visualization approach. Every
               keyword is represented as a node and its connections to other keywords as edges. The
               more these keywords appear in the same segment the closer they are placed together
               within the network using the Fruchterman-Reingold force-directed graph drawing
               algorithm provided by the NetworkX Python library <ptr target="#hagberg2008"/>.</p>
            <p>With the integration of this dataset into the VIAN WebApp we open up a broad range of
               opportunities for queries on the segment, film and corpus level to combine the manual
               annotation with all the colorimetric analysis and visualization methods elaborated in
               sections 6 and 7 (see <ref target="#section06">Section 6</ref>, see <ref
                  target="#section07">Section 7</ref>). By such a comprehensive approach we enable
               users to combine all the three different levels, from the micro level (close reading,
               for instance individual screenshots or segments) to the meso level of individual
               films to the macro levels (distant reading) of the full corpus or selected
               subcorpora. Such selected corpora can be queried by any concept regarding narrative
               aspects, characters’ emotional states, motives or themes, and all the aesthetic and
               stylistic dimensions mentioned in section 2 (see <ref target="#section02">Section
                  2</ref>).</p>
            <p>Two concept queries are displayed here, the search for dream sequences in the three
               periods 1895–1930 and the search for night sequences in early film. When we compare
               the visualization of dream sequences in early film with the period from 1930–1955 two
               insights emerge, dream sequences are often marked by monochrome color schemes, and
               often the dominant color is red. In the second plot (1930–1955) the relatively
               prominent incidence of green is related almost exclusively to the <title
                  rend="italic">Wizard of Oz</title> where the concept of dream applies to the
               primary narrative of the film (see <ref target="#figure25">Figure 25</ref>
               below).</p>
            <figure xml:id="figure25">
               <head>Visualizations on corpus level for the narrative concept <q>dream,</q>
                   1895–1930 (left) and 1930–1955 (right), AB image plots.</head>
               <graphic url="resources/images/figure25a.png"/>
               <graphic url="resources/images/figure25b.png"/>
            </figure>
            <p>Applied colors in films produced during the first three decades of film history —
               such as tinting and toning with their monochrome color schemes — followed loosely a
               set of conventions, which then have to be tested in individual films or over a
               certain period. Because there were many ambiguities, each film’s color schemes and
               attribution of hues to different locations, times, narrative strands, genre or gender
               conventions has to be carefully investigated for film scholars and restorers alike to
               understand the guiding rules of one particular historical film print <ptr
                  target="#ledig1988"/>( <ptr target="#mazzanti1998"/>
               <ptr target="#mazzanti2009"/>. For instance <title rend="italic">Das Cabinet des Dr.
                  Caligari</title> has survived in five differently tinted and toned versions, see
               gallery on the <title rend="italic">Timeline of Historical Film
                     Colors</title>,<note><ref
                     target="https://filmcolors.org/galleries/das-cabinet-des-dr-caligari-1919/"
                     >https://filmcolors.org/galleries/das-cabinet-des-dr-caligari-1919/</ref></note>
               but a reference print of the initial German premiere version has not been found yet
                  <ptr target="#wilkening2014"/>, see <ref target="#figure09">Figure 9</ref> for the
               comparison of a DVD vs. historical print. </p>
            <figure xml:id="figure26">
               <head>Corpus visualization exterior night in films from 1895–1930, with fire scenes
                  excluded.</head>
               <graphic url="resources/images/figure26.png"/>
            </figure>
            <p>One of the most stable associations of specific hues to a certain narrative dimension
               is blue tinting to exterior night scenes, because limited speed of early film stocks
               did not allow for night scenes to be actually shot by night. Therefore these scenes
               needed to be marked by typical hues. The visualizations show that blue is indeed one
               of the dominant hues with green almost as wide-spread as blue. Amber and red are the
               third dominant range. Amber is often associated to tungsten or candle light in
               interior scenes, so segments that contain connections between interior and exterior
               scenes in a certain sense contaminate the result. Fire scenes, by contrast, are
               typically tinted in red, so they were eliminated the query, see <ref
                  target="#figure20">Figure 20</ref>. </p>
            <p>In general, LAB image plots and palette dot plots are limited in informative value on
               corpus level as opposed to their usefulness on the film level, especially when
               displayed in print. They only indicate trends that then have to be confirmed by
               looking deeper into the films and segments where they occur. To this end, all the
               visualizations on the query page of the VIAN WebApp are highly interactive. When
               hovering over the plots, the researcher gets shown the corresponding segments of the
               film including screenshots and a scene description. In addition, all the segments and
               films are displayed with the corresponding color palettes in the form of coarse
               barcodes.</p>
            <p>See screen video of the query page: <ref target="https://vimeo.com/402360042"
                  >https://vimeo.com/402360042</ref></p>
            <figure>
               <head>On the query page of the VIAN WebApp, all the segments and projects detected in
                  the query are displayed with a coarse color palette (above). By clicking on a
                  segment, the screenshots, a short scene description  and a summary visualization
                  are displayed. <title rend="italic">Possession</title> (FRA / DEU 1981, Andrzej
                  Żuławski).</head>
               <graphic url="resources/images/figure27a.png"/>
               <graphic url="resources/images/figure27b.png"/>
            </figure>
            <p>To investigate the diachronic development, an additional method for corpus
               visualizations called <hi rend="italic">Color_dY</hi> was implemented that considers
               the temporal distribution over years instead of plotting a selected period into an
               overview in LAB that obscures the color schemes of individual films.</p>
            <figure>
               <head>Color_dY plots saturation (y-axis) over time (x-axis) for colored lights,
                   1895–1930 (top), 1930–1955 (middle), 1955–1995 (bottom).</head>
               <graphic url="resources/images/figure28a.png"/>
               <graphic url="resources/images/figure28b.png"/>
               <graphic url="resources/images/figure28c.png"/>
            </figure>
            <p>For instance in the middle plot the animation film <title rend="italic"
                  >Fantasia</title> (USA 1940, James Algar et. al.) sticks out with extremely high
               levels of saturation, and again also for an animation film <title rend="italic">Die
                  Abenteuer des Prinzen Achmed</title> (GER 1925, Lotte Reiniger; Carl Koch) in the
               first plot on the right hand side. Film titles, segments and screenshots in
               combination with a scene description are again displayed by a hover function (see
                  <ref target="#figure27">Figure 27</ref>).</p>
            <div xml:id="section08.1">
               <head>8.1 Problems</head>
               <p>In the course of developing these visualization methods on corpus level we noticed
                  difficulties to receive clear-cut pictures. One of the problems resulted from the
                  fuzziness of the concepts that generated quite a high amount of noise, as
                  elaborated in the previous section, see <ref target="#section07">Section 7</ref>.
                  However the most persistent issue that has been identified is the dominance of
                  monochrome color schemes in the LAB visualizations, in the same fashion as in the
                  image plots per film discussed in the previous section (see <ref
                     target="#section07.1">Section 7.1</ref>). Because of high levels of
                  chromaticity in some monochrome screenshots as compared to averaging effects by
                  variegated hues these images always stick out and therefore distort the result.
                  This effect is even stronger in image plots that represent data on corpus level,
                  because of the variations in different films’ color designs.</p>
            </div>
            <div xml:id="section08.2">
               <head>8.2 Lessons learned</head>
               <p>One of the first measures we took was to clean up the data. Secondly we also
                  integrated the dot plots explained in the previous section (see <ref
                     target="#section07">Section 7</ref>) into the corpus visualizations. One of the
                  most helpful parts of visualizations on corpus levels is the integration of the
                  temporal segments including scene descriptions and screenshots in a sidebar next
                  to the plots. Since the relationship between different keywords becomes complex in
                  such a large corpus, we have implement more types of visualizations to convey the
                  correlation and connections between concepts, the color-features associated to
                  them and the temporal distribution over time in image plots and palette dot
                  plots.</p>
            </div>
         </div>
         <div xml:id="section09">
            <head>9 Spatial Variations, Identification and Analysis of Patterns and Textures</head>
            <p>In general, colors are conceived as defined by the dimensions of hue, saturation and
               lightness. However, from the point of view of perception, there are many more factors
               that influence color appearance and the perception of colors correspondingly <ptr
                  target="#katz1911"/>
               <ptr target="#katz1930"/>
               <ptr target="#hurlbert2013"/>.</p>
            <p>One of the most significant, but hitherto overlooked features of color appearance is
                  <hi rend="italic">spatial variation</hi>. By spatial variation we understand the
               change of hues related to spatial frequency in a given image. Such variations are
               related to several factors. Image complexity can be caused by cluttered image
               compositions with many small details, either in different or similar hues. Massive
               crowds of characters dressed in different colors are one type of subject that causes
               a high amount of spatial variation. Another type are layered image compositions with
               occlusion generated by objects in the foreground.</p>
            <p>Visual complexity is connected to texture analysis in so far as spatial variations
               can be one feature that affects the legibility of image compositions (for a digital
               humanities approach to the investigation of image composition and style see <ref
                  target="#benini2016">Benini et al. 2016</ref>). An additional factor is the
               distribution of hues, with a high level of varying hues adding to visual complexity.
               At the same time an extremely uniform color distribution can lower legibility as
               well, if it is combined with a low degree of spatial variations and / or with
               darkness. Color separation and color attribution are a strong cue for object
               recognition and for scene detection <ptr target="#hurlbert2013"/>
               <ptr target="#hansen2017"/>.</p>
            <p>In our aesthetic analyses the distinction between patterns and textures has been
               fundamental from the start, for several reasons. <hi rend="italic">Patterns</hi>
               denote surface variations based on color attribution, for instance printed or woven
               patterns on fabrics, painted surfaces with patterns such as wallpapers etc. <hi
                  rend="italic">Textures</hi>, by contrast, refer to three-dimensional surface
               variations, such as knit-wear, rocks, brick walls, coarse unpolished wooden log
               structures. They invariably address tactile perception <ptr target="#liu2015"/>
               <ptr target="#zuo2016"/>.</p>
            <figure>
               <head>Patterns (left) in <title rend="italic">Jigokumon</title> (JAP 1953, Teinosuke
                  Kinugasa)  vs. textures (right) in <title rend="italic">Pierrot le fou</title>
                  (FRA 1965, Jean-Luc Godard).</head>
               <graphic url="resources/images/figure29.png"/>
            </figure>
            <p>One guiding hypothesis of our research was a strong connection between the
               materiality of color film stocks and material properties of the <hi rend="italic"
                  >diegesis</hi>, the spatio-temporal universe depicted in a film whose materials
               are selected and orchestrated by costume and production design. For instance
               half-tone printing as applied in Technicolor No. III to V dye-transfer processing is
               lacking definition due to problems to perfectly register the three printing dyes,
               which would be a prerequisite for spatial resolution of small-scale color variations.
               As a result we expected these films to omit patterns in their color design. Tinted
               films by contrast, lack spatial variation based on hues as they are uniformly colored
               by being submerged into dye baths, see <title rend="italic">Timeline of Historical
                  Film Colors</title>
               <ptr target="#flueckiger2012"/>. </p>
            <p>There is also a strong connection between affective modes of film perception and
               visual complexity or reduced legibility respectively. For instance in stressful
               scenes image complexity can increase substantially Layered image compositions are one
               form to obstruct the automated perception of films that was regarded to be a
               cornerstone of the Hollywood system. As team member Michelle Beutler’s research has
               shown, however, the Hollywood system itself was much less normative than previously
               assumed. The increase in tactile properties and affectively laden subjectivity
               noticed in the films of the 1960s onwards are at the center of Bregt Lameris’s
               investigation on film colors and affect (see Lameris 2019). In Joëlle Kost’s study of
               chromogenic film stocks visual complexity is one of the main topics as it relates to
               the improved resolution in these stocks.</p>
            <p>By training a deep learning network to perform pixelwise sub-figure segmentation
               using the LIP dataset <ptr target="#gong2017"/> we will be able to analyze both
               features.</p>
            <p>One possibility to assess the spatial frequency within a frame, is to use an edge
               detection algorithm, the intention is the more edges there are, the busier the region
               is. This has already shown to be a robust measure for spatial complexity, does
               however not cover solely hue and chroma related variance. VIAN currently visualizes
               three different measures as a heatmap over the player: The convolved edge density and
               the pixelwise luminance and a*b* channel variance. </p>
            <div xml:id="section09.1">
               <head>9.1 Problems</head>
               <p>Differentiation between patterns and texture computationally is a non-trivial
                  task. A naïve approach would be to assume that variance in luminance tendentially
                  indicates a tactile quality while high variance in hue and chroma would indicate
                  patterns. However, since patterns are not excluded from high variance in the
                  luminance channel, this approach does not yield accurate results. Furthermore,
                  many materials that have a tactile quality for humans often do not differ
                  significantly numerically from flat surfaces. Co-variance of spatial frequency,
                  color values (hue, lightness, saturation) and textures vs. patterns is tightly
                  connected to higher order processes in human visual perception, for instance color
                  memory and cross-modal integration, i.e. the connection of tactile experience to
                  visual and auditory perception. As shown previously in Flueckiger’s investigation
                  of sound design, material properties are often best detected by their acoustic
                  cues. For a future, more elaborate system it would be an asset to include
                  sound.</p>
            </div>
            <div xml:id="section09.2">
               <head>9.2 Lessons learned</head>
               <p>Spatial frequency and the differentiation and assessment of patterns and textures
                  are still part of our current research. Visual complexity is one of the most
                  important factors when it comes to style and diachronic developments. Therefore we
                  associated an eye-tracking study to the project to gain empirical insights into
                  the topic (see <ref target="#smith2013">Smith / Mital 2013</ref>; <ref
                     target="#rubo2018">Rubo / Gamer 2018</ref>). The study was conducted by Miriam
                  Loertscher in cooperation with Bregt Lameris. For this study we chose a set of
                  exemplary scenes for different types of image composition and complexity, for
                  instance the clear cut type without patterns and textures as in Une femme est une
                  femme, the type <quote rend="inline">overwhelming object world</quote> as in
                     <title rend="italic">Morte a Venezia</title> with completely cluttered, layered
                  image compositions, or <title rend="italic">Sayat Nova</title> (The Color of
                  Pomegranates), a film that works with many textures and material variations, often
                  by excluding the human figure. </p>
               <p>Results are currently being processed, but from a brief look at the heatmaps,
                  image parts with small-scale variations detract the viewers’ gaze the most from
                  the dominant focus on characters and most of all on faces. As Rubo and Gamer state
                     <quote rend="inline">The influence of social stimuli and visual low-level
                     saliency on eye movements have only recently been studied within the same
                     datasets, and rarely in direct juxtaposition. During face perception, it was
                     shown that facial regions diagnostic for emotional expressions received
                     enhanced attention irrespective of their physical low-level saliency</quote>
                  <ptr target="#rubo2018" loc="1"/></p>
               <figure>
                  <head>Heatmaps from the eye tracking study: Strong figure-ground separation and
                     lack of spatial variation in the background in <title rend="italic">Une femme
                        est une femme</title> (above), textures 8 and patterns in combination with
                     no humans in <title rend="italic">Sayat Nova</title> (middle) plus the
                     overwhelming object world with a high level of obstruction and visual
                     complexity in <title rend="italic">Morte a Venezia</title> (below). Study
                     conducted by Miriam Loertscher and Bregt Lameris, ERC Advanced Grant <title
                        rend="italic">FilmColors</title>.</head>
                  <graphic url="resources/images/figure30a.png"/>
                  <graphic url="resources/images/figure30b.png"/>
                  <graphic url="resources/images/figure30c.png"/>
               </figure>
               <p>The resulting hypotheses have to be tested to identify regions of high spatial
                  frequency and by comparison with the manually gathered data to assess if these
                  regions represent pattern or textures. </p>
            </div>
         </div>
         <div xml:id="section10">
            <head>10 Conclusion</head>
            <p>In this article we discussed the potential and limitations of digital tools for the
               analysis of film aesthetics and narration based on the use case of research on the
               technology and aesthetics of film colors. Following the central argument established
               in the introduction, namely that such tools require a robust theoretical foundation,
               human interpretation, constant discussion and thorough reflection of the
               epistemological assumptions embedded in the tools, we explored various approaches to
               connect the humanities perspective with methods from data and computer science. </p>
            <p>Our research has shown that we need to resort to a broad spectrum of finely grained
               analysis and visualization methods to avoid pitfalls of unfounded generalizations and
               anecdotal studies. On the downside of such a large dataset and sophisticated range of
               theoretical and analytical concepts there is a considerable amount of complexity and
               noise that tends to obscure clear-cut results. We found that for each of the research
               questions we need to take the full range of visualizations into account and
               re-evaluate the results on a case by case basis.</p>
            <p>Compared to traditional, mostly language-dominated approaches to the aesthetics,
               technology and narratology of film colors, the digital humanities tools create
               evidence through the mapping of results into an instantly accessible array of visual
               representations. By relating detailed human annotation and interpretation to these
               visual representations, the integrated workflow consisting of the VIAN visual
               analysis software in combination with the crowdsourcing portal VIAN WebApp has
               created a comprehensive ecosystem for the investigation of film aesthetics and
               narration. Therefore it significantly extends established methods in film studies. </p>
            <p>In currently running or planned cooperation projects we aim at exploring and
               extending this approach beyond the topic of film colors, in teaching, research and
               citizen science.</p>
         </div>
         <div xml:id="acknowledgements" type="appendix">
            <head>Acknowledgements</head>
            <p>This project has received funding from the European Research Council (ERC) under the
               European Union’s Horizon 2020 research and innovation programme, grant agreement No
               670446 <title rend="italic">FilmColors</title>. Analyses were executed by the PhD
               candidates Olivia Kristina Stutz, Michelle Beutler, Joëlle Kost, PostDoc researcher
               Bregt Lameris, PI Barbara Flueckiger, and three student assistants Manuel Joller,
               Valentina Romero, Ursina Früh. Visualization and Multimedia Lab VMML at the
               University of Zurich directed by Renato Pajarola with Enrique Paredes and Rafael
               Ballester-Ripoll. </p>
         </div>
      </body>
      <back>
         <listBibl>
            <bibl xml:id="arnold2020a" label="Arnold and Tilton 2020a">Arnold, Taylor; Tilton,
               Lauren (2020): <title rend="quotes">Enriching Historic Photography with Structured
                  Data using Image Region Segmentation</title>. In: <title rend="italic">Proceedings
                  of the First Artificial Intelligence for Historical Image Enrichment and Access
                  (AI4HI)</title>. Marseille, France: Association for Computational
               Linguistics.</bibl>
            <bibl xml:id="arnold2020b" label="Arnold and Tilton 2020b">Arnold, Taylor; Tilton,
               Lauren (2020 b): <title rend="quotes">Distant Viewing Toolkit. A Python Package for
                  the Analysis of Visual Culture</title>. In: <title rend="italic">Journal of Open
                  Source Software</title>, 5,45. <title rend="italic">The Open Journal</title>, S.
               1800, (<ref target="ttps://doi.org/10.21105/joss.01800"
                  >https://doi.org/10.21105/joss.01800</ref>).</bibl>
            <bibl xml:id="beau2002" label="Beau 2002">Beau, Frank (2002): <title rend="quotes">La
                  solitude du technobole. Puissance politique des effets spéciaux</title>. In:
                  <title rend="italic">CinémAction</title>, 102, pp. 196–207.</bibl>
            <bibl xml:id="benini2016" label="Benini et al. 2016">Benini, Sergio; Svanera, Michele;
               Adami, Nicola; Leonardi, Riccardo; Kovács, András Bálint (2016): <title rend="quotes"
                  >Shot Scale Distribution in Art Films</title>. In: <title rend="italic">Multimedia
                  Tools Appl.</title>, 75,23, Dez., pp. 16499–16527, (<ref
                  target="https://doi.org/10.1007/s11042-016-3339-9"
                  >https://doi.org/10.1007/s11042-016-3339-9</ref>, accessed 11/17/2019).</bibl>
            <bibl xml:id="bohn2000" label="Bohn 2000">Bohn, Cornelia (2000): <title rend="quotes"
                  >Clothing as Medium of Communication</title>. In: <title rend="italic">Soziale
                  Systeme</title>, 6,1, pp. 111–137.</bibl>
            <bibl xml:id="bordwell1989" label="Bordwell 1989">Bordwell, David (1989): <title
                  rend="quotes">Historical Poetics of Cinema</title>. In: Barton Palmer (ed.):
                  <title rend="italic">The Cinematic Text. Methods and Approaches</title>. New York:
               ASM Press.</bibl>
            <bibl xml:id="bordwell1985" label="Bordwell et al. 1985">Bordwell, David; Staiger,
               Janet; Thompson, Kristin (1985): <title rend="italic">The Classical Hollywood Cinema.
                  Film Style and Mode of Production to 1960</title>. London: Routledge.</bibl>
            <bibl xml:id="brodbeck2011" label="Brodbeck 2011">Brodbeck, Frederic (2011): <title
                  rend="quotes">Cinemetrics. Film Data Visualization</title>. In: <title
                  rend="italic">Cinemetrics</title>, (<ref
                  target="http://cinemetrics.fredericbrodbeck.de/"
                  >http://cinemetrics.fredericbrodbeck.de/</ref>, retrieved 05/30/2016).</bibl>
            <bibl xml:id="burghardt2016" label="Burghardt et al. 2016">Burghardt, Manuel; Kao, M.;
               Wolff, C. (2016): <title rend="quotes">Beyond Shot Lengths. Using Language Data and
                  Color Information as Additional Parameters for Quantitative Movie
               Analysis</title>. In: Maciej Eder and Jan Rybicki (eds.): <title rend="italic"
                  >Digital Humanities 2016. Conference Abstracts</title>. Kraków: Jagiellonian
               University &amp; Pedagogical University, p. 753‒755.</bibl>
            <bibl xml:id="burghardt2017" label="Burghardt et al. 2017">Burghardt, Manuel; Hafner,
               Katharina; Edel, Laura; Kenaan, Sabrin-Leila; Wolff, Christian (2017): <title
                  rend="quotes">An Information System for the Analysis of Color Distributions in
                  MovieBarcodes</title>. In: Maria Gäde (ed.): <title rend="italic">Proceedings of
                  the 15th International Symposium of Information Science (ISI 2017), Berlin,
                  Germany, 13th-15th March 2017</title>. Glückstadt: Verlag Werner Hülsbusch, pp.
               356–358, (<ref target="ttps://epub.uni-regensburg.de/35682/"
                  >https://epub.uni-regensburg.de/35682/</ref>, retrieved 09/08/2017).</bibl>
            <bibl xml:id="casey2014" label="Casey and Williams 2014">Casey, Michael; Williams, Mark
               (2014): <title rend="quotes">Action. Audio-visual Cinematics Toolbox for Interaction,
                  Organization, and Navigation of Film</title> (White Paper Report No. HD5139411),
               Hanover, Dartmouth College (<ref
                  target="https://hcommons.org/deposits/item/hc:12153/"
                  >https://hcommons.org/deposits/item/hc:12153/</ref>, retrieved 07/12/2020) </bibl>
            <bibl xml:id="cutting2016" label="Cutting 2016">Cutting, James E. (2016): <title
                  rend="italic">Perception, Attention, and the Structure of Hollywood Film</title>.
                  (<ref target="http://people.psych.cornell.edu/~jec7/curresearch.htm"
                  >http://people.psych.cornell.edu/~jec7/curresearch.htm</ref>, retrieved
               01/10/2018).</bibl>
            <bibl xml:id="cutting2012" label="Cutting et al. 2012">Cutting, James E.; Brunick,
               Kaitlin L.; Candan, Ayse (2012): <title rend="quotes">Perceiving Event Dynamics and
                  Parsing Hollywood Films</title>. In: <title rend="italic">Journal of Experimental
                  Psychology</title>, Advance online publication, (<ref
                  target="http://people.psych.cornell.edu/~jec7/pubs/jephppscenes.pdf"
                  >http://people.psych.cornell.edu/~jec7/pubs/jephppscenes.pdf</ref>, retrieved
               10/15/2016).</bibl>
            <bibl xml:id="dyer2006" label="Dyer 2006">Dyer, Richard (2006): <title rend="italic"
                  >Pastiche</title>. New York: Routledge.</bibl>
            <bibl xml:id="elan" label="ELAN">ELAN. (<ref
                  target="https://tla.mpi.nl/tools/tla-tools/elan/"
                  >https://tla.mpi.nl/tools/tla-tools/elan/</ref>, retrieved 10/15/2016).</bibl>
            <bibl xml:id="ferguson2013" label="Ferguson 2013">Ferguson, Kevin L. (2013): <title
                  rend="quotes">Western Roundup</title>. (<ref
                  target="http://typecast.qwriting.qc.cuny.edu/2013/10/07/western-roundup/"
                  >http://typecast.qwriting.qc.cuny.edu/2013/10/07/western-roundup/</ref>, retrieved
               07/11/2016).</bibl>
            <bibl xml:id="ferguson2015" label="Ferguson 2015">Ferguson, Kevin L. (2015): <title
                  rend="italic">Volumetric Cinem</title>a. (<ref
                  target="https://vimeo.com/119790662">https://vimeo.com/119790662</ref>, retrieved
               11/07/2016).</bibl>
            <bibl xml:id="ferguson2016" label="Ferguson 2016">Ferguson, Kevin L. (2016): <title
                  rend="quotes">The Slices of Cinema. Digital Surrealism as Research
                  Strategy</title>. In: Charles R. Acland and Eric Hoyt (eds.): <title rend="italic"
                  >The Arclight Guidebook to Media History and the Digital Humanities</title>.
               Reframe Books, pp. 270–299, (<ref target="ttp://projectarclight.org/book/"
                  >http://projectarclight.org/book/</ref>).</bibl>
            <bibl xml:id="flueckiger2011" label="Flueckiger 2011">Flueckiger, Barbara (2011): <title
                  rend="quotes">Die Vermessung ästhetischer Erscheinungen</title>. In: <title
                  rend="italic">Zeitschrift für Medienwissenschaft</title>, 5, pp. 44–60.</bibl>
            <bibl xml:id="flueckiger2012" label="Flueckiger 2012">Flueckiger, Barbara (2012): <title
                  rend="italic">Timeline of Historical Film Colors.</title> (<ref
                  target="http://filmcolors.org">http://filmcolors.org</ref>).</bibl>
            <bibl xml:id="flueckiger2017" label="Flueckiger 2017">Flueckiger, Barbara (2017): <title
                  rend="quotes">A Digital Humanities Approach to Film Colors</title>. In: <title
                  rend="italic">The Moving Image</title>, 17.2, pp. 71–94.</bibl>
            <bibl xml:id="flueckigeretal2017" label="Flueckiger et al. 2017">Flueckiger, Barbara;
               Evirgen, Noyan; Paredes, Enrique G.; Ballester-Ripoll, Rafael; Pajarola, Renato
               (2017): <title rend="quotes">Deep Learning Tools for Foreground-Aware Analysis of
                  Film Colors</title>. In: <title rend="italic">AVinDH SIG</title>, Digital
               Humanties Conference Montreal.</bibl>
            <bibl xml:id="flueckiger2018" label="Flueckiger and Halter 2018">Flueckiger, Barbara;
               Halter, Gaudenz (2018): <title rend="quotes">Building a Crowdsourcing Platform for
                  the Analysis of Film Colors</title>. In: <title rend="italic">The Moving
                  Image</title>, 18.1, pp. 80–83.</bibl>
            <bibl xml:id="flueckiger2019" label="Flueckiger 2019">Flueckiger, Barbara (2019): <title
                  rend="quotes">The Material Aesthetics of Len Lye‘s Experimental Color Films in the
                  1930s</title>. Presentation <title rend="italic">Len Lye Symposium</title>,
               Tinguely Museum Basel.</bibl>
            <bibl xml:id="genette1972" label="Genette 1972">Genette, Gérard (1972): <title
                  rend="italic">Figures III</title>. Paris: Seuil.</bibl>
            <bibl xml:id="genette1983" label="Genette 1983">Genette, Gerard (1983): <title
                  rend="italic">Nouveau Discours du récit</title>. Paris: Le Seuil.</bibl>
            <bibl xml:id="genette1992" label="Genette 1992">Genette, Gérard (1992): <title
                  rend="italic">Palimpsestes. La littérature au second degré</title>. Paris,
               Seuil.</bibl>
            <bibl xml:id="giunti2010" label="Giunti 2010">Giunti, Livia (2010): <title rend="italic"
                  >Problemi dell’analisi del testo di finzione audiovisivo. Verifica e sviluppo di
                  un modello analitico e interpretativo con strumenti digitali</title>. Università
               degli Studi di Pisa.</bibl>
            <bibl xml:id="giunti2014" label="Giunti 2014">Giunti, Livia (2014): <title rend="quotes"
                  >L’analyse du film a l’ère numérique. Annotation, geste analytique et lecture
                  active</title>. In: <title rend="italic">Cinéma &amp; Cie</title>, 14,22/23, pp.
               127–143.</bibl>
            <bibl xml:id="gong2017" label="Gong et al. 2017">Gong, Ke; Liang, Xiaodan; Zhang,
               Dongyu,; Shen, Xiaohui; Lin, Liang (2017): <title rend="quotes">Look into Person.
                  Self-supervised Structure-sensitive Learning and A New Benchmark for Human
                  Parsing.</title> In: arXiv:1703.05446, (2017). (<ref
                  target="http://arxiv.org/abs/1703.05446">http://arxiv.org/abs/1703.05446</ref>,
               retrieved 07/12/2020) </bibl>
            <bibl xml:id="gruber2009" label="Gruber 2009">Gruber, Klemens; Wurm, Barbara; Kropf,
               Vera (eds.) (2009): <title rend="italic">Digital Formalism. Die kalkulierten Bilder
                  des Dziga Vertov.</title> Wien: Böhlau Verlag.</bibl>
            <bibl xml:id="hagberg2008" label="Hagberg et al. 2008">Hagberg, Aric A.; Schult, Daniel
               A.; Swart, Pieter J. (2008): <title rend="quotes">Exploring Network Structure,
                  Dynamics, and Function using NetworkX</title>. In: Gaël Varoquaux, Travis Vaught
               and Jarrod Millman (eds.): <title rend="italic">Proceedings of the 7th Python in
                  Science Conference</title>. Pasadena, CA USA, pp. 11–15.</bibl>
            <bibl xml:id="hahn2009" label="Hahn 2009">Hahn, Stefan (2009): <title rend="quotes"
                  >Filmprotokoll Revisited. Ground Truth in Digital Formalism</title>. In: Klemens
               Gruber, Barbara Wurm and Vera Kropf (eds.): <title rend="italic">Digital Formalism:
                  Die kalkulierten Bilder des Dziga Vertov</title>. Wien: Böhlau Verlag, pp.
               129‒136.</bibl>
            <bibl xml:id="halter2019" label="Halter et al. 2019">Halter, Gaudenz; Ballester-Ripoll,
               Rafael; Flueckiger, Barbara; Pajarola, Renato (2019): <title rend="quotes">VIAN. A
                  Visual Annotation Tool for Film Analysis</title>. In: <title rend="italic"
                  >Computer Graphics Forum</title>, 38,3, pp. 119–129.</bibl>
            <bibl xml:id="hansen2017" label="Hansen and Gegenfurtner 2017">Hansen, Thorsten;
               Gegenfurtner, Karl R. (2017): <title rend="quotes">Color contributes to
                  object-contour perception in natural scenes</title>. In: <title rend="italic"
                  >Journal of Vision</title>, 17,3, März, pp. 14–14.</bibl>
            <bibl xml:id="heftberger2015" label="Heftberger 2015">Heftberger, Adelheid (2015):
                  <title rend="quotes"><title rend="quotes">Die Verschmelzung von Wissenschaft und
                     Filmchronik</title>. Das Potenzial der Reduktionslosen Visualisierung am
                  Beispiel von Das Elfte Jahr und Der Mann mit der Kamera von Dziga Vertov</title>.
               In: <title rend="italic">La Visualisation des Données en Histoire = Visualisierung
                  von Daten in der Geschichtswissenschaft</title>, pp. 229–263.</bibl>
            <bibl xml:id="heftberger2016" label="Heftberger 2016">Heftberger, Adelheid (2016):
                  <title rend="italic">Kollision der Kader. Dziga Vertovs Filme, die Visualisierung
                  ihrer Strukturen und die Digital Humanities</title>. München: Edition Text +
               Kritik. [English translation: Heftberger, Adelheid (2018): <title rend="italic"
                  >Digital Humanities and Film Studies. Visualising Dziga Vertov’s Work</title>.
               Berlin: Springer International Publishing.]</bibl>
            <bibl xml:id="hurlbert2013" label="Hurlbert 2013">Hurlbert, Anya (2013): <title
                  rend="quotes">The Perceptual Quality of Color</title>. In: Liliana Albertazzi
               (ed.): <title rend="italic">Handbook of Experimental Phenomenology. Visual Perception
                  of Shape, Space and Appearance</title>. New York: John Wiley &amp; Sons, Ltd SN,
               pp. 369–394.</bibl>
            <bibl xml:id="itten1970" label="Itten 1970">Itten, Johannes (1970): <title rend="italic"
                  >Kunst der Farbe</title>. Ravensburg: Ravensburger Buchverlag.</bibl>
            <bibl xml:id="jameson1991" label="Jameson 1991">Jameson, Fredric (1991): <title
                  rend="italic">Postmodernism. Or, the Cultural Logic of Late Capitalism</title>.
               London: Verso.</bibl>
            <bibl xml:id="katz1911" label="Katz 1911">Katz, David (1911): <title rend="italic">Die
                  Erscheinungsweisen der Farben und ihre Beeinflussung durch die individuelle
                  Erfahrung</title>. London: Kegan Paul, Trench, Trubner &amp; Co. Ltd.</bibl>
            <bibl xml:id="katz1930" label="Katz 1930">Katz, David (1930): <title rend="italic">Der
                  Aufbau der Farbwelt</title>. Leipzig: Johann Ambrosius Barth.</bibl>
            <bibl xml:id="lameris2019" label="Lameris 2019">Lameris, Bregt (2019): <title
                  rend="quotes">Hallucinating Colours. Psychedelic Film, Technology, Aesthetics and
                  Affect</title>. In: <title rend="italic">Cinéma &amp; Cie. Special Issue Cinema
                  and Mid-Century Colour Culture</title>, 32, Spring.</bibl>
            <bibl xml:id="ledig1988" label="Ledig and Ullmann 1988">Ledig, Elfriede; Ullmann,
               G.erhard (1988): <title rend="quotes">Rot wie Feuer, Leidenschaft, Genie, Wahnsinn.
                  Zu einigen Aspekten der Farbe im Stummfilm</title>. In Elfriede Ledig (ed.):
                  <title rend="italic">Der Stummfilm. Konstruktion und Rekonstruktion</title>.
               München, Schaudig, Bauer, Ledig, pp. 89‒116.</bibl>
            <bibl xml:id="liu2015" label="Liu et al. 2015">Liu, Jianli; Lughofer, Edwin; Zeng,
               Xianyi (2015): <title rend="quotes">Aesthetic Perception of Visual Textures. A
                  Holistic Exploration Using Texture Analysis, Psychological Experiment, and
                  Perception Modeling</title>. In: <title rend="italic">Frontiers in Computational
                  Neuroscience</title>, 9, p. 134.</bibl>
            <bibl xml:id="long2015" label="Long et al. 2015">Long, Jonathan; Shelhamer, Evan;
               Darrell, Trevor (2015): <title rend="quotes">Fully Convolutional Networks for
                  Semantic Segmentation</title>. pp. 3431–3440, (<ref
                  target="https://arxiv.org/abs/1411.4038">https://arxiv.org/abs/1411.4038</ref>,
               retrieved 07/12/2020).</bibl>
            <bibl xml:id="manovich2012" label="Manovich 2012">Manovich, Lev (2012): <title
                  rend="quotes">How to Compare One Million Images?</title> In: D. Berry (ed.):
                  <title rend="italic">Understanding Digital Humanities</title>. London: Palgrave
               Macmillan UK, pp. 249‒278.</bibl>
            <bibl xml:id="manovich2013a" label="Manovich 2013a">Manovich, Lev (2013): <title
                  rend="quotes">Kino-Eye in Reverse. Visualizing Cinema</title>. In: Jeffrey Geiger
               and Karin Littau (eds.): <title rend="italic">Cinematicity in Media History</title>.
               Edinburgh: Edinburgh University Press, pp. 211–234.</bibl>
            <bibl xml:id="manovich2013b" label="Manovich 2013b">Manovich, Lev (2013): <title
                  rend="quotes">Visualizing Vertov</title>. In: <title rend="italic">Russian Journal
                  of Communication</title>, 5,1, pp. 44–55.</bibl>
            <bibl xml:id="mazzanti1998" label="Mazzanti 1998">Mazzanti, Nicola (1998): <title
                  rend="quotes">The Colours of the Film d’Arte Italiana</title>. In: Luciano
               Berriatúa, et al., <title rend="italic">Tutti i colori del mondo. Il colore nei mass
                  media tra 1900 e 1930. = All the colours of the world</title>. Reggio Emilia,
               Edizioni Diabasis, pp. 141–146.</bibl>
            <bibl xml:id="mazzanti2009" label="Mazzanti 2009">Mazzanti, Nicola (1998): <title
                  rend="quotes">Colours, Audiences, and (Dis)Continuity in the <q>Cinema of the
                     Second Period</q></title>. In: <title rend="italic">Film History</title>, 21,1,
               pp. 67‒93.</bibl>
            <bibl xml:id="melgar2017" label="Melgar et al. 2017">Melgar Estrada, Liliana; Hielscher,
               Eva; Koolen, Marijn; Olesen, Christian Gosvig; Noordegraaf, Julia; Blom, Jaap (2017):
                  <title rend="quotes">Film Analysis as Annotation. Exploring Current Tools</title>.
               In: <title rend="italic">The Moving Image: The Journal of the Association of Moving
                  Image Archivists</title>, 17,2, pp. 40–70.</bibl>
            <bibl xml:id="olesen2017" label="Olesen 2017">Olesen, Christian Gosvig (2017): <title
                  rend="italic">Film History in the Making. Film Historiography, Digitised Archives
                  and Digital Research Dispositifs</title>. Amsterdam: University of Amsterdam,
                  (<ref
                  target="https://dare.uva.nl/search?identifier=ad68a275-e968-4fce-b91e-4783cd69686c"
                  >https://dare.uva.nl/search?identifier=ad68a275-e968-4fce-b91e-4783cd69686c</ref>,
               retrieved 10/07/2017).</bibl>
            <bibl xml:id="olesen2016a" label="Olesen et al. 2016a">Olesen, Christian Gosvig; Gorp,
               Jasmijn van; Fossati, Giovanna (2016): <title rend="quotes">Datasets and Colour
                  Visualizations for ‘Data-Driven Film History. A Demonstrator of EYE’s Jean Desmet
                  Collection</title>. In: <title rend="italic">Creative Amsterdam. An E-Humanities
                  Perspective. A Research Program at the University of Amsterdam</title>, (<ref
                  target="http://www.create.humanities.uva.nl/results/desmetdatasets/"
                  >http://www.create.humanities.uva.nl/results/desmetdatasets/</ref>, retrieved
               11/11/2016).</bibl>
            <bibl xml:id="olesen2016b" label="Olesen et al. 2016b">Olesen, Christian Gosvig; Masson,
               Eef; Gorp, Jasmijn van; Fossati, Giovanna; Noordegraaf, Julia (2016): Data-Driven
               Research for Film History. Exploring the Jean Desmet Collection. In: <title
                  rend="italic">The Moving Image</title>, 16,1, (<ref
                  target="https://muse.jhu.edu/article/640569"
                  >https://muse.jhu.edu/article/640569</ref>).</bibl>
            <bibl xml:id="plantinga2009" label="Plantinga 2009">Plantinga, Carl (2009): <title
                  rend="italic">Moving Viewers. American Film and the Spectator’s
               Experience</title>. Berkeley: University of California Press.</bibl>
            <bibl xml:id="pause2018" label="Pasue and Walkowski 2018">Pause, Johannes; Walkowski,
               Niels-Oliver (2018): <title rend="quotes">The Colorized Dead. Computerunterstützte
                  Analysen der Farblichkeit von Filmen in den Digital Humanities am Beispiel von
                  Zombiefilmen</title>, (<ref
                  target="https://edoc.bbaw.de/frontdoor/index/index/docId/2591"
                  >https://edoc.bbaw.de/frontdoor/index/index/ docId/2591</ref>).</bibl>
            <bibl xml:id="redmon2015" label="Redmon et al. 2013">Redmon, Joseph; Divvala, Santosh;
               Girshick, Ross; Farhadi, Ali (2015): You Only Look Once. Unified, Real-Time Object
               Detection. In: <title rend="italic">arXiv:1506.02640 [cs]</title>, Jun., (<ref
                  target="http://arxiv.org/abs/1506.02640">http://arxiv.org/abs/1506.02640</ref>,
               retrieved 05/29/2017).</bibl>
            <bibl xml:id="reyes-garvia2013" label="Reyes-García 2013">Reyes-García, Everardo (2013):
                  <title rend="quotes">On Visual Features and Artistic Digital Images</title>. New
               York: ACM, (<ref target="http://dl.acm.org/citation.cfm?id=2466835"
                  >http://dl.acm.org/citation.cfm?id=2466835</ref>).</bibl>
            <bibl xml:id="reyes-garcia2014" label="Reyes-García 2014">Reyes-García, Everardo (2014):
               Explorations in Media Visualization. New York: ACM, (<ref
                  target="ttp://www.academia.edu/download/35860006/Reyes_2014-Explorations_in_Media_Visualization.pdf,%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20http://ceur-ws.org/Vol-1210/datawiz2014_11.pdf"
                  >http://www.academia.edu/download/35860006/Reyes_2014-Explorations_in_Media_Visualization.pdf,%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20http://ceur-ws.org/Vol-1210/datawiz2014_11.pdf</ref>,
               retrieved 07/12/2020).</bibl>
            <bibl xml:id="reyes-garcia2017" label="Reyes-García 2017">Reyes-García, Everardo (2017):
                  <title rend="italic">The Image-interface. Graphical Supports for Visual
                  Information</title>. Hoboken, NJ: Wiley-ISTE.</bibl>
            <bibl xml:id="reyes-garciabouhai2017" label="Reyes-García and Bouhai 2017">Reyes-García,
               Everardo; Bouhai, Nasreddine (2017): <title rend="italic">Designing Interactive
                  Hypermedia Systems</title>. In: Nasreddine Bouhai (ed.). Wiley-ISTE.</bibl>
            <bibl xml:id="rosebrock2014" label="Rosebrock 2014">Rosebrock, Adrian (2014): <title
                  rend="quotes">How-To. OpenCV and Python K-Means Color Clustering</title>. In:
                  <title rend="italic">PyImageSearch</title>, (<ref
                  target="http://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/"
                  >http://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/</ref>,
               retrieved 06/26/2017).</bibl>
            <bibl xml:id="ross2007" label="Ross 2007">Ross, Jacqui (2007): <title rend="italic"
                  >Colour Analysis Tools in ImageJ</title>. (<ref
                  target="https://www.fmhs.auckland.ac.nz/assets/fmhs/sms/biru/docs/Colour_Analysis_Tools_in_ImageJ.pdf"
                  >https://www.fmhs.auckland.ac.nz/assets/fmhs/sms/biru/docs/Colour_Analysis_Tools_in_ImageJ.pdf</ref>,
               retrieved 0/12/2020).</bibl>
            <bibl xml:id="rother2004" label="Rother et la. 2004">Rother, Carsten; Kolmogorov,
               Vladimir; Blake, Andrew (2004): <title rend="quotes">GrabCut. Interactive Foreground
                  Extraction using Iterated Graph Cuts</title>. In: <title rend="italic">ACM
                  Transactions on Graphics (SIGGRAPH)</title>, Aug.</bibl>
            <bibl xml:id="rubo2018" label="Rubo and Gamer 2018">Rubo, M. and Gamer, M. <title
                  rend="quotes">Social Content and Emotional Valence Modulate Gaze Fixations in
                  Dynamic Scenes</title>, <title rend="italic">Scientific Reports</title>, 8.1
               (2018): 1–11. (<ref target="https://doi.org/10.1038/s41598-018-22127-w"
                  >https://doi.org/10.1038/s41598-018-22127-w</ref>, retreived 07/12/2020)</bibl>
            <bibl xml:id="smith1995" label="Smith 1995">Smith, Murray (1995): <title rend="italic"
                  >Engaging Characters. Fiction, Emotion, and the Cinema</title>. Oxford, New York:
               Oxford University Press.</bibl>
            <bibl xml:id="smith2013" label="Smith and Mital 2013">Smith, Tim J.; Mital, Parag K.
               (2013): <title rend="quotes">Attentional Synchrony and the Influence of Viewing Task
                  on Gaze Behavior in Static and Dynamic Scenes</title>. In: <title rend="italic"
                  >Journal of Vision</title>, 13,8, Juli, S. 16–16, (<ref
                  target="https://jov.arvojournals.org/article.aspx?articleid=2193975"
                  >https://jov.arvojournals.org/article.aspx?articleid=2193975</ref>, abgerufen
               03/31/2020).</bibl>
            <bibl xml:id="stutz2016" label="Stutz 2016">Stutz, Olivia Kristina (2016): <title
                  rend="italic">Algorithmische Farbfilmästhetik. Historische sowie
                  experimentell-digitale Notations- und Visualisierungssysteme des Farbfilms im
                  Zeichen der Digital Humanities 2.0 und 3.0</title>. Zürich: Universität Zürich,
                  (<ref
                  target="http://www.film.uzh.ch/dam/jcr:bed543b6-4a67-4ff8-8f51-b85a739417d5/MA_AlgorithmischeFarbfilmaesthetik_Stutz_HS2016_def.pdf"
                  >http://www.film.uzh.ch/dam/jcr:bed543b6-4a67-4ff8-8f51-b85a739417d5/MA_AlgorithmischeFarbfilmaesthetik_Stutz_HS2016_def.pdf</ref>,
               retrieved 04/09/2017).</bibl>
            <bibl xml:id="tan1996" label="Tan 1996">Tan, Ed (1996): <title rend="italic">Emotion and
                  the Structure of Narrative Film. Film as an Emotion Machin</title>e. Mahwah, N.J,
               Lawrence Erlbaum Assoc Inc (1996).</bibl>
            <bibl xml:id="thompson1986" label="Thompson 1986">Thompson, Kristin (1986): <title
                  rend="quotes">The Concept of Cinematic Excess</title>. In: Philip Rosen, Leo
               Braudy and Marshall Cohen (eds.): <title rend="italic">Film Theory and Criticism.
                  Introductory Readings</title>. New York: Columbia University Press, pp.
               487–498.</bibl>
            <bibl xml:id="thompson1988" label="Thompson 1988">Thompson, Kristin (1988): <title
                  rend="italic">Breaking the Glass Armor</title>. New Jersey: Princeton University
               Press.</bibl>
            <bibl xml:id="vanska2017" label="Vänskä 2017">Vänskä, Annamari (2017): <title
                  rend="quotes">Gender and Sexuality</title>. In: Alexandra Palmer (ed.): <title
                  rend="italic">A Cultural History of Dress and Fashion</title>. Bloomsbury
               Academic, pp. 107–129.</bibl>
            <bibl xml:id="wilkening2014" label="Wilkening 2014">Wilkening, Anke (2014): <title
                  rend="quotes">Die Restaurierung von Das Cabinet des Dr. Caligari</title>. In:
                  <title rend="italic">VDR Beiträge zur Erhaltung von Kunst- und Kulturgut</title>,
               2, pp. 27–47.</bibl>
            <bibl xml:id="zhao2016" label="Zhao et al. 2016">Zhao, Hengshuang; Shi, Jianping; Qi,
               Xiaojuan; Wang, Xiaogang; Jia, Jiaya (2016): <title rend="quotes">Pyramid Scene
                  Parsing Network</title>. In: <title rend="italic">arXiv:1612.01105 [cs]</title>,
               Dec., (<ref target="http://arxiv.org/abs/1612.01105"
                  >http://arxiv.org/abs/1612.01105</ref>, retrieved 03/27/2018).</bibl>
            <bibl xml:id="zuo2016" label="Zuo et al. 2016">Zuo, Hengfeng; Jones, Mark; Hope, Tony;
               Jones, Robin (2016): <title rend="quotes">Sensory Perception of Material Texture in
                  Consumer Products</title>. In: <title rend="italic">The Design Journal</title>,
               19.03, pp. 405–427.</bibl>
         </listBibl>
      </back>
   </text>
</TEI>
