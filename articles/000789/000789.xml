<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <!-- Author should supply the title and personal information-->
                <title type="article" xml:lang="en">"I was painted by...": A Case Study on the Use of CNNs for Image Classification in the Humanities </title>
                <!-- Add a <title> with appropriate @xml:lang for articles in languages other than English -->
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Marta <dhq:family>Kipke</dhq:family></dhq:author_name>
                    <idno type="ORCID">https://orcid.org/0000-0003-0130-261X</idno>
                    <dhq:affiliation>Institut für Digital Humanities, Georg-August-Universität Göttingen</dhq:affiliation>
                    <email>marta.kipke@uni-goettingen.de</email>
                    <dhq:bio><p></p></dhq:bio>
                </dhq:authorInfo>
                
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Lukas <dhq:family>Brinkmeyer</dhq:family></dhq:author_name>
                    <idno type="ORCID">https://orcid.org/0000-0001-5754-1746</idno>
                    <dhq:affiliation>Information Systems and Machine Learning Lab, Stiftung Universität Hildesheim</dhq:affiliation>
                    <email>lukas.brinkmeyer@ismll.de</email>
                    <dhq:bio><p></p></dhq:bio>
                </dhq:authorInfo>
                
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Martin <dhq:family>Langer</dhq:family></dhq:author_name>
                    <idno type="ORCID">https://orcid.org/0000-0002-6109-4878</idno>
                    <dhq:affiliation>Institut für Digital Humanities, Georg-August-Universität Göttingen</dhq:affiliation>
                    <email>martin.langner@uni-goettingen.de</email>
                    <dhq:bio><p></p></dhq:bio>
                </dhq:authorInfo>
                
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Lars <dhq:family> Schmidt-Thieme </dhq:family></dhq:author_name>
                    <idno type="ORCID">https://orcid.org/0000-0001-5729-6023</idno>
                    <dhq:affiliation>Information Systems and Machine Learning Lab, Stiftung Universität Hildesheim</dhq:affiliation>
                    <email>schmidt-thieme@ismll.uni-hildesheim.de</email>
                    <dhq:bio><p></p></dhq:bio>
                </dhq:authorInfo>
            </titleStmt>
            <publicationStmt><publisher>Alliance of Digital Humanities Organizations</publisher>
<publisher>Association for Computers and the Humanities</publisher>
            	
            	<!-- This information should be added when the file is created -->
                <idno type="DHQarticle-id">000789</idno>

            	
            	<!-- This information will be completed at publication -->
                <idno type="volume"><!-- volume number, with leading zeroes as needed to make 3 digits: e.g. 006 --></idno>
                <idno type="issue"><!-- issue number, without leading zeroes: e.g. 2 --></idno>
                <date><!-- include @when with ISO date and also content in the form 23 February 2024 --></date>
                <dhq:articleType>article</dhq:articleType>
                <availability status="CC-BY-ND">
<!-- If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default): <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>     
                  CC-BY:  <cc:License rdf:about="https://creativecommons.org/licenses/by/2.5/"/>
                  CC0: <cc:License rdf:about="https://creativecommons.org/publicdomain/zero/1.0/"/>
-->                    
                    <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
                </availability>
            </publicationStmt>
            
            <sourceDesc>
                <p>This is the source</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <classDecl>
                <taxonomy xml:id="dhq_keywords">
                    <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
                </taxonomy>
                <taxonomy xml:id="authorial_keywords">
                    <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
                </taxonomy>
            	<taxonomy xml:id="project_keywords">
            		<bibl>DHQ project registry; full list available at <ref target="http://www.digitalhumanities.org/dhq/projects.xml">http://www.digitalhumanities.org/dhq/projects.xml</ref></bibl>
            	</taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en" extent="original"/>
                <!-- add <language> with appropriate @ident for any additional languages -->
            </langUsage>
            <textClass>
                <keywords scheme="#dhq_keywords">
                    <!-- Authors may suggest one or more keywords from the DHQ keyword list, visible at https://github.com/Digital-Humanities-Quarterly/dhq-journal/wiki/DHQ-Topic-Keywords; these may be supplemented or modified by DHQ editors -->
                	
                	<!-- Enter keywords below preceeded by a "#". Create a new <term> element for each -->
                    <term corresp=""/>
                </keywords>
                <keywords scheme="#authorial_keywords">
                    <!-- Authors may include one or more keywords of their choice -->
                    <list type="simple">
                        <item></item>
                    </list>
                </keywords>
            	<keywords scheme="#project_keywords">
            		<list type="simple">
            			<item></item>
            		</list>
            	</keywords>
            </textClass>
        </profileDesc>
        <revisionDesc>
        	<!-- Replace "XXXXXX" in the @target of ref below with the appropriate DHQarticle-id value. -->
        	<change>The version history for this file can be found on <ref target=
        		"https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/master/articles/000789/000789.xml">GitHub
        	</ref></change>
        </revisionDesc>
    </teiHeader>
    <!-- If a translation is added to the original article, add an enclosing <text> and <group> element -->
    <text xml:lang="en" type="original">
        <front>
            <dhq:abstract>
               
                <p>EGRAPHSEN is a case study on image classification in the humanities, specifically on painter attribution on Attic vase paintings. 
                    The goal of this study was to explore the new perspective that artificial intelligence (AI) can provide us with when we study traditional methods and heterogenous domains. 
                    When we translate the task (painter attribution), we have to consider the idiosyncrasies of the data domain (Attic vase paintings). This is challenging for both, classical archaeologists and computer scientists. 
                    In this paper, we address how to approach the challenges in the creation of the dataset. We carefully selected and prepared the data, 
                    reflected on potential biases and trained a convolutional neural network (CNN) accordingly. Specifically, we developed sampling criteria to 
                    combat the biases and a hierarchical labelling system to segment the images into details. Our model architecture was designed to 
                    process sets of images instead of only one individual image, which enables us to experiment with different combinations of image segments. 
                    This forms the basis for an analysis framework, which allows us to go beyond mere painter attribution and to explore the ambiguity of 
                    image similarity itself.
                </p>
            </dhq:abstract>
            <dhq:teaser>
                <p>In this case study the authors explore Attic vase painters using CNNs, investigating image similarity through both archaeological and computational perspectives.</p>
            </dhq:teaser>
        </front>
         <body>
            <head></head>
                <div>
                    <head>1. Introduction</head>
                    <p>When visitors look at a painting in a museum, they might expect a clear answer to the question “who painted it?”. Often a painting contains a signature, which makes the answer to this question seem pretty obvious. 
                        However, the answer is not always straightforward. Sometimes the painter cannot be pinpointed to one specific individual, and our knowledge might be limited to a timeframe, a region, a workshop. Even well-known paintings were not always signed. 
                        A good example is the Sleeping Venus. It was first thought to be from the school of Titian and was later identified to be by Giorgione (Anderson 1996; Lüdemann 2005; Uglow 2014). 
                        Identifying a painter is a riddle, waiting to be solved by Art Historians and Classical Archaeologists. In our project EGRAPHSEN  we view this question from the perspective of artificial intelligence (AI): 
                        Can AI help solving this riddle? What does this reveal about the task itself? And more importantly: How can artificial intelligence help us go beyond that and answer fundamental questions regarding
                        image similarity and variation? How exactly does an artificial neural network differ from a human scholar? Painter attribution – the task of identifying painters on unsigned images – 
                        is a complex field with many differing opinions, which poses a challenge to the operationalisation of the task from the data selection up to the interpretation of the results. 
                    </p>
                    <p>The overall situation is complicated: It was not always common practice to sign paintings. And even a famous painter may have left some paintings unsigned, for reasons which we can only speculate about (Hegener and Horsthemke 2013; Burg 2007). 
                        Nor is an existing signature necessarily a confirmation of authorship, as it may have been forged for profit (Jones and Craddock 1990). Due to atelier workflows we cannot take real historical signatures at face value either: 
                        Was it the actual painter who signed a work, or the leader of the workshop (Liedtke 2004, Büttner 2017)? Overall, painter attribution can be understood as a tool which paves the way for further research on historical contexts, 
                        workshop processes and style in general.
                    </p>
                    
                    <p>In EGRAPHSEN we approach this task at the very core: Our main focus lies in understanding painter attribution as a method, especially its manifestation in Classical archaeology. Our use case are Attic vase paintings from Greek antiquity, 
                        which pose an even greater challenge than later canvas paintings, as the former are only rarely signed at all. With this, other hints to solving this riddle become increasingly important, 
                        which in this case are primarily found in the visual comparison of stylistic phenomena. By studying the artists styles a scholar can “develop an eye” for the respective artists. 
                        As fundamental as this method is, this skill is subjective and not always verifiable. The expert’s eye has to be trained and for an untrained eye the arguments might seem elusive and presumptuous, begging the question if they hold any value at all. 
                        Throughout the times the value of connoisseurship has been questioned in both Art History and Classical Archaeology (for the classical archaeological perspective see: Graepler 2016; Sparkes 2013, 90–113). 
                        The discussion is extensive and while Painter attribution has its defenders (Oakley 1998), it is still controversial and challenging to navigate. Despite of this, painter attribution is still practiced in major publications recently. 
                        The insight it offers is too valuable, making it a good use case to revise and discuss traditional methods through the lens of a novel computational approach. 
                    </p>
                    
                    <p>With this, we are also researching the role of AI in in humanities disciplines, including its metrics and its dangers. Humans are complex, as is humanities research and the material we study. Can a computer understand humans or art? 
                        This is a controversial question, which leads to heated discussions between computer scientists and art historians (Wasielewski 2023). Our work adds a case study which emphasizes the complexity of humanities research questions 
                        and the necessity of an informed and reflective approach, shaping the data compilation closely to our research questions. 
                    </p>
                    
                    <p>Our use case is particularly suitable because of its dual nature: On the one hand it is strictly about shapes and lines: the style of a painting. We call them formal characteristics, with “form” meaning the lines and shapes, 
                        the design, arrangement and style. This describes a phenomenological approach to images that should not be confused with formalism as a scholarly direction of the late 20th century (Pinotti 2012). 
                        These characteristics ultimately help answer the question: “How is a painting painted?” in contrast to what is painted. It seems that neither a human nor a computer needs additional information beyond the painting itself to be able to “learn” connoisseurship. 
                        On the other hand, painter attribution includes subjectivity and visual association and therefore uncertainty, fuzziness and ambiguity. These concepts are difficult to grasp with computational methods, but they are essential for the method of 
                        painter attribution as well as many research questions in the humanities in general. At first glance, it seems that painter attribution could be easily translated into a machine learning classification set-up, with the different painters representing the classes. 
                        However, human connoisseurship is inherently instinctive and algorithms require specificity. A neural network needs distinct and well-defined categories to function, but the data is subject to biases and distortion. 
                        In the end, additional information beyond the painting might prove more important than one might anticipate.
                    </p>
                    <p>This research promises new insights on both sides: As Classical Archaeologists we re-evaluate our view on painter attribution and the underlying concept of image similarity through the lens of AI, while Computer Scientists re-evaluate their algorithms using our complex and heterogenic data. 
                        Thus, our research goal is as follows: We aim to evaluate and develop methods for image-related research questions with the help of artificial intelligence. We do not aim at recreating painter attribution through computational means; instead we re-evaluate it critically and beyond its surface. 
                        In EGRAPHSEN we developed methods to (1) compile our data in a meaningful way and (2) explore image similarity with computational means. In this paper we are going to present the first part of our research and provide a preliminary insight into our results.
                    </p>
                    
                    <p>Working with AI presents major challenges when it comes to the translation of humanities knowledge into data – and conversely, it is also difficult to generate knowledge from experiment results. For the purpose of this paper, our research question can be divided into the following sub-questions:
                        <list type="unordered">
                            <item>How do we operationalize the traditional method painter attribution and how does it relate to the algorithms used?</item>
                            <item>What biases must be taken into account when compiling the dataset, and to what extent can we control the input in order to find an adequate data representation for the purpose of attribution?</item>
                        </list>
                        Overall, these questions set the baseline for the interpretation and exploration of the model in regards to uncertainty and fuzziness of visual references and relations. 
                    </p>
                    <p>In a first step we need to contextualize our research questions, both for the traditional method (2.1) as well as in regards to other computational painter attribution projects (2.2) 
                        and machine learning in general (2.3). Doing so, we want to demonstrate the methodological demands of the task. The second step concerns the sampling strategies on different levels of input – 
                        the selection of painters (3) and the selection of input segments (4). After a short interim conclusion (5), we present our experimental set-up and model architecture (6), where we outline the main challenges of the algorithms. 
                        We then provide a first analysis of our results, which outlines our model’s performance and first insights into the similarity networks between the painters (7). 
                        A final conclusion explores possibilities for further research, including an outlook on the analysis part of our work (8).
                    </p>
                   </div>
             <div>
                 <head>2. Painter Attribution in Context</head>
                 <div>
                     <head>2.1 Beazley and Painter Attribution in Classical Archaeology</head>
                     <p>In order better to understand the skill of connoisseurship and the visual relations between the paintings and their styles, we first need to outline the traditional method. How do Classical Archaeologists attribute painters on Attic vases?
                     </p>
                    
                     <p>We study an era so long ago that some aspects of the culture have been distorted and lost. Yet others have been carefully preserved. The ancient world has fascinated many people throughout
                         the times, sometimes even taking on an exemplary character. This includes all kinds of cultural property: history, philosophy and literature. As Classical Archaeologists we study the appearance, execution, creation and contexts of material culture, 
                         developing methods to describe the developments of imagery, objects and style. For this purpose, we have to correlate them with each other, which results in intricate chronological and typological systems (on the dating of vases specifically see Schmidt 2022). 
                         One interest of painter attribution lies in the creation of such an overarching system based on individual style, but also covering chronological aspects. 
                     </p>
                    
                     <p>The interest in the objects themselves is manifold due to the insight they give us into the realities and ideas of life in ancient Greek society. One aspect is their use in everyday life, for example as grave goods (Tsingarida 2009). Another aspect concerns the imagery they depict. 
                         The themes range from mythological stories to portrayals of everyday Athenian citizens (Bérard and Vernant 1985). This gives us an insight into the values, ideas and culture of that time. Research on Attic vase paintings is vast, 
                         as witnessed by numerous introductory handbooks on the subject (Vierneisel 1990; Robertson 1992a; Scheibler 1995; Boardman 2001; Mannack 2012; Cook 2013; Sparkes 2013). 
                         Another interest lies in artisan production and craftsmanship (Coulson, Oakley, and Palagia 1997; Palagia and Oakley 1997; J. Oakley 2014; Eschbach and Schmidt 2016). 
                     </p>
                    
                     <p>While some artists’ names, for example those of sculptors, are known from historical sources , we do not know much about vase painters historically. Sometimes, however, there is a Greek name painted on a vase, accompanied by the phrase EΓΡAΦΣEN (I was painted by), 
                         meaning that the person with that name painted that particular vase (Osborne 2010; Pevnick 2010; Hurwit 2015). These signatures were tempting clues that fuelled scholars to study the painters of the vases as if they were great masters. 
                         The deep appreciation for the paintings and the challenge of analysing their stylistic details led to decades of research on painter attribution in 19th-20th century Classical Archaeology (Schmidt 2016). The question “Who painted this vase?” became hard to resist.
                     </p>
                     
                     <p>One particular scholar, Sir John Davidson Beazley (1885-1970), emerged as an authority in this field. Beazley developed his skills at the height of painter attribution research on Attic vases during the first half of the 20th century (Rouet 2001). 
                         But his method is often retraced to earlier studies of Renaissance paintings and the specific approach developed by the art historian and doctor of human anatomy Giovanni Morelli (1816-1891, see Kurtz 1986). Morelli theorized about painter attribution and developed a specific approach for this task. 
                         It was his approach, that led to the Sleeping Venus being recognized as a painting by Giorgione. Morelli prided himself on being a anatomist and his method consisted of a systematic and refined comparison of anatomical details between the alleged paintings of an artist. 
                         Specifically those details that might seem insignificant at first glance turn out to be particularly important, because this is where the individuality of the artists is most clearly expressed (Wollheim 1973; Ginzburg and Davin 1980; Vakkari 2001; Hinojosa 2009; Uglow 2014). 
                         Regardless of whether Beazley actually followed Morelli specifically, it is conceivable that Attic vase painters could be distinguished by such characteristics as well. The craftsmen produced multiple paintings per day and were routinely handling their tools, making shapes flow easily from their hands.
                     </p>
                     
                     <p>By studying the signed works of a painter, scholars were able to grasp a painter’s handwriting, with details like eyes, hands or ankles being the letters. Looking at a signed cup (Figure 1 ), we are able gain a first impression of the painter Douris. He is one of the painters with the most signatures and as such his style 
                         is well studied and established (Buitron-Oliver 1995). Looking at the pictures, we are often drawn to the faces first. It is possible to discern the similarity between eyes or mouths, for example. Their context is also important: How are the features arranged in the face? How big or small are they? 
                         Are they scrunched together or more spaced out? With this, we look beyond mere letters, we also consider the context; the words they are used in. Scholars have of course examined not only faces, but other body parts as well. In fact, the monograph on Douris features a section on the renderings of 
                         larger body parts of naked male figures, such as the chest and the legs (Buitron-Oliver 1995). 
                     </p>
                     
                     <p>Studying the paintings in great detail gives a good impression of a painter’s idiosyncrasies. But it also reveals the variation of their ‘handwriting’. Beazley was one of the first to shift the focus from the signed works and to unsigned works on a larger scale (Neer 1997; Sparkes 2013; John H. Oakley 2009; Pérez 2018; Driscoll 2019). 
                         Not only was he able to identify unsigned paintings from known painters, he even identified painters with no known signatures at all. He named them after a topic they painted (e. g. “painter of the Paris Gigantomachy") or the city of the museum with their most well-known work (e. g. “Berlin Painter"). 
                         This way, he created an extensive structure with hundreds of painters. 
                     </p>
                     <figure>
                         <head>Faces from a signed cup by Douris. By studying the details and their variations scholars like Beazley are able to
                         recognize the painters handwriting. BAPD 275972, Los Angeles Getty Museum of Art, 86.AE.29</head>
                         <figDesc></figDesc>
                         <graphic url=""></graphic>
                     </figure>
                     <!-- figire 1 -->
                     
                     <p>To understand how he was able achieved that, we turn our attention to one of these painters. Figure 2 shows a few examples of the way the Berlin Painter drew faces. Beazley was especially fascinated by this painter, as attested by several publications (Beazley 1922; 1930; 1911). In the first publication he describes the linework of 
                         a handful of vases in great detail. He not only looked at faces, but placed great importance on the rendering of the body and especially the drapery of the clothes.  A combination of all the features, including their deviations, led him to the conclusion that these particular vases must come from one hand. 
                         He writes "A system so definite, coherent, distinctive, and in some respects so wilful, is most easily intelligible as a personal system" and "the child, above all else, of one man's brain and will (Beazley 1922). He describes the painters’ style as “system of renderings”, which helps to understand his approach: 
                         Beazley compared not only stylistic details, but their overall interconnection, allowing him to not only identify known painters, but systems themselves. Beazley trained his eye well during his long-lasting career and sometimes he changed his mind about certain attributions. 
                         The more pictures he studied, the better his connoisseurship became. 
                     </p>
                     
                     <p>Beazley’s success was unparalleled and many of his observations, especially those regarding the Berlin Painter, still hold value today (Sparkes 2013; Oakley 2017). His most important contribution remain the volumes of his Attic vase painter series, where he simply lists hundreds of thousands of vases, sorted by painter (Beazley 1963; Beazley 1956). 
                         His approach itself became subject of study as well (Kurtz 1986; Neer 1997). This demonstrates the ambivalent relationship of Classical Archaeology towards painter attribution.
                     </p>
                     
                     <!-- figure 2 -->
                     <figure>
                         <head>Cut out faces from vases attributed to the Berlin Painter.
                             Upper row: 201879B (New Haven, Yale University 1913.133), 201836A (London, British Museum 1843,1103.51, Image Credit: © The Trustees of the British Museum CC BY-NC-SA 4.0, Assetnumber: 1613148360), 201811B (New York, Metropolitan Museum 56.171.38), 275093 (New York, Metropolitan Museum 65.11.12 )
                             Lower row: 275093 (New York, Metropolitan Museum 65.11.12 ), 201836B (London, British Museum 1843,1103.51, Image Credit: © The Trustees of the British Museum CC BY-NC-SA 4.0, Assetnumber: 1613148365) 201829B (London, British Museum 1843,1103.74, Image Credit: © The Trustees of the British Museum CC BY-NC-SA 4.0, Assetnumber: 283160001), 202004 (New York, Metropolitan Museum 22.139.32)
                         </head>
                         <figDesc></figDesc>
                         <graphic url=""></graphic>
                     </figure>
                     
                     <p>While Beazley’s contribution to Classical Archaeology is undeniable, he and especially his successors were harshly criticized, especially in the 1990s and early 2000s. Many aspects, but also the very existence of this approach were criticized for many reasons, some of them valid, others just coming from a different place of interest (Sparkes 2013; Driscoll 2019; Graepler 2016; Arrington 2017). 
                         Some of the criticism is aimed at the language of painter attribution, which can come across as imprecise and judgemental. Beazley's early observations on the development of Douris for example reads as follows: "Douris the youth [meaning in his earlier period] is a lively and graceful character: Douris the man is scrupulously neat, highly accomplished, sleek, decent and dull." (Beazley 1918, 97). 
                         Calling a painter dull might seem insulting, but for us, even such statements are useful, as we can still extract formal observations from them. The term “dull” might indicate a certain repetitive nature in his works, which is a valuable observation on the variation of the renderings.
                     </p>
                     
                     <p>Beazley’s extensive work is fundamental for our own research, but not because we want to re-attribute works or re-analyse the works of certain painters. We are first and foremost interested in understanding these “systems of renderings” as a tool for categorizing visual similarity. At its core, Beazleys method is comparing one system of renderings against another, 
                         considering the variation within a painter’s hand. In the end, it comes down to two questions: How much can a style vary to still belong to one painter’s hand and how do we interpret specific kinds of similarity between paintings?
                     </p>
                 </div><!-- div 2.1 -->
                 
                 <div>
                     <head>2.2 Painter Attribution: A Classification Task</head>
                     <p>Connoisseurship is often criticized for focusing too much on the shapes in an image, instead of its content. However, this is actually an advantage for machine learning purposes, since a strictly descriptive approach is something an algorithm can usually easily process. So of course, we are the first to attempt and reflect painter attribution with computational methods. Most such attempts
                         are rooted in Art Historical research of later time periods however, which come with different approaches to data and painting styles. Paintings in later periods are usually canvases covered in brushstrokes. Although vase painters used a brush as well, usually only the contours of the figures are painted and there are rarely large areas covered in a close pattern of brushstrokes. 
                         In this sense they are closer to drawings than post-antique paintings. Apart from this, the task of painter attribution is the same in its basic structure. Therefore, other projects might offer useful insights into sampling strategies and other challenges. 
                     </p>
                     
                     <p>There have been large-scale approaches to  train classifiers on individual or periodical style based on large datasets like WikiArt as early as 2011 (for a review s. Santos et al. 2021). However, as Bell and Offert pointed out, the definition of style in such projects is not always in line with the definitions by Art Historians and Classical Archaeologists (Bell and Offert 2021). 
                         This is a phenomenon apparent in many projects, but it becomes less prevalent the more precise the research questions are and the stronger they connect to traditional Art History research. Such in-depth projects often revolve around painters who either have controversial bodies of work or who are subjected to forgeries due to their popularity. 
                         While forgery detection is a common goal for many scholars in that field (Levy et al. 2014; Narvaez et al. 2022), there are also examples of more profound Art Historical research questions beyond that, for example on Leonardo da Vinci and the heavily restored Salvador Mundi (Lewis 2019) (Frank and Frank 2021; Langmead et al. 2021; on the Salvador Mundi see: Lewis 2019) 
                         or Vincent van Gogh and his distinct brushstroke patterns (J. Li et al. 2011; Folego, Gomes, and Rocha 2016).
                     </p>
                     
                     <p>Despite varying degrees of success and methodological discussion, these approaches show that painter attribution translates especially well into supervised machine learning (SML) algorithms. It is a classification problem and SML algorithms treat given problems as a classification task. SML includes many methods, from statistical approaches to deep learning (El Mrabet et al. 2021). 
                         For the purpose of image pattern recognition, deep convolutional neural networks (CNN) prove to be the most successful approach.
                     </p>
                     
                     <p>In SML, a model is trained on a set of labelled data to recognize patterns and make predictions on new, unseen data. In our case, the labelled data would be a set of images of ancient vases with known painter attribution, and the model would be trained to recognize the stylistic characteristics that distinguish each painter's work. Once the model is trained, it can be used to analyse new images of 
                         vases and predict the most likely painter based on the similarities with the previously labelled data. In order to ensure that the neural network is accurately identifying the work of individual painters and not just picking up on general trends, it is important to test the model's ability to generalize. This can be done by withholding a portion of the images from the training set and using them to test 
                         the model's ability to correctly identify the painter. If the model is able to accurately identify the painters based on images it has not seen before, it suggests that the distinct classes are representative of stylistic similarities. The first key challenge stemming from this, is the model’s frame of reference. Everything it learns is framed through the class selection and has the be interpreted in relation to that. 
                         Therefore, selection of classes plays a major role in our approach, as elaborated in section 3.
                     </p>
                     
                     <p>Once verified through a model performance, the next step is to understand how the model is making its decisions. This process is often interpretative, as it involves inferring the decision-making processes from the classifications. However, there are also methods that provide insight into the model itself, for example with the use of heat maps (Selvaraju et al. 2017; Seifert et al. 2017). 
                     </p>
                     
                     <p>Our focus lies not in explaining the decisions behind our model in detail, but the implications they have for our own analysis. For this purpose, the experiments have to be as transparent as possible from the beginning. We can achieve this by controlling our dataset and the receptive field of the classification task. Limiting and controlling the input, for example by omitting or including specific details, 
                         controls the model’s decision-making from the beginning, rather than explaining it after training and validation. Since the painter attribution proves to be focused on the details of the paintings, laying a strong focus on them in the training process is not only preferable, but necessary.             
                     </p>
                     
                     <p>This has been a key challenge for other projects as well. Some solutions include an automatic segmentation into tiles, as performed by Frank and Frank (Frank and Frank 2020). They use the segments with the highest amount of information for their training. Another approach includes brushstroke-segmentation, which works particularly well for painters like van Gogh, who has a very distinct brushstroke-pattern (J. Li et al. 2011). 
                         Both these approaches are not suitable for our goal of painter attribution. The lines of vase paintings do not contain repetitive patterns such as van Gogh. Additionally, we are looking for more complex combinations of brushstrokes which constitute the motifs: Comparing hands to hands, eyes to eyes. Other scholars, such as Bell and Offert (Bell and Offert 2021) and Langmead et al (Langmead et al. 2021) acknowledge this as well. 
                         This is why they use pre-existing models such as keypoint RCNN or the Google API for a semantic segmentation via object detection and face recognition. These pre-trained models are trained on real-world data however and do not work well with vase paintings. So instead of these approaches, we choose to annotate the images manually. Our annotation strategy is presented in section 4. 
                     </p>
                     
                 </div> <!-- div 2.2 -->
                 
                 <div>
                     <head>2.3 Functionality of Convolutional Neural Networks (CNNs)</head>
                     <p>Lastly, we want to give some technical background on the functionality of CNNs, because they also present us with certain specifics to consider in our data compilation. CNNs have become the standard for image classification tasks in the recent years, with various models and model architectures being proposed (introductory works see O’Shea and Nash 2015; Venkatesan and Li 2017; 
                         Khan et al. 2018; Z. Li et al. 2021). The success of AlexNet (Krizhevsky et al. 2012) and the introduction of ImageNet (Deng et al. 2009), the first large-scale annotated image dataset, have played a significant role in promoting the use of CNNs for image classification. 
                     </p>
                     
                     <p>Since then, various extensions have been proposed to enhance the representational power of convolutional architectures. At its core, a neural network is a complex mathematical model compromised of multiple layers. Each layer is a parameterized mathematical function. In the case of CNNs, the defining layer is the convolutional layer, where the mathematical operation of the same name is used. 
                         In this operation the input image is combined with a set of filters, resulting in feature maps. From a human point of view these feature maps look like a filtered image, with specific characteristics emphasized. By using different filters, the neural network can recognize patterns and determine them as features for the specific class. This is the same concept used in Gaussian blurring and edge detection. 
                         Using a blurring filter the CNN would recognize features regarding the overall shapes, while an edge detecting filter would emphasize the lines. By stacking multiple convolutional layers, the network can learn representations of increasing complexity. Convolutional layers are usually coupled with a pooling layer to condense the features in the feature maps, 
                         and an activation function to introduce non-linearity to the model.  
                     </p>
                     
                     <p>When we train a neural network, our goal is to find the best parameters for the functions in the layers by making them fit our training data as closely as possible. We have a multitude of parameters across the layers, making it impossible to compute an exact solution. This is where
                         backpropagation comes into play. These iterative technique helps us fine-tune the network's parameters, by gradually reducing prediction errors.  During training, the neural network learns and optimizes the parameters, such as weights and biases, that can then be applied to new, unseen data. 
                         To put it simply, it basically involves backtracking through the model and optimizing the parameters to reduce errors in the classification.
                     </p>
                     
                 </div><!-- 2.3 -->
             </div> <!-- div 2 -->
             
             <div>
                 <head>3. Painter Selection and Biases</head>
                
                <div>
                    <head>3.1 Biases in the Image Selection</head>
                    <p>As the first step of our data compilation strategy, we want to address the class selection. Selecting the classes for our use case means choosing which painters we want to use as examples in our study. 
                        Furthermore, it also involves the question which paintings to choose and which painter attributions by which scholars to consider when assigning a specific painting to a class. 
                        Overall, our painter selection is influenced by both humanities and machine learning factors, with archaeological interests being the leading force. 
                        For the algorithms to work, some statistical requirements have to be considered as well: 
                    </p>
                    
                    <p>First, the algorithms call for a sufficient number of samples per painter, which should also be in a similar range for all painters to avoid a skewed distribution. Second, we have to keep our dataset diverse enough in every aspect that may possibly be relevant, otherwise the model will not be able to generalize to unseen images. 
                        This means that we have to choose paintings representative for the variety within a class. Creating such a dataset is not a problem for most machine learning applications as long as they work with real-world data. It is always easy to produce more data to balance or enlarge the dataset. With vase paintings however, 
                        we ‘only’ have the preserved images and simply cannot create more. Projects in the Digital Humanities often deal with the bottleneck of too few or too diverse data. In other projects on vase paintings there have been attempts to enhance the datasets artificially, for example by transferring the style of vase paintings 
                        onto real-world images and therefore creating more images in the same style (Madhu et al. 2022). Adrian Ryan even drew new paintings by his own hand (Ryan 2009). However, we have refrained from artificially enhancing our dataset, because it usually introduces new diversity into the data which might create another bias. 
                        Also, our research question is focused on individual renderings, which cannot be re-created faithfully. So at least for the initial set-up, we had to focus on painters with a naturally large body of work. 
                    </p>
                    
                    <p>However, this requirement raises another important question: By which criteria does a painting belong to a class? As discussed above, painter attribution on Attic vases is often done ambiguously and intuitively, making it difficult to objectify the attributions and put them into distinct classes. 
                        Beazley’s attributions are so vast in number that they offer a solid basis for machine learning algorithms. Nonetheless, not all of his attributions are undisputed.  The only factual evidence nobody can dispute are signatures. 
                        They are the real ground truth, even if we add the attributions of scholars who have a life-time of visual experience. Also, we do not want to limit ourselves to merely replicating Beazleys approach. We wanted to study connoisseurship and vase paintings in general. 
                        So, we also had to consider the number of signatures and potential controversies in regarding the painter’s bodies of works to avoid too much disagreement within the classes. Nevertheless, we did include some controversial paintings in the dataset, because we wanted to study how they would perform. 
                        They could give us an insight into which features might make it hard for human scholars to agree on an attribution and therefore add to our understanding of the method.
                    </p>
                    
                    <p>Adding to these criteria, Attic vase paintings also confronts us with inherent biases. They are a complex medium with dense information, pertaining to both formal characteristics and content. We are mostly interested in the  formal characteristics, as interpretative information is not relevant for painter attribution. 
                        The categories can correlate however. To identify biases in this labyrinth of features, we defined different levels of formal characteristics, going from general and external to specific and deep. General characteristics are, for example, the composition of a painting, or its motif. 
                        These are dominant characteristics that take up a lot of literal space in the painting. A deep characteristic, for example, is the personal style, which is found within the details in specific areas of the painting. Such details might be overshadowed by more general characteristics and potentially be “buried” underneath them.
                    </p>
                    
                    <p>Above these levels of image-inherent characteristics, there is an even more general level. It concerns external criteria, such as the image properties and image quality: If the model is expected to perform on images with different angles, lighting conditions and other variations, then these factors need to be accounted for in the training data as well. 
                        So, the images we chose had to be diverse in this respect as well, which is further limited by the natural occurrence of vase painting publications, meaning printed books and online databases. We included scanned and de-rasterized photographs from printed publications, photographs on Wikimedia commons (https://commons.wikimedia.org) 
                        and photographs from major museum databases online, especially the British Museum in London (https://www.britishmuseum.org/collection), the Metropolitan Museum in New York (https://www.metmuseum.org/art/the-collection), the J. Paul Getty Museum in  Los Angeles  (https://www.getty.edu/art/collection/). While keeping the dataset diverse, 
                        it is also important not to oversample images with certain characteristics for a specific painter, as they contain easy-to-learn textural qualities. If we chose only medium quality scans of book publications for one painter and high-resolution camera pictures from Wikimedia for another, the model would generalize unwanted features. 
                        Thus, it is important to consider the overall quality within the classes carefully to ensure that it is representative of the dataset and free from external biases. 
                    </p>
                    
                    <p>Going deeper into the levels of image information we can proceed from the more general to the more detailed levels. For a human it is easier to look for specific details, because we can control our visual attention. A neural network on the other hand, might get stuck on the more general shapes if they are generalizable, due to the nature of convolution. 
                        This makes it even more urgent that we carefully consider these levels and their connections between each other. Sometimes, they are hard to separate, with the following characteristics being worth exploring further:
                        
                        <list type="unordered">
                            <item>The first characteristic concerns the context of the painting, meaning its placement and size. Vases offer many differently shaped surfaces for painting, which can affect the basic structure of the picture. Again, as with handwriting, the linework might vary depending on the available space and on the vessel’s curvature. 
                                If a painter preferred certain shapes, this might lead to an unwanted bias.</item>
                            <item>The next characteristics include motivic features, for example composition,  scene, motif or the topic depicted. Those characteristics are often the first thing we notice in a picture, even if we reduce the depiction significantly. 
                                A neural network might learn those features before it learns anything else. If a painter always prefers certain motifs, the neural 
                                network might generalize this characteristic over the personal style, due to the space they take up in a painting.</item>
                            <item>The final characteristic is found at the same “depth” as personal style: The Zeitstil (period or temporal style). As in all time periods, certain visual features are typical – "in fashion" – for their time. A good example of this is the clothing and the way the folds are painted. They are very distinctive in different time periods (Langlotz 1920). 
                                Both of these stylistic features are contained in the same details, which makes it hard to separate them.</item>
                        </list>
                    </p>
                    
                    <p>Temporal style and personal style get confused sometimes and a study including different time periods might lead to a classification based on art periods or technical differences, rather than personal styles. The model might perform its task correctly at first glance, but the features it learns are not the ones intendent. 
                        Still, the temporal bias is the easiest to resolve, at least in our initial set-up: By focusing on only one art period with its immediate predecessors and successors we can eradicate a potential temporal bias and teach the neural network to recognize subtle differences between personal styles instead. 
                        This approach was also considered in some of the projects mentioned above (Frank and Frank 2022, 840; Bell and Offert 2021). 
                    </p>
                    
                    <p>The time frame we choose is the early 5th century BC, the late Archaic / early Classical times. 
                        The production of vase paintings in Athens spans over several centuries, with many stylistic and technical developments. Our chosen time frame takes place after the transition from black-figure to red-figure technique. 
                        In black-figure technique the figures were applied in a translucent slip onto the terracotta surface, which became black after firing the vessel. The details were then etched on with a sharp tool. 
                        Red-figure vases are the opposite: The vase was covered in black slip and the figures are blank areas that appear in the red colour of the terracotta. The contours and details are painted with a brush before firing the vase 
                        (Noble 1988, 99-117). In our chosen time-period, the red-figure style had just become firmly established, while the generation before that is considered more experimental (Boardman 1975, 89-91). 
                        It is also a time frame where it was common to sign the vases, which offers a good foundation for our dataset as well (Bolmarcich and Muskett 2017; Sapirstein 2013).
                    </p>
                    
                    <p>The vase size and shape, as well as the depicted motif, pose a challenge that cannot be solved this easily, because they may differ from painter to painter, even within a certain period. Between these two, size and shape are easier to control: 
                        They represent parameters that depend on the kind of vase onto which the image was painted on. According to Beazley, vase painters of that period can be roughly divided into cup painters and pot painters (Beazley 1961). Cups in this terminology means smaller vessels 
                        from which one can drink, for example kylikes (Figure 3). They have a round, shallow body and are decorated on the curved outside as well as the plane inside. Meaning there are two kinds surfaces with different curvatures. But there are also other vases, such as skyphoi, 
                        that are closer in shape to the kind of cups we use today. Pots include large vessels, often with a large body, a small foot, and a shoulder connecting to the neck of the vessel. At the top they are either curved inwards, or curved outwards. 
                        The body is usually broad, offering a slightly curved surface for the paintings. However, the curvature at the top of the painting, and the size of the vessels differ greatly from pot-shape to pot-shape, as seen in the examples in Figure 4. 
                        There are also many exceptions, for example lekythoi, which have a narrow and high body, or decorative zones featuring smaller figures on the necks of larger vessels. Moreover, this distinction between cup and pot painters does not mean that 
                        they only painted these specific vessels. There are exceptions to the case, which adds to the variety within the classes. The cup painter Douris, for example, also painted a larger vessel, a psykter, as indicated by his signature (BAPD 205309, London, British Museum E768). 
                        Other pots can also be attributed to his body of work on a stylistic basis, such as an amphora in St. Petersburg (BAPD 205310, State Hermitage Museum B5576.) and another one in Paris (BAPD 205311, Louvre S3853).
                    </p>
                    
                    <p>Possible solutions against this bias would include focusing only on pot (or cup) painters or creating sub-classes per painter. Only focusing on one kind of painter would take too much complexity from the task, however, and due to the high variety and the uneven distribution of shapes, 
                        creating subclasses is impossible. This diversity of vase shapes causes a bias with unpredictable extent. Therefore, contrary to our approach with the temporal bias, we decided to include both pot and cup painters. 
                        We specifically included vessels representing exceptions to their usual preference of vase shapes, to emphasize the variation of linework in our dataset.</p>
                
                    <!-- figure 3 -->
                    <figure>
                        <head>: Cups by Makron. 
                            Top: BAPD 204734, New York Metropolitan Museum (MET) 06.1152; Bottom: BAPD 6917, MET 1979.11.9
                        </head>
                        <figDesc></figDesc>
                        <graphic url=""></graphic>
                    </figure>
                
                    <p>A similar reasoning was used on the variety of the motifs. The depictions range from mythological fight scenes, to athletes doing sports, to women in their chamber. There is great variety in the topics depicted, but certain types of scenes or figures, such as mantle figures (Franceschini 2018), are often reused. 
                        As with the vase shapes, it seems that certain painters preferred certain motifs. The Berlin Painter for example frequently depicted musicians with stringed instruments (Padgett 2017 Nr. 4, 13, 15-16, 18-20, 28, 33, 39, 55). This observation can lead to circular reasoning, with attributions being based on the motifs. 
                        Since the dataset is limited, we cannot simply avoid having too many examples of a painter's favourite motifs. We can only ensure as much diversity as possible per class. Another strategy against this bias consists of stripping the details from their compositional and motivic context by segmentation, as explained in Section 4.
                </p>
      
                </div><!-- 3.1 -->
                 
                 <div>
                     <head>3.2 Selection of Painters and their Circles</head>
                     <p>By reducing these biases, our data selection was shaped in a certain way, either by focusing on certain characteristic or by ensuring diversity so that the model would be able to generalize. The final selection was further determined by 
                         painters’ potential for answering research questions and uncovering similarities and connections between them. With all this in mind, we chose four painters from around 500 to 470 BC: The Berlin Painter (Beazley 1963, 196ff; Padgett 2017), 
                         Douris (Beazley 1963, 425ff; Buitron-Oliver 1995), Makron (Beazley 1963, 458ff; Kunisch 1997) and the Brygos Painter (Beazley 1963; Pace 2019). Additionally, we also added Oltos (Beazley 1963; Bruhn 1943; de Hoffmeyer 1943). He was active a little earlier 
                         than the other painters and painted many cups, but also other vase shapes. His performance in training and evaluation should give us a deeper insight into the two potential temporal biases and vase shape biases throughout the experiments. 
                     </p>
                     
                     <!-- figure 4 -->
                     <figure>
                         <head>Pots by the Berlin Painter. Top: Neckamphora: BAPD 201878, MET 07.286.69; BAPD 201837, Los Angeles Getty Museum of Art 86.AE.187; BAPD 201888, MET 41.162.17; Amphora: BAPD 201811, MET 56.171.38; 
                             Bottom: Stamnos: BAPD 201960, MET 1988.40; Hydria: BAPD 201987, MET 10.210.19; Oinochoe: BAPD 202004, MET 22.139.32; Lekythos: BAPD 202022, MET 21.88.163.</head>
                         <figDesc></figDesc>
                         <graphic url=""></graphic>
                     </figure>
                     
                     <p>Three of these painters - the Berlin Painter, the Brygos Painter and Oltos – were put into relation to other painters by different scholars. Sometimes, when talking how painters might relate to each other, 
                         scholars have been overly interpretative with their assertions based on visual similarity. To avoid misunderstandings regarding the interpretation of our data in relation to the history of research in Classical Archaeology, 
                         we have to be very careful in our choice of words. Firstly, we will use the word 'relationship' only when talking about clearly definable relationships between painters. To this, we add the terms “relate to” and “connection”. 
                         With connection we mean visual similarity, which includes the possibility that there might not be a historical relationship at all. Second, we call the three painters “core painters” (= training classes) and will describe their 
                         groups of proximal painters as a “circles” (= test classes). Beazley used the word “circle” to describe an extended range of relationships beyond workshops or groups (Robertson 1989). In contrast, we use this term to include all 
                         kinds of relation(ship)s and connections that archaeological research claimed between certain painters and their styles of drawing. We neither agree nor disagree with this research and its interpretations. 
                         We simply use these circles to explore and further define the visual relations they are based on.
                     </p>
                     
                     <p>The three circles are based on different dimensions of argumentation. The first is the circle around Oltos. He signed his works frequently and many of his vases were also signed by their potters, which was used before to form a network of workshop relationships 
                         (Cline and Hasaki 2019). The second is the circle of the Brygos Painter. We do not know his real name, because there are no signed works. However, Beazley believed that he potentially worked together with a group of stylistically similar painters 
                         (Beazley 1963, 368. 400-405). His assertions are supported by a potter debris found in Athens with fragments of some of the visually similar painters (Tzachou-Alexandri 1968; Baziotopoulou-Valavani 1994; Monaco 2000; Maffre 2001; Williams 2017, 168). 
                         The fragments are also unsigned and it is therefore important to be wary of circular reasoning when discussing this group. Both Oltos and Brygos may give us insight into workshop processes and how the paintings of fellow craftsmen might relate to 
                         each other stylistically. 
                     </p>
                     
                     <p>The third circle surrounds the Berlin Painter and is based on purely stylistic observations. His circle is a prime example of historical interpretations of visual similarity, because it contains what connoisseurs label "teacher and student relationships". 
                         It is impossible to reconstruct such relationships based on straightforward evidence, instead it is based on the similarities between the painter’s styles and vase shapes (Oakley 1997, 97). Hypotheses such as these have been criticized in Classical Archaeology, 
                         because the arguments are circumstantial and too much historical information is inferred from visual observations (Neer 2009, 45). Nevertheless, we want to study the Berlin Painter’s circle in particular, because it represents the peak of connoisseurship 
                         intuition and association: Connoisseurs have seen distinct and nuanced similarities between the paintings that led them to label them with this specific interpretation. Our goal is to strip out all the historical assumptions and to re-examine said similarities. 
                         We will continue to use quotation marks when discussing their relationship, since they are only inferred. 
                     </p>
                     
                     <table>
                         <head>Painters in our data-set and number of instances. The arguments for their inclusion are based on a literature of supposed relations. 
                             For the Brygos P., this includes fragments in the archaeological find and their attribution, for the Berlin Painter the labels given by research and for 
                             Oltos the number of signatures on the works by the same potters.</head>
                         
                         <row role="label">
                             <cell></cell>
                             <cell>Supposed Relationship</cell>
                             <cell>Instances</cell>
                         </row>
                         
                         <row role="data">
                             <cell><hi rend="bold">Berlin P.</hi></cell>
                             <cell><hi rend="bold">Core Painter</hi></cell>
                             <cell><hi rend="bold">230</hi></cell>
                         </row>
                         
                         <row role="data">
                             <cell>Providence P.</cell>
                             <cell>"Student"</cell>
                             <cell>84</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Achilles P.</cell>
                             <cell>"Student"</cell>
                             <cell>164</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Hermonax</cell>
                             <cell>"Student"</cell>
                             <cell>97</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Phiale P.</cell>
                             <cell>"Student" of the Achilles P.</cell>
                             <cell>150</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Oinokles</cell>
                             <cell>"Follower" of the Providence P.</cell>
                             <cell>48</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Phintias</cell>
                             <cell>"Teacher"</cell>
                             <cell>43</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Euthymides</cell>
                             <cell>"Teacher"</cell>
                             <cell>40</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Kleophrades P.</cell>
                             <cell>"Student" of Phintias and Euthymides</cell>
                             <cell>305</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Myson</cell>
                             <cell>"Student" of Phintias</cell>
                             <cell>42</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Persephone P.</cell>
                             <cell>"akin in spirit" to the Achilles Painter</cell>
                             <cell>35</cell>
                         </row> 
                     </table>
                     
                     <table>
                         <row role="label">
                             <cell>Additional Painters to diversify the data-set</cell>
                        <cell></cell>
                         </row>
                         
                         <row role="data">
                             <cell>Douris</cell>
                             <cell></cell>
                             <cell>208</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Makron</cell>
                             <cell></cell>
                             <cell>314</cell>
                         </row>
                     </table>
                     
                     <table>
                         <row role="label">
                             <cell></cell>
                             <cell>Shared Potters</cell>
                             <cell>Instances</cell>
                         </row>
                         
                         <row role="data">
                             <cell><hi rend="bold">Oltos</hi></cell>
                             <cell><hi rend="bold">Core Painter</hi></cell>
                             <cell><hi rend="bold">150</hi></cell>
                         </row>
                         
                         <row role="data">
                             <cell>Euphronios</cell>
                             <cell>2 (4 Signed, 8 Attributed)</cell>
                             <cell>94</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Epiktetos</cell>
                             <cell>2 (4 Signed, 3 Attributed)</cell>
                             <cell>119</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Onesimos</cell>
                             <cell>1 (1 Signed, 9 Attributed)</cell>
                             <cell>129</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Nikosthenes</cell>
                             <cell>2 (15 Attributed)</cell>
                             <cell>31</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Pistoxenos</cell>
                             <cell>1 (1 Attributed)</cell>
                             <cell>28</cell>
                         </row>
                     </table>
                     
                     <table>
                         <row role="label">
                             <cell></cell>
                             <cell>Supposed Relationship</cell>
                             <cell>Fragments</cell>
                             <cell>Instances</cell>
                         </row>
                         
                         <row role="data">
                             <cell><hi rend="bold">Brygos P.</hi></cell>
                             <cell><hi rend="bold">Core Painter</hi></cell>
                             <cell><hi rend="bold">✓ (14)</hi></cell>
                             <cell><hi rend="bold">197</hi></cell>
                         </row>
                         
                         <row role="data">
                             <cell>Briseis P.</cell>
                             <cell>"Mild-Brygan-Group"</cell>
                             <cell>✓ (6)</cell>
                             <cell>100</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Dokimasia P.</cell>
                             <cell>"Mild-Brygan-Group"</cell>
                             <cell>✓ (3)</cell>
                             <cell>62</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Foundry P.</cell>
                             <cell>Visually Related by Beazley</cell>
                             <cell>? (1)</cell>
                             <cell>120</cell>
                         </row>
                         
                         <row role="data">
                             <cell>P. of the Paris G.</cell>
                             <cell>Visually Related by Beazley</cell>
                             <cell>? (1)</cell>
                             <cell>75</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Onesimos</cell>
                             <cell>"Teacher" of the Foundry P.</cell>
                             <cell>? (1)</cell>
                             <cell>129</cell>
                         </row>
                     </table>
                     
                     <p>Table 1 shows the distribution of instances per painter in our dataset. An instance is a single figure in a painting. Asking “who painted this figure?” instead of “who painted this vase?” has two advantages: First, it allows us to disregard the overall 
                         image composition, therefore reducing the potential motif bias; and second, it leads to a more nuanced assessment of painter attribution and the role individual figures may play when the model attributes a painting. 
                     </p>
                     
                     <p>In total, we carefully curated a dataset consisting of 2785 individual figures extracted from 1353 vase paintings created by the five core painters along with 19 other painters in their associated circles. 
                         Our total dataset includes 37 painters, 9,362 figures, and a total of 428,960 annotated objects. The distribution displays a natural imbalance, with a significant variation in the number of existing paintings across different painters. 
                         This inherent imbalance poses potential challenges for the training process, particularly when it means that classes are underrepresented because they have a low number of paintings. 
                         Such underrepresentation may adversely affect the model's performance, especially when assessing these painters during the testing phase. Fortunately, there are various methods to improve training when dealing with an 
                         imbalanced data source, which we will describe in Section 6 below.
                     </p>
                 </div><!-- 3.2 -->
             </div><!-- 3 -->
             
             <div>
                 <head>4. Image Annotation and Segmentation</head>
                 <p>With the painters selected we can now move onto the input-segments. Segmenting the images means that our model is not trained on the single figure, but on the (combination of) details per figure. As discussed above, the established methods for automating semantic segmentation do not work for vase paintings. 
                     Instead, we opted for a semi-automated workflow with manually annotated images as the basis for our own object-detection model. Adding to the need of transparency, our strategy also aims at reducing the biases of motif and vase shape, thereby focusing on the details of a painting.
                 </p>
                 
                 <!-- figure 5 -->
                 <figure>
                     <head>:  The annotation process involves annotating the figures at different levels of detail. The parts the figures are connected via parent-child-connections (for example the flute belongs to the hand, the hand to the arm, the arm to the woman). 
                         Vase depicted: BAPD 204117, MET 24.97.28</head>
                     <figDesc></figDesc>
                     <graphic url=""></graphic>
                 </figure>
                 
                 <p>For this purpose, we have developed annotation guidelines with a controlled vocabulary. It was important to have an agreement between the annotators on what exactly the labels represent and which part of the painting they encompass. It is also important that they do justice to the painting’s complexity and can be used not only our project, but also for future research. 
                     This requires detailed, comprehensive and explicit annotation guidelines, which we developed during our project. These are the three core principles:
                     
                     <list type="ordered">
                         <item>We want to compare different levels of detail, in which each label has to be connected to their corresponding higher-level-label (for example, an eye belongs to the head, a hand to an arm). For this, adapted a hierarchical system, in which the annotations get more detailed with each successive level, while the segments stay connected via parent-child connections. 
                             Specifically, this means that when we annotate a figure, we begin with the highest level: The figure itself. This can be either a man, a youth, a woman or a creature. Then we annotate the main body parts of the figure (for example the head or the arm). These body parts then get divided into their sub-parts. For the arm this would be the upper arm, the forearm, the elbow and the hand 
                             (s. Figure 3) The same goes for clothes: First, the specific garment is named; then the drape of the hem folds and the surface folds. This way we have three levels of detail: The figure, the larger body parts and the smaller details.</item>
                         
                         <item>For this purpose, we need a controlled vocabulary with a focus on the formal characteristics of a painting. A neural network is unable to understand the image. It learns from our categories which therefore must be as clear as possible. This is an important consideration for our controlled vocabulary. On the one hand, it is composed of specific terms. 
                             These are usually the names of the body parts, but sometimes, if necessary, we used technical terms from Classical Archaeology, for example to describe the clothes. This is because the specific types of clothing come with the same folds within their class. A chiton has fine folds at the bottom, a himation has large folds. On the other hand, our vocabulary also goes beyond simply determining semantic segments: 
                             It also has a visual component, describing the composition of brushstrokes associated with each label. The hip, for example, consists of two lines going from the lower side of a figure to the genitals. The shoulder (Figure 6) is described by the concave shape from the neck to the upper arm. The goal of the vocabulary is to clearly 
                             define the combinations of brushstrokes associated with each segment.</item>
                     
                         <item>Still, some segments vary depending on the context they of their depiction, even if they are clearly defined. Therefore, we had to include additional information concerning the variation of the labels. 
                             This additional information had to follow certain rules as well, to avoid overlapping and mix-ups between the strict form and levels of additional information. For example, we annotated whether or not a figure or 
                             their body parts are clothed, because the folds of the clothing change the depiction in a specific way. We also added information on the action the figure or their body parts are performing. A closed hand is a different 
                             shape than an open hand, for instance. We also added some interpretative information, if it comes with specific shapes, such as the iconographical identification of gods or heroes. It is usually based on the figure’s attributes, 
                             and thus contains information about its shape: Athena usually wears a large helmet, Eros has wings, Herakles wears a lion’s skin, and so on. This way, a figure is identifiable using a collection of features 
                             within the image, which adds to the identification of a potential motif-bias.                              
                         </item>
                     </list>
                 </p>
                 
                 <p>Most of the annotated information was not specifically used for training, but was used for describing the shapes contained in an image beyond that. It also opens up the possibility for motif-dependent de-biasing both before and after training, for example if we decided to exclude all 
                     hands playing instruments from the dataset. This way we can exclude motif-heavy labels from the beginning, reducing the bias efficiently. We also wanted to pave the way for future research on the contents of the image, 
                     such as iconographical analysis, which greatly profits from such a detailed and universal annotation.
                 </p>
                 
                 <!-- figure 6 -->
                 <figure>
                     <head>Annotation of the shoulder. Our polygons encompass clearly defined accumulations of brushstrokes, which do not always align with anatomical definitions of body parts, but rather the domain specific depiction thereof. 
                         From left to right: BAPD 201878, MET 07.286.69; BAPD 204497, MET 06.1021.188; BAPD 213926, MET 17.230.13.</head>
                     <figDesc></figDesc>
                     <graphic url=""></graphic>
                 </figure>
                 
                 <p>The annotation team consisted of student assistants with a background in Classical Archaeology. To avoid an annotator’s bias, we also split each painter between them. After annotating a large amount of images we used the manual annotations to implement our own object-detection model, which was trained to annotate the most common labels and also their the parent-child connections. 
                     We used our hierarchical system to make the process even more efficient: Our annotations are not nearly as numerous as real-world data. We resolved this problem by adding a control instance through a human annotator and initiating the detection in the same hierarchical order as our annotations: firstly, 
                     the human annotator selects the figure, which becomes the area for the regions-of-interest of the first hierarchical level (body parts). The process is then repeated for the sub-parts. This means, that the next level of annotation is only being searched for in the relevant regions, e. g. only looking for hands in the area of the arm. 
                     This made our detection very accurate despite the smaller training set (Kipke et al. 2022).
                 </p>
                 
                 <figure>
                     <head>Frequency of the object classes for the segments extracted from each figure</head>
                     <figDesc></figDesc>
                     <graphic url=""></graphic>
                 </figure>
                 
                 <p>For training and analysis, we used only the 21 most common object classes. We excluded the surroundings of the figures, as well as any objects they hold in their hands. Not only are those instances few, they also strongly indicate the motif of the image. In the end this annotation process resulted in a total of 45,442 components recorded across the paintings included in the experiments. 
                     This results in 16.3± 4.4 segments per figure (Figure 5).</p>
             </div><!-- div 4 -->
             
             <div>
                 <head>5. Interim Conclusion: What goes into the neural network?</head>
                 <p>In the end it comes down to the question of what we want the network to learn and which biases we plant into the training data, whether unknowingly or deliberately. This challenge begins with the choice of painters, continues in the selection of images and culminates in the segmentation of the individual images. In our selection we aimed at balancing potential biases using different strategies:
                 <list type="ordered">
                     <item><hi rend="bold">Limiting</hi> the painter selection to a specific characteristic (the training classes represent only two generations, which helped us to avoid a to temporal bias)</item>
                     <item><hi rend="bold">Maintaining</hi> heterogeneity with respect to the characteristics affected by potential biases on the same level as individual style, so as not to reduce the complexity of the task.</item>
                     <item><hi rend="bold">Reducing biases</hi> concerning full image characteristics (such as motif or composition) by <hi rend="bold">segmenting the image and excluding labels</hi> that carry characteristics of this bias 
                         (attributes, surroundings).</item>
                 </list>
                 </p>
                 
                 <p>It boils down to a question of representability. We want our data-set to represent the variation of the linework, while ignoring other image characteristics. Our decisions are based on archaeological criteria, but with machine learning algorithms in mind. This means that our data already underwent several layers of processing, which differentiates them from the original pictures a Classical archaeologist might look at:
                     <list type="ordered">
                         <item>The very photography of the vase is the first layer of distortion. By publishing vases as photographs, we are transforming the paintings from a three-dimensional surface into two dimensions, which results in details being distorted depending 
                             on the angle from which the picture was taken.</item>
                         <item>By sorting and compiling the data we contextualize the images in such a way, that the neural network has to assume common features within a class. This creates a framework, in which it can only “see” generalizable features of the images.</item>
                         <item>Our image annotation cuts each image into pieces. This way, we try to control which aspects add to the training of the model. We are trying to re-create the way an archaeologist is able to focus on certain details, even if it is just an approximation and not possible for every detail to the same extent.</item>
                     </list>
                 </p>
             </div><!-- div 5 -->
             
             <div>
                 <head>6. Experimental Set-Up</head>
                 <div>
                     <head>6.1 Experimental Details</head>
                     <p>With the data sampling laid down, we now come to our machine learning experiments. First, we want to elaborate on some of the experimental details, because they set the baseline for the analysis down the line. 
                         Addressing the imbalanced nature of our dataset, where the number of figures per painter varies drastically, we also employed standard data augmentation and overfitting-avoidance strategies.  
                     </p>
                     
                     <p>To assess the performance of our models, we employed a 10-fold cross-validation methodology (Berrar et al. 2019).  This is a method to make use of the data in smaller datasets as efficiently as possible. In this approach, we divided the images of each painter into ten equal parts (folds). For each of the ten experiments, one fold from each painter was assigned to the test set, 
                         while the remaining data was used for training and validation. This way different parts of the dataset rotated through the training / validation / test split and added to the model’s ability to generalize. This means, that looking at each fold we get an insight in how well an instance performs not only as training, but also as test and validation data.
                     </p>
                     
                     <p>We also employed transfer learning techniques. In many use cases, the neural network is not trained from scratch. In the lower layers it learns basic shapes and edges, which stay the same between different data domains. That is why many projects rely on transfer learning, where a pre-trained neural network is adapted to another data domain. 
                         In our work we employed the large feature extractor ResNet-50, which is pre-trained on ImageNet (He et al. 2016). ResNet-50 is the appropriate size for our experiments, because smaller versions resulted in a loss of performance and larger versions did not offer a significant lift. 
                         On top of the ResNet-50 model, we added layers with our own classification task. The pre-trained model is subject to its own data biases, through the adaption to our own data domain they do become mostly irrelevant however. 
                     </p>
                 </div><!-- div 6.1 -->
                 
                 <div>
                     <head>6.2 Image and Image Set Classification</head>
                     <p>As discussed above, there are many arguments in favour of a model trained on the details of the paintings. However, to confirm the efficacy of this approach, we trained models on other potential scenarios as well. In this experiment, we distinguish three scenarios, each of which gave us unique insights into the process. These approaches differ in their methodology and underlying assumptions, providing us with a comprehensive understanding of the task at hand. 
                       Figure 9 shows examples of the three scenarios:
                 <list type="ordered">
                     <item>The first approach involves a prediction based on the complete vase painting images. This encompasses not only the figures but also the overall scene, motif, ornaments and parts of the vase. We wanted to include the biases discussed above to analyse how they affect the model. </item>
                     <item>In the second approach, our focus shifted to detecting the painter based on a single figure extracted from the entire painting. This approach aims to eliminate some of the biases such as figure’s surroundings, ornaments etc. We wanted to see what remains and how much this approach differs from (1) and (3), 
                         since it borrowed from both, but has the advantages of neither.</item>
                     <item>(3)	The third approach constitutes our preferred strategy. Here, instead of presenting the model with the figure as a single image, we represented it as a collection of its sub-components, such as the arm, hand, and eye.</item>
                 </list>
                     </p>
                     
                     <p>This meant that we worked not only with different data inputs, but also with different classification set-ups. While the first two scenarios follow standard image classification protocols
                     
                     <note>15</note>, 
                      
                      the third scenario comes with the additional challenge of controlling the segments. The complexity of this task calls for an extension of the standard set-up to handle a <hi rend="bold">varying number of images</hi>, with each image representing a segment of the original painting. While the overall objective remained the same, our model now had to process sets of images, while maintaining invariance to the order and number
                         of elements in each set.
                     </p>
                     
                     <p>Recent studies have investigated the concept of invariant and equivariant layers from various perspectives. Maron et al. (Maron et al. 2018) introduced a methodology that involves a set of learned basis functions, while the set-transformer approach (Lee et al. 2019) employs straightforward self-attention mechanisms. Zaheer et al. proposed equivariant and invariant layers capable of operating on a set of elements by building upon the Kolmogorov-Arnold representation 
                         theorem as discussed by Zaheer et al. (2017). This theorem asserts that any multivariate continuous function ϕ can be expressed as a finite composition of continuous functions of a single variable and the binary operation of addition.  This means specifically, that our network consists of two components. The first component functions as an inner function f. After aggregating the images through summation, 
                         a second model g consisting of four dense layers is employed to compute the painter prediction for the entire set. Thus, the networks f and g are trained on the precomputed embeddings of our paintings to classify the actual painter. In this study, we have chosen to utilize a deep sets architecture due to its inherent simplicity, which makes it suitable for addressing problems characterized by limited available data.  
                     </p>
                     
                     <!-- figure 8 -->
                     <figure>
                         <head>: Example of the three different scenarios for processing the full painting, a single figure, and the set of annotations. Vase depicted: BAPD 201960, MET 1988.40</head>
                         <figDesc></figDesc>
                        <graphic url=""></graphic>
                     </figure>
                     
                     <p>It is also important to note that the experiments involving the full figure and the figure set employed the same split of figures, while the full image scenario involved a different random split across all paintings. Additionally, we ensured that figures or paintings from the same vase were not present in both the training and test sets simultaneously. 
                         Apart from these distinctions, the general experimental set-up and pre-processing across these three variants remained consistent.                    
                </p>
                 </div><!-- 6.2 -->
                 
                 
            <div>
                <head>6.3 Pre-Processing and Image Distortion</head>
                <p>Another point to address is the input distortion. Not only are the images scaled down for training, they have to be normalized to a fixed aspect ratio as well. Since we relied on a pre-trained deep feature extractor, the size of the input image is already predetermined to be 224 x 224 px by the pretraining dataset, even if we annotated high resolution images. 
                    Operating on full high-resolution images, which can be up to 4000 x 4000 px, would limit the number of images we can process simultaneously, potentially slowing or even impairing the training process.</p>
                    
                <!-- figure 9 -->
                <figure>
                    <head><hi rend="italic">The arm and hem folds scaled (left) and padded (right). With scaling the linework gets distorted significantly, especially for narrow and long labels. Left: BAPD 200751, MET 09.221.47; Right: BAPD 201811, MET 56.171.38</hi></head>
                    <figDesc></figDesc>
                    <graphic url=""></graphic>
                </figure>
            
                <p>Although these methods are advantageous due to their simplicity and low computational cost, they have the drawback that they distort the image significantly. Every segment is scaled without respect to their ratio, making small details larger and vertically compressing labels such as the arms or hem folds (Figure 8). While this distortion is considered negligible for standard computer vision tasks (Hashemi 2019), it was crucial to investigate this factor in our research, since the specific linework observed is assumed to have a significant impact on painter attribution. 
                    Does the contortion pose a disadvantage for the task or is the model able to compensate for it?
            </p>
                
                <table>
                    <head>Comparison of the performance between padded images and scaled images. 
                        Results are given as accuracy aggregated across the 10-fold cross-validation</head>                    
                    <row role="label">
                        <cell>Accuracy with standard deviation training with….</cell>
                    </row>
                    
                    <row role="label">
                        <cell></cell>
                        <cell>...paded images</cell>
                        <cell>...scaled images</cell>  
                    </row>
                    
                    <row role="data">
                        <cell>Berlin P.</cell>
                        <cell>61.7 ± 5.1</cell>
                        <cell>71.3 ± 4.2</cell>
                    </row>
                    
                    <row role="data">
                        <cell>Brygos P.</cell>
                        <cell>54.3 ± 5.9</cell>
                        <cell>53.3 ± 5.6</cell>
                    </row>
                    
                    <row role="data">
                        <cell>Douris</cell>
                        <cell>50.8 ± 8.7</cell>
                        <cell>62.1 ± 7.5</cell>
                    </row>
                    
                    <row role="data">
                        <cell>Makron</cell>
                        <cell>66.5 ± 8.9</cell>
                        <cell>78.9 ± 5.2</cell>
                    </row>
                    
                    <row role="data">
                        <cell>Oltos</cell>
                        <cell>56.1 ± 2.8</cell>
                        <cell>54.7 ± 9.1</cell>
                    </row>
                                        
                    <row role="data">
                        <cell>Average</cell>
                        <cell>58.9 ± 2.9</cell>
                        <cell>66.3 ± 3.4</cell>
                    </row>          
                </table>
                
                <p>We tested this by training three models on different pre-processing scenarios. In the first variation we kept the distorting normalisation, in the second scenario we scaled the image to their longest side and added black padding to the empty space around it (Figure 8). In the third variation we refrained from up-scaling smaller segments, as this results in different line thicknesses for different labels depending on their size. As expected, however, the third scenario did not 
                    create satisfactory results due to the small size. The comparison between the first two other scenarios can be found in Table 2. 
                    Contrary to our concerns, the distorted images do in fact offered better results. This may be because scaling the images maximizes the input 
                    information, while padding the images adds large areas of black background, which results in unused space. 
                    In the case of the hem-folds and the arm the distortion might even be helpful. For the hem-folds it emphasizes the linework and rhythm of the folds and for the arms the focus 
                    lies on the direction changes of the lines rather than their length.
                </p>

                <p>Additionally to the input-distortion, the images are often naturally distorted due to their curvature. Especially the hydria in Figure 4 shows clearly, how some paintings are difficult to photograph. 
                    This difficulty is specific to certain vase shapes and brings us back to the problem of a potential vessel shape bias.
            </p>
                
                <p>The problem of vase painting photography has been addressed on other occasions and with un-warping-algorithms (f. e. Felicisimo et al. 2019). However, they add another level of distortion in the pre-processing level, skewing the dataset even further. Due to the heterogeneity of our 
                    image selection concerning vase shapes and the focus on details rather than the whole vase, it would be impossible to create a workflow that addressed all of them. The findings of the padding vs. scaling experiment support our decision, as distortion 
                    in itself does not seem to affect the outcome of the experiment negatively, except for a potential shape bias. However, this should of course continue to be tested in further research and the methods should be adjusted if necessary.</p>
            </div>  <!-- div 6.3 --> 
                 
                 <div>
                     <head>6.4	Robustness</head>
                     <p>Finally, we also want to address about model robustness. “Robustness”, in this context, refers to the stability and consistency of a model's predictions when trained multiple times. Neural networks exhibit both determinism and non-determinism in their behaviour. 
                         When fully trained, (non-bayesian) neural networks operate deterministically, consistently producing the same outputs for a given input, ensuring their reliability. However, since the parameters of a neural network are typically initialized randomly before training, 
                         model performance might vary across multiple training runs, even with the same architecture and data. It is important to quantify this variation to ensure that the results hold ground, not only regarding the robustness of classes, but also the single instances.</p>
                 
                 <table>
                     <head><hi rend="italic">Standard deviation over the test-training folds and over then re-trainings with the same set-up</hi></head>
                     <row role="label">
                         <cell></cell>
                         <cell></cell>
                         <cell>Standard deviation over…</cell>
                     </row>
                     
                     <row role="label">
                         <cell></cell>
                         <cell>Accuracy</cell>
                         <cell>...folds</cell>
                         <cell>...runs</cell>
                     </row>
                     
                     <row role="data">
                         <cell>Berlin P.</cell>
                         <cell>73.9</cell>
                         <cell>± 4.2</cell>
                         <cell>± 1.5</cell>
                     </row>
                     
                     <row role="data">
                         <cell>Brygos P.</cell>
                         <cell>61.5</cell>
                         <cell>± 5.6</cell>
                         <cell>± 3.0</cell>
                     </row>
                     
                     <row role="data">
                         <cell>Douris</cell>
                         <cell>58.6</cell>
                         <cell>± 7.5</cell>
                         <cell>± 3.2</cell>
                     </row>
                     
                     <row role="data">
                         <cell>Makron</cell>
                         <cell>79.3</cell>
                         <cell>± 5.2</cell>
                         <cell>± 1.9</cell>
                     </row>
                     
                     <row role="data">
                         <cell>Oltos</cell>
                         <cell>65.3</cell>
                         <cell>± 9.1</cell>
                         <cell>± 2.5</cell>
                     </row>
                     
                     <row role="data">
                         <cell>Average</cell>
                         <cell>67.7</cell>
                         <cell>± 6.32</cell>
                         <cell>± 2.42</cell>
                     </row>
                 </table>
                     
                     <table>
                         <head><hi rend="italic">Classification accuracy of each painter along with the 2nd and 3rd most frequently assigned classes</hi></head>
                         <row role="label">
                             <cell></cell>
                             <cell>Most frequent class</cell>
                             <cell>Second frequent class</cell>
                             <cell>Third frequent class</cell>
                         </row>

                    <row role="data">
                        <cell>Berlin P.</cell>
                        <cell>Berlin P. (73.9%)</cell>
                        <cell>Brygos P. (11.4%)</cell>
                        <cell>Makron (8.1%)</cell>
                            </row>   
                         
                         <row role="data">
                             <cell>Brygos P.</cell>
                             <cell>Brygos P. (61.5%)</cell>
                             <cell>Makron (9.9%)</cell>
                             <cell>Douris	 (8.7%)</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Douris</cell>
                             <cell>Douris (58.6%)</cell>
                             <cell>Makron (13.8)</cell>
                             <cell>Brygos	(11.3%)</cell>
                         </row>
                         
                         
                         <row role="data">
                             <cell>Makron</cell>
                             <cell>Makron (79.3%)</cell>
                             <cell>Brygos P. (14.7%)</cell>
                             <cell>Berlin	 (7.1%)</cell>
                         </row>
                         
                         <row role="data">
                             <cell>Oltos</cell>
                             <cell>Oltos 	(65.3%)</cell>
                             <cell>Berlin (7.8%)</cell>
                             <cell>Brygos	 (7.0%)</cell>
                         </row>
                     </table>
                     
                     <p>This investigation primarily focused on two key dimensions: First, the ability of the model's predictions to withstand repeated executions on identical but permuted inputs; and second, the possible alignment of a high confidence level in the model's class scores with the robustness of its predictions. 
                         For this purpose, we repeated our main experiment with the same 10-fold cross-validation image sets 10 times. We then analysed the specific class assignments across these 10 runs. 
                         As shown in Table 4, the accuracy over runs varies only up to ± 2.42%, meaning our best model achieves an overall accuracy of 70.12% ± standard deviation.</p>
                 
                 <!-- figure 10 -->
                     <figure>
                         <head><hi rend="italic">Class distribution over 10 repeated training runs with random weight initialization. The scatter plots show the relation between mean assigned class probability for the correct class of an instance and its standard deviation</hi></head>
                         <figDesc></figDesc>
                         <graphic url=""></graphic>
                 </figure>
                 
                     <p>Two more experiments give us a better insight into the different aspects of the robustness. First, we examined the instances for each painter and analysed the correlation of the standard deviation and prediction value. The prediction value is the raw model output and represents the level of certainty for the attribution of an instance. 
                         The scatter plot in Figure 10 shows the mean of the assigned class probability over the 10 repeated runs for each figure, plotted against the standard deviation over these runs. It shows a curve, in which a high mean probability corresponds with a low standard deviation. Similarly, a low score also corresponds with a low standard deviation, 
                         meaning strong predictions come with a high confidence and predictions in the middle field tend to vary over the runs. This suggests that the predictions with a very high, but also with very low prediction values are especially stable, meaning that they might provide good case studies for studying painter attribution.
                 </p>
                     
                     <p>This became even more apparent looking at each assigned class ordered by its frequency. For this, we analysed the class prediction with the highest probability and evaluated the frequencies over assigned class: Did the model assigned the same class 10 out of 10 times, or did the final prediction change frequently? The boxplot in Figure 11 shows these frequencies. 
                         The mean/centre of each boxplot corresponds to the relative frequency over predicted classes. Over 10 runs, the model would assign the most frequent class for an instance 70% of the time; conversely, the second most frequent class was assigned at a rate of only 20%.                      </p>
                 
                 <!-- figure 11 -->
                     <figure>
                         <head><hi rend="italic">Class distribution over 10 repeated training runs with random weight initialization. Left to right shows the boxplot over the relative frequency of the class assigned the most, then second most, etc., up the class least likely to be assigned.</hi></head>
                         <figDesc></figDesc>
                         <graphic url=""></graphic>
                     </figure>
                 
                     <p>This means that the model is fairly sure about the overall classification, even when it misclassifies an instance and, in that regard, it is stable when making attributions, even if they are wrong. In further analysis, the second highest class might still be relevant, as it attests which painters get confused more easily than others. 
                         The second and third frequent classes can be found in Table 5. Overall, these experiments add an important perspective for the analysis of peculiar attributions, especially if they are confidently wrong. </p>
                 
                 </div><!-- 6.4 -->
             </div><!-- div 6 -->
             
             <div>
                 <head>7. A First Look at the Results</head>            
                 
                 <div>
                     <head>7.1	Image and Image-Set Classification in Comparison</head>
                     <p>Finally, we turn to the results of our experiments, starting with the comparison of training scenarios regarding the input images (table 3). The difference in accuracy between full vase paintings segment sets is surprisingly close. 
                         Considering the fact that the data is highly complex and that the task requires deep and specific knowledge (in human experts as well) the numbers up to 70% accuracy with 5 classes is within expected parameters. 
                         The full figures have an accuracy about 17% lower than the other scenario.                     
                 </p>
                     
                     
                           <table>
                               <row role="label">
                                   <cell></cell>
                                   <cell></cell>
                                   <cell></cell>
                                   <cell></cell>
                               </row>
                           </table>                     
             
                 </div> <!-- 7.1 -->
             </div><!-- 7 -->
             
        </body>
        <back>
            <listBibl>
                <bibl></bibl>
            </listBibl>
           
        </back>
    </text>
</TEI>
