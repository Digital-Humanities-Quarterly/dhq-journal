<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>[PREVIEW] DHQ: Digital Humanities Quarterly: </title>
      <link href="../../common/css/dhq.css" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_screen.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../common/css/dhq_print.css" media="print" type="text/css" rel="stylesheet" />
      <style type="text/css">
        #mainContent {
          float: none;
          padding-top: 2em;
          padding-left: 4em;
          padding-right: 4em;
          margin-left: 225px;
           
        }</style>
   </head>
   <body>
      <div id="mainContent">
         <div class="DHQarticle">
            <div id="pubInfo">Preview<br />Volume 017 Number 3</div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            
            <div class="DHQheader">
               
               
               
               <h1 class="articleTitle lang en">Developing Computational Models for Formalizing Concepts in the British Colonial India
                  Corpus</h1>       	
               
               <div class="author"><span style="color: grey">T. Shanmugapriya</span> &lt;<a href="mailto:shanmu_dot_shanmugapriya_at_utoronto_dot_ca" onclick="javascript:window.location.href='mailto:'+deobfuscate('shanmu_dot_shanmugapriya_at_utoronto_dot_ca'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('shanmu_dot_shanmugapriya_at_utoronto_dot_ca'); return false;">shanmu_dot_shanmugapriya_at_utoronto_dot_ca</a>&gt;, Digital Humanities Postdoctoral Scholar, Department of Historical and Cultural Studies,
                  University of Scarborough</div>
               
               
               
               
               
               
               
               <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Developing%20Computational%20Models%20for%20Formalizing%20Concepts%20in%20the%20British%20Colonial%20India%20Corpus&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=&amp;rft.volume=017&amp;rft.issue=3&amp;rft.aulast=Shanmugapriya&amp;rft.aufirst=T.&amp;rft.au=T.%20Shanmugapriya"> </span></div>
            
            	
            <div id="DHQtext">
               
               
               <div id="abstract">
                  <h2>Abstract</h2>
                  
                  <p>The concepts embedded in humanities materials are unstructured and possess multifaceted
                     attributes. New insights from these materials are derived through systematic qualitative
                     study. However, for the purpose of quantitative analysis using digital humanities
                     methods and tools, formalizing these concepts becomes imperative. The functionality
                     of digital humanities relies on the deployment of formalized concepts and models.
                     Formalization converts unstructured data into a more structured form. Concurrently,
                     models function as representations created to closely examine the modeled subject,
                     while metamodels define the structure and properties of these models. In this case,
                     the absence of formalized concepts and models for studying the British India colonial
                     corpus hampers the computational application to address humanities research questions
                     quantitatively. The texts are intricate, and the format is non-standard, as colonial
                     officials documented extensive information to govern and control the colonized people
                     and land. In this scenario, the British India colonial corpus cannot be effectively
                     utilized for topic-specific research questions employing advanced text mining without
                     formalizing the concepts within it. This article addresses the questions of what the
                     most effective approach is for identifying multifaceted concepts within the non-standard
                     British colonial India corpus through models and how these concepts can be formalized
                     using formal models. It also explores how metamodels can be developed based on this
                     experiment for a similar corpus.</p>
                  </div>
               
               
               	
               	
               
               
               
               <div id="section01" class="div div0">
                  
                  <h1 class="head">1. Introduction</h1>
                  
                  <div class="counter"><a href="#p1">1</a></div>
                  <div class="ptext" id="p1">The concepts embedded in humanities materials are unstructured and possess multifaceted
                     attributes. New insights from these materials are derived through a systematic qualitative
                     study. However, for the purpose of quantitative analysis using digital humanities
                     (DH) methods and tools, it becomes imperative to formalize these concepts. The functionality
                     of DH is contingent upon the deployment of formalized concepts and models. Formalization
                     converts unstructured data into a more structured form and is applied to various fields
                     such as computer science, medicine, and mathematics. Concurrently, models serve as
                     representations created to closely examine the modeled subject, while metamodels define
                     the structure and properties of these models. Fundamentally, metamodels provide a
                     framework for the analysis and construction of models that are applicable to and beneficial
                     for a predetermined class of problems [<a class="ref" href="#tomasi2018">Tomasi 2018</a>, 173]. Formalization and models constitute essential elements in both applied and theoretical
                     DH. Michael Piotrowski defines applied DH as concerned with constructing formal models
                     for phenomena studied by their “mother disciplines” (e.g., digital history and digital literary studies) and their methodology [<a class="ref" href="#piotrowski_etal2020">Piotrowski et al. 2020</a>, 178]. Theoretical DH, on the other hand, studies the general properties of formal models
                     in the humanities at a higher level of abstraction. The objectives of these sub-fields
                     involve theoretical DH creating and studying metamodels, while applied DH apply these
                     metamodels to research questions. Documentations outlining the advantages, disadvantages,
                     challenges, and constraints of algorithms are crucial for constructing metamodels.</div>
                  
                  <div class="counter"><a href="#p2">2</a></div>
                  <div class="ptext" id="p2">Piotrowski discusses formalization and models in the humanities and DH. He contends,
                     based on the works of Gilles-Gaston Granger, that formalization in humanities not
                     only extracts structure from the unstructured through hermeneutic interpretation but
                     also invents “new structures”  [<a class="ref" href="#piotrowski2022a">Piotrowski 2022a</a>, 11]. Similarly, some disciplines, such as linguistics in humanities, have been using
                     models to study grammar [<a class="ref" href="#mccarty2004">McCarty 2004</a>]. On the contrary, formalization and modeling in DH are used to computationally operationalize
                     “scholarly arguments”  [<a class="ref" href="#ciula_etal2018">Ciula et al. 2018</a>, 347]. In order to derive “new structures”  [<a class="ref" href="#piotrowski2022a">Piotrowski 2022a</a>, 11] especially for domain-specific humanities materials using computational study, it
                     is imperative to formalize and model the materials. The absence of formalized concepts
                     and models for studying the British India colonial corpus, in this regard, hampers
                     the computational application to address humanities research questions quantitatively.</div>
                  
                  <div class="counter"><a href="#p3">3</a></div>
                  <div class="ptext" id="p3">Since “mapping and surveying have been seen as instrumental in extending” the colonizers control over land to establish their government [<a class="ref" href="#ehrlich2023">Ehrlich 2023</a>, 193]. This resulted in transcending the survey from military and geographical to granule
                     details of “natural history, political economy, and every conceivable species of inquiry into
                     native society”  [<a class="ref" href="#ehrlich2023">Ehrlich 2023</a>, 196]. The documents hence are intricate, and the format is rather non-standard as they
                     are “chaotic, if not anarchic, character”  [<a class="ref" href="#edney1997">Edney 1997</a>, 162]. In this scenario, the British India colonial corpus cannot be effectively utilized
                     for topic-specific research questions employing advanced text mining without formalizing
                     the concepts within it. For instance, in the corpus curated to study water-related
                     features in the Madras Presidency<a class="noteRef" href="#d4e223">[1]</a> in British colonial South India using DH methods, data about water is not explicitly
                     provided in most texts unless they are specifically dedicated to hydraulics. Subsequently,
                     extracting information requires strenuous close reading due to the presence of heterogeneous
                     concepts in these texts.</div>
                  
                  <div class="counter"><a href="#p4">4</a></div>
                  <div class="ptext" id="p4">For instance, <cite class="title italic">Madras District Manual Coimbatore Volume II</cite> (1898) contains diverse data about population, religion, caste, marriage, and many
                     other details, along with information about water features in Coimbatore. While it
                     serves as a comprehensive manual for the Coimbatore district, the challenge lies in
                     extracting specific water-related data from this text. Disregarding other potentially
                     relevant data is not feasible, as it may have connections with water-related information.
                     Identifying such connections or potential concepts for topic-driven questions poses
                     a challenge. Apart from this text, several others, such as <cite class="title italic">Handbook Of The Madras Presidency</cite> (1879), <cite class="title italic">Madras District Gazetteers Coimbatore District</cite> (1880), and <cite class="title italic">Report On The Administration Of The Madras Presidency</cite> During The Year 1869–70 (1870), encompass a variety of concepts, including attributes
                     relevant to water. During the curation of these texts, keyword searches were employed,
                     using terms like Coimbatore, water, canal and river etc. While this method revealed
                     information related to the specified keywords, relying solely on a corpus curated
                     through simple keyword searches presents challenges. As pointed out by Oberbichler
                     and Pfanzelter, the complexity of language “characterized by ambiguity and concepts that are difficult, if not impossible, to
                     trace by computational methods and thus keyword searches alone”  [<a class="ref" href="#oberbichler_etal2021">Oberbichler et al. 2021</a>, ¶18]. Therefore, formalizing the multifaceted concepts within the texts is imperative
                     for further computational study. In this article, the questions I ask are as follows:
                     What constitutes the optimal approach for identifying multifaceted concepts within
                     the non-standard British colonial India corpus through models, and how can these concepts
                     be formalized using formal models? How can metamodels be developed based on this experiment
                     for a similar corpus? The aim of this article is to propose proficient concept-based
                     models to formalize heterogeneous concepts from the non-standard British colonial
                     India corpus using computational models, and subsequently, to establish metamodels
                     through experimental methods for the construction and analysis of analogous corpora.</div>
                  
                  <div class="counter"><a href="#p5">5</a></div>
                  <div class="ptext" id="p5">This article is divided into six sections following this introduction. <a href="#section02">Section 2</a> focuses on the conceptual theoretical framework for constructing computational models
                     to formalize concepts. It elucidates how models can be constructed using the infrastructure
                     of the texts through concept diagrams and illustrates the model through a theoretical
                     example. <a href="#section03">Section 3</a> outlines the methodology of the experiment, encompassing preprocessing, the application
                     of computational models, and the visualization of the extracted models. <a href="#section04">Section 4</a> examines the extracted models by illustrating selected texts from the corpus to assess
                     the efficacy of the proposed models. It discusses two kinds of outcomes from the experiment:
                     one delineates the distribution of the concepts both in sub-models and primary models
                     and the other explores the features of the models. This section also includes the
                     disadvantages and challenges of the experiment. <a href="#section05">Section 5</a> delves into the metamodels using concept diagrams to develop a similar domain-specific
                     non-standard corpus. <a href="#section06">Section 6</a> presents the conclusion of this article.</div>
                  </div>
               
               
               <div id="section02" class="div div0">
                  
                  <h1 class="head">2. Creating computational models to formalize concepts in the British India colonial
                     corpus</h1>
                  
                  <div class="counter"><a href="#p6">6</a></div>
                  <div class="ptext" id="p6">Corpus building is an integral part of the machine learning process, especially when
                     dealing with a large amount of text. Oberbichler and Pfanzelter discuss the rewarding
                     nature of identifying patterns for research questions in big data using quantitative
                     methods; however, it oftentimes comes with its own intriguing challenges “to find and extract those parts in the massive data dumps that are relevant for the
                     topic in question”  [<a class="ref" href="#oberbichler_etal2021">Oberbichler et al. 2021</a>, ¶6]. As they say, identifying conceptual patterns within the British India colonial corpus
                     is notably challenging owing to its intricate content infrastructure. This infrastructure
                     exhibits variations across texts and incorporates a multitude of concepts and topics
                     which hamper the application of formal models. Given that my research focuses on extracting
                     information about water features in the corpus using computational methods, my inquiry
                     revolves around understanding the discourses related to water and water-related features.
                     Specifically, I aim to investigate the transformation of water bodies in the Coimbatore
                     region. The goal of constructing this corpus is to present pertinent headings, sections
                     of texts, and complete texts that address my research question. This will facilitate
                     further quantitative and qualitative analysis.</div>
                  
                  <div class="counter"><a href="#p7">7</a></div>
                  <div class="ptext" id="p7">Relevant methodologies for constructing and analyzing corpora based on concepts, topics,
                     indices, and representativeness can be found in DH literature [<a class="ref" href="#jahnichen2017">Jähnichen 2017</a>] [<a class="ref" href="#englmeier_etal2021">Englmeier et al. 2021</a>] [<a class="ref" href="#oberbichler_etal2021">Oberbichler et al. 2021</a>] [<a class="ref" href="#verheul_etal2022">Verheul et al. 2022</a>]. Nevertheless, building and applying formal models to examine British India colonial
                     corpus has never garnered attention within the realm of DH. The concepts embedded
                     in this historical corpus not only hold significance for comprehending the past but
                     also aid in establishing connections between the present and past. The proposed methodology
                     is designed to extract both primary and secondary heterogeneous concepts. While the
                     latter may not always be the primary focus of British India colonial manuscripts,
                     it remains relevant for topic-oriented research.</div>
                  
                  <div class="counter"><a href="#p8">8</a></div>
                  <div class="ptext" id="p8">Discussions concerning models are pivotal in the field of DH [<a class="ref" href="#mccarty2004">McCarty 2004</a>] [<a class="ref" href="#mccarty2005">McCarty 2005</a>] [<a class="ref" href="#buzzetti2002">Buzzetti 2002</a>] [<a class="ref" href="#beynon_etal2006">Beynon et al. 2006</a>] [<a class="ref" href="#flanders_etal2015">Flanders et al. 2015</a>] [<a class="ref" href="#ciula_etal2018">Ciula et al. 2018</a>]. William McCarty defines a model as “a representation of something for purposes of study or a design for realizing something
                     new”  [<a class="ref" href="#mccarty2004">McCarty 2004</a>]. This definition draws upon Clifford Geertz’s analytical differentiation between
                     a model (representation) of something, exemplified by a grammar describing the features
                     of a language, and a model (design) for something, akin to an architectural plan providing
                     design [<a class="ref" href="#mccarty2004">McCarty 2004</a>]. Typically, models inherently exhibit simplification and shed light on previously
                     unknown aspects. However, models within the humanities often maintain only partial
                     explicitness, commonly expressed informally through natural language [<a class="ref" href="#mccarty2004">McCarty 2004</a>] [<a class="ref" href="#piotrowski2019">Piotrowski 2019</a>]. In contrast, the natural and engineering sciences extensively employ explicit and
                     formal mathematical models [<a class="ref" href="#epstein2008">Epstein 2008</a>] [<a class="ref" href="#piotrowski2019">Piotrowski 2019</a>]. In the realm of computing, as Brian Smith, cited by McCarty, emphasizes, formal
                     “models are fundamental,” running by manipulating representations, always formulated in terms of models [<a class="ref" href="#mccarty2004">McCarty 2004</a>]. Concerning formal models, the term “formal,” as elucidated by Piotrowski, signifies being “logically coherent + unambiguous + explicit” and in the domain of DH, a requisite degree of formalization is crucial to enable
                     models to be processed and manipulated by computers, referred to as computational
                     models [<a class="ref" href="#piotrowski2019">Piotrowski 2019</a>]. Additionally, a metamodel, employing graphical representation and natural language
                     to elucidate the criteria and parameters essential for the computational process,
                     can inform computational model to improve the efficiency of the process. These metamodels
                     are methodically transformed into computable implementations through varying levels
                     of formality in modeling [<a class="ref" href="#ciula_etal2018">Ciula et al. 2018</a>]. While metamodeling remains relatively unexplored in DH, modeling, in general, is
                     regarded as one of the fundamental research practices in DH. Nevertheless, the goal
                     of a computational/formal model in DH is to mitigate complexity and uncertainty through
                     the logical structure of the model.</div>
                  
                  <div class="counter"><a href="#p9">9</a></div>
                  <div class="ptext" id="p9">In similar to the definition of model, the definition of a concept varies across disciplines,
                     with philosophers viewing it as an inquiry into changes manifested through various
                     events, linguists identifying concepts in onomasiological words and mapping conceptual
                     changes over different periods, and historians exploring various concepts and their
                     significant changes throughout periods in corpora using computational models [<a class="ref" href="#brigandt2010">Brigandt 2010</a>] [<a class="ref" href="#linguisticdna_nd">Linguistic DNA</a>] [<a class="ref" href="#verheul_etal2022">Verheul et al. 2022</a>]. In this context, the concept, as defined for this specific study, can be inferred
                     from the organization of words and their contextual relationships. Nonetheless, to
                     identify, trace and inquire concepts, first understanding and identifying them in
                     the corpus is imperative. In this case, the formal model plays a crucial role in formalizing
                     and extracting concepts through its logical framework which interconnects the former
                     and the latter. The concept-based formal model endeavors to capture meaningful concepts
                     by processing raw data, facilitating organization, correlation, and the establishment
                     of a semantic network among concepts. This, in turn, enables more nuanced and context-aware
                     analysis or decision-making. In this case, my goal is to formalize and extract the
                     heterogeneous concepts hidden and layered in the British India colonial manuscripts
                     using computational models.</div>
                  
                  <div class="counter"><a href="#p10">10</a></div>
                  <div class="ptext" id="p10">To formalize the concepts, given the non-standard format of the corpus, the models
                     can be divided into three kinds: sub-model, primary model, and larger model, as the
                     concepts are layered at various levels in the texts, as demonstrated in the concept
                     diagrams in Figures <a href="#figure01">1</a> and <a href="#figure02">2</a>. The concepts embedded in the content of each heading are classified as sub-models
                     and those present in the entire text are labeled as primary models (see <a href="#figure01">Figure 1</a>). The interconnection between these models can be used to develop the larger model,
                     as the similarity network drawn in the diagram (see <a href="#figure01">Figure 1</a>). For a more nuanced comprehension of the model, let us study a hypothetical elucidation
                     based on my research about the water in the colonial period. In <a href="#figure02">Figure 2</a>, number one enclosed in a red circle signifies the interconnection between the primary
                     model “rivers and channels” and a sub-model “waterbodies and canal company” derived from text 3 and 1; number two delineates the correlation between a sub-model
                     “water scarcity” and a sub-model “water infrastructure” identified in text 3 and 1; number three establishes a connection between a sub-model
                     “public and investment” and “dam construction” found in text 1 and 3; number 4 links a sub-model “water tax” and the primary model “waterbodies and canal company” observed in text 2 and 1, while number 5 designates the non-connected primary model
                     of text 2 with any of the models.</div>
                  	
                  
                  <div id="figure01" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure01.jpg" rel="external"><img src="resources/images/figure01.jpg" style="" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 1. </div>Concept-based model representing the features of both sub-model and primary model</div>
                  </div>
                  	
                  
                  <div id="figure02" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure02.jpg" rel="external"><img src="resources/images/figure02.jpg" style="" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 2. </div>A hypothetical elucidation of concept-based model</div>
                  </div>
                  	
                  
                  <div class="counter"><a href="#p11">11</a></div>
                  <div class="ptext" id="p11">During the British colonial period, the concept of water extended from the primary
                     resource for drinking, farming, and ritual entity to a taxable resource and expandable
                     colonial revenue. Such an attitude has resulted in focusing on “developing irrigation infrastructure through building larger dams” [Saravanan 2020, 37]. Ratna Reddy says “[t]he interest of the British Government in increasing public investment in irrigation
                     was to gain higher revenue”  [<a class="ref" href="#reddy1990">Reddy 1990</a>, 1047]. The colonial government approved a private entity, the Madras Canal Company, to
                     invest in irrigation projects. This Company started to focus on building bigger water
                     bodies and dams. The British colonial government “used all possible ways to extract maximum revenue in the name of irrigation development”  [<a class="ref" href="#reddy1990">Reddy 1990</a>, 1057].</div>
                  
                  <div class="counter"><a href="#p12">12</a></div>
                  <div class="ptext" id="p12">In such scenarios, the aforementioned hypothetical concepts elucidate concerns regarding
                     water during the colonial period, excluding the primary model “political and movement” from text 2. Despite the relevance of the sub-model “water tax” from text 2 to other models, the logical framework of the formal model for the primary
                     model might overlook the sub-model “water tax.” This oversight is due to the primary model being designed to extract the most crucial
                     concepts from the entire text, and the aforementioned sub-model may not be estimated
                     a pivotal concept. However, it remains pertinent to topic-driven research. For further
                     analysis, one can employ additional machine learning models for a quantitative study
                     of the selected sub-models and primary models or curate these models for a qualitative
                     study. Alternatively, the corpus can undergo reorganization by filtering texts, informed
                     by these models. In every aspect, these models contribute to our exploration, categorization,
                     and understanding of the corpus.</div>
                  </div>
               
               
               <div id="section03" class="div div0">
                  
                  <h1 class="head">3. Methodology</h1>
                  
                  <div class="counter"><a href="#p13">13</a></div>
                  <div class="ptext" id="p13">For this conceptual and theoretical framework, I chose an unsupervised approach using
                     Affinity Propagation Algorithm (APA). The APA is widely used in many diverse fields
                     for data mining such as medicine, chemistry and bioinformatics etc. Brendan J. Frey
                     and Delbert Dueck introduced APA in 2007 [<a class="ref" href="#frey_etal2007">Frey et al. 2007</a>]. It has a number of advantages compared to other clustering algorithms such as Kmeans.
                     Kmeans requires a number of clusters to group words (or in other words data points)
                     gleaned from its similarities. On the other hand, APA does not entail the number of
                     clusters and it takes “input measures of similarity between pairs of data points and [r]eal-valued messages
                     are exchanged between data points until a high-quality set of exemplars and corresponding
                     clusters gradually emerges”  [<a class="ref" href="#frey_etal2007">Frey et al. 2007</a>, 972]. If the data point i is similar (s) to the data point k which is determined through
                     negative Euclidean distance, then s(i, k) is s(i,k) = −||xi − xk||2 [<a class="ref" href="#frey_etal2007">Frey et al. 2007</a>, 972]. and Levenshtein Distance is employed to calculate the distance between data points.
                     It measures the distance between the data points based on their similarity and assigns
                     a weightage to each word.</div>
                  
                  <div class="counter"><a href="#p14">14</a></div>
                  <div class="ptext" id="p14">The communication between data points (i, k) happens through responsibility(r) and
                     availability (a). The <em class="term">r</em> on behalf of data point <em class="term">i</em> will send a message to check the a of the <em class="term">k</em> and looking for a s pattern. If <em class="term">k</em> does not have similarity, then <em class="term">i</em> will look for other data points. It is an iterative process till the data point <em class="term">i</em> finds its group and vice versa [<a class="ref" href="#frey_etal2007">Frey et al. 2007</a>, 972]. The other advantage feature of APA is “exemplar” which will be chosen as the “representative” of the cluster. For instance, if the data points (k, k) have larger values than other
                     data points in the same cluster, it will be selected to represent the cluster. APA
                     also chooses the number of clusters according to the density. This algorithm is applicable
                     to the corpus like British India colonial as we cannot presume the number of clusters
                     as the number could vary from text to text in the corpus. APA is efficient when it
                     comes to small amounts of data. I applied APA to contents in each heading of text
                     in the corpus for extracting sub models and also harnessed to each text separately
                     for mining the primary models, but not to the whole corpus.</div>
                  
                  <div class="counter"><a href="#p15">15</a></div>
                  <div class="ptext" id="p15">The corpus that I use for this article is part of an AHRC funded project “Digital Innovation in Water Scarcity” at Lancaster University in which I worked as a Research Associate. The primary aim
                     of this project is to study the water transformation from early ninetieth century
                     British India Coimbatore to present through diverse corpus of historical maps, texts
                     and oral testimonies through various innovative DH methods. The British colonial India
                     corpus is curated from various open access online platforms such as Internet Archive,
                     Google books and National Library of Calcutta. These texts are out of copyright. This
                     corpus is small and consists of 29 texts (see <a href="#figure03">Figure 3</a>). The corpus is cleaned as they were curated as PDFs and image files through third
                     party with help of project fund.</div>
                  
                  <div class="counter"><a href="#p16">16</a></div>
                  <div class="ptext" id="p16">In the preprocessing, each text in the corpus is divided into a number of parts such
                     as titles, table of contents, preface, index and body of the content. These parts
                     are marked using hyperlinks tags. These tags are used to extract table of contents
                     and body of the content. The tagged “Table of contents” and “Body of the content” are cleaned to remove the punctions and other symbols as they encumber mining the
                     clusters. However, this preprocessing has a few challenges since not all historical
                     texts are standardized using the table of contents. Three texts did not have table
                     of contents but they have headings inside the text and five texts did not have neither
                     table of contents nor headings inside the text. Since all headings inside texts are
                     in uppercase and most of the table of contents are also in uppercase. The headings
                     in <a href="#figure03">Figure 3</a> uppercase facilitated extracting their content using first heading as start and second
                     head as end.
                     	
                     	
                     <div id="figure03" class="figure">
                        		
                        		<a href="resources/images/figure03.jpg" rel="external"><img src="resources/images/figure03.jpg" style="" alt="" /></a>
                        	
                        <div class="caption">
                           <div class="label">Figure 3. </div>List of texts in the corpus</div>
                     </div>
                     
                     However, last heading, of course, would not have a subsequent heading for which I
                     added “End of the Doc” at the end of the text. Then I extracted the contents inside the headings for twenty-seven
                     texts using regular expressions. For the remaining five texts, I had to extract the
                     body of the text as there is no option to separate the content using table of contents.
                     I used loop function to run the text one by one in Python. After preprocessing, I
                     converted the extracted data into DataFrame using Pandas which later passed to APA.
                     Kmeans<a class="noteRef" href="#d4e492">[2]</a> algorithm in Sklearn is applied to predict the clusters through elbow method, which
                     is applied to “test the consistency of the best number of clusters by comparing the difference of
                     the sum of square error,” to compare the efficiency of means and APA to improve the efficiency [<a class="ref" href="#umargono_etal2020">Umargono et al. 2020</a>, 121]. The proficiency of the latter is much better than the former. I also decided to
                     extract top fifteen words in each cluster after a few trials. Finally, the data in
                     dataframe, prediction and the top features of the cluster passed into the APA’s similarity
                     function to extract clusters and exemplars for the content in each heading and the
                     entire text and both are stored into separate CSV files. Then I created three kinds
                     of visualizations using Tableau and RAW online graph: representing the total number
                     of clusters across the corpus; distinguishing between the sub-model and primary model
                     through selected two texts and visualizing the models from the selected texts for
                     further investigation.</div>
                  </div>
               
               
               <div id="section04" class="div div0">
                  
                  <h1 class="head">4. Discussion</h1>
                  	
                  
                  <div id="section04.1" class="div div1">
                     
                     <h2 class="head">Distribution of concepts in sub-model and primary model</h2>
                     
                     <div class="counter"><a href="#p17">17</a></div>
                     <div class="ptext" id="p17">Investigating the number of clusters obtained by models for both heading clusters
                        (hereafter HC) and text clusters (hereafter TC) would help us discern the complexity
                        and nature of the corpus before delving into studying the labels of the clusters.
                        Although the concepts presented in the headings are pertinent to the text, often,
                        the headings represent unique concepts that might not be traversed throughout the
                        text. In this case, when the model identifies unique words and their similarities
                        based on the distance, the output for the clusters of each heading could be greater
                        in number, as they may be unique and dense only for their respective headings, unlike
                        the entire text. Hence, <a href="#figure04">Figure 4</a>, depicting the clusters of all the HC in red and TC in blue, reveals that the former
                        outnumber the latter. However, to discern this difference, we will discuss how the
                        concepts distributed across the headings and text vary from one another through selected
                        texts from the corpus.</div>
                     	
                     
                     <div id="figure04" class="figure">
                        
                        
                        <div class="ptext"><a href="resources/images/figure04.jpg" rel="external"><img src="resources/images/figure04.jpg" style="" alt="" /></a></div>
                        
                        <div class="caption">
                           <div class="label">Figure 4. </div>The clusters of all the heading clusters in red and text cluster in blue</div>
                     </div>
                     	
                     
                     <div id="figure05" class="figure">
                        
                        
                        <div class="ptext"><a href="resources/images/figure05.jpg" rel="external"><img src="resources/images/figure05.jpg" style="" alt="" /></a></div>
                        
                        <div class="caption">
                           <div class="label">Figure 5. </div>The total heading clusters and text clusters of the texts AJMMCM and APAM</div>
                     </div>
                     	
                     
                     <div class="counter"><a href="#p18">18</a></div>
                     <div class="ptext" id="p18"><a href="#figure05">Figure 5</a> shows HC and TC of Francis Buchanan’s <cite class="title italic">A Journey from Madras Through the Countries of Mysore, Canara, and Malabar</cite> (1807) (hereafter AJMMCM) <cite class="title italic">Volume 1</cite> and <cite class="title italic">Annual Report On The Administration Of The Madras Presidency 1862–63</cite><a class="noteRef" href="#d4e540">[3]</a> (hereafter APAM). We can observe that the TC of the latter are more in number than
                        HC of the former and vice versa. Bernard Cohn states,
                        	
                        	               
                        <blockquote>
                           <p>
                              	               	For many British officials, India was a vast collection of numbers. This mentality
                              began in the early seventeenth century with the arrival of British merchants who compiled
                              and transmitted lists of products, prices, customs and duties, weights and measures,
                              and the values of various coins.
                              	               	 [<a class="ref" href="#cohn1996">Cohn 1996</a>, 8]
                              	               </p>
                        </blockquote>
                     </div>
                     	
                     
                     <div class="counter"><a href="#p19">19</a></div>
                     <div class="ptext" id="p19">As he rightly says, such numbers were used to govern and control the colonized people
                        and land as Nicholas B. Dirks, in his Foreword to Cohan’s <cite class="title italic">Colonialism And Its Forms Of Knowledge The British In India</cite>, says “[c]olonial knowledge both enabled conquest and was produced by it; in certain important
                        ways, knowledge was what colonialism was all about”  [<a class="ref" href="#cohn1996">Cohn 1996</a>, ix]. As Dirks states, the British officials were so keen in surveying and documenting
                        everything about Indian society. In the selected text AJMMCM, the Scottish surgeon
                        and botanist Buchanan surveyed the recently annexed kingdom of Mysore, Canara, and
                        Malabar in southern India at the beginning of the nineteenth century. The survey covers
                        the physical and human geography of the region, commerce, detailing agriculture, arts,
                        culture, indigenous religions, society, customs and natural history. In this Volume
                        1, he emphasizes the agricultural aspects, including irrigation systems, variety of
                        crops and their cultivation details, the condition of the soil and many more. AJMMCM
                        is divided into six long chapters with specific sub-headings. On the other hand, APAM,
                        containing thirty-six headings, offers diverse information and details on legislative,
                        judicial, criminal justice, and also topics related to forest conservancy, plantations,
                        and irrigation. The aim of AJMMCM is to survey the features of the recently annexed
                        southern regions, and the concept and theme of the text are consistent through its
                        lengthy descriptive narrative. Hence, APA found a few crucial concepts to cluster
                        for the primary model. But they clustered the unique heterogenous concepts in each
                        heading that might not be overlapped with other parts text. Conversely, APAM has numerous
                        concepts and information but is presented concisely in analytical narrative. Therefore,
                        APA could not find many clusters in the headings but, <span class="foreign i">de facto</span>, grouped many diverse concepts that appeared throughout the text.</div>
                     
                     <div class="counter"><a href="#p20">20</a></div>
                     <div class="ptext" id="p20">Nevertheless, this helps us fathom out how the concepts are distributed in each heading
                        and the entire text, which can vary. Corpas and Seghiri rightly point out that “[t]he number of tokens and/or documents a specialized corpus should contain may vary
                        in relation to the languages, domains, and textual genres involved, as well as to
                        the objectives set for a specific analysis (i.e., a corpus should provide enough evidence
                        for the researchers’ purposes and aims)”  [<a class="ref" href="#corpaspastor_etal2010">Corpas Pastor and Seghiri 2010</a>, 135]. It also brings attention to the selection of the text for building this corpus.
                        As I mentioned in the introduction, my aim is to mine the details of water in British
                        India colonial documents, particularly the documents, texts, reports, and surveys
                        of The Madras Presidency. I aggregated texts that might have any potential data about
                        water. The above-mentioned two texts, for instance, although vary in terms of their
                        rationale and aim, have much data about water.</div>
                     </div>
                  
                  
                  <div id="section04.2" class="div div1">
                     
                     <h2 class="head">Studying the models</h2>
                     
                     <div class="counter"><a href="#p21">21</a></div>
                     <div class="ptext" id="p21">To comprehend the semantics of the mined clusters, I explored the labels of clusters
                        and its exemplar feature of APA. According to Frey and Dueck, “[a] common approach is to utilize data to learn a set of centers such that the sum
                        of squared errors between data points and their nearest centers is small. When the
                        centers are chosen from actual data points, they are referred to as ‘exemplars’”  [<a class="ref" href="#frey_etal2007">Frey et al. 2007</a>, 972]. Exemplars serve as representatives of their respective clusters and also help us
                        to build the semantic model of clusters. However, a comprehensive exploration of the
                        entire labels of clusters and exemplars extends beyond the scope of this article;
                        therefore, I will closely study AJMMCM. The potential sub-models derived from the
                        six chapters of AJMMCM encompass fanams, farmer, irrigation, drugs, fades, fair, iron,
                        turban, canara, cloth, cubits, oil, prey, weavers, crop, zemindars, extent, and july
                        (see <a href="#figure06">Figure 6</a>). These exemplars and their clusters succinctly encapsulate the distinct concepts
                        of AJMMCM. For instance, the exemplars fanams, fades, cloth, turbans, and weaver and
                        their significant clustered terms such as families, brahmans, devangas, villages,
                        natives, strata, customs, cotton, silver<a class="noteRef" href="#d4e592">[4]</a> etc. from Chapters 1, 3 and 4 signify Buchanan’s survey of social and cultural milieus
                        of southern India. These models hold relevance for research inquiries concerning socio-cultural
                        settings in southern India. Similarly, the exemplars irrigation, july, crop, harulu,
                        farmers, cultivation, extent, country, and zemindars and their clustered terms such
                        as ragy, casts, seed, rice, corn, buffalo, water, field, straw, plough, soil, barugu,
                        weights, grain, sugar, bees, tobacco<a class="noteRef" href="#d4e594">[5]</a> etc.  from all six chapters convey Buchanan’s detailed study of the agricultural
                        system in the southern regions. These models offer valuable insights for research
                        related to environmental, agrarian, and economic history.</div>
                     
                     <div class="counter"><a href="#p22">22</a></div>
                     <div class="ptext" id="p22">It is crucial to acknowledge that these exemplars should not be entirely relied upon,
                        as they do not serve as either the topic or title of the clusters; instead, they merely
                        function as representatives. They provide only a glimpse into the clusters. To comprehend
                        the model, one must delve into the terms of the clusters. Moreover, not all exemplars
                        are truly useful and provide an immediate sense of the clusters. For instance, in
                        the previously mentioned exemplars, terms such as extent, fades, and july did not
                        contribute any meaningful sense to construct the concepts. However, a meticulous examination
                        of the terms of these exemplars, including customs, measures, plough, sows, sesame,
                        palm gardens, cultivation, soil, bushes, jola, barugu, etc., once again signifies
                        the extended discussion on the agrarian culture of the regions. For example, in the
                        quotes below, Buchanan explains the crop of Jola, its kinds, and cultivation.</div>
                     	            
                     <blockquote>
                        <p class="ptext">
                           		Of these crops Jola (Holcus sorghum) is the greatest. There are two kinds of it, the
                           white and the red which are sometimes kept separate, and sometimes sown mixed. The
                           red is the most common. Immediately after cutting the Vaisaka, crop: of, rice, plough
                           four times in the course of twenty days.
                           		 [<a class="ref" href="#buchanan1807">Buchanan 1807</a>, 283]
                           	            </p>
                     </blockquote>
                     	
                     
                     <div id="figure06" class="figure">
                        
                        
                        <div class="ptext"><a href="resources/images/figure06.jpg" rel="external"><img src="resources/images/figure06.jpg" style="" alt="" /></a></div>
                        
                        <div class="caption">
                           <div class="label">Figure 6. </div>Sub-models of the chapters of the text AJMMCM</div>
                     </div>
                     	
                     
                     <div class="counter"><a href="#p23">23</a></div>
                     <div class="ptext" id="p23">There are nine clusters in the primary model and the important exemplars are barugu,
                        extract, fair, famine, harica<a class="noteRef" href="#d4e617">[6]</a>, water etc. (see <a href="#figure07">Figure 7</a>). These representees and their terms such as rice, fanam, sugarcane, cultivation,
                        irrigation, jola, ragy, july, bushes, plough, seed, trade, dry, land etc. indeed convey
                        the agricultural facets which is the primary concept of the text. Although the close
                        study of the terms presented in the model can be associated with the pivotal concept
                        of the text, the nuanced heterogenous concepts extracted in the sub-model have been
                        disregarded in the primary model.</div>
                     	
                     
                     <div id="figure07" class="figure">
                        
                        
                        <div class="ptext"><a href="resources/images/figure07.jpg" rel="external"><img src="resources/images/figure07.jpg" style="" alt="" /></a></div>
                        
                        <div class="caption">
                           <div class="label">Figure 7. </div>Primary models of the text AJMMCM</div>
                     </div>
                     	
                     
                     <div class="counter"><a href="#p24">24</a></div>
                     <div class="ptext" id="p24">For example, Buchanan demonstrated a keen interest in surveying autochthonous resources,
                        as manifested in exemplars such as drugs, oil, and iron. The text features subheadings
                        specifically addressing these resources. The term drug occurs 11 times, oil 111 times,
                        and iron 68 times in the text. Nevertheless, in the clustered terms of the primary
                        model, oil appears 5 times, and iron appears once. Remarkably, the term drug does
                        not appear at all due to its dense paucity.</div>
                     	
                     			
                     <blockquote>
                        <p class="ptext">
                           				<span class="label bold">Drugs. </span>A kind of drug merchants at Bangalore, called Gandhaki, trade to a considerable extent.
                           Some of them are Banijigaru, and others are Ladaru, a kind of Mussulmans. They procure
                           the medicinal plants of the country by means of a set of people called Pacanat Jogalu,
                           who have huts in the woods, and, for leave to collect the drugs, pay a small rent
                           to the Gaudas of the villages. They bring the drugs hither in small caravans of tea
                           or twelve oxen, and sell them to the Gandhaki, who retail them. None of them are exported.
                           				 [<a class="ref" href="#buchanan1807">Buchanan 1807</a>, 204]
                           			</p>
                     </blockquote>
                     	
                     
                     <div class="counter"><a href="#p25">25</a></div>
                     <div class="ptext" id="p25">In the above excerpt, Buchanan elucidates the procurement process of drugs by Gandhaki,
                        drug merchants in Bengaluru, from local suppliers Pacanat Jogalu, who gather them
                        in the woods. Additionally, he provides a detailed explanation of the manufacturing,
                        trade, and application of various oils, including coconut oil, sesame oil, castor
                        oil, bassia oil, and hoingay oil. Likewise, Buchanan delves into the examination of
                        natural minerals. In a subsequent passage, he narrates how a specific local community
                        acquires materials for iron manufacturing and he dedicates a substantial portion in
                        Chapter 3 to elucidate the comprehensive iron production process.</div>
                     	
                     			
                     <blockquote>
                        <p class="ptext">
                           				<span class="label bold">Iron forges. </span>About two miles from Naiekan Eray, a torrent, in the rainy season, brings down from
                           the hills a quantity of iron ore in the form of black sand, which in the dry season
                           is smelted. The operation is performed by Malawanlu, the Telinga name for the cast
                           called Parriar by the natives of Madras. Each forge pays a certain quantity of iron
                           for permission to carry on the work.
                           				 [<a class="ref" href="#buchanan1807">Buchanan 1807</a>]
                           			</p>
                     </blockquote>
                     
                     
                     <div class="counter"><a href="#p26">26</a></div>
                     <div class="ptext" id="p26">Owing to the extensive discussions on these resources within the Chapters, APA has
                        selected drugs, oil, and iron clusters based on their density in the corresponding
                        headings in the sub-model. These diverse concepts were disregarded in the primary
                        model. On the contrary, as detailed in the <a href="#section04.1">initial subsection</a> of this section, certain texts exhibit more clusters in the primary model than in
                        the sub-model, or in the case of the APAM, wherein crucial concepts like “settlement” have been omitted from its sub-model. Nevertheless, when scrutinizing the British
                        colonial India corpus, the integration of these models demonstrates greater efficacy
                        in formalizing the heterogeneous concepts.</div>
                     
                     <div class="counter"><a href="#p27">27</a></div>
                     <div class="ptext" id="p27">The model, in general, designed to identify overarching patterns in the data. However,
                        it is imperative to incorporate the sub-model in the exploration. Theoretical DH should
                        address these crucial considerations in the characteristics of formal models for examining
                        a complex corpus. Nevertheless, building computational models to extract primary and
                        sub-modes was quite challenging as big data models, in general, are significantly
                        utilized to discern trends within the data to generate novel insights [<a class="ref" href="#bhattacharyya2017">Bhattacharyya 2017</a>]. The data models might neglect non-trends that still constitute part of the data.
                        Sayan Bhattacharya conducted an experiment utilizing the Bookworm tool, designed to
                        visualize language usage trends within millions of digitized texts in HathiTrust.
                        He contends that the model, crafted to explore and visualize language usage trends,
                        has a limitation in identifying “words from less hegemonic languages”  [<a class="ref" href="#bhattacharyya2017">Bhattacharyya 2017</a>, 34]. He illustrates his argument by showcasing underreported transliterated words (English)
                        from Global South languages and delves into the causes behind such limitations<a class="noteRef" href="#d4e671">[7]</a>. Indeed, the issue stems from tools like HathiTrust Bookworm relying on an index
                        that, for performance reasons, excludes entries for low-frequency words. This disproportionately
                        impacts the representation of low-frequency words in larger collections.</div>
                     
                     <div class="counter"><a href="#p28">28</a></div>
                     <div class="ptext" id="p28">This is applicable when studying corpora like British colonial India, as less trendy
                        concepts are overshadowed by the trend concepts within the text in both models. Unlike
                        digital tools, which do not permit alterations to their frameworks, computational
                        models can be manipulated to formalize these less-trendy concepts in the corpus. Hence,
                        the amalgamation of primary and sub-models proves advantageous in studying and formalizing
                        the heterogeneous concepts within the British colonial India corpus as demonstrated
                        using the selected text AJMMCM. I can reorganize the texts in the corpus based on
                        the formalized concepts and apply formal models for further investigation.</div>
                     </div>
                  
                  
                  <div id="section04.3" class="div div1">
                     
                     <h2 class="head">Disadvantages, challenges and future work</h2>
                     
                     <div class="counter"><a href="#p29">29</a></div>
                     <div class="ptext" id="p29">Numerous issues were encountered during the experiment, including problems with text
                        format, non-standard text, parameters for cleaning texts, and limitations in the selected
                        algorithm. The first issue arose from tagging the table of contents. Some texts lacked
                        a table of contents but had headings inside the text, while others had neither. Separate
                        algorithms were designed for each case. The second issue was the exclusion of stemming<a class="noteRef" href="#d4e686">[8]</a> and lemmatization despite removing stop words. These processes could impact clustering,
                        especially sub-models derived from a few paragraphs or pages. Lemmatization might
                        reduce counts and, additionally, the inconsistent content distribution across headings,
                        with some having only one or two paragraphs, led to an increase in outliers<a class="noteRef" href="#d4e699">[9]</a>. Spelling variation in Indian names and place names posed another challenge. For
                        instance, the river name “Noyal” had various spellings like “Noyil,” “Noel,” and “Noyl” affecting frequency and clustering patterns.</div>
                     
                     <div class="counter"><a href="#p30">30</a></div>
                     <div class="ptext" id="p30">Another challenge is the inclusion of footnotes and references running throughout
                        most texts. There are many terms and exemplars derived from these ciations. APA accumulated
                        many outliers, such as “separately,” which did not contribute explicitly to clustering concepts, but indicated numerous
                        tables attached separately with the content. Subsequently, I excluded tables, prioritizing
                        the narrative over statistics in The Madras Presidency reports. Involving grain details,
                        surveyors included various statistics — crops, revenue, a census of houses, and population
                        categorized by religion, castes, and more. These details are crucial for event-based
                        research questions and should be formalized in future work. Another limitation is
                        in the chosen algorithm, APA, with constraints like “high time complexity” for larger datasets. On the FAQ page for Affinity Propagation, Frey and his team
                        addressed dataset size concerns, assuring APA’s reliability for small datasets. For
                        instance, they answered a question: “Is affinity propagation only good at finding a large number of quite small clusters?” Their answer is:</div>
                     
                     <div class="counter"><a href="#p31">31</a></div>
                     <div class="ptext" id="p31">It depends on what you mean by “large” and “small”. For example, it beats other methods at finding 100 clusters in 17,770 Netflix movies.
                        While “100” may seem like a large number of clusters, it is not unreasonable to think that there
                        may be 100 distinct types of movies. Also, on average there are 178 points per cluster,
                        which is not “quite small”. However, if you’re looking for just a few clusters (eg, 1 to 5), you’d probably
                        be better off using a simple method [<a class="ref" href="#affinity2009">Affinity Propagation FAQ 2009</a>].</div>
                     
                     <div class="counter"><a href="#p32">32</a></div>
                     <div class="ptext" id="p32">In this case, APA was suitable for sub-models and should also work for primary models
                        since I mined the latter per text, which is not indeed a large dataset. However, it
                        did not select potential exemplars for all primary models due to inconsistency in
                        dissemination of the concepts.</div>
                     </div>
                  
                  </div>
               
               
               <div id="section05" class="div div0">
                  
                  <h1 class="head">5. Metamodel for concept-based corpus building</h1>
                  
                  <div class="counter"><a href="#p33">33</a></div>
                  <div class="ptext" id="p33">In the realm of computer science and related fields, a metamodel has surfaced, serving
                     the purpose of “facilitating conceptual modeling, defining constructs of conceptual modeling languages,
                     specifying constraints on the use of constructs, and encoding the similarities of
                     different models”  [<a class="ref" href="#jeusfeld2009">Jeusfeld 2009</a>, 1728]. Jeusfeld characterizes a metamodel as encompassing several models that include models,
                     parameters, features, challenges, and limitations. Metamodels are designed “to build explicit” models, which are meticulously delineated to enable a thorough understanding of their
                     contents [<a class="ref" href="#epstein2008">Epstein 2008</a>]. Their significance in theoretical DH lies in facilitating a computational approach
                     to studies in the humanities. Piotrowski underscores the importance of metamodels
                     in theoretical DH, asserting that “the theoretical digital humanities create and study the metamodels whose concrete
                     application to research questions in the disciplines of the humanities is the object
                     of the applied DH”  [<a class="ref" href="#piotrowski2022a">Piotrowski 2022a</a>, 3].</div>
                  
                  <div class="counter"><a href="#p34">34</a></div>
                  <div class="ptext" id="p34">In the absence of an existing metamodel for the non-standard corpus to formalize the
                     concepts within theoretical DH, I have formulated one based on processes, results,
                     experiments, and experiences and represented it through concept diagrams. This metamodel
                     is poised to significantly contribute to similar corpus-building research, serving
                     as a valuable resource to improve future endeavors by addressing errors noted during
                     experimentation and redesigning for enhanced comprehension.</div>
                  
                  <div class="counter"><a href="#p35">35</a></div>
                  <div class="ptext" id="p35">Model 1 provides a detailed depiction of the corpus selection and pre-processing (see
                     <a href="#figure08">Figure 8</a>). Establishing a corpus involves the construction of a model. Consequently, modelers
                     must address inquiries such as: What constitutes the original? In what ways does the
                     model serve as a reduction of it? And for whom and for what purpose is the model being
                     created? [<a class="ref" href="#piotrowski2022b">Piotrowski 2022b</a>, 90]. Curating texts for a corpus pose significant challenges, including considerations
                     about the collection of texts, copyright status, and existing machine-readable formats
                     for materials. Despite this, the curated corpus is primarily guided by a general understanding
                     of the research field. Consequently, eliminating the most and/or less relevant materials
                     from the corpus is neither straightforward nor transparent. Subsequently, preprocessing
                     becomes a crucial step in Model 1, marking the initial phase of any quantitative study.
                     The texts should not only be in machine-readable formats (such as plain texts or PDF
                     files) but also formalized using Text Encoding Initiative or hyperlink tags, particularly
                     essential for non-standard corpus. A notable challenge in digital humanities methods
                     for historical corpus is the presence of spelling variations in the text [<a class="ref" href="#gregory2014">Gregory 2014</a>]. Acknowledging the impact of spelling issues on the models is paramount. Being cognizant
                     about the influence of spelling issues in the models is pivotal. The nature of the
                     research inquiry will determine whether the texts in the corpus necessitate deep cleaning,
                     involving not only the removal of stop words but also stemming and lemmatization of
                     words, significantly influencing the results in the subsequent model.</div>
                  	
                  
                  <div id="figure08" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure08.jpg" rel="external"><img src="resources/images/figure08.jpg" style="" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 8. </div>Model 1</div>
                  </div>
                  	
                  
                  <div id="figure09" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure09.jpg" rel="external"><img src="resources/images/figure09.jpg" style="" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 9. </div>Model 2</div>
                  </div>
                  	
                  
                  <div class="counter"><a href="#p36">36</a></div>
                  <div class="ptext" id="p36">Model 2 delineates the parameters and criteria governing the construction of the corpus
                     through concept-based models (see <a href="#figure09">Figure 9</a>). The determination of whether to ground sub-models and/or primary models is contingent
                     upon event- or topic-based research inquiries. Additionally, the choice between a
                     single algorithm or a combination of algorithms for extracting concepts and their
                     models significantly influences the selection of relevant texts for the corpus. The
                     decision is also influenced by the nature of the research, as mining sub-models may
                     be appropriate for some topic-driven research, while extracting both sub-models and
                     primary models may be essential for others. In cases where the corpus is intricate
                     and comprises various forms and genres, such as documents, surveys, and reports, building
                     the corpus based on both sub-models and primary models is deemed more fruitful. However,
                     the selection of appropriate algorithms is crucial, as it determines the outcome of
                     the quantitative study.</div>
                  
                  <div class="counter"><a href="#p37">37</a></div>
                  <div class="ptext" id="p37">Moreover, the process of choosing models to represent concepts is pivotal and can
                     be achieved either manually or through an algorithm. For example, if one opts for
                     APA due to its exemplar feature, which is significant for the corpus used in this
                     article, relying on a single exemplar from the cluster may sometimes be misleading.
                     This bias arises as the concept is determined based on the preferred representative,
                     leading to potential distortion. To mitigate this bias, selecting multiple exemplars
                     based on the density of the cluster will, to a certain extent, evade this issue in
                     concept-based models. However, this model presents other potential challenges, such
                     as running headings on each page and an increase in the number of outliers due to
                     fewer words in the content of the headings. Setting parameters to deriving concepts
                     and models for headings with only a few sentences can address this issue; however,
                     it may also result in the neglect of crucial data. Decisions regarding such trade-offs
                     can be made through a process of trial and error.</div>
                  	
                  	 
                  <div id="figure10" class="figure">
                     
                     
                     <div class="ptext"><a href="resources/images/figure10.jpg" rel="external"><img src="resources/images/figure10.jpg" style="" alt="" /></a></div>
                     
                     <div class="caption">
                        <div class="label">Figure 10. </div>Model 3</div>
                  </div>
                  
                  
                  <div class="counter"><a href="#p38">38</a></div>
                  <div class="ptext" id="p38">Model 3 outlines the parameters for developing a larger model for the corpus (see
                     <a href="#figure10">Figure 10</a>). Larger models can be generated from three types of datasets: sub-model, primary
                     model, and standalone model. It can be created through a identifying the semantic
                     network between sub-models and primary models. Such semantic network can also be employed
                     to reorgainze the texts in the corpus based on the priority and to develop a sub-corpus.
                     Comparing the three models would be worthwhile to explore the dispersal of concepts
                     and their models throughout the corpus.</div>
                  </div>
               
               
               <div id="section06" class="div div0">
                  
                  <h1 class="head">6. Conclusion</h1>
                  
                  <div class="counter"><a href="#p39">39</a></div>
                  <div class="ptext" id="p39">The British colonial India corpus, which has not received attention in the field of
                     DH, poses considerable challenges and drawbacks due to its intricate format and diverse
                     concepts. This research seeks to confront these challenges by introducing concept-based
                     formal models designed to formalize the heterogeneous concepts present in corpus,
                     leveraging computational methods. In summary, this study illustrates the potential
                     and challenges inherent in the development and application of formal models for the
                     specified corpus. Derived from the investigation, several promising findings emerge:
                     	
                     	            
                     <ol class="list">
                        <li class="item">Quantitative studies in DH typically prioritize the identification of trend patterns
                           within a corpus. However, the computational approach proposed in this work assigns
                           equal importance to both trend and non-trend patterns in the text, as the latter also
                           significantly contributes to shaping the overall trend pattern. This stands in contrast
                           to traditional approaches to studying historical concepts, which often rely on limited
                           texts through qualitative studies or use computational methods to identify broader
                           conceptual patterns. The recommended model enables a comprehensive study of concepts,
                           even within extensive datasets.</li>
                        <li class="item">Additionally, the concept-based model emerges as a convincing and promising framework,
                           not only illustrating how concepts are distributed across the text and its headings
                           but also capable of formalizing nuanced concepts to construct a more comprehensive
                           model. The construction of the concept involves studying exemplars and their associated
                           terms, underscoring the significance of domain knowledge in the decision-making process.
                           Nevertheless, this model introduces a novel computational approach to trace concepts
                           and provides insight into the curation of colonial knowledge.</li>
                        <li class="item">The application of the theoretical framework, as outlined in <a href="#section02">Section 2</a>, is highly effective in exploring the chosen corpus. This model proposes to categorize
                           the text into two types: the text itself and the units of the text based on its peritext.
                           The development of formal models can be accomplished using this categorization. However,
                           as mentioned in <a href="#section03">Section 3</a>, some challenges arose in these divisions, as a few texts could not be segmented
                           into units due to the absence of peritext. Nevertheless, these challenges were addressed
                           by manipulating the formal models to extract units based on categorization within
                           the text (headings).</li>
                        <li class="item">The analysis in <a href="#section04">Section 4</a> reveals that the number of models between sub-models and primary models may vary
                           based on the distribution of concepts within the unit and the text. The examination
                           of the extracted models from the chosen text underscores the significance of the sub-model
                           in deriving nuanced concepts from the text, which are overlooked in the primary model
                           and vice versa. However, in the process of constructing and studying the corpus for
                           topic-specific research, both models are indispensable and can mutually enhance exploration
                           of the concepts within the text, aligning with the primary objective of this proposed
                           model.</li>
                        <li class="item">Lastly, <a href="#section05">Section 5</a> delineates the metamodels, a facet not prioritized in theoretical DH. Derived from
                           the experiment, it provides insights into the general properties, possibilities, and
                           challenges involved in studying a similar corpus.</li>
                     </ol>
                  </div>
                  	
                  
                  <div class="counter"><a href="#p40">40</a></div>
                  <div class="ptext" id="p40">The findings of this article propose several directions for future research:
                     	
                     	            
                     <ol class="list">
                        <li class="item">The current corpus is relatively modest in size. In subsequent work, an expansion
                           of the corpus by curating additional texts is planned and the texts will be categorized
                           based on its forms and genres, including documents, surveys, and reports. Moreover,
                           the adoption of TEI guidelines to generate tags for the texts will be considered.
                           Systematic categorization and tagging systems aim to enhance the formalization process.</li>
                        <li class="item">While the APA computational algorithm demonstrates efficacy for the proposed model,
                           there are limitations in the exemplar features and clustering patterns, notably a
                           surge in outliers, and not all exemplars convey meaningful insights. Future investigations
                           will explore alternative advanced computational models or combinations thereof to
                           achieve more efficient pattern clustering. Additionally, efforts will be made to fine-tune
                           parameters for extracting more than one exemplar per cluster based on content density.</li>
                        <li class="item">The next research focus involves formalizing the spelling of Indian names. As highlighted
                           in the <a href="#section04.3">final subsection</a> of Section 4, a considerable number of Indian names did not appear in the cluster
                           due to inconsistencies in their spellings. Ongoing efforts are dedicated to addressing
                           this issue, with a specific emphasis on formalizing concepts based on Indian names
                           [<a class="ref" href="#shanmugapriya2023">Shanmugapriya 2023</a>].</li>
                     </ol>
                  </div>
                  </div>
               	
               	
               <div class="div div0">
                  		
                  <h1 class="head">Acknowledgements</h1>
                  		
                  <div class="counter"><a href="#p41">41</a></div>
                  <div class="ptext" id="p41">I express my gratitude to Mohanapriya, the software trainer, for her assistance in
                     preparing the codes for the entire project. Many thanks to Bhavani Raman, a historian
                     at the University of Toronto Scarborough, for providing valuable insights into the
                     format and non-standard nature of the British colonial India corpus. I am also thankful
                     to the AHRC for funding the “Digital Innovation in Water Scarcity Coimbatore India” project, through which the corpus was collected and cleaned using project funds.
                     Additionally, I appreciate Deborah Sutton, who served as the Principal Investigator
                     of this project at Lancaster University.</div>
                  	</div>
               
               
               	
               
               
               
               </div>
            
            <div id="notes">
               <h2>Notes</h2>
               <div class="endnote" id="d4e223"><span class="noteRef lang en">[1] The Madras Presidency was one of the subdivisions of British India. It covered most
                     part of the southern states. It was divided into five districts after the independence,
                     namely Erode, Coimbatore, Karur and Tirupur.</span></div>
               <div class="endnote" id="d4e492"><span class="noteRef lang en">[2] I used kmeans to explore through prediction to compare and verify the efficiency of
                     APA.</span></div>
               <div class="endnote" id="d4e540"><span class="noteRef lang en">[3] The author’s name was not mentioned in the document.</span></div>
               <div class="endnote" id="d4e592"><span class="noteRef lang en">[4] The Brahmans and Devangas are cast in South India.</span></div>
               <div class="endnote" id="d4e594"><span class="noteRef lang en">[5] Harulu refers to Ricinus and Ragi and Barugu are primary millets in South Indian regions.</span></div>
               <div class="endnote" id="d4e617"><span class="noteRef lang en">[6] Harica is also a kind of millet in South India.</span></div>
               <div class="endnote" id="d4e671"><span class="noteRef lang en">[7] Besides the limitation of the tool, Bhattacharya also discusses other reasons such
                     as spelling inconsistencies and optical character recognition issues in digitized
                     texts from the Global South impacted the frequency of the transliterated words [<a class="ref" href="#bhattacharyya2017">Bhattacharyya 2017</a>, 36].</span></div>
               <div class="endnote" id="d4e686"><span class="noteRef lang en">[8] Stemming and lemma are text normalization methods used in Natural Language Processing.
                     The former is applied to remove the affixes of the word, for example, the stem of
                     “reading” and “reads” is “read.” The latter is used to find the root words for instance, the lemma of the word “went” is “go.” </span></div>
               <div class="endnote" id="d4e699"><span class="noteRef lang en">[9] If the cluster has only one word, it is known as outlier as it has a “minimal membership proportion”  [<a class="ref" href="#evans_etal2015">Evans et al. 2015</a>, 2]</span></div>
            </div>
            <div id="worksCited">
               <h2>Works Cited</h2>
               <div class="bibl"><span class="ref" id="affinity2009"><!-- close -->Affinity Propagation FAQ 2009</span> “Affinity Propagation FAQ.” (2009) <cite class="title italic">Probabilistic and Statistical Inference Group University of Toronto</cite>. Available at: <a href="http://genes.toronto.edu/affinitypropagation/faq.html" onclick="window.open('http://genes.toronto.edu/affinitypropagation/faq.html'); return false" class="ref">http://genes.toronto.edu/affinitypropagation/faq.html</a> (Accessed: 5 October 2022).</div>
               <div class="bibl"><span class="ref" id="beynon_etal2006"><!-- close -->Beynon et al. 2006</span> Beynon, M., Russ, S. and McCarty, W. (2006) “Human Computing — Modelling with Meaning,” <cite class="title italic">Literary and Linguistic Computing</cite>, 21(2), pp. 141–157. Available at: <a href="https://doi.org/10.1093/llc/fql015" onclick="window.open('https://doi.org/10.1093/llc/fql015'); return false" class="ref">https://doi.org/10.1093/llc/fql015</a>.</div>
               <div class="bibl"><span class="ref" id="bhattacharyya2017"><!-- close -->Bhattacharyya 2017</span> Bhattacharyya, S. (2017) “Words in a world of scaling-up:: Epistemic normativity and text as data,” <cite class="title italic">Sanglap: Journal of Literary and Cultural Inquiry</cite>, 4(1), pp. 31–42. Available at: <a href="https://sanglap-journal.in/index.php/sanglap/article/view/86" onclick="window.open('https://sanglap-journal.in/index.php/sanglap/article/view/86'); return false" class="ref">https://sanglap-journal.in/index.php/sanglap/article/view/86</a> (Accessed: 27 November 2023).</div>
               <div class="bibl"><span class="ref" id="brigandt2010"><!-- close -->Brigandt 2010</span> Brigandt, I. (2010) “The epistemic goal of a concept: accounting for the rationality of semantic change
                  and variation,” <cite class="title italic">Synthese</cite>, 177(1), pp. 19–40. Available at: <a href="https://www.jstor.org/stable/40985618" onclick="window.open('https://www.jstor.org/stable/40985618'); return false" class="ref">https://www.jstor.org/stable/40985618</a> (Accessed: 20 November 2022).</div>
               <div class="bibl"><span class="ref" id="buchanan1807"><!-- close -->Buchanan 1807</span> Buchanan, F. (1807) <cite class="title italic">A Journey From Madras Through The Countries Of Mysore, Canara, And Malabar Volume
                     1</cite>. London: The Directors Of The East India Company.</div>
               <div class="bibl"><span class="ref" id="buzzetti2002"><!-- close -->Buzzetti 2002</span> Buzzetti, D. (2002) “Digital Representation and the Text Model,” <cite class="title italic">New Literary History</cite>, 33(1), pp. 61–88. Available at: <a href="https://www.jstor.org/stable/20057710" onclick="window.open('https://www.jstor.org/stable/20057710'); return false" class="ref">https://www.jstor.org/stable/20057710</a> (Accessed: 5 November 2023).</div>
               <div class="bibl"><span class="ref" id="ciula_etal2018"><!-- close -->Ciula et al. 2018</span> Ciula, A. et al. (2018) “Models and Modelling between Digital and Humanities: Remarks from a Multidisciplinary
                  Perspective,” <cite class="title italic">Historical Social Research</cite>, 43(4), pp. 343–361. Available at: <a href="https://doi.org/10.12759/hsr.43.2018.4.343-361" onclick="window.open('https://doi.org/10.12759/hsr.43.2018.4.343-361'); return false" class="ref">https://doi.org/10.12759/hsr.43.2018.4.343-361</a>.</div>
               <div class="bibl"><span class="ref" id="cohn1996"><!-- close -->Cohn 1996</span> Cohn, B.S. (1996) <cite class="title italic">Colonialism &amp; Its Forms of Knowledge – the British in India</cite>. Princeton, NJ: Princeton University Press.</div>
               <div class="bibl"><span class="ref" id="corpaspastor_etal2010"><!-- close -->Corpas Pastor and Seghiri 2010</span> Corpas Pastor, G. and Seghiri, M. (2010) <cite class="title italic">Size matters: A quantitative approach to corpus representativeness</cite>. León: Universidad de León, Área de Publicaciones, 2010. Available at: <a href="https://buleria.unileon.es/handle/10612/4752" onclick="window.open('https://buleria.unileon.es/handle/10612/4752'); return false" class="ref">https://buleria.unileon.es/handle/10612/4752</a> (Accessed: 7 November 2022).</div>
               <div class="bibl"><span class="ref" id="edney1997"><!-- close -->Edney 1997</span> Edney, M. H. (1997) <cite class="title italic">Mapping an Empire: The Geographical Construction of British India 1765–1843</cite>. Chicago: University of Chicago Press.</div>
               <div class="bibl"><span class="ref" id="ehrlich2023"><!-- close -->Ehrlich 2023</span> Ehrlich, J. (2023) <cite class="title italic">The East India Company and the Politics of Knowledge</cite>. Cambridge University Press. Available at: <a href="https://doi.org/10.1017/9781009367967" onclick="window.open('https://doi.org/10.1017/9781009367967'); return false" class="ref">https://doi.org/10.1017/9781009367967</a>.</div>
               <div class="bibl"><span class="ref" id="englmeier_etal2021"><!-- close -->Englmeier et al. 2021</span> Englmeier, T. et al. (2021) “Using an Advanced Text Index Structure for Corpus Exploration in Digital Humanities,” 15(1). Available at: <a href="https://www.digitalhumanities.org/dhq/vol/15/1/000526/000526.html" onclick="window.open('https://www.digitalhumanities.org/dhq/vol/15/1/000526/000526.html'); return false" class="ref">https://www.digitalhumanities.org/dhq/vol/15/1/000526/000526.html</a> (Accessed: 8 November 2022).</div>
               <div class="bibl"><span class="ref" id="epstein2008"><!-- close -->Epstein 2008</span> Epstein, J.M. (2008) “Why Model?”, <cite class="title italic">Journal of Artificial Societies and Social Simulation</cite>, 11(4). Available at: <a href="https://www.jasss.org/11/4/12.html" onclick="window.open('https://www.jasss.org/11/4/12.html'); return false" class="ref">https://www.jasss.org/11/4/12.html</a> (Accessed: 8 October 2022).</div>
               <div class="bibl"><span class="ref" id="evans_etal2015"><!-- close -->Evans et al. 2015</span> Evans, K., Love, T. and Thurston, S.W. (2015) “Outlier Identification in Model-Based Cluster Analysis,” <cite class="title italic">Journal of Classification</cite>, 32(1), pp. 63–84. Available at: <a href="https://doi.org/10.1007/s00357-015-9171-5" onclick="window.open('https://doi.org/10.1007/s00357-015-9171-5'); return false" class="ref">https://doi.org/10.1007/s00357-015-9171-5</a>.</div>
               <div class="bibl"><span class="ref" id="flanders_etal2015"><!-- close -->Flanders et al. 2015</span> Flanders, J. and Jannidis, F. (2015) <cite class="title italic">Knowledge Organization and Data Modeling in the Humanities</cite>. Available at: <a href="http://www.wwp.northeastern.edu/outreach/conference/kodm2012/index.html" onclick="window.open('http://www.wwp.northeastern.edu/outreach/conference/kodm2012/index.html'); return false" class="ref">http://www.wwp.northeastern.edu/outreach/conference/kodm2012/index.html</a> (Accessed: 8 November 2023).</div>
               <div class="bibl"><span class="ref" id="frey_etal2007"><!-- close -->Frey et al. 2007</span> Frey, B.J. and Dueck, D. (2007) “Clustering by Passing Messages Between Data Points,” <cite class="title italic">Science</cite>, 315(5814), pp. 972–976. Available at: <a href="https://doi.org/10.1126/science.1136800" onclick="window.open('https://doi.org/10.1126/science.1136800'); return false" class="ref">https://doi.org/10.1126/science.1136800</a>.</div>
               <div class="bibl"><span class="ref" id="gregory2014"><!-- close -->Gregory 2014</span> Gregory, I. (2014) “Challenges and Opportunities for Digital History,” <cite class="title italic">Frontiers in Digital Humanities</cite>, 1. Available at: <a href="https://www.frontiersin.org/articles/10.3389/fdigh.2014.00001" onclick="window.open('https://www.frontiersin.org/articles/10.3389/fdigh.2014.00001'); return false" class="ref">https://www.frontiersin.org/articles/10.3389/fdigh.2014.00001</a> (Accessed: 8 November 2022).</div>
               <div class="bibl"><span class="ref" id="jeusfeld2009"><!-- close -->Jeusfeld 2009</span> Jeusfeld, M.A. (2009) “Metamodel,” in L. LIU and M.T. ÖZSU (eds) <cite class="title italic">Encyclopedia of Database Systems</cite>. Boston, MA: Springer US, pp. 1727–1730. Available at: <a href="https://doi.org/10.1007/978-0-387-39940-9_898" onclick="window.open('https://doi.org/10.1007/978-0-387-39940-9_898'); return false" class="ref">https://doi.org/10.1007/978-0-387-39940-9_898</a>.</div>
               <div class="bibl"><span class="ref" id="jahnichen2017"><!-- close -->Jähnichen 2017</span> Jähnichen, P. et al. (2017) “Exploratory Search Through Visual Analysis of Topic Models,” <cite class="title italic">Digital Humanities Quarterly</cite>, 011(2). Available at: <a href="https://www.digitalhumanities.org/dhq/vol/11/2/000296/000296.html" onclick="window.open('https://www.digitalhumanities.org/dhq/vol/11/2/000296/000296.html'); return false" class="ref">https://www.digitalhumanities.org/dhq/vol/11/2/000296/000296.html</a> (Accessed: 8 November 2023).</div>
               <div class="bibl"><span class="ref" id="linguisticdna_nd"><!-- close -->Linguistic DNA</span> Linguistic DNA. (n.d.) “Approaching concepts,” <cite class="title italic">Linguistic DNA Modelling concepts and semantic change</cite>. Available at: <a href="https://www.linguisticdna.org/approaching-concepts/" onclick="window.open('https://www.linguisticdna.org/approaching-concepts/'); return false" class="ref">https://www.linguisticdna.org/approaching-concepts/</a> (Accessed: 2 October 2022).</div>
               <div class="bibl"><span class="ref" id="mccarty2004"><!-- close -->McCarty 2004</span> McCarty, W. (2004) “Modeling: A Study in Words and Meanings,” in S. Schreibman, R. Siemens, and J. Unsworth (eds) <cite class="title italic">A Companion to Digital Humanities</cite>. Oxford: Blackwell, pp. 254–270. Available at: <a href="https://doi.org/10.1002/9780470999875.ch19" onclick="window.open('https://doi.org/10.1002/9780470999875.ch19'); return false" class="ref">https://doi.org/10.1002/9780470999875.ch19</a>.</div>
               <div class="bibl"><span class="ref" id="mccarty2005"><!-- close -->McCarty 2005</span> McCarty, W. (2005) <cite class="title italic">Humanities Computing | SpringerLink</cite>. London and New York: Palgrave.</div>
               <div class="bibl"><span class="ref" id="oberbichler_etal2021"><!-- close -->Oberbichler et al. 2021</span> Oberbichler, S. and Pfanzelter, E. (2021) “Topic-specific corpus building: A step towards a representative newspaper corpus on
                  the topic of return migration using text mining methods,” <cite class="title italic">Journal of Digital History</cite>, 1(1), pp. 74–98. Available at: <a href="https://journalofdigitalhistory.org/en/article/4yxHGiqXYRbX" onclick="window.open('https://journalofdigitalhistory.org/en/article/4yxHGiqXYRbX'); return false" class="ref">https://journalofdigitalhistory.org/en/article/4yxHGiqXYRbX</a> (Accessed: 2 November 2022).</div>
               <div class="bibl"><span class="ref" id="piotrowski2019"><!-- close -->Piotrowski 2019</span> Piotrowski, M. (2019) “Accepting and Modeling Uncertainty,” <cite class="title italic">Zeitschrift für digitale Geisteswissenschaften</cite> [Preprint]. Available at: <a href="https://zfdg.de/sb004_006#fn32" onclick="window.open('https://zfdg.de/sb004_006#fn32'); return false" class="ref">https://zfdg.de/sb004_006#fn32</a> (Accessed: 6 November 2023).</div>
               <div class="bibl"><span class="ref" id="piotrowski2022a"><!-- close -->Piotrowski 2022a</span> Piotrowski, M. (2022) <cite class="title italic">Epistemological Issues in Digital Humanities</cite>, <cite class="title italic">Zenodo</cite>. Available at: <a href="https://doi.org/10.5281/zenodo.6498979" onclick="window.open('https://doi.org/10.5281/zenodo.6498979'); return false" class="ref">https://doi.org/10.5281/zenodo.6498979</a> (Accessed: 1 November 2022).</div>
               <div class="bibl"><span class="ref" id="piotrowski2022b"><!-- close -->Piotrowski 2022b</span> Piotrowski, M. (2022) <cite class="title italic">Some Reflections on Historiographical Uncertainty and Computational Modeling</cite>, <cite class="title italic">Zenodo</cite>. Available at: <a href="https://zenodo.org/records/6672504" onclick="window.open('https://zenodo.org/records/6672504'); return false" class="ref">https://zenodo.org/records/6672504</a> (Accessed: 10 November 2022).</div>
               <div class="bibl"><span class="ref" id="piotrowski_etal2020"><!-- close -->Piotrowski et al. 2020</span> Piotrowski, M. and Fafinski, M. (2020) “Nothing New Under the Sun? Computational Humanities and the Methodology of History,” in <cite class="title italic">CEUR Workshop Proceedings</cite>. <cite class="title italic">CHR2020: Workshop on Computational Humanities Research</cite>, Amsterdam, The Netherlands, pp. 171–181. Available at: <a href="https://ceur-ws.org/Vol-2723/" onclick="window.open('https://ceur-ws.org/Vol-2723/'); return false" class="ref">https://ceur-ws.org/Vol-2723/</a> (Accessed: 6 November 2022).</div>
               <div class="bibl"><span class="ref" id="reddy1990"><!-- close -->Reddy 1990</span> Reddy, V.R. (1990) “Irrigation in Colonial India: A Study of Madras Presidency during 1860–1900,” <cite class="title italic">Economic and Political Weekly</cite>, 25(18/19), pp. 1047–1054. Available at: <a href="https://www.jstor.org/stable/4396266" onclick="window.open('https://www.jstor.org/stable/4396266'); return false" class="ref">https://www.jstor.org/stable/4396266</a> (Accessed: 5 November 2023).</div>
               <div class="bibl"><span class="ref" id="saravanan2020"><!-- close -->Saravanan 2020</span> Saravanan, V. (2020) <cite class="title italic">Water and the Environmental History of Modern India</cite>. London: Bloomsbury Academic.</div>
               <div class="bibl"><span class="ref" id="shanmugapriya2023"><!-- close -->Shanmugapriya 2023</span> Shanmugapriya, T. (2023) “From Uncertainty to Action: Recalibrating Digital and Spatial Humanities Methods and
                  Tools for Non-standard Historical Data from Global South,” in <cite class="title italic">GeoHumanities ’23: Proceedings of the 7th ACM SIGSPATIAL International Workshop on
                     Geospatial Humanities</cite>. <cite class="title italic">7th ACM SIGSPATIAL International Workshop on Geospatial Humanities</cite>, Hamburg, Germany: Association for Computing Machinery Library, pp. 60–62. Available
                  at: <a href="https://dl.acm.org/doi/10.1145/3615887.3627762" onclick="window.open('https://dl.acm.org/doi/10.1145/3615887.3627762'); return false" class="ref">https://dl.acm.org/doi/10.1145/3615887.3627762</a> (Accessed: 13 November 2023).</div>
               <div class="bibl"><span class="ref" id="tomasi2018"><!-- close -->Tomasi 2018</span> Tomasi, F. (2018) “Modelling in the Digital Humanities: Conceptual Data Models and Knowledge Organization
                  in the Cultural Heritage Domain,” <cite class="title italic">Historical Social Research / Historische Sozialforschung. Supplement</cite>, (31), pp. 170–179. Available at: <a href="https://www.jstor.org/stable/26533637" onclick="window.open('https://www.jstor.org/stable/26533637'); return false" class="ref">https://www.jstor.org/stable/26533637</a> (Accessed: 1 November 2023).</div>
               <div class="bibl"><span class="ref" id="umargono_etal2020"><!-- close -->Umargono et al. 2020</span> Umargono, E., Suseno, J. and Gunawan, S.K. (2020) “K-Means Clustering Optimization Using the Elbow Method and Early Centroid Determination
                  Based on Mean and Median Formula,” in <cite class="title italic">Proceedings of the 2nd International Seminar on Science and Technology (ISSTEC 2019)</cite>. <cite class="title italic">2nd International Seminar on Science and Technology</cite>, Atlantis Press, pp. 121–129.</div>
               <div class="bibl"><span class="ref" id="verheul_etal2022"><!-- close -->Verheul et al. 2022</span> Verheul, J. et al. (2022) “Using word vector models to trace conceptual change over time and space in historical
                  newspapers, 1840–1914,” <cite class="title italic">Digital Humanities Quarterly</cite>, 016(2). Available at: <a href="https://www.digitalhumanities.org/dhq/vol/16/2/000550/000550.html" onclick="window.open('https://www.digitalhumanities.org/dhq/vol/16/2/000550/000550.html'); return false" class="ref">https://www.digitalhumanities.org/dhq/vol/16/2/000550/000550.html</a> (Accessed: 10 November 2022).</div>
            </div>
            <div class="toolbar"><a href="#">Preview</a>  |  <span style="color: grey">XML</span> |  <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div>
            <div class="license"><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
               </div>
         </div>
      </div>
   </body>
</html>