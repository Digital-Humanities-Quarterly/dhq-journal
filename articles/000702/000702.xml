<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
   xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
   xmlns:mml="http://www.w3.org/1998/Math/MathML"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <!--Author should supply the title and personal information-->
            <title type="article" xml:lang="en">Nonsense Code: A Nonmaterial Performance</title>
            <!--Add a <title> with appropriate @xml:lang for articles in languages other than English-->
            <dhq:authorInfo>
               <dhq:author_name>Barry <dhq:family>Rountree</dhq:family></dhq:author_name>
               <idno type="ORCID">https://orcid.org/0000-0002-0087-4301</idno>
               <dhq:affiliation>Computer Scientist, Lawrence Livermore National
                  Laboratory</dhq:affiliation>
               <email>rountree@llnl.gov</email>
               <dhq:bio>
                  <p>Dr. Rountree received his PhD in Computer Science from the University of
                     Arizona in 2010 (advised by Dr. David K. Lowenthal), an MS in System and
                     Network Administration from Florida State University, and a BA in Theater from
                     the Ohio University Honors Tutorial College. He has been at the Center for
                     Applied Scientific Computing at Lawrence Livermore National Laboratory since
                     2010, first as a postdoctoral researcher and then, from 2013, as a staff
                     scientist. He has co-authored over fifty peer-reviewed publications, primarily
                     in power-constrained, high-performance computing, but also several in
                     collaboration with Dr. William Condee on the principles and practice of
                     Nonmaterial Performance.</p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>William <dhq:family>Condee</dhq:family></dhq:author_name>
               <idno type="ORCID">https://orcid.org/0000-0003-3357-8485</idno>
               <dhq:affiliation>J. Richard Hamilton Professor Emeritus of Humanities, Ohio
                  University</dhq:affiliation>
               <email>condee@ohio.edu</email>
               <dhq:bio>
                  <p>William Condee (Baker and Hostetler Professor Emeritus of Humanities, Ohio
                     University) is the author of <title rend="italic">Coal and Culture: The Opera
                        House in Appalachia</title> and <title rend="italic">Theatrical Space: A
                        Guide for Directors and Designers</title>. His work on Nonmaterial
                     Performance, co-authored with Barry Rountree, is in <title rend="italic"
                        >Theatre Journal</title>, <title rend="italic">TDR: The Drama
                     Review</title>, and <title rend="italic">Imagined Theatres</title>. Articles on
                     puppetry appeared in <title rend="italic">Puppetry International</title>,
                        <title rend="italic">Studies in Theatre and Performance</title> and
                     forthcoming in <title rend="quotes">Representing Alterity through Puppetry and
                        Performing Objects</title> and <title rend="italic">Puppet and
                        Spirit</title> (Routledge). He co-authored work (with Thomas Irmer) on
                     German theater in <title rend="italic">A History of German Theatre</title> and
                        <title rend="italic">Theatre Journal</title>. Articles on other subjects
                     were in <title rend="italic">Theatre Survey</title>, <title rend="italic"
                        >Theatre Topics</title>, and <title rend="italic">Theatre Annual</title>.
                     Condee was Visiting Professor at Chubu University, and Fulbright Senior
                     Specialist at University of Leipzig and University of Malaya.</p>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <!--This information will be completed at publication-->
            <idno type="DHQarticle-id"><!--including leading zeroes: e.g. 000110-->000702</idno>
            <idno type="volume"
               ><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006-->017</idno>
            <idno type="issue"><!--issue number, without leading zeroes: e.g. 2-->2</idno>
            <date/>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND">
               <!--If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default):        
                  CC-BY:    
                  CC0:  -->
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref
                     target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
                     >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
            <taxonomy xml:id="project_keywords">
               <bibl>DHQ project registry; full list available at <ref
                     target="http://www.digitalhumanities.org/dhq/projects.xml"
                     >http://www.digitalhumanities.org/dhq/projects.xml</ref>
               </bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
            <!--add <language> with appropriate @ident for any additional languages-->
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords">
               <!--Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#authorial_keywords">
               <!--Authors may include one or more keywords of their choice-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#project_keywords">
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <!-- Replace "NNNNNN" in the @target of ref below with the appropriate DHQarticle-id value. -->
         <change>The version history for this file can be found on <ref
               target="https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/main/articles/000702/000702.xml"
               >GitHub </ref>
         </change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract>
            <!--Include a brief abstract of the article-->
            <p>Critical Code Studies often relies on the textual representation of code in order to
               derive extra-textual significance, with less focus on how code performs and in what
               contexts. In this paper we analyze three case studies in which a literal reading of
               each programâ€™s code is effectively nonsense. In their performance, however, the
               programs generate meaning. To discern this meaning, we use the framework of
               nonmaterial performance (NMP), which is based on four tenets: code abstracts, code
               performs, code acts within a network, and code is vibrant. We begin with what is to
               our knowledge the oldest example of nonsense code: a program (now lost) from the
               1950s that caused a Univac 1 computer to hum <title rend="quotes">Happy
                  Birthday</title>. Second, we critique Firestarter, a processor stress test from
               the Technical University of Dresden. Finally, we analyze one of the family of
               processor power side-channel attacks known collectively as Platypus. In each case,
               the text of the code is a wholly unreliable guide to its extra-textual significance.
               This paper builds on work in Critical Code Studies by bringing in methodologies from
               actor-network theory and political science, examining code from a performance-studies
               perspective and with expertise from computer science. Code can certainly be read as
               literature, but ultimately it is text written to be performed. Imagining and
               observing the performance forces the critic to engage with the code in its own
               network. The three examples we have chosen to critique here are outliers---very
               little code in the world is purposed to manipulate the physical machine. Nonsense
               shows us the opportunity that nonmaterial performance creates: to decenter text from
               privileged position and to recenter code as a performance.</p>
         </dhq:abstract>
         <dhq:teaser>
            <!--Include a brief teaser, no more than a phrase or a single sentence-->
            <p>Nonsense shows us the opportunity that nonmaterial performance creates: to decenter
               text from privileged position and to recenter code as a performance.</p>
         </dhq:teaser>
      </front>
      <body>
         <div>
            <head>1. Happy Birthday, Nonsense, and Nonmaterial Performance</head>
            <figure xml:id="figure01">
               <head>Note that programming the UNIVAC 1 is done with pencil, paper, and flow
                     charts.<ptr target="#sperryrand1959"/></head>
               <figDesc>Scanned reproduction of 1950s title graphic featuring cartoon man in suit
                  programming with paper and pencil. Title is <title rend="quotes">Basic Programming
                     Univac 1 Data Automation System</title>.</figDesc>
               <graphic url="resources/images/figure01.png"/>
            </figure>
            <figure xml:id="figure02">
               <head>Assembly language instructions for the UNIVAC 1.<ptr target="#koss2003"
                  /></head>
               <figDesc>Scanned reproduction of 1950s title graphic featuring cartoon man in suit
                  programming with paper and pencil. Title is <title rend="quotes">Basic Programming
                     Univac I Data Automation System</title>.</figDesc>
               <graphic url="resources/images/figure02.png"/>
            </figure>
            <p>Consider a somewhat mysterious computer tape from the early 1950s that was run a
               handful of times each year on Lawrence Livermore National Laboratoryâ€™s (LLNL) UNIVAC
               1 computer. The code is easy enough to describe. Single instructions are repeated
               thousands of times, but the results of those instructions are discarded. The
               instruction loops are occasionally repeated. There are only a couple dozen of these
               loops. There is no program input or output. Execution takes less than twenty
               seconds.</p>
            <p>The giveaway is the tape label: Happy Birthday. The UNIVAC 1, which filled an entire
               room, was a noisy machine. The noise varied in pitch, and the pitch depended on the
               electrical consumption needed for the different individual instructions the machine
               happened to be running. Executing those instructions repeatedly would increase the
               duration of that particular tone. This program was a favorite of pioneering
               programmer Mary Ann Mansigh Karlsen, a physics coder at LLNL from the mid-1950s to
               the mid-1990s. She would help celebrate her colleaguesâ€™ birthdays by calling their
               office from the machine room and serenading them by running the program on the tape
                  <ptr target="#rountreecondee2021"/>. Unfortunately, to the best of our knowledge,
               the tape for the UNIVAC 1 Happy Birthday has disappeared into history.</p>
            <p>While hardly a consequential milestone in the history of computer science, this
               program does illustrate the limits of text-centric critical analysis. The semantic
               content of the code is irrelevant, yet that code is what drives the physical
               performance of the physical machine. Rerunning the code on a different computer (or a
               hardware emulator) reverts the performance back to nonsensical loops of
               instructions.</p>
            <p>We offer this trivial example to illustrate a point central to this paper: code
               comprises text, purpose, and performance. That performance in turn is both material
               (the UNIVAC 1 humming Happy Birthday in the 1950s) and nonmaterial (mental models of
               a described, recollected, or intended performance). This code is the simplest example
               of what we define as nonsense code: the class of programs designed to change the
               physical state of the computer using side effects of the machineâ€™s instructions.</p>
            <p>We begin with a short review of Nonmaterial Performance (NMP) and define nonsense
               code. We then describe Firestarter and Platypus as examples of nonsense code and
               critique them using the framework of NMP. Firestarter is a processor stress test that
               makes use of Intelâ€™s Running Average Power Limit (RAPL) technology, and Platypus is a
               set of processor side channel attacks that also make use of RAPL, as well as Intelâ€™s
               Software Guard Extensions (SGX). Both Firestarter and Platypus rely on manipulating
               the physical machine, and in both cases the code remains opaque unless studied as
               performance.</p>
            <p>Nonsense code poses challenges to traditional approaches in Critical Code Studies. We
               demonstrate how an NMP approach reveals how meaning, in the wild, can escape the
               authorsâ€™ initial intent, even in nonsense code.</p>
         </div>
         <div>
            <head>2. Nonmaterial Performance </head>
            <p>Nonmaterial Performance (NMP) is a framework that uses performance studies, actor
               network theory, and vibrant matter to expose how code acts in the world. NMP is based
               on four tenets: code abstracts, code performs, code acts within a network, and code
               is vibrant. The performance of code comprises the mental models, the text, and the
               machineâ€™s physicality <ptr target="#condeerountree2020"/>. In this paper we bring the
               framework of NMP to bear on code that is profoundly physical.</p>
            <div>
               <head>Code Abstracts</head>
               <p>Abstractions, which are ubiquitous in computer science, hide nuance and detail in
                  order to create concepts that are simpler to work with. There are dozens of layers
                  of abstractions, beginning with the silicon, up through assembly language (the
                  lowest level of abstraction available to programmers), and on to high-level
                  programming languages and frameworks. These abstractions, of course, still affect
                  the machine at the physical layer â€” the abstractions hide complexity, not remove
                  it.</p>
               <p>There is a similar idea of abstraction in mathematics, but mathematical
                  abstractions such as <code>sum()</code> and <code>average()</code> destroy
                  information (one can't get back to the original data given a sum or average).
                  Abstraction in computer science only hides the information <ptr
                     target="#colburn2007"/>; underneath the assembly language instructions, the
                  picky details still exist. Abstraction in computer science, then, is done for the
                  convenience of the programmer.</p>
               <p>If one wants to manipulate the physical machine through code, the only tools
                  available are the higher-level abstractions of programming languages. Given a deep
                  enough knowledge of a particular architecture and software stack, one can use
                  these abstractions to change the properties of the physical machine. Because the
                  abstractions were not created to bring about physical change, the resulting code
                  looks like nonsense.</p>

            </div>
            <div>
               <head>Code Performs</head>
               <p>The textual representation of code, like the script of a play, is only a score for
                  its performance. According to Richard Schechner, the focus of performance studies
                  is human behavior: <quote rend="inline">any action that is framed, presented,
                     highlighted or displayed is a performance</quote>
                  <ptr target="#schechner2006" loc="2"/>. Performance studies provides useful models
                  for highlighting behaviors not previously framed as performance and/or not
                  privileged as objects for study, including not only the arts, but also sports,
                  business, sex, ritual, play, everyday life â€” and technology (although Schechner
                  acknowledges that the last is <quote rend="inline">not usually analyzed</quote>)
                     <ptr target="#schechner2006" loc="31"/>.</p>
               <p>Schechner famously defines performance as <quote rend="inline">restored
                     behavior</quote> and <quote rend="inline">twice-behaved behavior,</quote> and
                  goes on to suggest that when <quote rend="inline">onceness</quote> is <quote
                     rend="inline">broken down finely enough and analyzed,</quote> the behaviors
                     <quote rend="inline">are revealed as restored behaviors</quote>
                  <ptr target="#schechner2006" loc="29"/>. In other words, it is restored behavior
                  all the way down. Similarly, in computing, individual actions (in the form of
                  assembly language instructions) are all restored behavior â€” there is nothing new
                  that can be done on a processor. It is only the aggregation of twice-behaved
                  behavior that makes novelty possible. Both programmers and performers wield their
                  creative power through the combination of these existing behaviors <ptr
                     target="#rountreecondee2021" loc="304â€“5"/>. Code Acts within a Network</p>
               <p>Code performs within multiple layers of networks, comprising both objects and
                  humans. NMP employs actor-network theory (ANT) to crack open computing in ways not
                  possible with standard computer science approaches. From an ANT perspective,
                  everything in the social and natural world is the result of a diverse web of
                     <quote rend="inline">materially heterogeneous</quote> relations <ptr
                     target="#law2009" loc="143"/>. ANT privileges neither humans nor objects, since
                  neither alone determines the processes and outcomes of these networks. Instead,
                  networks consist of the interaction of humans and objects, with implications for
                  all. ANT uses Bruno Latourâ€™s term <quote rend="inline">actant,</quote> which Jane
                  Bennett defines as <quote rend="inline">a source of action that can be either
                     human or nonhuman; it is that which has efficacy, can do things, has sufficient
                     coherence to make a difference, produce effects, alter the course of
                     events</quote> (<ptr target="#bennett2010" loc="viii, emphasis in original"/>;
                     <ptr target="#rountreecondee2021" loc="302"/>). Code is Vibrant </p>
               <p>We borrow the idea of vibrancy from Bennettâ€™s book, Vibrant Matter: A Political
                  Ecology of Things. While matter is conventionally viewed as passive, Bennett
                  asserts that matter is vibrant. She describes the <quote rend="inline"
                     >vitality</quote> of matter as <quote rend="inline">the capacity of things . .
                     . not only to impede or block the will and designs of humans but also to act as
                     quasi agents or forces with trajectories, propensities, or tendencies of their
                     own</quote>
                  <ptr target="#bennett2010" loc="viii"/>. Her goal is <quote rend="inline">to
                     articulate a vibrant materiality that runs alongside and inside humans</quote>
                  <ptr target="#bennett2010" loc="viii"/>. Similarly, the conventional view of code
                  requires that it be inert: fashioned to fulfill the single intent of its author.
                  From an NMP perspective, code in performance also has vibrancy: the ability to act
                  and have influence independent of its creators <ptr target="#condeerountree2020"
                     loc="149"/>. As we will conclude, what code execution means ultimately accrues
                  in the domain of human perception, and these meanings are informed by the unseen
                  ensemble of performance occurring behind the screen. That meaning is unstable,
                  independent of the authorâ€™s intention, and contingent on time and place. NMP makes
                  the nonmaterial visible <ptr target="#condeerountree2020" loc="303â€“4"/>.</p>
            </div>
         </div>
         <div>
            <head>3. Nonsense Code</head>
            <p>As noted above, we define nonsense code as the class of programs designed to change
               the physical state of the computer using side effects of the machineâ€™s instructions.
               The text of code abstracts away physical details such as energy consumption, thermal
               characteristics, and electrical resonance; nonsense code uses its text to manipulate
               those physical characteristics. Examining this class of code without considering its
               performance â€” what it actually does to the physical machine â€” renders it nonsense. In
               the case of Happy Birthday, the machine instructions of the UNIVAC 1 did not provide
               a mechanism for creating sounds. That physical effect had been abstracted from the
               text of the instructions. What makes the Happy Birthday tape compelling is that the
               programmers ignored the instructionsâ€™ semantics (for example, adding up numbers) in
               order to manipulate the material implementations of those instructions (for example,
               making the machine hum the note <q>G</q>). The result is textual nonsense and an
               amusing performance. Assembly language instructions will, in performance,
               inadvertently cause a computer to consume more power, increase its temperature, and
               resonate at a particular frequency. The text of these instructions, however, does not
               convey this physicality. Nonsense code, then, relies on the physical side effects
               that have been abstracted away from the code.</p>
            <p>Evolvable hardware (and the evolutionary algorithms used to create it) bears more
               than a passing resemblance to nonsense code: the results are often impenetrable, but
               the reason for the impenetrability differs. The evolutionary algorithms used for
               creating hardware manipulate theoretical abstractions of actual physical components
               to arrive at a solution that fits the constraints of the problem. That abstract
               solution can then be transformed into physical hardware <ptr target="#cancare2011"/>.
               Nonsense code also uses abstractions, but does so in order to manipulate the physical
               properties of a machine that does not appear in the abstractions. The evolutionary
               algorithm for evolvable hardware does not know and cannot discover what details have
               been elided in the abstractions it was given. Those details are available to the
               author of nonsense code.</p>
            <p>Most examples of Critical Code Studies focus primarily on the textual representation
               of a program, which is the immediate point of entry for code analysis. Our approach
               centers instead on the performance of code, which is especially valuable for the vast
               majority of cases for which text is unavailable. Code may be unreleased (Platypus),
               proprietary (RAPL, SGX), or simply lost (Happy Birthday). In such cases, approaches
               from performance studies, relying on paratextual information, including oral history,
               documentation, specifications, and scholarship, restore and interpret ephemeral
               performances.</p>
         </div>
         <div>
            <head>4. Firestarter</head>

            <list type="gloss">
               <item>
                  <label>Author:</label> Daniel Hackenberg </item>
               <item>
                  <label>Citation:</label> D. Hackenberg, R. Oldenburg, D. Molka and R. SchÃ¶ne,
                     <title rend="quotes">Introducing Firestarter: A processor stress test
                     utility,</title> 2013 International Green Computing Conference Proceedings,
                  Arlington, VA, USA, 2013, pp. 1-9, <ref
                     target="https://doi.org/10.1109/IGCC.2013.6604507"
                     >doi:10.1109/IGCC.2013.6604507</ref>. </item>
               <item>
                  <label>Version:</label> 1.7.4 (1.0 released in 2013, 2.0 released in 2021)</item>
               <item>
                  <label>Source:</label>
                  <ref target="https://github.com/tud-zih-energy/Firestarter"
                     >https://github.com/tud-zih-energy/Firestarter</ref>
               </item>
               <item>
                  <label>Invocation:</label>
                  <code><![CDATA[./Firestarter â€” timeout=60 â€“report]]></code>
               </item>
               <item>
                  <label>Technical Description:</label>
                  <p>Firestarter is a processor stress test, essentially a program that makes the
                     processor work as hard as possible in order to determine how the processor will
                     behave under high load, for example, testing cooling systems at maximum power
                        <ptr target="#hackenberg2013"/>. Prior to the creation of Firestarter, best
                     practice was to use numerically intensive codes such as Prime95 or LINPACK.
                     These codes, however, were written to solve mathematical problems, and only
                     incidentally required a large amount of power. Firestarter is designed to
                     consume maximum power â€” and nothing else. As such it can reach both higher and
                     more consistent levels of power consumption, thereby producing more reliable
                     results. Firestarterâ€™s code is a carefully constructed mass of assembly
                     language instructions that work nearly all of the components of the processor
                     simultaneously and as hard as possible â€” without calculating anything useful at
                     all. Firestarter thus meets our definition of nonsense: its purpose is to
                     change the state of the physical processor using the side effects of the
                     available assembly language instructions.</p>
               </item>
            </list>
            <p>In this section we briefly critique Firestarter, as well as demonstrate its vibrancy
               when repurposed.</p>
            <figure xml:id="figure03">
               <head>A brief Firestarter run on 112 CPUs across two Xeon processors.<ptr
                     target="#rountreecondee2021"/></head>
               <figDesc>Screenshot of terminal session with 58 lines of logging and performance
                  stats for Firestarter.</figDesc>
               <graphic url="resources/images/figure03.png"/>
            </figure>
            <p>We begin with the output of a short Firestarter run (Figure 3). A few technical
               details require explanation in order to understand how this code becomes nonsense.
               Lines 1-5 are code attribution and licensing information. Lines 7-41 describe
               Firestarterâ€™s understanding of the architecture it is running on. For clarity, we
               have included the results of only four of the 112 CPUs: 0, 1, 110 and 111. The
               performance report begins on line 44 and provides a total number of iterations
               completed for each CPU during the run (again, we only show CPUs 0, 1, 110 and 111).
               Adjacent to those values is the amount of time taken in clock ticks
                  (<code>tsc_delta</code>).</p>
            <p>In the performance recorded in Figure 3, Firestarter is executed for 60 seconds
               across 112 hyperthreads on two Cascade Lake processors. Lines 46-50 are of particular
               interest. Each thread reports how many iterations of the Firestarter payload loop it
               executed and how long it spent running those loops. The elapsed time for each thread
               is remarkably consistent: the difference between the longest-running thread of the
               four threads shown (thread 0) and the shortest-running thread (thread 110) is just
               over 0.02%.</p>
            <p>The total work accomplished, however, by thread 110 is 4.2% greater than thread 0.
               Under this kind of load and this particular power management regime, not all
               hyperthreads are created equal (we will return to this phenomenon momentarily).</p>

            <figure xml:id="figure04">
               <head>A portion of the handwritten assembly code used during the Firestarter
                  execution recorded in Figure 3 <ptr target="#hackenberg2013"/>.</head>
               <figDesc>Screenshot of about assembly, with about 50 lines in a four-column
                  format.</figDesc>
               <graphic url="resources/images/figure04.png"/>
            </figure>

            <p>Figure 4 shows a portion of the code being executed. The code is x86 assembly
               language using AT&amp;T syntax embedded in a larger C language function. There are
               two unusual aspects of this code. First is the four-column formatting, since each CPU
               in this architecture can retire up to four instructions per cycle â€” in simpler terms,
               each CPU can do four things at once. After a great deal of study and experimentation,
               the Firestarter authors were able to handcraft the selection and placement of these
               instructions so that they do in fact execute simultaneously. As a result, the program
               causes the computer to do more work and consume more energy per unit of time. Their
               accomplishment may not appear at first blush to be that astonishing: each CPU can
               execute four instructions, and they wrote code to do that. However, most
               non-nonsensical programs rarely have more than one instruction executing at a time,
               and very few reliably get up to three instructions per tick. What the Firestarter
               authors accomplished was to assemble a jigsaw puzzle in space and time, finding
               exactly which instructions could be cobbled together based only on their particular
               fit. This approach exposes the second unusual aspect of Firestarter: it uses a great
               deal of energy to do nothing in particular.</p>

            <p>Closer study of the code reveals multiple duplicated patterns: results are repeatedly
               calculated, overwritten, and discarded. The simplest pattern occurs in the
               instructions placed in the <q>decode 2</q> column.</p>

            <figure xml:id="figure05">
               <head>Detail of Figure 4 <ptr target="#hackenberg2013"/>.</head>
               <figDesc>Cropped screenshot of six assembly instructions from the decode2 column,
                  e.g. <quote rend="inline">shl $1, %%edi;</quote></figDesc>
               <graphic url="resources/images/figure05.png"/>
            </figure>

            <p>The values in these three registers (<term>edi</term>, <term>esi</term>, and
                  <term>edx</term>), as seen in Figure 5, are shifted to the left by one bit
                  (<term>shl</term>), then shifted back to the right by one bit (<term>shr</term>),
               over and over again. At a semantic level, this repeated shuffling back-and-forth
               accomplishes nothing. Moving the values in these 64-bit registers does not consume
               nearly as much power as the 512-bit registers used in the <q>decode 0</q> and
                  <q>decode 1</q> columns, nor does it take as much power as the cache transfers
               under <q>decode 3.</q> But these shift instructions do soak up that last bit of
               execution capacity, thus they have found their place here.</p>

            <div>
               <head>Critique</head>
               <p>Focusing solely on the text of the code itself runs headlong into its
                  pointlessness. Alternatively, including the authorsâ€™ intent (as recorded in the
                  code comments and authorsâ€™ published papers) reveals one meaning of Firestarter,
                  but does not exhaust the potential for other meanings. Code is sufficiently
                  vibrant to escape the intent of the authors, and we now discuss how the nonsense
                  of Firestarter reveals the messy details behind another abstraction: all processor
                  cores are created equal.</p>
               <p>In introducing Firestarter, we touched on its origins in heating and cooling
                  processors. Most cooling occurs when the processor decides to run more slowly
                  (thus consuming less energy and generating less heat), so as not to cook itself.
                  To understand how this relates to Firestarter, it is necessary to go back to
                  August, 2008, and Intelâ€™s introduction of the multicore Nehalem processor
                  architecture.</p>
               <p>Prior to Nehalem, processors had a maximum speed (the CPU clock frequency) that
                  would support any workload. Nehalem changed that equation. Restricting a workload
                  to a single core meant that particular core could run at the maximum clock
                  frequency; using more than one core lowered the ceiling for all cores. Higher
                  clock frequencies use quadratically more power, so for a given processor, the
                  programmer could spend the power budget on fewer, faster cores or more, slower
                  cores. For the first time, configuration had to encompass both code and the
                  underlying processor.</p>
               <p>In subsequent architectures, power and performance management strategies included
                  in the processor became increasingly sophisticated, and while manufacturers
                  exposed a few interfaces to this firmware, processor vendors kept the underlying
                  actants (algorithms and implementation) opaque. A program like Firestarter allowed
                  researchers to see how processors reacted to predictable loads, particularly those
                  that were designed to draw maximum power and generate maximum heat.</p>
               <p>As an example, here are the results of multiple Firestarter runs on the dual
                  Cascade Lake machine mentioned above.</p>
               <table>
                  <head>Firestarter 60-second runs, using different numbers of cores (column 1). The
                     resulting units of work completed (column 2) scale poorly. (Rountree)</head>
                  <row role="label">
                     <cell>Number of cores</cell>
                     <cell>Units of work<lb/> completed in 60 seconds</cell>
                  </row>
                  <row role="data">
                     <cell>1 </cell>
                     <cell>1.0</cell>
                  </row>
                  <row role="data">
                     <cell>14 </cell>
                     <cell>9.9</cell>
                  </row>
                  <row role="data">
                     <cell>28 </cell>
                     <cell>13.3</cell>
                  </row>
                  <row role="data">
                     <cell>56 </cell>
                     <cell>27.0</cell>
                  </row>
                  <row role="data">
                     <cell>112 </cell>
                     <cell>24.7</cell>
                  </row>
               </table>

               <p>Here, the use of Firestarter has shifted. Rountree repurposed an unmodified
                  Firestarter into a performance evaluation tool. A single CPU completes a
                  (normalized) unit of work in 60 seconds. Increasing the number of CPUs running
                  simultaneously from 1 to 14 does not result in 14 units of work completed;
                  instead, the result is just 9.9. Using all 112 CPUs only increases the completed
                  work to 24.7. The fact that this processor scales poorly is less relevant here
                  than Firestarter being used in a novel way: as a generic work generator. The
                  purpose is malleable, even if the text is fixed.</p>
               <p>Table 1 (above) shows a small example of using a nonsense code for a purpose other
                  than for which it was designed. While one can delineate code through its purpose,
                  text, and performance, doing so does not prevent code from being repurposed and
                  re-presented. Because of this potential to be repurposed, code is vibrant. Code is
                  not defined by a single meaning; it generates multiple meanings, and understanding
                  one particular meaning does not necessarily give insight into any others.</p>
               <p>Earlier in this paper we noted the different magnitudes in time and work completed
                  across different hyperthreads (Figure 3 lines 46-50). Firestarter had been
                  developed on a handful of machines, and any differences across cores, processors,
                  or threads were not seen as significant enough to include in the initial paper
                  introducing Firestarter. Rountree ran Firestarter across 4,200 Broadwell
                  processors for 350 minutes (60 seconds for each run). Across that much larger
                  population of processors, the observed variation became much more interesting.</p>

               <figure xml:id="figure06">
                  <head>The three bands of box-and-whisker plots are the best, median, and worst out
                     of 4,200 Broadwell processors. Note that the variation within this single
                     processor model can exceed 20% <ptr target="#marathe2017"/>.</head>
                  <figDesc>Data plot of Firestarter scaled performance (Y) in processor cores 1-18
                     (X) for three processors (box-and-whisker data).</figDesc>
                  <graphic url="resources/images/figure06.png"/>
               </figure>

               <p>The three horizontal bands in Figure 6 correspond to the best, median, and worst
                  processors out of the 4,200 processors characterized. These Broadwell processors
                  have 18 cores with two hyperthreads per core. Each box-and-whisker plot represents
                  the scaled number of iterations for a single hyperthread across 350 60-second
                  executions of Firestarter (the box represents 50% of the results, the whiskers
                  represent the total range).</p>
               <p>The most striking result from this graph is that the performance of the best,
                  median, and worst processor under Firestarter do not overlap at all, despite being
                  ostensibly the same processor model. There is also variation across cores (core 12
                  is consistently better than 13), hyperthreads (hyperthread 1 is consistently a bit
                  better than hyperthread 0 across all cores and processors), and from run to run
                  (the height of each box-and-whisker plot). What Firestarter reveals,
                  serendipitously, is the nuance and detail abstracted away by the shared concepts
                  of <q>processor,</q>
                  <q>core,</q> and <q>hyperthread.</q> For a particular processor model, the
                  received abstraction is that all processors of that type are identical, certainly
                  insofar as performance is concerned. Within a given processor, a core is
                  abstracted to the point where it becomes identical to all other cores, and
                  likewise for hyperthreads; there is no programmatic method for distinguishing
                  them. Slight variations within the silicon will make some processors more or less
                  efficient â€” essentially, it takes fractionally more energy to push bits down the
                  wire. Processors that, by luck of the draw, are less efficient will heat up more
                  quickly at the same CPU clock speed, meaning they will have to slow down sooner,
                  and thus get less work done. Note that Firestarter remains unmodified and the
                  purpose has shifted yet again: Firestarter is now a tool for revealing variation
                  in silicon across populations of processors. The only way of getting to the nuance
                  and detail of processor performance is through observing that performance under
                  load. And the only way of maximizing that load is through nonsense.</p>
               <p>From some previous Critical Code Studies perspectives, the starting point is the
                  text of Firestarter, and while the comments and apparatus surrounding that code do
                  indicate the authorsâ€™ intentions, textual analysis does not exhaust the potential
                  meanings. Firestarter (and nonsense codes in general) generate meaning based on
                  performance in particular environments. NMP centers the analysis on the
                  performance.</p>
               <p>Returning to the tenets of NMP described above (code abstracts, code performs,
                  code acts within a network, and code is vibrant), we focus here on how Firestarter
                  is vibrant. To make the notion of vibrancy more concrete, consider puppetry. Shari
                  Lewis, the great puppeteer of Lamb </p>
               <p>Chop fame, describes the importance of discovering <quote rend="inline">what the
                     puppet wants to do</quote> (quoted in <ptr target="#bell2008" loc="7"/>). John
                  Bell goes on to describe the <quote rend="inline">weird concept of letting the
                     object determine action</quote>
                  <ptr target="#bell2008" loc="7"/>. A puppeteer may design a puppet for a
                  particular character, play, and action. Through play, however, the puppet reveals
                  what it can do and what it wants to do, unveiling a myriad of new possibilities.
                  In other words, the puppet has vibrancy.</p>
               <p>Programmers (and perhaps code critics) can be tempted to think that code does one
                  thing. Instead, playing with Firestarter reveals what else it wanted to do: expose
                  inhomogeneity <ptr target="#inadomi2015"/>. Rountree allowed Firestarter to
                  perform in new ways, which was unplanned by its authors. Because code is vibrant,
                  those actions were discoverable and discovered. Firestarter reveals that, even at
                  the level of assembly language, individual instructions have their own vibrancy.
                     <q>Shift-left</q> (<term>shl</term>) does indeed shift the bits in the given
                  register to the left, but it also takes time, draws power, fills a decoder slot,
                  affects how surrounding instructions are scheduled by the processor, and can
                  ultimately slow the processor down and unmask variation. None of this potential
                  vibrancy is recorded in the textual representation of <q>shl.</q> Accessing that
                  vibrancy requires the combination of an imagined, nonmaterial performance and the
                  careful measurement of a material performance.</p>
               <p>Firestarter illustrates the pointlessness of trying to nail code that has been
                  released in the wild to a single meaning or purpose. Firestarter was explicitly
                  designed as the epitome of pointless busywork. Without modification, however, it
                  was used to measure work rates under increasing loads and core counts, and as a
                  tool for quantifying processor, core, hyperthread, and runtime variation across
                  thousands of processors.</p>
               <p>The skilled puppeteer asks, <said>What does the object want (and not want) to
                     do?</said> Forcing thousands of processors to behave identically is possible,
                  but only by limiting their performance to the lowest common denominator. The
                  notion of vibrancy enables the question, <said>What is possible given that
                     supercomputers consist of thousands of inhomogeneous processors?</said> Once
                  that question is on the table, computer scientists can rethink job scheduling,
                  power efficiency, and performance reproducibility. From the Critical Code Studies
                  perspective, vibrancy opens the door to thinking about processors as individual,
                  unique entities whose traits (e.g., efficiency, speed, thermal characteristics,
                  etc.) exist across a spectrum. </p>
            </div>
         </div>
         <div>
            <head>5. Platypus</head>
            <list type="gloss">
               <item>
                  <label>Author:</label> Moritz Lipp et al. </item>
               <item>
                  <label>Citation:</label>
                  <title rend="quotes">PLATYPUS: Software-based Power Side-Channel Attacks on
                     x86</title>, 2021 IEEE Symposium on Security and Privacy. </item>
               <item>
                  <label>URL:</label>
                  <ref target="https://platypusattack.com">https://platypusattack.com</ref>
               </item>
               <item>
                  <label>Source:</label> Proof-of-concept code has not been released. </item>
            </list>
            <div>
               <head>Safecrackers and Side-Channel Attacks</head>
               <figure xml:id="figure07">
                  <head>Headline from 1950s newspaper article about safecracking: <title
                        rend="quotes">Locksmiths Used to Worry About Yeggs; Now It's
                        Spies</title><ptr target="#winget1950"/>.</head>
                  <figDesc>Newspaper clipping of 1950 headline.</figDesc>
                  <graphic url="resources/images/figure07.png"/>
               </figure>

               <p>Daniel Gruss and his students at the Technical University of Graz created Platypus
                  to demonstrate the feasibility of one form of side-channel attacks that exploit
                  processor vulnerabilities. Gruss is best known for co-discovering and analyzing
                  the Spectre <ptr target="#kocher2019"/> and Meltdown <ptr target="#lipp2018"/>
                  side-channel attacks. In these attacks, information designed to be kept secret on
                  a computer was attacked using the processor cache as a side-channel. For Platypus,
                  the side channel is the processorâ€™s energy accounting system. These kinds of
                  attacks leverage features found in nearly all mobile, consumer, and server-grade
                  processors. They are particularly difficult to guard against because they exploit
                  the underlying system architecture rather than software faults.</p>
               <p>Platypus was announced to the world in November, 2020 (<ptr target="#cimpanu2020"
                  />; <ptr target="#peterson2020"/>). Shortly thereafter, processor-power research
                  was restricted at LLNL while the seriousness of the vulnerability was evaluated by
                  a team headed by Rountree, as well as by teams at Intel, AMD, IBM, nVidia, and
                  Arm. As a result, Intel updated its processor microcode and <q>a Platypus
                     attack</q> entered the security lexicon.</p>
               <cit>
                  <quote rend="block">
                     <p>To understand side-channel attacks, consider state-of-the-art safecracking
                        in 1950: Combination locks are simple. Discs with slots are aligned until a
                        lever falls into the slots. Then the lock opens. The moving discs and the
                        falling lever make a noise. Legendary cracksmen filed their fingertips to
                        the quick and felt the movement. So locks were refined. Then cracksmen used
                        stethoscopes to listen to the movement. Locks were then made too smooth for
                        that device.</p>
                     <p>But the war brought on the development of electronic detection of supersonic
                        sound. In any radio store you can buy the apparatus. Cracksmen use an aerial
                        the size of a knitting needle some six inches high set in a base the size of
                        a biscuit. Push it against the safe dial. The sound is picked up, amplified
                        in a box about six by four by two inches in size and recorded on a dial like
                        the ammeter in a car.</p>
                     <p>What happens inside the combination lock is read as easily as an electro
                        cardiograph by a physician. Which means it is not easy, but it can be done
                        by an expert.</p>
                  </quote>
                  <ptr target="#winget1950"/>
               </cit>
               <p>The author quoted above offers an abstraction of a combination lock: <quote
                     rend="inline">[d]iscs with slots are aligned until a lever falls into the
                     slots.</quote> When this abstraction is translated into physical reality, a
                  side-channel opens: metal rubs against metal, levers scrape along dials, and
                  information leaks. Side-channel attacks, then, are not head-on: no dynamite blows
                  open the safe door. Instead, the side-channel attack relies on details of the
                  physical machine that have been abstracted away.</p>
            </div>
            <div>
               <head>SGX and the Cloud</head>
               <p>The particular Platypus attack we critique recovers a cryptographic key from
                  Intelâ€™s Software Guard Extensions system. SGX, as it is more commonly known, was
                  introduced in 2013 as the most recent attempt to solve a problem of great
                  commercial interest: how can a user safely run code on a machine owned and
                  maintained by someone they do not necessarily trust? For example, a hypothetical
                  tech startup has a new way of applying machine learning to medical imaging. The
                  images can be encrypted at the hospital and sent to the startup and the results
                  can be encrypted and sent back. But the startup doesnâ€™t want to own the pile of
                  computers needed for the analysis when it is so much cheaper to rent them from
                  Amazon, Google, Microsoft, or another cloud provider.</p>
               <p>SGX is yet another layer of defense to address the scenario in which an attacker
                  has gained control of the machine and can observe and modify the operating system.
                  SGX adds the capability to create what is called an enclave: a secure space that
                  would allow code written and uploaded by the medical imaging startup to be
                  executed in such a way that no compromised operating system can read it. The
                  startup can cryptographically sign their code before loading it, and then have SGX
                  validate that it received the code unmodified. Even if an adversary has physical
                  possession of the machine and the ability to tap the memory bus, no decrypted
                  information will be visible.</p>
               <p>In this example, the startup would put code in the enclave to decrypt the incoming
                  image, do whatever it does with machine learning, and encrypt the results. The
                  small amount of code that runs outside of the enclave only forwards encrypted
                  images into the enclave and forwards encrypted results back to the hospital.</p>
               <p>Platypus managed to crack this system. To see how this was done, we need to sketch
                  two more subsystems in Intel processors: Running Average Power Limit (RAPL) and
                  the Advanced Programmable Interrupt Controller (APIC).</p>
            </div>
            <div>
               <head>RAPL</head>
               <p>For Platypus, energy measurement is the side-channel capable of being attacked. In
                  response to the needs of both its mobile and datacenter customers, Intel unveiled
                  its Running Average Power Limit (RAPL) technology in its Sandy Bridge architecture
                  in 2010. RAPL allows the operating system to set upper limits on the amount of
                  power the processor is allowed to consume and, more crucially for Platypus,
                  measure how much energy has been used. Every so often (in this case, approximately
                  every fifty microseconds), the energy meter on the processor is updated: a
                  particular register is incremented by the number of fractional Joules that have
                  been consumed since the last update.</p>
               <p>Given physical access to a much simpler (and slower) processor and an expensive
                  oscilloscope, one can surreptitiously observe the electrical signal generated by
                  individual instructions, and perhaps even infer something about the data. The
                  general term for this kind of attack is Differential Power Analysis <ptr
                     target="#kocher1999"/>. Given a large number of electrical traces at a high
                  enough sampling rate, good-enough guesses can be made about enough of the
                  cryptographic key to allow its eventual recovery. For simple systems that are
                  expected to be in the physical control of an adversary (smartcards, mobile
                  devices), this analysis is a realistic method of attack. What appears to preclude
                  its use here in more complex processors is that thousands of instructions can be
                  executed over the fifty-microsecond energy update time. There is not enough energy
                  information to identify individual instructions, thereby making this attack
                  apparently infeasible in the real world.</p>
            </div>
            <div>
               <head>APIC</head>
               <p>The second Intel subsystem required by Platypus provides precise user control over
                  interrupts. The Advanced Programmable Interrupt Controller (APIC) is a much older
                  technology with roots in the 80486 Intel processor introduced in 1989. The idea of
                  interrupts goes back much further (to the 1953 UNIVAC 1103), solving what was then
                  a universal performance problem. Prior to interrupts, when a program needed to
                  interact with the outside world (for example, reading or writing to a tape), all
                  progress came to a halt until that read/write request succeeded or failed.
                  Interrupts allowed a program to do two things at once: the program, while
                  continuing to run, says, in effect, <said>Go write this data to the tape drive and
                     interrupt me when youâ€™re done.</said> While the program is running, the tape
                  device can complete its operation in its own time. When the tape completes, it
                  notifies the program by raising an interrupt.</p>
               <p>At the physical level, when the processor receives an interrupt, whatever code
                  happened to be running is interrupted, and control is transferred to the operating
                  system, which checks for errors and updates needed bookkeeping. Once that is
                  complete, the previously running code is allowed to continue (usually none the
                  wiser that it had been momentarily halted).</p>
               <p>APIC allows the operating system to trigger an interrupt at a precise moment in
                  the future. There are several registers that keep track of time. At each clock
                  tick, 1 is added (incremented) to the current value in the register. But rather
                  than incrementing once per second, recent processors increment much faster â€” more
                  than one billion times each second. Assembly language instructions in a program
                  take several clock ticks (billionths of a second) to make it through the processor
                  pipeline, so this clock is essentially running faster than instructions can
                  execute. In a bit of foreshadowing, APIC can set an interrupt to occur just a
                  handful of ticks in the future.</p>
               <p>We now have all the pieces in place to describe the Platypus attack.</p>
            </div>
            <div>
               <head>The Attack</head>
               <p>Returning to the attack on the enclave: What happens when an interrupt is received
                  when code is executing in the secure space of an SGX enclave? There are two bad
                  choices: First, put off dealing with the interrupt until the secret code that is
                  executing in the secure enclave completes (which might be anywhere from
                  milliseconds to weeks). Second, hand off control to the operating system and hope
                  it has not been compromised. SGX makes a better choice. SGX wipes out any
                  unencrypted data in the cache and only then transfers control to the (untrusted)
                  operating system. The operating system sees no data, encrypted or otherwise, in
                  the cache and cannot decipher any of the encrypted data still in memory. When the
                  operating system finishes handling the interrupt, it passes control back to SGX,
                  which will reload the enclave back into cache and decrypt the secret code again.
                  An attacker who is able to generate interrupts at will, for example through APIC,
                  is still not going to get a chance to see unencrypted data. So far, SGX appears
                  secure.</p>
               <p>How does one break into this locked room? During that interrupt-handling process,
                  the side channel has continued to accumulate energy. Can the measurements reveal
                  what was happening during enclave execution? Not really. At best, that measurement
                  refers to the accumulated energy of several thousands of instructions that
                  executed during the fifty-microsecond update window. Thereâ€™s no way to pick out
                  individual instructions from that single energy reading, much less their
                  associated data. SGX still appears to be secure. The technique used by Platypus to
                  solve this locked-room mystery is called zero stepping. Debuggers allow
                  programmers to slowly single-step through each assembly language instruction to
                  observe its effects at human timescales. Zero-stepping, in contrast, executes the
                  same single instruction over and over again. If a secret instruction running in an
                  enclave could be zero-stepped for fifty microseconds, the energy measurement would
                  cover only that instruction (and the interrupt process). That measurement may be
                  enough to identify the instruction and its data. Processors do not support native
                  zero-stepping, but processors do provide APIC. Platypusâ€™s trick is to schedule the
                  APIC interrupt a handful of ticks in the future to throw an interrupt just as the
                  first secret instruction running in the enclave is finishing. Platypus has already
                  added code (an <q>interrupt handler</q>) into the compromised operating system to
                  schedule another interrupt the same number of ticks into the future as the first.
                  The effect is that the first secret instruction in the enclave is executed over
                  and over again, never quite finishing, because it keeps getting interrupted. If
                  this pattern can be held for a hundred microseconds or so, the energy measurement
                  will capture that instruction, as well as all the other instructions involved with
                  firing the interrupt, running the interrupt handler, and restarting the enclave.
                  When enough energy information has been gathered on the first secret instruction,
                  a similar sequence begins: the second instruction is executed over and over again.
                  The net effect is that Platypus gets precise-enough energy measurement on each
                  secret instruction executing in the secure enclave to decode it. That is enough to
                  identify not only the instruction but the data it uses. Platypus effectively
                  creates an oscilloscope out of a combination of APIC and RAPL, thereby recovering
                  the secret key used by the enclave to decrypt the secret program.</p>
               <p>Absent all the above context, the execution of a Platypus attack is inscrutable: a
                  single instruction is continuously interrupted over and over and over again. That
                  process of continuous interruption modifies the underlying physical state of the
                  machine. Measuring that state allows the recovery of secret information. Platypus
                  is nonsense.</p>
               <p>A noncomputing example might elucidate how Platypus works, albeit in a simplistic
                  and partial way. Bill obsessively vacuums his bedroom. Barry is aware of this
                  hangup and is trying to help Bill. So, Bill starts vacuuming, and Barry knocks on
                  the door. Bill, trying to mask his behavior, stops vacuuming, hides the Hoover in
                  the closet, and invites Barry in. Barry looks around, sees nothing, and leaves.
                  Bill resumes cleaning, Barry knocks again, Bill hides his Hoover, Barry enters,
                  looks around, and leaves. Meanwhile, Bill has a few lights on (heâ€™s not a Roomba
                  and canâ€™t vacuum in the dark) and is making coffee (Billâ€™s obsession runs on
                  caffeine). This cycle of vacuuming, knocking, hiding, entering, and leaving
                  repeats scores or hundreds (or in the case of Platypus, thousands) of times.
                  Barry, still suspicious and concerned about his friend, proceeds to examine Billâ€™s
                  electrical meter. He is able to read the background usage, indicating the ongoing
                  use of lights and Mr. Coffee. But he is also able to see repeated spikes of
                  electricity usage of a particular shape. Because Barry owns a similar vacuum
                  cleaner, he knows the particular electrical pattern of Billâ€™s WindTunnel Air
                  Steerable Upright (as opposed to the spikes from the dryer or Billâ€™s welding
                  hobby). Busted. Reading the electrical meter is a side channel attack by which
                  Billâ€™s activity can be covertly observed and disambiguated. And, to return to
                  Rountreeâ€™s story, this is what caused LLNL to, metaphorically, lock up their power
                  meters.</p>
               <p>Returning to the startup example: the attacker knows the first task the enclave is
                  going to perform is decrypt the data. Determining which encryption algorithm is
                  used, how long the key is, etc., will be a tedious effort, but itâ€™s an effort that
                  can be automated. At the end of the process, the attacker has the key and can
                  decrypt the medical images prior to their being loaded into the enclave.</p>
            </div>
            <div>
               <head>Critique</head>
               <p>Platypus is not the first side-channel attack on SGX, although it is the first one
                  to use power. The vulnerabilities exposed by the Platypus research are not
                  considered to be nearly as serious as Spectre and Meltdown. Mitigating power as a
                  side channel attack for SGX may be as simple as having the processor not update
                  the energy meter when running inside an enclave. Unlike Spectre/Meltdown, however,
                  Platypus is (just) simple enough to be described in some detail to people who are
                  not computer security professionals.</p>
            </div>
            <div>
               <head>Code Acts within Network </head>
               <p>Returning to the tenets of NMP, we focus here on how Platypus exists within an
                  actor network, which includes a precise, programmable interrupt controller, a
                  fine-grained energy meter, an operating system that provides access to both, and a
                  security enclave that lies beyond the operating system but executes on the same
                  processor cores. Absent any of these, there is either no need for Platypus, or
                  Platypus canâ€™t exist. These actants are themselves code, and each comes with its
                  own set of abstractions and vibrancies. Platypus is a study in how these separate
                  code-actants, created in different decades by different teams for different
                  markets, did not quite align well enough to prevent information leakage.</p>
               <p>Code is not written in isolation. Both exploits and critiques can occur at the
                  joints of the actant-network. At a broader level, Platypus exists because SGX
                  exists, SGX exists because cloud computing exists, and cloud computing exists
                  because of the economics of renting computers to process private information. Part
                  of those economics is the expense of maintaining computers securely in the face of
                  growing and changing complexity across the hardware and system software stack,
                  with that complexity being driven by the perceived needs of the market.</p>
            </div>
         </div>
         <div>
            <head>6. Conclusion</head>
            <p>By choosing these particular examples we decentered the text of the code. Asking what
               Happy Birthday, Platypus, or Firestarter mean could not be answered by a recitation
               of algorithms used or a summary of code comments. Instead, we had to begin with
               abstractions, performances, and networks, and from there to paratextal resources:
               author interviews, peer reviewed publications, and discussions among colleagues. In
               doing so, we rediscovered two axioms: meaning accrues in the relationship of actants
               in a network and meaning changes as the network changes. The fact that code abstracts
               and performs in these fluid networks is what reveals the vibrancy of code.</p>
            <p>Happy Birthday meant, at the time of its creation, that <q>computers,</q> such as
               Mary Ann Mansigh Karlsen, had the freedom to play with a new piece of arithmetic
               equipment. Decades later its meaning evolved and became, alongside the scientific
               work she supported, one her most vivid and pleasant memories. In a decade of working
               with Firestarter, Rountree has seen it transform into a catalyst for revealing
               unspoken processor design decisions. With Platypus, Daniel Gruss and his students
               took advantage of the change in the network that occurred when Intel introduced
               secure enclaves to a platform with sophisticated energy measurement and interrupt
               control.</p>
            <p>The contribution of this paper is mapping out the mechanisms and limits of those
               meanings.</p>
            <list type="gloss">
               <item>
                  <label>Code abstracts:</label>
                  <p>Languages allow programmers to work with a simpler world than physical
                     reality.</p>
               </item>
               <item>
                  <label>Code performs:</label>
                  <p>Unlike mathematics, code has an embodied physicality of heat, energy, and
                     resonance.</p>
               </item>
               <item>
                  <label>Code acts within a network:</label>
                  <p>The network in which the code performs is not fixed, and meaning accrues in the
                     juxtapositions of its actants. If one changes the network, the meaning
                     changes.</p>
               </item>
               <item>
                  <label>Code is vibrant:</label>
                  <p>Code cannot be nailed to a single meaning. Meaning is generated within a
                     particular relationship of a particular set of actants, including text,
                     machine, and people. Vibrancy describes what happens as the actants and their
                     relationships change.</p>
               </item>
            </list>
            <p>Asking what code means is the wrong question. Diversity of meaning is limited only by
               the diversity and relationships of actants. Instead, ask what the network means.</p>
         </div>
      </body>
      <back>
         <listBibl>
            <bibl xml:id="bell2008" label="Bell 2008"> Bell, J. (2008) <title rend="italic">American
                  Puppet Modernism: Essays on the Material World in Performance</title>. New York:
               Palgrave Macmillan. </bibl>
            <bibl xml:id="bennett2010" label="Bennett 2010"> Bennett, J. (2010) <title rend="italic"
                  >Vibrant Matter: A Political Ecology of Things</title>. Durham: Duke University
               Press. </bibl>
            <bibl xml:id="cancare2011" label="Cancare et al. 2011"> Cancare, F., Bhandari, S,
               Bartolini, D., Carminati, M., and Santambrogio, M. (2011) <title rend="quotes">A
                  Birdâ€™s Eye View of FPGA-based Evolvable Hardware</title>. In <title rend="italic"
                  >2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS)</title>, pp.
               169-175, <ref target="https://doi.org/10.1109/AHS.2011.5963932"
                  >doi:10.1109/AHS.2011.5963932</ref>. </bibl>
            <bibl xml:id="cimpanu2020" label="Cimpanu 2020"> Cimpanu, C. (2020) <title rend="quotes"
                  >New Platypus Attack Can Steal Data from Intel CPUs</title>. <title rend="italic"
                  >ZDNet</title>, 10 Nov. 2020, <ref
                  target="https://www.zdnet.com/article/new-platypus-attack-can-steal-data-from-intel-cpus/"
                  >https://www.zdnet.com/article/new-platypus-attack-can-steal-data-from-intel-cpus/</ref>. </bibl>
            <bibl xml:id="colburn2007" label="Colburn &amp; Shute 2007"> Colburn, T., and Shute, G.
               (2007) <title rend="quotes">Abstraction in Computer Science</title>. <title
                  rend="italic">Minds and Machines</title>, vol. 17, pp. 169â€“84. </bibl>
            <bibl xml:id="condeerountree2020" label="Condee &amp; Rountree 2020"> Condee, W., and
               Rountree, B. (2020) <title rend="quotes">Nonmaterial Performance</title>, <title
                  rend="italic">TDR: The Drama Review</title>, vol. 64, no. 4, pp. 147-57. </bibl>
            <bibl xml:id="costan2016" label="Costan &amp; Devadas 2016"> Costan, V. and Devadas, S.
               (2016) <title rend="quotes">Intel SGX Explained</title>. <title rend="italic"
                  >Cryptology ePrint Archive</title>, Report 2016/086, p. 118. </bibl>
            <bibl xml:id="hackenberg2013" label="Hackenberg et al. 2013"> Hackenberg, D., Oldenburg,
               R., Molka, D., and SchÃ¶ne, R. (2013) <title rend="quotes">Introducing Firestarter: A
                  Processor Stress Test Utility</title>, <title rend="italic">2013 International
                  Green Computing Conference Proceedings</title>, pp. 1-9, <ref
                  target="https://ieeexplore.ieee.org/document/6604507"
                  >https://ieeexplore.ieee.org/document/6604507</ref>. </bibl>
            <bibl xml:id="inadomi2015" label="Inadomi et al. 2015"> Inadomi, Y., Patki, T., Inoue,
               K., Aoyagi, M., Rountree, B., Schulz, M., Lowenthal, D., Wada, Y., Fukazawa, K.,
               Ueda, M., Kondo, M., and Miyoshi, I. (2015) <title rend="quotes">Analyzing and
                  mitigating the impact of manufacturing variability in power-constrained
                  supercomputing</title>, <title rend="italic">SC '15: Proceedings of the
                  International Conference for High Performance Computing, Networking, Storage and
                  Analysis</title>, pp. 1-12, <ref target="https://doi.org/10.1145/2807591.2807638"
                  >doi:10.1145/2807591.2807638</ref>. </bibl>
            <bibl xml:id="kocher2019" label="Kocher et al. 2019"> Kocher, P., Horn, J., Fogh, A.,
               Genkin, D., Gruss, D., Haas, W., Hamburg, M., Lipp, M., Mangard, S., Prescher, T.,
               Schwarz, M., and Yarom, Y. (2019) <title rend="quotes">Spectre Attacks: Exploiting
                  Speculative Execution</title>, <title rend="italic">2019 IEEE Symposium on
                  Security and Privacy</title> (SP), pp. 1- 19, <ref
                  target="https://ieeexplore.ieee.org/abstract/document/8835233"
                  >https://ieeexplore.ieee.org/abstract/document/8835233</ref>. </bibl>
            <bibl xml:id="kocher1999" label="Kocher, Jaffe, and Jun 1999"> Kocher, P., Jaffe, J.,
               and Jun, B. (1999) <title rend="quotes">Differential Power Analysis</title>, <title
                  rend="italic">Advances in Cryptology â€“ Crypto 99 Proceedings, Lecture Notes in
                  Computer Science Vol. 1666</title>, M. Wiener, ed., Springer-Verlag. </bibl>
            <bibl xml:id="koss2003" label="Koss 2003"> Koss, A. M. (2003) <title rend="quotes"
                  >Programming on the Univac 1: A Woman's Account</title>, <title rend="italic">IEEE
                  Annals of the History of Computing</title>, 25, pp. 48-59. </bibl>
            <bibl xml:id="law2009" label="Law 2009"> Law, J. (2009) <title rend="quotes">Actor
                  Network Theory and Material Semiotics</title>, In Turner B. (ed.), <title
                  rend="italic">The New Blackwell Companion to Social Theory</title>.
               Wiley-Blackwell, Chichester, UK, pp. 141â€“58. </bibl>
            <bibl xml:id="lipp2018" label="Lipp et al. 2018"> Lipp, M. Schwarz, M., Gruss, D.,
               Prescher, T., Haas, W., Fogh, A., Horn, J., Mangard, S., Kocher, P., Genkin, D.,
               Yarom, Y., and Hamburg, M. (2018) <title rend="quotes">Meltdown: Reading Kernel
                  Memory from User Space</title>, <title rend="italic">Proceedings of the 27th
                  USENIX Security Symposium</title>, pp. 973-990, <ref
                  target="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-lipp.pdf"
                  >https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-lipp.pdf</ref>. </bibl>
            <bibl xml:id="lipp2021" label="Lipp et al. 2021"> Lipp, M., Kogler, A., Oswald, D,
               Schwarz, M., Easdon, C., Canella, C., and Gruss, D. (2021) <title rend="quotes"
                  >PLATYPUS: Software-Based Power Side-Channel Attacks on x86</title>, <title
                  rend="italic">2021 IEEE Symposium on Security and Privacy</title>, 17 pages, <ref
                  target="https://platypusattack.com">https://platypusattack.com</ref>. </bibl>
            <bibl xml:id="marathe2017" label="Marathe et al. 2017"> Marathe, A., Zhang, Y., Blanks,
               G., Kumbhare, N., Abdulla, G., and Rountree, B. (2017) <title rend="quotes">An
                  Empirical Survey of Performance and Energy Efficiency Variation on Intel
                  Processors</title>, <title rend="italic">Proceedings of E2SCâ€™17: Energy Efficient
                  Supercomputing (E2SCâ€™17)</title>, 9 pages. </bibl>
            <bibl xml:id="peterson2020" label="Peterson 2020"> Peterson, M. (2020) <title
                  rend="quotes">New 'Platypus' Attack Can Extract Data from Intel Chips, But Macs
                  Are Mostly Safe</title>. Appleinsider.com, November 11, 2020, <ref
                  target="https://appleinsider.com/articles/20/11/11/new-platypus-attack-can-extract-data-from-intel-chips-but-macs-are-mostly-safe"
                  >https://appleinsider.com/articles/20/11/11/new-platypus-attack-can-extract-data-from-intel-chips-but-macs-are-mostly-safe</ref>. </bibl>
            <bibl xml:id="rountree2020" label="Rountree 2020"> Rountree, B. (2020) Personal
               communication with Mary Ann Mansigh Karlsen, April 2020. </bibl>
            <bibl xml:id="rountreecondee2021" label="Rountree and Condee 2021"> Rountree, B. and
               Condee, W. <title rend="quotes">The Nonmaterial Mirror: Performing Vibrant
                  Abstractions in AI Networks</title>, <title rend="italic">Theatre Journal</title>,
               73, 2021, pp. 299â€“318. </bibl>
            <bibl xml:id="schechner2006" label="Schechner 2006">Schechner, Richard. (2006) <title
                  rend="italic"> Performance Studies: an Introduction.</title> 2nd edition. pp.
               1-31.</bibl>
            <bibl xml:id="sperryrand1959" label="Sperry Rand Corporation 1959"> Sperry Rand
               Corporation. (1958, 1959) <title rend="quotes">Basic Programming: Univac1 Data
                  Automation System</title>, <ref
                  target="http://www.bitsavers.org/pdf/univac/univac1/UNIVAC1_Programming_1959.pdf"
                  >http://www.bitsavers.org/pdf/univac/univac1/UNIVAC1_Programming_1959.pdf</ref>. </bibl>
            <bibl xml:id="winget1950" label="Winget 1950"> Winget, R. (1950) <title rend="quotes"
                  >Locksmiths Used to Worry about Yeggs: Now Itâ€™s Spies</title>, Louisville Courier
               Journal, April 16, 1950, p. 92, <ref
                  target="https://www.newspapers.com/newspage/110607246/"
                  >https://www.newspapers.com/newspage/110607246/</ref>. </bibl>
         </listBibl>
      </back>
   </text>
</TEI>
