<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xmlns:cc="http://web.resource.org/cc/"
     xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
     xmlns:mml="http://www.w3.org/1998/Math/MathML"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="article" xml:lang="en">Introduction to the Special Issue: Using Visual AI Applied to Digital Archives</title>
            <dhq:authorInfo>
               <dhq:author_name>Lise <dhq:family>Jaillant</dhq:family>
               </dhq:author_name>
               <idno type="ORCID">https://orcid.org/0000-0002-2680-4571</idno>
               <dhq:affiliation>Loughborough University, UK</dhq:affiliation>
               <email>l.jaillant@lboro.ac.uk</email>
               <dhq:bio>
                  <p>Dr. <name>Lise Jaillant</name> is a Reader (Associate Professor) in Digital Cultural Heritage at <name>Loughborough University</name>, 
                     <name>UK</name>. She has a background in publishing history and digital humanities. Dr. <name>Jaillant</name> is an expert on 
                     born-digital archives and the issues of preservation and access to these archives. Since 2020, she has been the UK PI for four projects 
                     on archives and artificial intelligence funded by the <name>AHRC</name> (<name>Arts and Humanities Research Council</name>). These 
                     international projects aim to make digitised and born-digital archives more accessible to researchers and to use innovative research 
                     methods such as AI to analyse archival data. More information can be found at 
                     <ref target="http://www.lisejaillant.com/">http://www.lisejaillant.com</ref>.
                  </p>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <idno type="DHQarticle-id">000752</idno>
            <idno type="volume"><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006--></idno>
            <idno type="issue"><!--issue number, without leading zeroes: e.g. 2--></idno>
            <date><!--include @when with ISO date and also content in the form 23 February 2024--></date>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND">
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
            <taxonomy xml:id="project_keywords">
               <bibl>DHQ project registry; full list available at <ref target="http://www.digitalhumanities.org/dhq/projects.xml">http://www.digitalhumanities.org/dhq/projects.xml</ref>
               </bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords">
               <term corresp="#archives"/>
               <term corresp="#digitization"/>
               <term corresp="#glam"/>
               <term corresp="#machine_learning"/>
            </keywords>
            <keywords scheme="#authorial_keywords">
               <list type="simple">
                  <item>artificial intelligence</item>
               </list>
            </keywords>
            <keywords scheme="#project_keywords">
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <change>The version history for this file can be found on <ref target="https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/main/articles/000752/000752.xml">GitHub</ref>
         </change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract>
            <p/>
         </dhq:abstract>
         <dhq:teaser>
            <p/>
         </dhq:teaser>
      </front>
      <body>
        <div>
          <head></head>
            <p>As more and more museums and archives are making their image collections digitally available, new forms of knowledge and exploration of this 
               growing mass of pictures from the past are needed. Computational techniques, which can process and help visualise tens of thousands of images, 
               will be key to unlocking these digital archives. This Special Issue focuses on the theme of  <hi rend="bold">Using Visual AI Applied to Digital 
               Archives</hi>. It seeks to improve the discoverability, accessibility, and use of digitised cultural archives by working at the crossroads 
               between the humanities (including visual studies, history, and ethics), computer science, and other fields (including information and archival 
               studies). It addresses key challenges and solutions in preservation, cataloguing, and discoverability, as well as cutting-edge digital 
               technologies that are being applied to make visual records more accessible within the cultural heritage sector. These technologies include 
               artificial intelligence (AI) and its subsets: machine learning, computer vision, and automated information retrieval, extraction, and 
               labelling.  </p>
            <p>There are multiple ways in which AI can help unlock digitised (i.e., paper to digital) and born-digital images. AI can be used to 
               automatically create metadata when metadata is otherwise missing or relies on outdated and potentially harmful language (e.g., racist language 
               in the case of images produced during the colonial period). In addition, computer vision can identify individuals and objects across huge 
               numbers of visual images. This includes the identification of sensitive and violent content, which can be useful when flagging such material 
               and adding content warnings.
            </p>
            <p>At the time when libraries, archives, and museums are striving to make their collections more discoverable and accessible to diverse 
               audiences, AI therefore offers unprecedented opportunities to process and analyse collections at scale — but it also carries risks. In 
               particular, AI can magnify existing issues in collections. In the case of archives with potentially harmful language used in metadata, the 
               risk is that an AI system will reproduce and amplify the contentious data used for its training. Computer vision can also be viewed as 
               unethical when applied to photographs obtained without the informed consent of those they represent (e.g., medical images of patients with 
               diseases and physical deformities). Keeping humans in the loop is therefore essential to apply responsible AI to visual archives.
            </p>
            <p>This Special Issue is born of the EyCon (<hi rend="bold">E</hi>arly <hi rend="bold">Con</hi>flict Photography 1890-1918 and Visual AI) 
               project<note>See <ref target="https://eycon.hypotheses.org/">https://eycon.hypotheses.org/</ref> for the project website and 
               <ref target="https://eycon.huma-num.fr/s/en/page/accueil">https://eycon.huma-num.fr/s/en/page/accueil</ref> for the project database.</note>, 
               funded by <name>AHRC</name> in the <name>UK</name> and <name>LABEX</name> in <name>France</name>. Using visual AI technologies, the EyCon 
               project aims to unlock the potential of digital archives, focusing particularly on images of war and colonial violence. AI applications to 
               sensitive historical archives raise ethical questions regarding data ownership, consent, and cultural sensitivity. Furthermore, transparency 
               in how AI algorithms are trained and used within archival contexts is essential for accountability. This includes consideration of the sources 
               of data, the methodologies used in AI applications, and the potential limitations or biases inherent in these systems. Balancing these 
               sometimes-conflicting imperatives will continue to pose a challenge for researchers, users, and professionals in the GLAM (galleries, 
               libraries, archives, and museums) sector.
            </p>
            <p>This collection of articles offers an interdisciplinary forum to explore innovative technologies, methodologies, and practices applying visual 
               AI to digital archives — and the digital humanities and social sciences more broadly. With the advancements in text-recognition technologies 
               applied to digitised written materials, image archives are facing increasing pressures from users to return similarly accessible results. 
               However, the technologies to enable this accessibility and discoverability are still at an experimental stage.  More collaborations between 
               institutions and disciplines are urgently needed to unlock these visual digital archives.
            </p>
            <p>In their article <ref target="../000722/000722.html"><title rend="quotes">Augmenting Access to Embodied Knowledge Archives: A Computational 
               Framework</title></ref>, <name>Giacomo Alliata</name>, <name>Yumeng Hou</name>, and <name>Sarah Kenderdine</name> demonstrate that 
               interdisciplinarity and collaborative work between archivists, computer scientists, artists, and other stakeholders can reveal novel strategies 
               for archival exploration. In their work, they employ a computational framework incorporating machine intelligence, archival science, and digital 
               museology to examine the link between living heritage archives and embodied knowledge experience. Through their examination of two cases 
               (the <name>Prix de Lausanne</name> archive, a collection of 50 years of video recordings of dance performances, and the <name>Hong Kong Martial 
               Arts Living Archive</name>), the authors conclude that computational capacities can make archives easier to discover and analyse. Indeed, 
               algorithmic tools can be used to extract archive-specific features and create meaningful representations of human bodies.
            </p>
            <p>While AI offers unprecedented opportunities to unlock digital archives, it also brings new challenges. <name>Jonathan Dentler</name>, 
               <name>Lise Jaillant</name>, <name>Daniel Foliard</name>, and <name>Julien Schuh</name> explore the ethical dimensions of digitising sensitive 
               war archives from colonial pasts in their article <ref target="../000742/000742.html"><title rend="quotes">Sensitivity and Access: Unlocking 
               the Colonial Visual Archive with Artificial Intelligence</title></ref>. From a large database of sensitive visual materials from colonial 
               conflicts gathered within the EyCon Project (<hi rend="bold">E</hi>arly <hi rend="bold">Con</hi>flict Photography 1890-1918 and Visual AI), they 
               propose an experimental multi-modal computer vision tool for analysing such sensitive archives. <name>Dentler</name> et al. contend that critical 
               and transparent multimodal AI can improve responsible access to colonial archives for researchers and the public. Their proposition demonstrates the 
               importance of developing research tools that check biases, particularly around sensitive historical events such as colonial expansion and 
               violence.
            </p>
            <p><name>Lise Jaillant</name> and <name>Katherine Aske</name> continue to explore the ethical dimensions of AI in the archives sector in the 
               next article, <title rend="quotes">AI and Medical Images: Addressing Ethical Challenges to Provide Responsible Access to Historical Medical 
               Illustrations</title>. Like colonial images, medical pictures are often very sensitive — for example, when they show images of people with 
               diseases who were photographed without informed consent. On the one hand, AI can improve access to digital images while also safeguarding 
               fragile materials in print format. On the other hand, AI also raises concerns about privacy and ethical use when dealing with potentially 
               harmful content. Through interviews with 10 archivists, librarians, and researchers in the <name>UK</name> and <name>US</name>, the authors 
               demonstrate that improved access to medical illustrations is essential to producing new knowledge in the humanities and medical research and 
               to bridge the gap between historical and modern understandings of the human body. They also highlight the importance of appropriate metadata, 
               which can be enhanced with AI tools to improve discoverability and facilitate access to these archives in an ethical way. The article 
               concludes by making recommendations for cultural heritage institutions to help them find the right balance between providing access for 
               research and education and protecting vulnerable audiences from potentially traumatic encounters with such sensitive images.
            </p>
            <p>Captions often enhance the storytelling experience by providing additional context or insights into illustrations or photographs. In their 
               article <ref target="../000740/000740.html"><title rend="quotes">Capturing Captions: Using AI to Identify and Analyse Image Captions in a Large 
               Dataset of Historical Book Illustrations</title></ref>, <name>Julia Thomas</name> and <name>Irene Testini</name> take the less-trodden path of 
               examining the significance of captions from historical books published between the sixteenth century and early twentieth century. Their dataset 
               consists of over a million illustrations from 68,000 volumes in the <name>British Library</name>'s collection, which were digitised by Microsoft. 
               By interrogating the captions of historical book illustrations at such a large scale, the authors aim to uncover how captions relate to the content 
               of the pictures that they accompany. They also explore how the wider dialogue between word and image characterises illustration as a mode of 
               representation. The authors propose <quote rend="inline">indeterminacy</quote> — what is not clearly known, defined, or fixed — as an 
               analytical concept for examining the relationship between word and image. Indeed, the words of a caption are neither part of the image, nor 
               do they fully belong to the body of the text: something we rarely notice in our everyday encounters with captions.
            </p>
            <p>In the final article, <ref target="../000744/000744.html"><title rend="quotes">Deep Learning for Historical Cadastral Maps and Satellite Imagery 
               Analysis: Insights from <name>Styria</name>'s Franciscean Cadastre</title></ref>, <name>Wolfgang Thomas Göderle</name>, <name>Fabian Rampetsreiter</name>, 
               <name>Christian Macher</name>, <name>Katrin Mauthner</name>, and <name>Oliver Pimas</name> examine the significance of AI for enhancing the 
               interpretation of nineteenth-century historical cadastral maps of the Franciscean Cadastre in the province of <name>Styria</name> in 
               <name>Austria</name>. This article analyses outcomes of a 2022 Austrian Science Fund (FWF) project, RePaSE (Reading the Past from the Surface 
               of the Earth).  Cadastral maps offer fascinating insight into land use, property boundaries, and, more broadly, economic and social histories. 
               AI can be useful to fully exploit the potential of these historical records, which have not been sufficiently exploited.
            </p>
            <p>With the rapid deployment of AI in the GLAM sector, these articles offer the opportunity to pause and reflect on the opportunities and 
               challenges offered by artificial intelligence. This special issue is therefore an invitation to work collaboratively, across disciplines and 
               sectors, to address these challenges and fully embrace the potentialities of technology to make visual archives more accessible in an ethical 
               way. Future avenues of research include the application of generative AI (GenAI) to archives. Commercially developed tools such as ChatGPT 
               often do not work well on historical texts, largely because they have been trained using contemporary data. Developing better GenAI tools 
               requires collaborations between humanities scholars, archivists, and computer scientists. Applying GenAI to visual archives rather than text 
               is another exciting research avenue. In May 2024, Google announced the launch of Ask Photos, an experimental add-on feature relying on its 
               GenAI tool Gemini. Instead of scrolling through pages on Google Photos, or using keywords, users can ask for what they are looking for using 
               natural language. Similar technologies could be trained on historical visual archives and modified to take into account the unique features 
               of these collections. AI will continue to transform the archive sector. As the authors in this special issue collectively show, humanities 
               scholars and GLAM sector professionals should not be left aside by this revolution.
            </p>
      </div></body>
   </text>
</TEI>
