<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xmlns:cc="http://web.resource.org/cc/"
     xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
     xmlns:mml="http://www.w3.org/1998/Math/MathML"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <teiHeader>
      <fileDesc>
         <titleStmt><!--Author should supply the title and personal information-->
            <title type="article" xml:lang="en"><!--article title in English--></title>
            <!--Add a <title> with appropriate @xml:lang for articles in languages other than English-->
            <dhq:authorInfo><!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>first name(s) <dhq:family>family name</dhq:family>
               </dhq:author_name>
               <idno type="ORCID"><!--if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000--></idno>
               <dhq:affiliation/>
               <email/>
               <dhq:bio>
                  <p/>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <!--This information will be completed at publication-->
            <idno type="DHQarticle-id"><!--including leading zeroes: e.g. 000110--></idno>
            <idno type="volume"><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006--></idno>
            <idno type="issue"><!--issue number, without leading zeroes: e.g. 2--></idno>
            <date/>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND"><!--If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default):        
                  CC-BY:    
                  CC0:  -->
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
            <taxonomy xml:id="project_keywords">
               <bibl>DHQ project registry; full list available at <ref target="http://www.digitalhumanities.org/dhq/projects.xml">http://www.digitalhumanities.org/dhq/projects.xml</ref>
               </bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
            <!--add <language> with appropriate @ident for any additional languages-->
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords"><!--Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#authorial_keywords"><!--Authors may include one or more keywords of their choice-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#project_keywords">
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc><!-- Replace "NNNNNN" in the @target of ref below with the appropriate DHQarticle-id value. -->
         <change>The version history for this file can be found on <ref target="https://github.com/Digital-Humanities-Quarterly/dhq-journal/commits/main/articles/NNNNNN/NNNNNN.xml">GitHub
        	   </ref>
         </change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract><!--Include a brief abstract of the article-->
            <p/>
         </dhq:abstract>
         <dhq:teaser><!--Include a brief teaser, no more than a phrase or a single sentence-->
            <p/>
         </dhq:teaser>
      </front>
      <body>
         <p>Reconstructing historical texts from fragmentary sources: Charles S. Parnell and the Irish crisis, 1880-86.</p>
         <p>Professor Eugenio Biagini, University of Cambridge</p>
         <p>Professor Patrick Geoghegan, Trinity College Dublin</p>
         <p>Dr Hugh Hanley, University of Cambridge</p>
         <p>Aneirin Jones, University of Cambridge</p>
         <p>Huw Jones, University of Cambridge</p>
         <p>Abstract</p>
         <p>Charles Stewart Parnell was one of the most controversial and effective leaders in the United Kingdom in the second half of the nineteenth century. Almost single-handedly, he transformed the proposal of Home Rule for Ireland from a languishing irrelevance to a mass-supported cause. Though the historiography on Parnell is substantial, the main primary sources for accessing both his thinking and strategies – his speeches – have never been collected or edited. One of the core questions in working towards an edition of his speeches was whether it would be possible to use automated methods on these fragmentary sources to reconstruct what Parnell actually said in them. We were also interested in how the reports varied, and what that variation might tell us about the practices and biases of the journalists who wrote them and the newspapers which published them. This article discusses the use of two digital tools in our attempts to answer these research questions: CollateX, which was designed by Digital Humanities practitioners for the comparison of textual variants, and SBERT Sentence Transformers, which establishes levels of similarity between texts. In this article we talk about how the application of digital methods to the corpus led us away from the idea of producing definitive reconstructions of the speeches, and towards a deeper understanding of the corpus and the journalistic practices which went into its creation.</p>
         <p>1 Introduction</p>
         <p>Charles Stewart Parnell (1846-1891) was one of the most controversial and effective leaders in the United Kingdom in the second half of the nineteenth century. Almost single-handedly, he transformed the proposal of Home Rule for Ireland from a languishing irrelevance to a mass-supported cause. The political backing which he secured was sufficient to persuade one of the two major British parties, W.E. Gladstone’s Liberals, to adopt Home Rule from 1886. Their opponents, the Tories, felt compelled to respond to the extent that they eventually redefined their identity in reaction to the Parnell programme, and became the Conservative and Unionist party, and yet were forced to accept and implement some of Parnell’s demands, specifically with reference to land reform and the democratisation of local government. What is even more extraordinary is that the remapping of the United Kingdom’s political landscape that Parnell provoked proved long-lasting, if not permanent. The idea of Home Rule survived both Parnell himself and Gladstone and came to epitomise the quintessential British and Irish road to constitutional reform from 1920 (when it was adopted for Northern Ireland) and 1998 (when it was applied, in a modified form, to both Scotland and Wales) (Jackson, 2003 and 2012). Moreover, Parnell’s parallel campaign for land reform not only succeeded beyond his own hopes and expectations, but was also exported to other parts of the British Empire, providing the blueprint for the negotiation of late-colonial agrarian conflicts from India to Kenya and Uganda (Low, 1991). </p>
         <p>Though the historiography on Parnell is substantial (e.g. Boyce and O’Day, 1991; Travers and McCartney, 2013), the main primary sources for accessing both his thinking and strategies – his speeches – have never been collected or edited. Though they have been frequently cited, they have not been systematically studied and have often been quoted selectively from newspaper reports which have been considered to be at best biased and sometimes tendentious. In 2020 we secured a Cambridge Humanities Research Grant to remedy this situation by working towards the first critical edition of Parnell’s speeches.</p>
         <p>If Parnell kept drafts of his speeches we do not have them, and our sources consist of multiple reports made by the newspapers that recorded his words and commented on them.</p>
         <p>One of the core questions in working towards an edition was whether it would be possible to use automated methods on these fragmentary sources to reconstruct what Parnell actually said in his speeches. We were also interested in how the reports varied, and what that variation might tell us about the practices and biases of the journalists who wrote them and the newspapers which published them. This article discusses the use of two digital tools in our attempts to answer these research questions: CollateX, which was designed by Digital Humanities practitioners for the comparison of textual variants, and SBERT Sentence Transformers, which establishes levels of similarity between texts.</p>
         <p>Perhaps the most interesting aspect of the project was that the digital methods did not generally reveal the implicit bias in reporting the content of the speeches that we were looking for (with one significant exception, described in Section 6.2), nor did they allow us to construct single reliable texts of the speeches. Instead, they gave us insight into the process of reporting Parnell’s speeches, and how the practices and methods of newspapers, editors and journalists, their approaches, mistakes and omissions, might help historians to better understand the speeches as a corpus. This highlights the role of digital humanities methods and approaches in generating new perspectives, even if they appear to be unsuccessful in answering our original questions – as Willard McCarty has said “a good model can be fruitful in two ways: either by fulfilling our expectations, and so strengthening its theoretical basis, or by violating them, and so bringing that basis into question. … from the research perspective … failure to give us what we expect is by far the most important result” (McCarty, 2013).</p>
         <p>2 Related Work</p>
         <p>Related work on automated approaches to digital editions highlights two aspects of particular relevance to our project: the edition as a process rather than a finished output, and the necessity of combining digital methods with the kind of detailed interpretation and deep reading usually associated with more traditional humanities research.</p>
         <p>The adaptation of the scholarly edition to the digital age has led to an emphasis on viewing the text within the context of its creation, and an understanding of textual boundaries as both mutable and extensible. Recent approaches to digital scholarly editing position editorial work as a dynamic, creative process, with hybridity and differing textual versions given a new prominence (Nabugodi and Ohge, 2022). This is also true of the edition in itself, which is increasingly approached as a multifaceted object, with a ‘final’ text presented alongside manuscript variants, related texts, images and digital tools. This movement towards a mutable vision of the text has a clear relevance to what might be seen as the ‘limitations’ of the Parnell speech source material - the ephemeral nature of the speech itself, and the lack of any canonical version of the text against which to compare witnesses. While recent literature emphasises the importance of digital approaches to the scholarly edition, it is also clear that editorial intervention is an important factor, both in the interpretation of results and in feeding back to the digital processes themselves.</p>
         <p>The blurring of the boundary between an authoritative central text and its context is a problem which increasingly preoccupies the producers of modern scholarly editions. James Cummings draws a distinction between the ‘document’ as ‘a particular instance of a physical manifestation of this text’ and the ‘work’ as ‘an abstraction as understood by readers (including authors and editors)’ (Cummings, 2019a). From this viewpoint, the edition is continually destabilised by the contextual environment from which it originates and continues to be formed. While in some ways this is true of all editions, it is presented as being particularly true of the digital edition, which has the potential ‘[to] be near-infinitely refactorable and dynamically to provide different views depending on external interactions’. This can be expanded to the process of creating the digital edition and the foregrounding within the edition itself of the research methods and techniques, such as collation, which are used as part of the editorial process. Dirk van Hulle asserts the potential of modern editions to simulate ‘a process, such as the creative and imaginative process of a literary work’ (Van Hulle, 2019). This reflects our own experience of the automated collation of an edition as a research method which raises new questions about the corpus, rather than a tool for providing definitive versions of texts.</p>
         <p>CollateX is the most commonly used software for the collation of texts in the digital humanities. It was conceived within the Interedition research group, a cross-institutional initiative created with the aim of developing tools for textual scholarship in a collaborative environment. In <hi rend="italic">Computer-supported collation of modern manuscripts: CollateX and the Beckett Digital Manuscript Project,</hi> members of the group outline the implementation of the software in relation to a digital edition of Samuel Beckett’s manuscripts (Dekker et al, 2014). Their approach is based on the ‘Gothenburg Model’, created to explore the ‘conceptual commonalities’ between fields relating to collation in digital textual scholarship. Here, the collation process is broken up into five steps: tokenisation of the texts to be compared into textual sub-units such as characters words or sentences; normalisation of the tokens to ensure that ‘equivalent’ tokens will align correctly (though see Birnbaum and Spadini, 2020 on normalisation as a process that occurs at every stage of collation, including transcription of witnesses); alignment of tokens between texts to see where they match and differ; analysis of the computed alignment to interpret and correct it; and output/visualisation of the collation results. Much emphasis is put on the human aspect of this process, both in the analysis of results and in decisions on the appropriate level of tokenisation. The inherent ambiguity of the collation process is also highlighted, particularly in relation to transposed text: ‘In some cases, even human interpretation may of course not determine decisively whether an actual transposition took place. We may have to conclude that some cases of potential transposition cannot be determined with absolute certainty.’ This reciprocal and iterative relationship between digital methods and scholarly interpretation, including establishing the point at which the methods fail to produce conclusive results, was central to our work.</p>
         <p>For our project, in which the base text of the speech (i.e. what Parnell actually said) is absent, perhaps the most relevant examples of related research come from work on medieval manuscripts and biblical editions, where multiple sources are collated in an ongoing effort to reconstruct an authoritative text. The <hi rend="italic">Novum Testamentum Graecum: Editio Critica Maior</hi> is an ambitious project that ‘has as its goal to offer a new reconstruction of the earliest attainable text for each of the New Testament writings, termed the <hi rend="italic">Ausgangstext</hi> or ‘Initial Text’, and to present the evidence for the textual history of the Greek New Testament during the first millennium.’ (Houghton et al, 2020). The group also use CollateX, taking advantage of its concept of ‘a baseless collation, allowing the divergences in the textual tradition to be presented without assumptions about the earliest form of text.’ While automated collation and digital tools have a prominent role in the project, these are combined with editorial procedures that emphasise the human, interpretative aspects of textual scholarship. Automated outputs are rigorously checked for misalignment and ‘spelling differences, errors or other peculiarities of individual manuscripts which are considered to be “noise” and are not deemed to be significant for the edition’ are eliminated. It is made clear that any deployment of digital tools in relation to an edition, particularly in the absence of a base text, must form part of a collaborative editorial workflow.</p>
         <p>3 Dataset</p>
         <p>Our dataset consists of 630 TEI P5 XML records relating to reports of Parnell’s speeches. These were created by members of the project team through a combination of OCR and manual transcription. For each report, metadata is recorded on the newspaper (or other outlet) where it was published, on the date and place of publication, and on the type of report (newspaper, pamphlet etc.). Identifier schemes are used for places (Getty Thesaurus of Geographical Names), and publications (Virtual International Authority File, or VIAF) to disambiguate entries and to enable future linked data approaches. ISO 8601 forms of dates are recorded alongside transcriptions of the dates as they appear in the reports. While the hierarchical nature of TEI has come under some criticism in the context of literary editions (e.g. McGann, 2022, but see rebuttal of some points in Cummings, 2019b), its structured approach has lent itself very well to the aims of our project, in particular the close relationship between detailed metadata and transcription. TEI also provides the kind of general standardisation which could allow for comparative approaches with related datasets.</p>
         <p>A separate local authority file is maintained for the speeches themselves, recording when and where each speech took place (if known) and a short summary of the content of the speech (where applicable). Each speech is given an identifier which is referenced in the report records - allowing for the grouping together of all reports relating to a single speech, and creating an entry point where new information about speeches (as distinct from reports of speeches) can be recorded.</p>
         <p>Our TEI records also contain the texts of the reports. Other than basic structural units such as headings and paragraphs we have not introduced further markup (e.g. of places, people, dates) into the report texts. This provides a blank slate for textual analysis and opens up the possibility of using natural language processing techniques such as parts-of-speech tagging and named entity recognition in future stages of the project.</p>
         <p>The data has been modelled both for publication and research - allowing us to easily extract reports relating to speeches, and to analyse and compare them by date, place and publication. This involves, for instance, comparing reports published in English newspapers with those published in Irish newspapers, looking at aspects of the speeches over time, seeing how Parnell tailored his speech to different audiences or places.</p>
         <figure/>
         <p>Figure 1: TEI data model with links to external authority schemes</p>
         <p>4 Methodology</p>
         <p>A key problem in the development of our methodology was finding texts with sufficient levels of similarity for the collation process to be effective. Reports for the same speech sometimes differed to the point where any kind of automated textual comparison became impossible, especially in the comparison of full transcriptions of speeches with summaries of their content. To address this problem, an additional step was introduced before the collation process to identify which texts would collate effectively. This initial stage produced interesting results on the general level of similarity between accounts of speeches, pointing to patterns of copying and adaptation in the writing of reports, and also absence of reporting or partial coverage by some newspapers. This process of calculating source similarity, which was first seen as a purely pragmatic activity to assemble reports which were suitable for collation, instead opened up interesting new pathways for research on journalistic practice around reporting on Parnell.</p>
         <p>Reports which met the required level of similarity for collation were processed using CollateX. The outputs of the collation process were assessed by subject experts to see how effective the workflow was in providing us with useful insights not only into what Parnell did or did not say, but also on the way in which newspapers and other outlets reported on his speeches. One unintended result of the collation process, discussed below, was to discover that it was useful in highlighting what seemed to be the results of mishearings or misunderstandings in the contemporary transcriptions produced by journalists who were witnesses to the speeches.</p>
         <figure/>
         <p>Figure 2: Project workflow</p>
         <p>4.1 Selection of tools and Python libraries</p>
         <p>Our approach was developed around the use of two Python libraries: SBERT Sentence Transformers for establishing similarity levels between sources, and CollateX for visualising the similarities and differences between them.</p>
         <p>
            <ref target="https://www.sbert.net/">SBERT Sentence Transformers Library</ref> is a modification of the BERT (Bidirectional Encoder Representations from Transformers) model, adapting BERT to establish ‘semantically meaningful sentence embeddings’. Sentences from a group of texts are converted into embeddings, and the cosine-similarity of these embeddings can then be used to calculate the similarity between sentences within our groups of texts.</p>
         <p>
            <ref target="https://collatex.net/">CollateX</ref>, is a tool specifically developed for tasks such as manuscript criticism and textual analysis.<ref target="https://collatex.net/" xml:space="preserve"> </ref>It provides a means of tokenising and comparing multiple text items, identifying similarities and differences, and aligning them in tabular output. This output format enables users to view and interpret patterns of similarity and difference between texts as they appear side by side.</p>
         <list rend="numbered">
            <item>Data Extraction and Sentence Tokenisation</item>
         </list>
         <p>As an initial process, we extracted the data for each speech from the speech register file and the corresponding source files related to each speech. We then used data cleaning operations to improve sentence recognition and standardise the texts – removing extra spacing, trailing spaces, newlines and preventing abbreviations (e.g. ‘Mr.’, ‘Rev.’, ‘Dr.’) from ending sentences incorrectly.</p>
         <p>The text for each source file was then tokenised into sentences, using a sentence tokenising tool from the NLTK Python library. For each speech we produced an intermediary dataset containing speech identification number, source, source periodical, sentence number in document and sentence text.</p>
         <list rend="numbered">
            <item>Sentence Transformation and Clustering</item>
         </list>
         <p>These sentences were converted into embeddings which were used to ascertain similarity levels using the SBERT Sentence Transformers tool. They were then assigned to clusters using the agglomerative clustering tool from the sklearn Python library, an algorithm which works recursively to create a hierarchical cluster tree or dendrogram of similar sentences according to a distance threshold.</p>
         <list rend="bulleted">
            <item>Establishing the distance threshold was a key part of our workflow. For the purposes of our project we were aiming to capture sentences which related to the same part of the speech, requiring a high level of similarity. At a lower level of similarity (i.e. higher up the cluster tree) we were more likely to capture sentences which were similar in terms of content but did not relate to the same part of the speech.</item>
         </list>
         <p>Having run the code using different distance thresholds and performed checks on the results, we decided that the most appropriate threshold for our purposes was a level of 0.8. This threshold level took sentences from each report that were the same or clearly referred to the same part of the speech and gathered them together into clusters for the next stage of our process.</p>
         <list rend="numbered">
            <item>Speech Source Similarity</item>
         </list>
         <p>The sentence clusters we created for each speech were then used to establish the similarity of the sources relating to that speech. We did this by extracting the sentence cluster values for each source and comparing the values to those of every other source related to the same speech, creating a Jaccard matrix with calculations of similarity between the clusters for sources.</p>
         <p>These matrices were then converted into a series of heatmaps for each speech, which provided a graphical representation of similarity and clusters of similarity across all the sources related to that speech.</p>
         <list rend="bulleted">
            <item/>
            <item>Figure 3: Example heatmap for similarity of reports of a single speech</item>
         </list>
         <p>As can be seen in Figure 3, the x and y axes have the same data and each square on the heatmap represents the level of similarity between the sentence clusters of a source on the y axis and the sentence clusters of a source on the x axis, with higher levels of similarity represented by lighter squares. The long diagonal line of lightly coloured squares represents sources which are being compared with themselves and therefore have 100 percent similarity to one another.</p>
         <p>This similarity measure was not meant to be completely accurate, but rather to quickly ascertain sources with a degree of similarity which indicated that they would be good candidates for the collation process.</p>
         <list rend="numbered">
            <item>Collation</item>
         </list>
         <p>The input files for the collation process were selected using information gained from establishing source similarity. Once the inputs were finalised, the texts were extracted from the relevant files and normalised to remove line breaks and extra spaces.</p>
         <p>The CollateX tool was then used to tokenise the text into word and punctuation tokens before aligning tokens by similarity and dissimilarity. CollateX outputs colour-coded tables of input texts, with matching rows of text given a lighter colour than non-matching rows. In order to be able to save our tables in an easily viewable form, we adapted the CollateX output using the Plotly Python library.</p>
         <p>5 Case Study: Speech 73, Theatre Royal, Cork, 22 January 1885</p>
         <p>This case study illustrates the importance of establishing an appropriate level of similarity between texts before embarking on automated collation.</p>
         <p>5.1 Low Similarity Sources</p>
         <p>Even for sources with a low level of similarity, the model seemed to be able to pick out the points where there were matches on a specific unit of text.</p>
         <p>However, a coherent collation was not really possible and the CollateX model often picked out false positives using common words. For instance, isolated instances of punctuation or words such as ‘the’, ‘of’ or ‘and’ as the points of similarity between the sources.</p>
         <p>Figure 4: Collatex output for a speech with a low level of similarity between reports</p>
         <p>5.2 High Similarity Sources</p>
         <p>Once a degree of similarity had been established, CollateX was good at picking out the similarities and differences between texts in a more coherent way, with fewer false positives. This occured at between 40 to 60 percent sentence cluster similarity.</p>
         <p>Even with sources exhibiting a very high level of cluster similarity, where there could seem to be little point in performing the collation process (as they were likely to be essentially the same), minor variations sometimes proved to be of interest, as discussed below.</p>
         <p>Figure 5: Collatex output for a speech with a high level of similarity between reports</p>
         <p>5.3 Working with a Cluster of Multiple Similar Sources</p>
         <p>Looking at the heatmap for Speech 73, a main group of consistently similar sources was clearly visible: 308, 311, 313, 314, 315, 323, 330, 351. By performing a collation on these all together we could see that the model performed well in identifying similar and dissimilar passages of text.</p>
         <p>However, the colour coding scheme for identifying matching and non-matching groups of sources could not be relied upon in this instance. If there were one or more non-matching pieces of text in a row that generally matched, the row was defined as non-matching and all table cells came out the same colour.</p>
         <p>Figure 6: Collatex output for a speech with multiple reports</p>
         <p>6 Assessment</p>
         <p>6.1 Coverage and Bias</p>
         <p>Late-Victorian polemics highlighted by modern historiography (Bew, 2012) and the analysis of high-profile examples of contrasting accounts of speeches (Travers, 2000/2001, and see our own example in Section 6.2) have created the impression that the reporting of the speeches was biased and sometimes tendentious, reflecting the wish of editors and reporters to please their readers or represent Parnell in a way that would be either favourable or hostile to a certain interpretation of his words (e.g. that he was more or less constitutional or revolutionary in the way he wished to proceed with the implementation of the nationalist programme). </p>
         <p>However, the results of the collation process show that the newspapers which attempted to provide full accounts of his speeches tended to agree with one another about what he had actually said, and sometimes relied on the same source (suggesting that different newspapers employed a limited number of reporters specialising on Parnell). There were discrepancies, but they generally reflected editorial decisions in cases where certain phrases were omitted or contracted for the sake of space, or where a reporter had misheard a specific word resulting in equally plausible variants, such as when <hi rend="italic">The Times</hi> reported Parnell as saying the Conservative Party was ‘most remarkable for its wisdom’, even though all other outlets reported it as ‘most remarkable for its discipline’. Moreover, and not surprisingly, for the speeches that Parnell delivered when campaigning in the United States, American newspapers often provided a fuller record than their British and Irish counterparts.</p>
         <p>Though the police deployed their own reporters, in general their surviving accounts relied on the records published in the newspapers, and the officers who produced or received the reports limited themselves to underlining sentences which in their view were more significant or revealing. Therefore, police records implicitly and indirectly confirmed that the newspaper press was substantially accurate and reliable in its coverage of Parnell’s speeches. </p>
         <p>Political bias was more clearly evident in choices on how to report (or not report) the speeches. In the results from the initial similarity analysis, it is clear that some newspapers refused to report in detail what Parnell said, providing instead short summaries. This was typically the case with Ulster Unionist newspapers. For example, <hi rend="italic">The Northern Whig</hi>, a Belfast-based Liberal unionist publication, only published brief descriptive reports of even Parnell’s most significant orations. In the five speeches in the corpus that <hi rend="italic">The Northern Whig</hi> and <hi rend="italic">Hansard</hi> both reported, the similarity rating given to them was zero, meaning there was no similarity between their reports. Likewise, <hi rend="italic">The Northern Whig</hi> and the nationalist weekly, <hi rend="italic">The Irishman</hi>, also received a score of zero over eight reports. In the reports it had in common with the nationalist daily <hi rend="italic">The Freeman’s Journal </hi>and the <hi rend="italic">Times </hi>of London, which aspired to be perceived as the ultimate record, <hi rend="italic">The Northern Whig</hi> had a similarity rating of 0.61 and 0.87 respectively. </p>
         <p>Therefore, in our preliminary assessment of what the results tell us about how the press responded to Parnell, two considerations stand out: on the one hand, the nineteenth-century positivist emphasis on ‘factual’ accounts (Matthew, 1987) remained pervasive even when the speaker was as ambiguous and divisive as Parnell, with editors generally relegating the expression of opinion to leading articles. On the other hand, it also showed that readers relying only on regional newspapers in strongly anti-Parnell areas would not have had access to what the nationalist leader actually said, and may have tended to form their views through strongly opinionated editorials.</p>
         <p>6.2 The Collation Process</p>
         <p>The outputs from CollateX encouraged us to read the source material with a greater level of reflexivity than we had previously done. While the tool did not generally uncover obvious ideologically motivated editorial interventions, the sheer number of textual discrepancies it highlighted should persuade historians to be more circumspect about the reliability of contemporary reportage regarding what historical actors actually said.</p>
         <p>For instance, in January 1880, during his tour of North America, the House of Representatives invited Parnell to address a House session and on the evening of 2 February a speech was given from the Speaker’s rostrum. While many media outlets covered the event, only three sources purported to give a full transcript of the speech, namely the <hi rend="italic">Congressional Record, The Washington Post</hi>, and <hi rend="italic">The Irish World </hi>.<note> The Boston Irish-American newspaper <hi rend="italic">The Pilot</hi> printed a full report that was credited to the<hi rend="italic"> Congressional Record </hi>and which was almost identical to the <hi rend="italic">Record</hi>’s account, see <hi rend="italic">The Pilot</hi>, 14 Feb. 1880; after a delay of two weeks, <hi rend="italic">The Freeman’s Journal</hi> printed a report that was almost identical to the <hi rend="italic">Post’s</hi>, see <hi rend="italic">Freeman’s Journal</hi>, 16 Feb. 1880.</note> However, CollateX revealed major differences between the three sources in length, wording, punctuation, and the recording of audience reactions. In terms of length, the <hi rend="italic">Congressional Record</hi>’s report was over ten percent longer than that of <hi rend="italic">The Washington Post</hi> and 25 percent longer than <hi rend="italic">The Irish World</hi>. The report printed in <hi rend="italic">The Post</hi> did not record Parnell’s formal opening in which he marked out the ‘Speaker and gentlemen of the House of Representatives’ as the ‘ratified audience’ for his remarks, and it omitted a further bulky passage where Parnell outlined the social and political context of his speech. <hi rend="italic">The Irish World </hi>was also silent on these opening remarks, which were rhetorically significant as they contained the speech's emotional ballast or <hi rend="italic">pathos</hi>. Nonetheless, before we decided that the <hi rend="italic">Congressional Record</hi> account should be given precedence, we found problems that would probably have gone unnoticed were it not for the CollateX outputs.</p>
         <p>In the weeks preceding Parnell’s speech to Congress, the English historian J.A. Froude published a series of articles about Irish history and politics in <hi rend="italic">The North American Review</hi>. Parnell quoted an extract from one of these articles in which Froude described the land system as the worst of the ‘fatal gifts’ England had bestowed upon Ireland. In the <hi rend="italic">Congressional Record</hi> the first sentence of the quotation was recorded as ‘But – of all the <hi rend="italic">feudal</hi> gifts which we bestowed upon our unhappy possession was the English system of owning lands.’ By contrast, <hi rend="italic">The Washington Post</hi> reported it as ‘But, of all the fatal gifts which we bestowed upon our unhappy possession was the English system of owning land.’ <hi rend="italic">The Irish World </hi>likewise printed the term ‘fatal gifts’. Leaving aside the differences in punctuation and the plural versus singular of land versus lands, the reports disagree on whether Parnell said ‘fatal gifts’ or ‘feudal gifts’. </p>
         <p>The inconsistency is not significant in its own right, as the disagreement most likely comes from a congressional stenographer mishearing the speaker or from a slip of the tongue on Parnell’s part. It is certainly possible that Parnell misspoke and <hi rend="italic">The Washington Post </hi>and <hi rend="italic">The Irish World</hi> corrected his mistake while the <hi rend="italic">Record </hi>did not. Yet, given the prestige and authority of the <hi rend="italic">Congressional Record</hi> as the record of the United States Congress, such mistakes have a legacy in the garbled transmission of Parnell’s speech. For example, a volume published in approximately 1904 entitled <hi rend="italic">Irish Literature</hi> printed an edited version of the <hi rend="italic">Congressional Record</hi>’s account of Parnell’s speech and the volume’s editor, the writer and politician Justin McCarthy, failed to correct the error. Additionally, in a 1986 debate regarding the recently signed Anglo-Irish Agreement and the responsibility of the United States for helping to secure peace in Northern Ireland, Senator D.P. Moynihan commended Parnell’s speech to the Senate, leading to its republication in the record of that body, replete with the misquotation of Froude. </p>
         <p>
            <hi rend="italic">The Irish World</hi>’s report deserves its own discussion, as it bucked the trend by demonstrating significant editorial intervention in its reporting of the address to the House. Unlike the myriad other variations in the dataset, the divergences in the <hi rend="italic">World</hi>’s report display signs that they were ideologically motivated. <hi rend="italic">The Irish World</hi>, edited by Patrick Ford, was widely read on both sides of the Atlantic, circulating over 60,000 copies in the United States with a further 20,000 copies circulating in Ireland and Great Britain (Dungan, 2014). As none of the major Irish newspapers printed a full report, Ford’s newspaper was the context in which most Irish readers would have encountered Parnell’s address. Furthermore, during the 1888-89 special commission into Parnellism and crime, one of Parnell’s counsels, H.H. Asquith, read <hi rend="italic">The Irish World</hi>’s report into the record as an authoritative account of Parnell’s speech (<hi rend="italic">Special Commission Act, 1888</hi>). Its role in the afterlife and reformulation of the speech grants it a status that outweighs its unreliability as evidence for what Parnell actually said before the House. </p>
         <p>
            <hi rend="italic">The Irish World</hi> dotted sub-headings, such as ‘REPLACE THE ARTIFICIAL BY THE NATURAL’ and ‘CONDEMNED BY ENGLISH AUTHORITY’, intended to guide the reader through the speech. The paper also capitalised and italicised certain words and phrases to enhance their effect on the reader. However, the most significant variations in <hi rend="italic">The Irish World</hi>’s account were the notable silences it contained in relation to the other two accounts. In the passage that the <hi rend="italic">World</hi> labelled ‘THE OVERPOPULATION TALE’, large portions dealing with emigration and overcrowding were expurgated: </p>
         <figure/>
         <p>Figure 7: Collatex output for Parnell’s speech to the House of Representatives, January 1880</p>
         <p>Two sentences further on we find another major omission. The <hi rend="italic">Congressional Record </hi>and <hi rend="italic">The Washington Post</hi> reported in terms closely resembling each other that Parnell declared:</p>
         <p>Let the next emigration be from the West to the East, instead of from the East to the West – from the hills of Connemara back to the fertile lands of Meath. When the resources of my country have been fully taken advantage of and developed, when the agricultural prosperity of Ireland has been secured, then if we have any surplus population we shall cheerfully give it to this great country. Then our emigrants will go willingly and as free men – not shoveled out by a forced emigration, a disgrace to the Government whence they could come and to humanity in general. (Applause.) Then our emigrants would come to you as come the Germans, with money in their pockets, and education to enable them to obtain a good start in this great and free country, with sufficient means to enable them to push out to your western lands, instead of remaining about the eastern cities, doomed to hard manual labor, and many of them falling a prey to the worst evils of modern city civilization.</p>
         <p>
            <hi rend="italic">The Irish World</hi>, however, skipped this passage altogether. The image of Irish immigrants to the United States that Parnell painted was not a flattering one. Considering the nature of <hi rend="italic">The Irish World</hi>’s predominantly urban, immigrant Irish-American readership, it is possible that the <hi rend="italic">World</hi> did not wish to show Parnell as having said words to this effect. </p>
         <p>The last significant omission in the <hi rend="italic">World</hi>’s report was to do with Parnell’s use of land reform in Prussia as a model for reform in Ireland. In an open letter to Parnell, <hi rend="italic">The Irish World</hi> urged him not to make comparisons with European land systems but, as Paul Bew phrased it, Parnell ‘pointedly’ flouted this recommendation (Bew, 1979). In the open letter, the <hi rend="italic">World</hi> declared that people who use examples from the European continent to argue for changes to land tenure in Ireland were ‘half-way men’. Parnell’s use of the Prussian example placed him out of ideological alignment with the <hi rend="italic">World</hi>. In return, the <hi rend="italic">World</hi> excised most of his discussion of land reform in Prussia.</p>
         <p>6.3 Tools</p>
         <p>The SBERT Sentence Transformers and sklearn Librariues were easy to use and both in establishing a general level of similarity between sources, which proved crucial to the clustering process, and in elucidating general patterns in the reporting of Parnell’s speeches. Experimenting with the distance threshold to find an appropriate level of similarity was an essential part of this process.</p>
         <p>The Collatex software proved very effective at collating texts which had a sufficient level of general similarity. With texts with low levels of similarity the software collated on false positives generated by commonly used words or punctuation. For a corpus containing texts with very variable levels of similarity, a preprocessing stage to establish which groups of texts are suitable for collation becomes essential. As pointed out by the developers of the library, Collatex (as with all collation software) sometimes struggles with transposed text. This is a known problem which the developers are working on. The outputs produced by the software can be slightly confusing to read, especially when run across multiple texts, as described above in Section 5.3.</p>
         <p>7 Conclusions</p>
         <p>The implementation of automated collation on our corpus brought with it a number of challenges. Whilst we had some success in building a workflow for collation, this necessarily involved a sub-process of finding sources that were similar enough for the automated tools to pick out similarities and differences in a coherent manner. When speech reports, or parts of reports, were too dissimilar, the collation outputs devolved into picking out false positives, such as isolated instances of punctuation. The SBERT library was extremely useful in enabling us to find clusters of reports around speeches that were similar enough to be collated. This process also highlighted significant variations in journalistic practice, such as the fact that Ulster Unionist newspapers tended only to report what Parnell said in summary. </p>
         <p>As a research tool, our collations enabled us to highlight discrepancies between sources more easily, drawing attention to additions and omissions as they occurred. This allowed for notable insights, making us aware of errors in respected sources such as the <hi rend="italic">Congressional Record</hi> that have gone on to be quoted in other contexts. With the exception of <hi rend="italic">The Irish World</hi>, we were unable to see the influence of ideological bias in the ways different sources reported the speeches, but this is an insight in itself, perhaps revealing a general editorial trend towards objectivity in relation to speech reports or the reliance of many publications on a single eyewitness account. Ideological bias seemed to be mainly expressed through other journalistic practices, such as only providing short summaries of speeches, or omitting to report on them altogether.</p>
         <p>In terms of new information, the project told us less about Parnell and his speeches, and more about the practices of the publications, editors and journalists who reported (or failed to report) on them. This concentration on the factors which went into the creation of reports of the speeches will help us to see Parnell and the reception of his ideas in a broader and richer context. As regards the methods themselves, the project highlighted the potential of digital approaches to raise new questions and therefore generate new research pathways. It was fascinating and very fruitful to see the interplay of digital method and scholarly expertise in practice, as the results of the methods generated new insights for the project team, which then fed back into the methodology in a highly productive iterative process.</p>
         <p>Building on the work described in this article, project members have submitted a funding proposal to construct a “transparent edition” of Parnell’s speeches, including a full and open publication of the TEI dataset which forms the basis of the edition (both as data and through a simple web interface), open and documented code for all of the tools used or developed in the course of creating the edition, and the critical edition itself. By doing this we hope to make explicit the iterative and exploratory relationship between digital methods and editorial work which has proved so fruitful in understanding Parnell’s speeches and their context.</p>
         <p>References</p>
         <p>Bew, P. (2012)<hi rend="italic"> Enigma: A New Life of Charles Stewart Parnell.</hi> Dublin: Gill Books.</p>
         <p>Bew, P. (1979) <hi rend="italic">Land and the National Question, 1858-82.</hi> Atlantic Highlands, NJ: Gill and MacMillan.</p>
         <p>Birnbaum, D. and Spadini, E. (2020) ‘Reassessing the locus of normalization in machine-assisted collation’, <hi rend="italic">Digital Humanities Quarterly, </hi>14(3).</p>
         <p>Boyce, D. and O’Day, A. (eds) (1991) <hi rend="italic">Parnell in Perspective</hi>. London: Routledge.</p>
         <p>Cummings, J. (2019a) ‘Opening the book: data models and distractions in digital scholarly editing’, <hi rend="italic">International Journal of Digital Humanities</hi>, 1, pp. 179–93, <ref target="https://doi.org/10.1007/s42803-%20019-00016-6">https://doi.org/10.1007/s42803- 019-00016-6</ref>
         </p>
         <p>Cummings, J. (2019b) ‘A world of difference: Myths and misconceptions about the TEI’, <hi rend="italic">Digital Scholarship in the Humanities</hi>, 34 (Supplement 1), pp. 58–79, <ref target="https://doi.org/10.1093/llc/fqy071">https://doi.org/10.1093/llc/fqy071</ref>
            <ref target="https://openhumanitiesdata.metajnl.com/articles/10.5334/johd.72/main-text-B4">  </ref>
         </p>
         <p>Dungan, M. (2014) <hi rend="italic">Mr. Parnell’s Rottweiler: Censorship and the United Ireland Newspaper, 1881-1891.</hi> Dublin: Irish Academic Press.</p>
         <p>Dekker, R., Van Hulle, D., Middell, G., Neyt, V., Van Zundert, J. (2014) ‘Computer-Supported Collation of Modern Manuscripts: CollateX and the Beckett Digital Manuscript Project’, <hi rend="italic">Digital Scholarship in the Humanities</hi>, 30(3), pp. 452–70, <ref target="https://doi.org/10.1093/llc/fqu007">https://doi.org/10.1093/llc/fqu007</ref>
         </p>
         <p>Houghton, H., Parker, D., Robinson, P.,  Wachtel, K. (2020) ‘The <hi rend="italic">Editio Critica Maior</hi> of the Greek New Testament: Twenty Years of Digital Collaboration’, <hi rend="italic">Early Christianity</hi>, 11(1), pp. 97–117, <ref target="https://doi.org/10.1628/ec-2020-0009">https://doi.org/10.1628/ec-2020-0009</ref>
         </p>
         <p>Jackson, A. (2003) <hi rend="italic">Home Rule : An Irish History, 1800-2000</hi>. London: Weidenfeld &amp; Nicolson.</p>
         <p>Jackson, A. (2012) <hi rend="italic">The Two Unions : Ireland, Scotland, and the Survival of the United Kingdom, 1707-2007.</hi> Oxford: Oxford University Press.</p>
         <p>Low, D.A. (1991) <hi rend="italic">Eclipse of Empire.</hi> Cambridge: Cambridge University Press.</p>
         <p>Matthew, H.C.G. (1987) ‘Rhetoric and  Politics  in  Britain, 1860–1950’, in Waller, P.J. (ed.) <hi rend="italic">Politics and Social Change in Modern Britain</hi>. Brighton: Harvester, pp. 34–58.</p>
         <p>McGann, J. (2022) ‘Editing and Curating Online: Beginning Again’, <hi rend="italic">Textual Cultures</hi>, 15(1), 53-62.</p>
         <p>McCarty, W. (2013) ‘Knowing: Modelling in Literary Studies’ in Siemens, R. and Schriebman, S. (eds.) <hi rend="italic">A companion to digital literary studies</hi>. London: Blackwell, pp. 391-401.</p>
         <p>Nabugodi, M. and Ohge, C. (2022) ‘Provocations towards Creative Critical Editing’, <hi rend="italic">Textual Cultures</hi>, 15(1), pp.1-10.</p>
         <p>Travers, P. (2000/2001) ‘Reading between the Lines: The Political Speeches of Charles Stewart Parnell’, <hi rend="italic">Studia Hibernica</hi>, 2000/2001, 31, pp. 243-256.</p>
         <p>Travers, P. and McCartney, D. (eds.) (2013) <hi rend="italic">Parnell reconsidered.</hi> Dublin: University College Dublin Press.</p>
         <p>Van Hulle, D. (2019) ‘Artificial imagination, imagine: new developments in digital scholarly editing’, <hi rend="italic">International Journal of Digital Humanities</hi>, 1, pp. 137–40, <ref target="https://doi.org/10.1007/s42803-019-00020-w">https://doi.org/10.1007/s42803-019-00020-w</ref>
         </p>
      </body>
      <back>
         <listBibl>
            <bibl/>
         </listBibl>
      </back>
   </text>
</TEI>
