<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
   xmlns:mml="http://www.w3.org/1998/Math/MathML">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <!--Author should supply the title and personal information-->
            <title type="article" xml:lang="en"><!--article title in English-->Minimal Computing for
               Exploring Indian Poetics</title>
            <!--Add a <title> with appropriate @xml:lang for articles in languages other than English-->
            <dhq:authorInfo>
               <!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>Zahra <dhq:family>Rizvi</dhq:family>
               </dhq:author_name>
               <idno type="ORCID"
                  ><!--if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000-->https://orcid.org/0000-0001-8874-8731</idno>
               <dhq:affiliation>Department of English, Jamia Millia Islamia</dhq:affiliation>
               <email>rs.zrizvisasuke@jmi.ac.in</email>
               <dhq:bio>
                  <p>Zahra Rizvi is Ph.D. scholar at the Department of English, Jamia Millia Islamia, Delhi, India. Her research interests include utopia/dystopia studies, digital media, young adult participatory spaces, and ethics of care in/and play. She is a founding-member of the Indian chapter of Digital Games Research Association (DiGRA). She was recently Ministry of Education-SPARC Fellow in Digital Humanities and Digital Cultures at Michigan State University, and is a member of the Digital Humanities Research Group at Department of English, Jamia Millia Islamia. Her work has been published in several online and print journals.</p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>Rohan <dhq:family>Chauhan</dhq:family>
               </dhq:author_name>
               <idno type="ORCID"
                  ><!--if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000-->https://orcid.org/0000-0002-3259-6270</idno>
               <dhq:affiliation>Department of Modern Indian Languages and Literary Studies, University of Delhi</dhq:affiliation>
               <email>chauhan.rohan01@gmail.com</email>
               <dhq:bio>
                  <p>Rohan Chauhan has been trained in Comparative Literature at the Department of Modern Indian Languages and Literary Studies, University of Delhi. He is presently learning about various interfaces between literature and history in the print cultures of colonial North India on a Junior Research Fellowship from UGC. His interests include technologies that support textual studies in the digital age.</p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>A. Sean <dhq:family>Pue</dhq:family>
               </dhq:author_name>
               <idno type="ORCID"
                  ><!--if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000-->https://orcid.org/0000-0001-8463-8578</idno>
               <dhq:affiliation>Department of Linguistics, Languages and Cultures, Michigan State University</dhq:affiliation>
               <email>pue@msu.edu</email>
               <dhq:bio>
                  <p>A. Sean Pue is associate professor of South Asian Literature and Culture at Michigan State University.</p>
               </dhq:bio>
            </dhq:authorInfo>
            <dhq:authorInfo>
               <!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>Nishat <dhq:family>Zaidi</dhq:family>
               </dhq:author_name>
               <idno type="ORCID"
                  ><!--if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000-->https://orcid.org/0000-0001-8017-6185</idno>
               <dhq:affiliation>Department of English, Jamia Millia Islamia</dhq:affiliation>
               <email>nzaidi@jmi.ac.in</email>
               <dhq:bio>
                  <p>Nishat Zaidi is Professor and former Head, Department of English, Jamia Millia Islamia, New Delhi. Her publications include her monographs, Makers of Indian Literature: Agha Shahid Ali (Sahitya Akademi 2014), Terrains of Consciousness: Multilogical Perspectives on Globalization (Wurzburg University Press, 2021. Her forthcoming work is Karbala: A
                     Historical Play (translation of Premchand’s Play Karbala with a critical introduction and notes, OUP, 2022) and her monographs, Dreaming of the Digital DIvan: Digital Apprehensions of Poetry in Indian Languages (with A Sean Pue et al. Bloomsbury 2022), and  Ocean as Method: Thinking with the Maritime (with Dilip Menon et al, Routledge, 2022).</p>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <!--This information will be completed at publication-->
            <idno type="DHQarticle-id"><!--including leading zeroes: e.g. 000110-->000589</idno>
            <idno type="volume"
               ><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006-->016</idno>
            <idno type="issue"><!--issue number, without leading zeroes: e.g. 2-->2</idno>
         	<date when="2022-06-25">25 June 2022</date>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND">
               <!--If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default):        
                  CC-BY:    
                  CC0:  -->
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref
                     target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
                     >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
            <!--add <language> with appropriate @ident for any additional languages-->
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords">
               <!--Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#authorial_keywords">
               <!--Authors may include one or more keywords of their choice-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <!--Each change should include @who and @when as well as a brief note on what was done.-->
         <change when="2022-08-02" who="BRG">fixed errors in encoding and added teaser</change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract><!--Include a brief abstract of the article-->
            <p>This paper explores multilingual minimal computing and plain text for Indian literatures. It focuses on our workflow designed to produce multilingual, annotated digital critical editions of Indian-language poetry, and to model, explicate, and visualize their poetics. In the absence of digital scholarly corpora, resources developed by citizen scholars working outside of academia are essential; for our team and audience, this includes free and open source solutions — including optical character recognition tools — developed in other contexts. Modeling formal, metrical, thematic, and rhythmic structures opens up the possibility for computer-assisted scholarly analysis across the variously related languages and literary histories of India, which are usually treated in isolation. Positioning our work as a form of minimal computing, we discuss our workflow as a <emph>jugaad</emph> — a North Indian term for reuse and innovation in the presence of constraints.</p>
         </dhq:abstract>
         <dhq:teaser>
            <!--Include a brief teaser, no more than a phrase or a single sentence-->
            <p>Exploring minimal computing as a method for creating multilingual, digital critical editions of Indian-language poetry.</p>
         </dhq:teaser>
      </front>
      <body>
         <div>
        <head></head>
         <p>India is a multilingual society with hundreds of years of continuous literary traditions
            in dozens of languages, some stretching as far back as two and a half millennia. We use
            <q>India</q> here not only to refer to the contemporary nation-state but also to the greater
            Indian subcontinent, taking note of the complex, overlapping territorial histories of
            the premodern <q>Hind</q> or <q>Hindustan,</q> the <q>des</q> or <q>desh,</q> <q>British India,</q> and Cold War
            <q>South Asia.</q> Additionally, we acknowledge the interconnectedness of India and its
            diaspora — the world's largest — with other regions. For any project on Indian
            literature(s), it makes more sense to speak of multiple literary traditions instead of
            one. When we speak of <q>Indian poetics,</q> we are actually referring to the longstanding
            traditions of poetics in what come to be understood in the modern period as distinct
            literary traditions in multiple languages, such as Hindi, Urdu, Bengali, Marathi, Tamil,
            and Telugu among many others, which cumulatively stand for <q>Indian Literature(s).</q>
            While the specificities of literary traditions are of interest in themselves, we choose
            to emphasize commonalities and interactions in various poetic traditions of modern
            Indian languages by reading them comparatively.</p>
         <p>Indian literature, imagined this way, is an enormously broad conception that demands
            philological skills that exceed the capacity of any single individual. Therefore, for
            our research project, we started with Hindi and Urdu, two languages with which our
            larger research group, consisting of students and faculty in India and the United
            States, generally felt some familiarity. These languages have an entangled yet estranged
            relationship, and they are the two Indian languages, other than English, that our
            multilingual team knows the best. It is not unusual in India for a person to know two or
            three languages well enough to share in these literary traditions partially. Languages
            such as Punjabi and Bengali have some common sources of vocabulary and generally similar
            grammars to Hindi and Urdu but are written in different scripts with varying
            pronunciations. Other languages, such as Malayalam, have, in addition to script and
            phoneme differences, fully divergent grammars — Dravidian rather than Indo-Aryan —
            though they also incorporate some common sources, such as Sanskrit.</p>
         <p>Hindi and Urdu share a common ancestry: the North Indian speech of the Delhi area.
            Literary histories of <q>Urdu</q> and <q>Hindi</q> name this common ancestor as
            Hindi/Hindui/Hindavi. But they note, this name could be Persian for <title rend="quotes">Indian</title> or any
            language spoken in India (<emph>Hind</emph>). Even though the literary
            language around Delhi began to put <quote rend="inline">undue — and sometimes even almost mindless emphasis on ‘correct’ or ‘standard, sanctioned’ speech in poetry and prose</quote> sometime in
            the eighteenth century, perhaps due to the growing prestige of Persian, it was the British bias in
            language policy that eventually led to the separation of the North Indian speech into
            two separate languages defined along religious lines <ptr target="#faruqi2003" loc="850"/> <ptr target="#mcgregor2003" loc="912–957"/>.
            The gulf only widened further in the late 19th century, when a Hindi-language
            movement led to the development of Modern Standard Hindi. The movement fashioned Hindi
            as the language of Hindus by embracing Sanskrit-derived vocabulary and disparaging
            <q>Urdu</q> and its literature as foreign to South Asia because of its <q>Persian</q> language
            elements and metaphors <ptr target="#king1994"/>. Tied primarily to the ambitions of identity
            formation in the emerging struggles of nationalism, as well as the economic competition
            that was a consequence of colonial linguistic policy in Colonial North India, Hindi and
            Urdu were reconceptualized as representing different religious identities <ptr target="#rai2001"/>.
            That separation saw its highpoint during the partition of British India and continues to
            reverberate across South Asia today. We believe that the intimate yet fraught nature of
            the history that these languages share provides a fruitful ground for comparisons.</p>
            <p>Our collaborative project between the Department of English at Jamia Millia Islamia and
            Michigan State University, titled <title rend="quotes">Digital Apprehensions of Indian Poetics,</title> is
            supported by India's Ministry of Education’s Scheme for Promotion of Academic and
            Research Collaboration (SPARC), which aims to facilitate academic and research
            collaboration between higher education institutes in India and abroad. This new
            collaboration facilitates data-intensive textual studies in Indian languages by creating
            machine-readable, genre-specific corpora and by curating datasets of annotations. We
            attend to the specific conditions of Indian and South Asian languages, for which there
            are few scholarly digital editions and where access to computing is often minimal, even
            at research institutes and universities <ptr target="#shanmugapriya2020"/>. Our goal is to
            create digital editions based on minimal computing principles for use by scholars, the
            public, and students and teachers in the classroom, as well as for ingestion in
            information systems. This involves creating corpora using optical character recognition
            (OCR) and adapting existing digital resources, which include those developed by
            passionate individuals based outside of the academy, or citizen scholars. Therefore,
            we aim to facilitate the study of texts by the general public, as well as professional
            scholars. Additionally, we aim to build a vocabulary to document, interpret, analyze,
            and visualize these textual corpora using linked open data, visualizations, and
            keywords. Throughout our work, we presume a multilingual audience and aim to facilitate
            digital humanities research across Indian languages. </p>
         <p>In what follows, we expound on our desired outcomes, approach, and architecture. As
            noted above, we aim to develop digital critical editions and datasets of annotations,
            including poetic keywords. We approach corpora development as a form of making rooted in
            the principle of <emph>jugaad</emph>, a North Indian term for reuse and
            innovation in the presence of constraints. We conclude with a description of the minimal
            computing architecture that we have adopted for our publishing, editing, and annotation
            work. We present an architecture that can be accessed across Indian languages — starting
            with Hindi, Urdu, and English — using minimal computational resources. Finally, we
            conclude with a note on plain text and the promise it holds for data-intensive textual
            studies in Indian languages. </p></div>
         <div>
         <head>Critical Editions and Keywords for Indian Poetics</head>
         <p>Critical editions have long been a central component of traditional humanities, primarily
            for framing our <quote rend="inline">perception of history, literature, art, thinking, language</quote> by
            establishing <quote rend="inline">reliable sources for research</quote> and authorizing and canonizing <quote rend="inline">certain
               readings</quote> <ptr target="#sahle2016" loc="19"/>. Digital critical editions add a new suite of possibilities,
            including <quote rend="inline">interactivity, multimedia, hypertext, and immaterial and highly dynamic (or
            fluctuating) ways of representing content,</quote> which are absent from printed critical
            editions <ptr target="#hillesund2017" loc="122"/>. The digital paradigm renders the static text
            of a printed critical edition into a <quote rend="inline">laboratory where the user is invited to work with
            the text more actively,</quote> with the help of integrated features and tools <quote rend="inline">allowing for
               customization, personalization, manipulation and contribution</quote> <ptr target="#sahle2016" loc="30"/>.
            Harnessing the networked nature of computation, we envision developing a digital
            platform for scholarly collaboration in publishing. Our goal is to curate and annotate
            critical editions of individual poets' works, while providing critical bibliographies to
            facilitate research and appreciation.</p>
         <p>Through such digital critical editions, our aim is not merely to <quote rend="inline">bring the past into
            the future,</quote> but also to furnish it for newer modes of computational inquiries
            <ptr target="#hillesund2017" loc="123"/>. Remediating the text not only breathes life into
            discussions of Indian poetics but also makes the works of a variety of poets more easily
            accessible to scholars and readers alike. More than that, the endeavor also enables
            reconsideration of questions about the very notion of the digital text and what it means
            to read digitally within the context of South Asian languages and literature(s).</p>
         <p>We draw from Raymond Williams’ method of <quote rend="inline">developing accounts of words as reflective
            essays</quote> for Indian poetics in order to make sense of our textual corpus <ptr target="#keywords2020"/>.
            Through a mix of distant and close reading approaches on a textual corpus
            derived through OCR, we hope to develop a historically informed vocabulary of poetic
            terms and genres that are crucial for understanding the technical field of poetry in
            Indian languages. We extend Williams’ keyword approach to take stock of the emergent
            vocabulary that continues to displace established frameworks in the humanities,
            especially as a consequence of shifting media paradigms. Our objective with the
            fundamental vocabulary of poetic traditions is not to focus on <quote rend="inline">fixing (their)
            definition</quote>; rather, like Williams, we hope to explore the <q>complex uses</q> of a variety
            of conceptual categories to convey the contested nature of their meanings as clearly and
            succinctly as possible <ptr target="#bennett2005" loc="xvii"/>. When we speak of a fundamental
            vocabulary, we are obviously presupposing the existence of a canon, and our plan is to
            foreground the basic implications of the accepted canon in respected literary traditions
            as much as it is to explore the marginal. </p>
         <p>While we want to make this resource accessible to a general audience, we are also keen
            on designing it for use by specialists and teachers and students in the classroom, as well as in computational or traditional research, by providing a snapshot of the historical
            evolution of the semantic fields associated with these terms. While the historical
            variations of meaning might not be as evident for topics pertaining to prosody, we
            believe this might be particularly useful for pinning down both the <quote rend="inline">history of words
            and the contestation of their meanings</quote> for technical poetic vocabularies in different
            literary traditions over generations, eras, and epochs, acknowledging their
            discontinuities, ruptures, erasures, and reconstructions, especially in moments of
            political and social upheaval <ptr target="#keywords2020"/>.<note> For an overview of Urdu literary
               culture, see <ptr target="#faruqi2003"/>. For Hindi, see <ptr target="#mcgregor2003"/>. Also see <ptr target="#king1994"/>, <ptr target="#dalmia2010"/>,
               <ptr target="#rai2001"/>, and <ptr target="#mody2018"/>.</note>
         </p>
         </div>
         <div>
         <head>Making Digital Corpora for Indian Languages</head>
         <p>Because of the absence of existing Indian language digital corpora, especially for
            literary texts, <q>making</q> became a necessary component of our research. Making has
            undoubtedly been central to digital humanities and, as recent debates on the issue have
            clarified, doesn’t necessarily have to begin <q>from scratch</q> but instead can start <quote rend="inline">in
               media res</quote> <ptr target="#sayers2017" loc="11"/>. This conception of making — rooted in collaboration,
            sharing, sustainability, and improvising upon what already exists while critically
            attending to the specificities of the localities where such making is taken up — focuses
            on maintaining or remaking instead of reinventing the wheel. Such <q>critical making,</q> in
            Matt Ratto’s sense of the term, not only opens the disciplinary boundaries of digital
            humanities for introspection but also enriches it by drawing upon practices unfamiliar
            in its predominantly Anglo-American roots.</p>
         <p>For us, critical making also entails localization, whereby we hope to develop, reuse,
            and repurpose open-source tools and technologies for the particularities of Indian
            languages and scripts. Our conception of making is rooted in <emph>jugaad</emph>, an intrinsically Indian way of making do, as Pankaj Sekhsaria
            describes, by <quote rend="inline">reconfiguring materialities</quote> of existing tools to <quote rend="inline">overcome obstacles
               and find solutions</quote> <ptr target="#sekhsaria2013" loc="1153"/>. Our conception of <emph
               >jugaad</emph>, which leans less towards engineering than bricolage, is intrinsically
            tied to localization, and because of this, we inhabit a position closer to a bricoleur
            than to an engineer. We see our labor as bricolage, in the sense that Claude
            Lévi-Strauss articulates: using what's at hand, we design new tools by redeploying a
            finite set of heterogeneous tools in contexts for which they were not originally
            designed, in turn not only extending the intended applications of these tools, but also
            renewing or enriching the stock of tools for future use <ptr target="#levistrauss1974"/>. For
            Sekhsaria, <emph>jugaad </emph>underlies every conversation on technological
            innovation in India, <quote rend="inline">particularly north of the Vindhya Mountain Range,</quote> which refers to
            the territories associated with the Indo-Aryan languages in which the word occurs, and
            testifies to the prevalence of this word in a large Indian populace, given that the
            Vindhya Mountain Range essentially splits the country in half <ptr target="#sekhsaria2013" loc="1153"/>.
            Analyzing <emph>jugaad </emph>as a <q>techno-myth</q> — alongside other cultural
            practices of making in the Global South that Ernesto Oroza would deem <quote rend="inline">technological
               disobedience</quote> <ptr target="#gil2016"/> — Kat Braybrooke and Tim Jordan contrast the element of
            necessity in <emph>jugaad</emph> with the element of leisure and choice in the
            maker movement in the West <ptr target="#braybrooke2017" loc="30–31"/>. This notion of necessity
            in <emph>jugaad</emph> is also central to Padmini Ray Murray and Chris Hand’s
            account of making culture in Indian digital humanities, wherein they advocate for a
            critical dialogue between academic practices and local modes of making <ptr target="#murray2015"/>. <emph>Jugaad</emph>, 
            then, as a quintessential Indian practice, is primarily to
            make-do in response to resource constraints. To borrow from Oroza, <quote rend="inline">misery is not an
            alternative</quote> for us, as we are motivated to engage with <q>hybrid</q> means to achieve our
            scholarly objectives <ptr target="#gil2016"/>.</p>
         <p>For example, our initial efforts to localize open-source OCR tools for Indian languages
            take advantage of two ongoing development efforts in France and Germany. First, we
            focus on creating ground truth corpora to provide accurate transcriptions for training
            and testing of both automatic text recognition (ATR) and automatic layout analysis (ALA)
            models for historical documents in Indian languages using eScriptorium. eScriptorium is
            an open-source tool, currently under development for hand-written text recognition (HTR)
            at École Pratique des Hautes Études, Université Paris Science et Lettres (EPHE – PSL),
            that adapts well for bidirectional scripts. It enables easy application of
            state-of-the-art neural networks for transcribing and annotating historical documents
            using an intuitive graphical user interface in modern web browsers. Developed as part of
            the Scripta project<note> The Scripta project integrates computational humanities and
               the disciplinary questions in the human and social sciences with the history and
               practice of writing across most of human history. </note>, it integrates the Kraken
            engine for OCR/HTR<note> Developed by Benjamin Kiessling, Kraken is an extensively
               rewritten fork of the OCRopus system. It is easily retrainable, and is designed to
               work with a wide variety of scripts by eliminating implicit assumptions about the
               writing system.</note>, and can be installed both locally and as preconfigured Docker
            images <ptr target="#stokes2021"/> <ptr target="#kiessling2019"/>.</p>
         <p>We also draw from ongoing developments within the context of the DFG funded OCR-D
            project<note> <ref target='https://ocr-d.de/'>OCR-D</ref> is a multi-institutional collaboration for improving open-source
               tools for OCR.</note>
            <ptr target="#neudecker2019"/>. Although it is designed for a different context, OCR-D’s clear
            guidelines for transcribing and labelling ground truth in the PAGE-XML format offer us a
            broader framework to maintain consistency across our ground truth. More importantly, we
            rely on the modularity of OCR-D’s software stack for streamlining workflows best suited
            for our documents. OCR-D maintains, builds, and repackages a collection of open-source
            projects in the form of what they call modules. These modules can be painlessly
            installed with either Makefiles or as pre-built Docker images. Each module comes with an
            array of tools, which are called processors. These processors can be easily called from
            the command line for each task in an end-to-end OCR pipeline. Here, image data stored in
            a workspace or local directories can be easily exposed to either a single processor or
            several processors sequentially for different processing tasks through their
            corresponding Metadata Encoding and Transmission Schema (METS) files. Once a task is
            finished, the information about the processing step(s) is written to the METS file,
            while the processed data is saved in the respective output directory. This integrated
            pipeline with pre-configured dependencies becomes extremely salient and functional for
            the needs of our larger group. </p>
         <p>Working with historical documents in different layouts and typefaces, this part of our
            project will create a publicly available textual corpus in Hindi and Urdu that can be
            further processed downstream for a host of data-driven humanistic inquiries. These
            include information extraction methods, such as named entity recognition. Our objective
            is to work primarily with publicly available digital images accessed through
            International Image Interoperability Framework (IIIF) API endpoints hosted at different
            cultural institutions, including the British Library and Internet Archive. Additionally,
            we will publish well-documented state-of-the-art OCR models in public repositories,
            along with their corresponding provenance and ground truth datasets, for use in further
            development of open source OCR for historical print in Hindi and Urdu.</p>
         <p>In the absence of robust institutional support, citizen scholars around the world have
            done much of the work to make Hindi and Urdu texts available on the Internet. Care for
            languages and poetic experience has led impassioned citizen scholars to launch digital
            platforms such as Rekhta (Urdu), KavitaKosh (Hindi), and PunjabiKavita (Punjabi). The
            reach of these projects, especially Rekhta, is enormous, spanning from social media like
            Twitter, Facebook, and Instagram, to festivals and conferences, to classrooms, to more
            personal spaces such as family chat groups. Though these platforms provide enormous
            resources to scholars, their primary and intended audience is not the academy. Our
            collaboration intervenes here to provide access to these texts as data for an audience
            that includes the quotidian Indian as well as scholars, poets, information
            technologists, library systems, and nonhuman agents. Proper metadata is essential for
            such aims. Using linked open data, we incorporate citizen-scholar projects and resources
            into our projects as well. </p>
         <p> Citizen scholarship is only one example of the changes in the portability of texts
            through new digital technologies. The malleability and flexibility of digital texts,
            coupled with their easy accessibility and reproducibility, make them increasingly
            desirable for scholarly inquiry. These affordances motivate our focus on the production
            of high-quality, accessible digital editions. While learning from community-driven
            initiatives by citizen-scholars, our objective is to digitally remediate the critical
            editions of individual poets’ corpora in Indian languages, using minimal markup schemes
            such as Markdown that are easy to reproduce for anyone willing to <quote rend="inline">decode, receive, and
               revise</quote> them <ptr target="#tenen2017" loc="21"/>. The sharing and archiving of these digital editions draw
            inspiration from projects such as OpenArabicPE and OpenITI. These projects not only
            version plain-text data using Git but also link it to facsimiles, wherever available,
            with minimal markup so that scholars can review, contribute, and track changes.</p>
         <p>As we will describe below, we follow this model of using plain text in human- and
            machine-readable Markdown files. While the interface we use to access this data may
            change, the form of the data, a simple text file, is remarkably versatile. The
            transformation from Markdown to Textual Encoding Initiative (TEI) XML, too, can be a
            simple and automatable procedure. However, we require additional layers of annotation,
            especially for poetry, as well as a multilingual interface.</p></div>
         <div>
         <head>Minimal Computing Approaches to Indian Digital Texts </head>
         <p>Prefaced by traditions of localization and open-source activism within India, such as
            those of Delhi's Sarai program<note> Since its inception in 2000, the Sarai program at
               CSD, Delhi has played an active role in facilitating the localization of computing in
               several Indian languages including Kannada, Telugu, Odiya, Kashmiri, and Urdu.
            </note> at the Centre for the Study of Developing Societies, we grapple with questions
            of software translation and localization of linguistic resources. Our focus is on plain
            text and the need for an interface that supports both the conceptual and practical
            dimensions of studying poetics in Indian languages, especially when the digital text
            itself, no matter how plain, is insufficient. Our Hindi and Urdu texts span alphabets
            and scripts — left-to-right and right-to-left, Indic, Perso-Arabic, Roman, Devanagari,
            and unwritten — and yet are mutually aurally comprehensible, for the most part. While we
            are working under constraints, we dare to dream big and use computing to get around
            barriers that otherwise look imposing. </p>
         <p>We use Git to organize and collaboratively write and contribute to our project, as it
            makes both minimal dependence and minimal maintenance possible. Though used primarily to
            version computer code, we use Git both in software development and in our other
            collaborative efforts, including writing. It allows us to avoid dependency on research
            computing professionals or buying expensive, high-maintenance technology. Minimal
            computing helps us avoid the alienation of users or the fetishization of tools. While a
            certain amount of code goes into any GitHub or GitLab project, it makes entry into
            project development possible and accessible for beginners.<note> There are a number of
               free, easy-to-use GitHub and Git tutorials available on the Internet which provide
               dummy projects to work on as a hands-on learning process. Our team made use of Meghan
               Nelson’s <ref
                  target="https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners"
                  ><title rend="quotes">An Intro to Git and GitHub for Beginners (Tutorial)</title></ref> and the <ref
                  target="https://guides.github.com/activities/hello-world/"><q>Hello World</q> GitHub
                  Guides</ref>. Nelson’s tutorial was used by our team members because it has
               accessible slides and cheat sheets, with reduced technical language.</note> As
            humanists, the "making" of Git-based projects appeals to our sensibilities. It is useful not only for not learning but also for tinkering around in a perfect <emph
               >jugaad</emph> fashion, using code and tools in ways that they might not have been
            intended for before, allowing for backtracking and trying out new branches. Git makes
            minimal automation possible by circumventing reliance on dedicated web servers; instead,
            writing and editing work can be done in one's local system and then committed
            to the central GitHub repository. This feature is particularly useful in situations where Internet access is unreliable or during power outages. Also, it uses low
            bandwidth, as on each update only the changes are transferred.</p>
         <p>As noted, we turn to adaptation and localization of existing tools for our collaborative
            writing workflow instead of reinventing the wheel. Specifically, we use Jupyter Book,
            part of the Executable Book Project, which enables users to assemble books and articles
            from a combination of Markdown files, executable Jupyter Notebooks and other sources
            using Sphinx, the robust documentation engine developed for Python. Though originally
            used for collaborative computing in STEM fields, we find the executable notebook and
            book approach of great interest for our digital humanities work, as it allows code to be
            embedded alongside text. Sharing the source files allows for one team member's work to
            be reviewed by others, permitting open access to any calculations and visualizations as
            well as the techniques used to render them. By utilizing Sphinx, Jupyter Book allows
            these various documents to be easily combined and cross-referenced. Like with Markdown,
            the text can be converted into HTML for website viewing, as well as into other
            formats.</p>
         <p>In our workflow, we had to make some adjustments to attend to the specific requirements
            of Indian languages and of our multilingual audiences, as well as to the needs of our
            larger research group. In Unicode, the standard system used to digitally encode the
            world's writing systems, only the orthographic information about a word can be encoded.
            Unlike in English, there can be more than one way to write certain ligatures in both
            Devanagari and Nastaliq scripts, which therefore requires some normalization.
            Transliteration between scripts, metrical analysis, lexicography, and interfacing with
            information systems, however, requires additional layers. For example,
            there is simply not enough information outside of context to distinguish between کیا
               (<emph>kiyaa</emph>: done) and کیا (<emph>kyaa</emph>: what). For
            our larger group, another concern is getting their computer systems ready for the
            minimal computing toolkit. Though the technical requirements are few, minimal computing
            still requires some training and setup. Running Jupyter Book locally, for example,
            requires installing a number of programming languages and libraries to be installed: Python, to run the documentation-generator Sphinx, and Pandoc, a Haskell library, to generate bibliographic citations. We wanted to have the option of two different approaches: 1) to be able to
            sync from a locally running machine to a remote Git repository and 2) to have an
            alternative to syncing between a locally running server and the remote.</p>
         <p>To address these issues, we took advantage of two newer developments: the JAMstack and
            using Git as a content management system.<note> <q>JAM</q> here refers to JavaScript, API,
               and Markup; these are the <soCalled>stack</soCalled> of tools necessary to get the job done. This web
               framework uses the ubiquitous programming language JavaScript (or higher-level
               TypeScript), which runs both in the web browser (<q>client-side</q>) and as a local or
               remote server (<q>server-side</q>). In the JAMstack, an external API (<q>A</q>) can be accessed
               in Javascript and used to populate a website with data. Individual content pages,
               such as blog posts, are usually written in Markdown for the <q>Markup</q> (<q>M</q>). </note>
            In the JAMstack, web pages are typically pre-generated and written to disk through a
            process referred to as <q>Server-Side Rendering</q> (SSR). SSR is advantageous from a search
            engine optimization perspective. As the web crawlers of Internet search engines visit a
            page, they learn not only that there's a page at a given address but also what its
            contents are. Another advantage is that pages can be loaded very quickly because the
            pages are pre-generated and static. Finally, these websites are usually relatively
            small and can often be hosted for free on GitHub, GitLab, Netlify, or other web
            providers.</p>
         <p>While there are several popular JAMstack frameworks, all of which could have handled the
            tasks at hand, we were attracted to the Vue.js JavaScript framework and within it the
            Gridsome JAMstack framework. Vue.js recommends a "single page component" approach to web
            design, whereby code, template, and webpage style declarations are all kept together in
            one file. We decided to embrace this new approach, hoping it would help us get our
            projects going quickly. Gridsome uses Vue.js and adds additional features, such as a
            GraphQL (Graph Query Language) interface to query collections. It relies on plugins,
            which can import data from different sources. Commonly used sources include hidden or
            public blogs, Drupal websites, and, as in our case described below, a directory of plain
            text Markdown files. In addition to markup of text, Markdown files can also contain data
            of nearly any sort in their header. The following example shows a sample header encoded
            in the YAML format, a human-readable way of storing or transmitting data: </p>
         <p><eg lang="xml">
         —-
         title: Bol
         author: Faiz Ahmed Faiz
         —-
         Bol kih lab… (Poem text is here in the <hi rend="quotes">body</hi> )</eg> </p>
         <p>The sample above includes a <q>title</q> and an <q>author</q> field. These fields, which usually
            provide metadata about the text in the <q>body</q> of the Markdown file, can be used to store
            numbers, dates, tags, and nearly any sort of data.</p>
         <p>The second trend that we adopted is the move to use Git not only to write or code
            together but also as a content management system. Here, we used the open-source,
            JavaScript-based Netlify CMS, which is written using React, an alternative to Vue.js.
            Easily added to Gridsome and other frameworks, Netlify CMS allows users to authenticate
            with a Git repository — we used GitLab — and make and commit changes to the repository
            via a web-accessible editor page. A plugin to Gridsome adds a route to a webpage where
            users can edit the Markdown header fields online according to a configuration that they
            specify; we can determine what their content should be (e.g., dates, strings, numbers,
            lists of strings, or references to other nodes). Netlify CMS then handles the updates to
            the Git repository. As a result, we are able to have people access and update the data
            without requiring them to install the full JAMStack on their local computer. </p>
         <p>We also knew we wanted to have certain content and data be available in Hindi, Urdu, and
            English. Fortunately, we were able to adapt the internationalization (i18n) features of
            Netlify CMS to work with those of Gridsome. Netlify CMS handles translation of Markdown
            header and body fields by keeping certain common fields in the default locale — we chose
            English (<q>en</q>) for this project — and by storing <q>localized</q> (translated) fields in
            other locales, as in this YAML header:</p>
         <p><eg lang="xml">
            —-
         en:
            title: Faiz Ahmed Faiz
            bday: 1911.02.13
            body: Urdu poet
         hi:
            title: "फ़ैज़ अहमद फ़ैज़" 
            body: उर्दू शायर
         ur:            title: فیض احمد فیض
            body: اردو شاعر 
         —-</eg></p>
         <p>In this sample from an <q>author</q> collection, the field <q>bday</q> only appears in the default
            locale (<q>en</q>). The fields that can be translated (<q>title</q> and <q>body</q>) appear also in the
            Hindi (<q>hi</q>) and Urdu (<q>ur</q>) locales. Note that the <q>body</q> field, which followed the
            header in the previous Markdown header example, is now contained as a field within the
            header itself. </p>
         <p>The Markdown file of a text can then reference its author(s) using the <q>author</q>
            field:</p>
         <p><eg lang="xml">
         —-
         en:
             title: Bol
         author:
            - Faiz Ahmed Faiz
         body: |-
         bol kih lab aazaad hai tere
         bol zabaa;n ab tak terii hai
         hi:
            author:
            - Faiz Ahmed Faiz
            title: बोल
               body: |-
               बोल कि लब आज़ाद है तेरे 
               बोल ज़बाँ अब तक तेरी है 
         ur:
            author:
               - Faiz Ahmed Faiz
            title: بول
            body: |-
               بول کہ لب آزاد ہے تیرے                 
               بول زباں اب تک تیری ہے 
         —-</eg></p>
         <p>In this example, we specify that there can be more than one <q>author,</q> hence that field
            contains a list, indicated in YAML by the hyphen. The author is referenced using the
            Roman version of the poet's name. This allows for a fully human- and machine-readable
            version of this document. In this way, the plain text files in the directory of a Git
            repository are treated as a document-oriented database. (Gridsome, in fact, uses the
            speedy JavaScript LokiJS database internally). When displayed, fields are presented on a
            webpage in accordance with the client's chosen locale — Hindi, Urdu, or English.</p>
         <p>Through this combination of the JAMstack and a Git repository content management system,
            we can provide localized access not only to viewers but to our contributors, even if
            they are on a mobile phone or tablet without proper access to a computer. By using
            continuous integration — in our case, the running of a script when a commit is made to
            the Git repository — the website is automatically updated when changes to the content
            are made, and tests are run to assert that the changes are valid. Updates to the data
            can also be federated; by adjusting the Netlify CMS settings to use permission levels in
            Git, some users can automatically make changes while others require approval. These
            proposed changes can come from the public, too, offering a straight-forward pathway to
            crowdsourcing.</p>
         <p>For web-based annotation, we are developing a custom widget that starts from the
            transcription of the text in its original script (OCRed, if appropriate) stored in the
            <q>body</q> field of a Markdown file. A <q>genre</q> field determines how exactly the text will be
            treated. In general, we address the location of the individual tokens/words by their
            coordinates in the Markdown file. This allows us to add multiple layers of annotation.
            The transcribed words are treated as <q>phrases</q> that can contain multiple <q>words.</q> A
            name, for example, can be a phrase, but so can a compound word. (Linguists also prefer
            to have some features, such as future case markers, separated.) Sentences are stored as
            a span of coordinates (e.g., for poetry indexed by line group, line, and phrase) after
            we split the original text between spaces, punctuation, and paragraphs. While editing,
            changes to a custom widget are mapped to a model representation of the text in the web
            browser and then written to disk following updates. </p>
         <p>We are also able to produce a view of the text in the Textual Encoding Initiative (TEI)
            XML, which is widely used in digital humanities. Sentences map to TEI’s <q><code>&lt;s&gt;</code></q>
            element, phrases to the <q><code>&lt;phr&gt;</code></q> element, and words are its <q><code>&lt;w&gt;</code></q> element. In
            this way, we avoid the awkwardness of dealing with right-to-left text in XML editors.
            Individual words or phrases, moreover, can have additional views or links attached to
            them, such as scholarly or library-system transliteration or the International Phonetic
            Alphabet. Also, we can offer views of the individual sentences using the CoNLL-UL format
            used by Universal Dependencies (UD), a framework for grammatical annotation, allowing us
            to take advantage of the rich set of annotation tools developed for UD.</p>
         <p>For the purposes of developing an annotated corpus, this <emph
            >jugaad</emph> — using the JAMstack and Git as a CMS — is sufficient. Our plain-text data is
            relatively small, and it can be read by humans and machines alike. We avoid hosting
            large image files by instead providing IIIF links to allow transcribers and developers
            to query the images. Using Git, changes can be tracked and
            undone. There are few limitations as to the data or links we can provide. For example,
            interfacing with citizen scholar projects or Wikidata merely requires adding additional
            fields. For interoperability, the Markdown header field can also approximate (to a
            certain extent) the graph-based Research Description Framework (RDF), which
            uses a subject-predicate-object (S-P-O) approach. For example, the previous example can
            be transformed to RDF as: poem <q>Bol</q> (S) <q>hasAuthor</q> (P) <q>Faiz Ahmed Faiz </q> (O). The
            <q>document</q> or <q>node</q> serves as a <q>subject</q>; the metadata field (e.g., <q>author:</q>) as the
            RDF <q>predicate</q> (e.g, <q>hasAuthor</q>); and the value (e.g., <q>Faiz Ahmed Faiz</q>) as the
            <q>object.</q> In Gridsome, the entire network graph of relations is available both through
            the query language GraphQL and as a database. Finally, the whole system can be accessed
            and updated either on a local machine that has the JAMstack implemented or through a web
            interface to Git using Netlify CMS. While the former is especially useful for those of
            us doing computational analysis, the latter allows updates to be made from any phone.
            The data can be easily versioned and progressively archived from Git to Zenodo or other
            repositories, and the interface expands to meet our needs.</p></div>
         <div>
         <head>Conclusion: Plain Text for Indian Languages</head>
         <p>Plain text is not only simple and dynamic in its potential but also allows authors and
            researchers to have more creative and scholarly freedom over their work that proprietary
            tools and formats often lack. If one hopes to make understanding of Indian poetics
            sustainable and accessible, such minimal computing approaches <quote rend="inline">reduce the use of
            proprietary technologies and paywalls to increase access to content, data, and/or source
            files</quote> <ptr target="#sayers2016"/>. Our project stresses this approach for its contributors as well as
            for its future audience and users. With plain text, the authors have a close
            relationship with their work rather than spending time, money, resources, or effort on
            the tool. More than that, plain text files with minimal markup have a much smaller
            memory size, which reduces both <quote rend="inline">ecological cost of storage for digital preservation</quote>
            and accessibility issues for users in low bandwidth regions <ptr target="#gil2015"/>. It eliminates
            the underlying complex layer of code which mystifies and alienates making from the
            maker. Instead, it brings all the elements to the surface offering new possibilities for
            participation and discovery. </p>
         <p>Above we have described a collaboration to enable data-intensive textual study of Indian
            languages. In the absence of existing digital corpora, especially literary corpora, we
            have turned to making our own, starting with OCR workflows. To do so, we have embraced a
            form of innovation under constraint by reusing or repurposing what is at hand, which is
            commonly referred to in North India as <emph>jugaad</emph>. This process also
            involves sharing methodological innovations as well as data sets. Beginning with poetry
            in Hindi and Urdu, we have sought to develop digital critical editions as well as sets
            of annotations that allow for comparative study across Indian languages. We take a
            minimal computing approach focused on plain text, producing machine- and human-readable
            data.  We use the
            JAMstack and Git as a content management system to allow for not only computational
            approaches to text but also to facilitate access and possibilities for contribution for
            those without a full computer system. Starting with left-to-right and right-to-left
            materials, we anticipate this approach can be expanded to other Indian languages as we
            continue to realize the possibilities of minimal computing for exploring Indian
            poetics.</p></div>
    
      </body>
      <back>
         <listBibl>
            <bibl xml:id="bennett2005" label="Bennett 2005"> Bennett et al. <title rend="quotes">Introduction.</title> In <title rend="italic">New Keywords: A
               Revised Vocabulary of Culture and Society,</title> edited by Tony Bennett, Lawrence
               Grossberg, and Meaghan Morris, xvii–xxvi. Malden, MA: Blackwell Publications,
               2005.</bibl>
            <bibl xml:id="braybrooke2017" label="Braybrooke and Jordan 2017"> Braybrooke, Kat and Tim Jordan. <title rend="quotes">Genealogy, Culture and
               Technomyth: Decolonizing Western Information Technologies, from Open Source to the Maker
               Movement.</title> <title rend="italic">Digital Culture &amp; Society</title> 3 (2017): 25-46. </bibl>
            <bibl xml:id="dalmia2010" label="Dalmia 2010"> Dalmia, Vasudha. <title rend="italic">The Nationalization of Hindu Traditions:
               Bhartendu Harischandra and Nineteenth-Century Banaras</title>. New Delhi: Permanent
               Black, 2010.</bibl>
            <bibl xml:id="faruqi2003" label="Faruqi 2003"> Faruqi, Shamsur Rahman. <title rend="quotes">A Long History of Urdu Literary Culture, Part 1:
               Naming and Placing a Literary Culture.</title> In <title rend="italic">Literary Cultures in
                  History: Reconstructions from South Asia,</title> edited by Sheldon Pollock, 805–863.
                Berkeley: University of California Press, 2003.</bibl>
            <bibl xml:id="gil2015" label="Gil 2015"> Gil, Alex. <title rend="quotes">The User, the Learner, and the Machines We Make.</title> <title
               rend="italic">Minimal Computing Working Group  to Minimal Computing: A Working Group of GO::DH,</title>May 21, 2015.
               <ref target="https://go-dh.github.io/mincomp/thoughts/2015/05/21/user-vs-learner/">https://go-dh.github.io/mincomp/thoughts/2015/05/21/user-vs-learner/</ref>.</bibl>
            <bibl xml:id="gil2016" label="Gil 2016"> Gil, Alex. <title rend="quotes">Interview with Ernesto Oroza.</title> In <title rend="italic">Debates in
               the Digital Humanities,</title> edited by Matthew K. Gold and Lauren F. Klein, 184-193.
               Minneapolis: University of Minnesota Press, 2016. </bibl>
            <bibl xml:id="gil2017" label="Gil 2017"> Gil, Alex. <title rend="quotes">Minimal Computing and the Borders of the New Republic of
               Letters.</title> Michigan State University Global Digital Humanities Symposium, January 27,
               2017. <ref target="https://youtu.be/D0sfv7xWNSE">https://youtu.be/D0sfv7xWNSE</ref>.</bibl>
            <bibl xml:id="hillesund2017" label="Hillesund et al. 2017"> Hillesund, Terje and Claire Bélisle. "What Digital Remediation
               Does to Critical Editions and Reading Practices." In <title rend="italic">Digital Critical
                  Editions,</title> edited by Daniel Apollon et al., 114-154. Urbana: University of
               Illinois Press, 2017.</bibl>
            <bibl xml:id="keywords2020" label="The Keywords Project 2020"> The Keywords Project. <title rend="quotes">What is a ‘Keyword’?</title> <title
               rend="italic">Keywords</title>. Accessed July 15, 2020.
               <ref target="https://keywords.pitt.edu/whatis.html">https://keywords.pitt.edu/whatis.html</ref>. </bibl>
            <bibl xml:id="king1994" label="King 1994"> King, Christopher. <title rend="italic">One Language, Two Scripts: The Hindi
               Movement in Nineteenth Century North India</title>. New Delhi: Oxford University Press,
               1994.</bibl>
            <bibl xml:id="kiessling2019" label="Kiessling 2019"> Kiessling, B. <title rend="quotes">Kraken – A Universal Text Recognizer for the
               Humanities.</title> <title rend="italic">Digital Humanities Book of Abstracts,</title> 2019. <ref
                  target="https://dev.clariah.nl/files/dh2019/boa/0673.html"
                  >https://dev.clariah.nl/files/dh2019/boa/0673.html</ref>.</bibl>
            <bibl xml:id="levistrauss1974" label="Levi-Strauss 1974"> Levi-Strauss, Claude. <title rend="italic">The Savage Mind,</title> translated
               by Ernest Gellner. London: Weidenfeld Nicholson, 1974.</bibl>
            <bibl xml:id="mcgregor2003" label="McGregor 2003"> McGregor, Stuart. <title rend="quotes">The Progress of Hindi, Part 1: The Development of a Transregional Idiom.</title> In <title rend="italic">Literary Cultures in History: Reconstructions from South Asia</title>, edited by Sheldon Pollock, 912–957. Berkeley: University of California Press, 2003.</bibl>
            <bibl xml:id="mody2018" label="Mody 2018"> Mody, Sujata. <title rend="italic">The Making of Modern Hindi: Literary
               Authority in Colonial North India</title>. Oxford University Press, 2018.</bibl>
            <bibl xml:id="murray2015" label="Murray and Hand 2015"> Murray, Padmini Ray and Chris Hand. <title rend="quotes">Making Culture: Locating The
               Digital Humanities India.</title> <title rend="italic">Visual Language: The Journal of Visual and
                  Communication Research</title> 49 (2015): 140–55.</bibl>
            <bibl xml:id="neudecker2019" label="Neudecker et al. 2019"> Neudecker, Clemens, Konstantin Baierer, Maria Federbusch,
               Matthias Boenig, Kay-Michael Würzner, Volker Hartmann, and Elisa Herrmann. <title rend="quotes">OCR-D: An
               End-to-end Open Source OCR Framework for Historical Printed Documents.</title> <title
                  rend="italic">DATeCH2019: Proceedings of the 3rd International Conference on Digital
                  Access to Textual Cultural Heritage</title>, 53-58. <ref target="https://doi.org/10.1145/3322905.3322917">https://doi.org/10.1145/3322905.3322917</ref>.</bibl>
            <bibl xml:id="nigst2020" label="Nigst et al. 2020"> Lorenz Nigst, Maxim Romanov, Sarah Bowen Savant, Masoumeh Seydi, and
               Peter Verkinderen. "OpenITI: a Machine-Readable Corpus of Islamicate Texts." <title
                  rend="italic">Zenodo,</title> February 3, 2020.
               <ref target="https://doi.org/10.5281/zenodo.4075046">https://doi.org/10.5281/zenodo.4075046</ref>.</bibl>
            <bibl xml:id="pue2019" label="Pue 2019"> Pue, A. Sean. <title rend="quotes">Digital Apprehensions of Indian Poetics.</title> SPARC Course, <title
               rend="italic">Jamia Millia Islamia</title>, 2019.</bibl>
            <bibl xml:id="rai2001" label="Rai 2001"> Rai, Alok. <title rend="italic">Hindi Nationalism</title>. Hyderabad: Orient
               Blackswan, 2001.</bibl>
            <bibl xml:id="ratto2011" label="Ratto 2011"> Ratto, Matt. <title rend="quotes">Critical Making: Conceptual and Material Studies in
               Technology and Social Life.</title> <title rend="italic">The Information Society</title> 27 (2011):
               252-260.</bibl>
            <bibl xml:id="sahle2016" label="Sahle 2016"> Sahle, Patrick. <title rend="quotes">What is a Scholarly Digital Edition?</title> In <title rend="italic"
               >Digital Scholarly Editing: Theories and Practices</title>, edited by Matthew James
               Driscoll and Elena Pierazzo, 19-39. Cambridge: Open Book Publishers, 2016.</bibl>
            <bibl xml:id="sayers2017" label="Sayers 2017"> Sayers, Jentery. <title rend="quotes">Introduction: 'I Don’t Know About Circuitry.'</title> In <title rend="italic">Making Things and Drawing Boundaries: Experiments in the Digital Humanities</title>, edited by Jentery Sayers, 1-18. Minneapolis: University of Minnesota Press, 2017. 
            </bibl>
            <bibl xml:id="sayers2016" label="Sayers 2016"> Sayers, Jentery. <title rend="quotes">Minimal Definitions (tl;dr version).</title> <title rend="italic"
               >Minimal Computing Working Group  to Minimal Computing: A Working Group of GO::DH</title>, October 3, 2016. <ref
                  target="https://go-dh.github.io/mincomp/thoughts/2016/10/03/tldr"
                  >https://go-dh.github.io/mincomp/thoughts/2016/10/03/tldr</ref>.</bibl>
            <bibl xml:id="shanmugapriya2020" label="Shanmugapriya and Menon 2020"> Shanmugapriya T. and Nirmala Menon. "Infrastructure and
               Social Interaction: Situated Research Practices in Digital Humanities in India." <title
                  rend="italic">Digital Humanities Quarterly</title> vol. 14.3 (2020). <ref
                     target="http://digitalhumanities.org:8081/dhq/vol/14/3/000471/000471.html"
                     >http://digitalhumanities.org:8081/dhq/vol/14/3/000471/000471.html</ref>.</bibl>
            <bibl xml:id="sekhsaria2013" label="Sekhsaria 2013"> Sekhsaria, Pankaj. <title rend="quotes">The Making of an Indigenous STM: Technological
               Jugaad as a Culture of Innovation in India.</title> In <title rend="italic">Shaping Emerging Technologies:
               Governance, Innovation, Discourse,</title> edited by Kornelia Konrad et al., 137-152. Berlin:
               AKA Press, 2013.</bibl>
            <bibl xml:id="stokes2021" label="Stokes et al. 2021"> Stokes, Peter A., Benjamin Kiessling, Daniel Stökel Ben Ezra, Robin Tissot, and El Hassne Gargem. <title rend="quotes">The eScriptorium VRE for Manuscript Cultures.</title> <title rend="italic">Classics@</title> vol. 18.1 (2021). <ref target="https://classics-at.chs.harvard.edu/classics18-stokes-kiessling-stokl-ben-ezra-tissot-garge">https://classics-at.chs.harvard.edu/classics18-stokes-kiessling-stokl-ben-ezra-tissot-garge</ref>.</bibl>
            <bibl xml:id="tenen2017" label="Tenen 2017"> Tenen, Dennis Yi. <title rend="italic">Plain Text: The Poetics of Computation</title>. Sanford, CA:
               Stanford University Press, 2017.</bibl>
            <bibl xml:id="tenen2014" label="Tenen and Wythoff 2014"> Tenen, Dennis Yi and Grant Wythoff. <title rend="quotes">Sustainable Authorship in
               Plain Text using Pandoc and Markdown.</title> <title rend="italic">The Programming Historian</title> 3, 2014. <ref
                  target="https://doi.org/10.46430/phen0041">https://doi.org/10.46430/phen0041</ref>.
            </bibl>
         </listBibl>
      </back>
   </text>
</TEI>
