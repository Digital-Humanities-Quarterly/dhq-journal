<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title type="article" xml:lang="en">Sentiment Analysis: Limits and Progress of the
                    Syuzhet Package and Its Lexicons</title>
                <dhq:authorInfo>
                    <dhq:author_name>Hoyeol <dhq:family>Kim</dhq:family></dhq:author_name>
                    <idno type="ORCID"
                        ><!-- if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000 --></idno>
                    <dhq:affiliation/>
                    <email>elibooklover@gmail.com</email>
                    <dhq:bio>
                        <p/>
                    </dhq:bio>
                </dhq:authorInfo>
            </titleStmt>
            <publicationStmt>
                <publisher>Alliance of Digital Humanities Organizations</publisher>
                <publisher>Association for Computers and the Humanities</publisher>
                <!-- This information will be completed at publication -->
                <idno type="DHQarticle-id">000611</idno>
                <idno type="volume"
                    ><!-- volume number, with leading zeroes as needed to make 3 digits: e.g. 006 --></idno>
                <idno type="issue"><!-- issue number, without leading zeroes: e.g. 2 --></idno>
                <date/>
                <dhq:articleType>article</dhq:articleType>
                <availability status="CC-BY-ND">
                    <!-- If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default): <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>     
                  CC-BY:  <cc:License rdf:about="https://creativecommons.org/licenses/by/2.5/"/>
                  CC0: <cc:License rdf:about="https://creativecommons.org/publicdomain/zero/1.0/"/>
-->
                    <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
                </availability>
            </publicationStmt>

            <sourceDesc>
                <p>This is the source</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <classDecl>
                <taxonomy xml:id="dhq_keywords">
                    <bibl>DHQ classification scheme; full list available at <ref
                            target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
                            >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
                </taxonomy>
                <taxonomy xml:id="authorial_keywords">
                    <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
                </taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en" extent="original"/>
            </langUsage>
            <textClass>
                <keywords scheme="#dhq_keywords">
                    <!-- Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors -->
                    <list type="simple">
                        <item/>
                    </list>
                </keywords>
                <keywords scheme="#authorial_keywords">
                    <!-- Authors may include one or more keywords of their choice -->
                    <list type="simple">
                        <item>Syuzhet</item>
                        <item>Sentiment Analysis</item>
                        <item>Lexicons</item>
                        <item>Bing</item>
                        <item>Afinn</item>
                        <item>NRC</item>
                    </list>
                </keywords>
            </textClass>
        </profileDesc>
        <revisionDesc>
            <!-- Each change should include @who and @when as well as a brief note on what was done. -->
            <change/>
        </revisionDesc>
    </teiHeader>
    <!-- If a translation is added to the original article, add an enclosing <text> and <group> element -->
    <text xml:lang="en" type="original">
        <front>
            <dhq:abstract>
                <!-- Include a brief abstract of the article -->
                <p>Syuzhet is a dictionary-based tool for the sentiment analysis of literary texts
                    that draws upon the Syuzhet, Bing, Afinn, and NRC lexicons. Syuzhet is a work in
                    progress with the potential to become an invaluable tool for the sentiment
                    analysis of literary texts. However, there have been doubts about sentiment
                    analysis in the digital humanities field, especially after Swafford’s impactful
                    critique of Syuzhet. Since it is impossible to achieve 100% accuracy in
                    sentiment analysis, we should embrace the imperfection and continue to use
                    Syuzhet while also making efforts to fully understand its limits and abilities.
                    In addition, we should continuously provide feedback for the tool, since the
                    duty of improving digital tools belongs to all digital humanists who employ
                    digital tools. This article explores the limits of and improvements made upon
                    Syuzhet by examining and testing its code and functions with 19th century
                    British novels; the subjectivity of its lexicons; and the validity of Swafford’s
                    critique.</p>
            </dhq:abstract>
            <dhq:teaser>
                <!-- Include a brief teaser, no more than a phrase or a single sentence -->
                <p/>
            </dhq:teaser>
        </front>
        <body>
            <head/>
            <div>
                <head>1. Introduction</head>
                <p>Text mining is no longer an uncommon research method when it comes to analyzing
                    texts in the digital humanities. Once limited to the research field, text mining
                    now influences <quote rend="inline">our lives, our teaching, and our
                        scholarship, and digital humanists</quote>
                    <ptr target="#binder2016" loc="213"/> as <quote rend="inline">a logocentric
                        practice</quote>
                    <ptr target="#clement2016" loc="534"/>. Sentiment analysis, also known as
                    opinion mining, shares common features with text mining when parsing, detecting,
                    and locating words or sentences. Sentiment analysis is <quote rend="inline">the
                        process of extracting an author’s emotional intent from text</quote>
                    <ptr target="#kwartler2017" loc="85"/>. Sentiment analysis has historically
                    focused on product reviews, such as those of movies, hotels, cars, books, and
                    restaurants, in addition to blog data. There have been attempts at employing
                    sentiment analysis in literature, mainly grounded on dictionary-based
                    approaches, but sentiment analysis in literature has been a target of attack in
                    digital humanities due to its limits as a research method: Swafford’s critique
                    of the Syuzhet package made a great impact on the digital humanities field by
                    alerting readers to the danger of choosing faulty tools, although her criticism
                    rehashed already existing issues in sentiment analysis. <ptr
                        target="#swafford2015"/> Along with her critique of Syuzhet, other DHers
                    shared erroneous results found through Syuzhet and expressed uneasy feelings
                    about sentiment analysis in literature. In reality, perfect codes/tools cannot
                    exist, so we need to <quote rend="inline">embrace <quote rend="inline"
                            >problems</quote></quote> with Syuzhet <quote rend="inline">as a feature
                        rather than a flaw</quote>
                    <ptr target="#rhody2015"/>. Syuzhet has the potential to be an exquisite tool
                    for the sentiment analysis of literary texts if it can overcome its limits with
                    the application of machine/deep learning algorithms. However, it is impossible
                    to develop digital tools with 100% accuracy, and machine/deep learning
                    algorithms are still under development. Ted Underwood asserts that if we <quote
                        rend="inline">use algorithms in our research,</quote> we should <quote
                        rend="inline">find out how they work</quote>
                    <ptr target="#underwood2014" loc="69"/>. Similarly, when using digital tools, it
                    is important to understand their functions, algorithms, and programming syntax,
                    instead of simply drawing upon the visualized results, in order to avoid
                    creating faulty results. </p>
                <p>Sentiment analysis processes are based on three classification techniques: a
                    lexicon-based approach; a machine learning approach; and a hybrid approach. The
                    machine learning approach uses machine learning algorithms based on linguistic
                    features, such as topic modeling, whereas the lexicon-based approach draws upon
                        <quote rend="inline">a collection of known and precompiled sentiment
                        terms</quote>
                    <ptr target="#medhatetal2014" loc="1098"/>. There are a variety of tools for
                    sentiment analysis, such as the SentimentR, Tidytext, Syuzhet, RSentiment, and
                    SentimentAnalysis packages. All of these sentiment analysis packages are
                    lexicon-based, sharing similar limits and features, such as providing the user
                    the option to use customized dictionaries. Sentiment analysis algorithms and
                    lexicons were originally developed with the aim to analyze tweets and product
                    reviews, but current sentiment analysis has expanded to <quote rend="inline"
                        >stock markets, new articles, [and] political debates</quote>
                    <ptr target="#medhatetal2014" loc="1094"/>, and serves a variety of purposes.
                    For instance, the sentiment analysis package with the Loughran-McDonald
                    Sentiment Words Lists (DictionaryLM) contains the LM (Law Minor) sentiment words
                    with five categories (positive, negative, litigious modal, uncertainty
                    constraining), which can be used in a legal setting. Similarly, Henry’s
                    Financial Dictionary (DictionaryHE) is a suitable lexicon for economic and
                    monetary topics.</p>
                <p>Despite the fact that sentiment analysis has been commonly employed in a variety
                    of fields, mainly for commercial purposes, sentiment analysis for literature did
                    not exist until January 2015, when the Syuzhet package was first released, aimed
                    at providing a proper tool for literary analysis. Syuzhet 0.2.0 was released on
                    February 22, 2015 and was soon critiqued by Swafford, who pointed out problems
                    with Syuzhet on her personal blog on March 2, 2015, such as (1) splitting
                    sentences, (2) negators, (3) parts of speech, such as <q>well</q> and
                        <q>like,</q> (4) lexicons being based on contemporary English words, (5)
                    counting a word once for a sentence even if it is repeated, (6) scoring
                    subjectivity, (7) satire and sarcasm, (8) foundation shapes. <ptr
                        target="#swafford2015"/> Despite the effort by Jockers’ lab to create a
                    useful tool for sentiment analysis tailored to analyzing literary texts, the
                    limits of Syuzhet that Swafford pointed out caused DHers to have qualms about
                    sentiment analysis in literature. After Swafford’s criticism against Syuzhet
                    0.2.0, Syuzhet 1.0.0 was released on April 28, 2016, followed by another release
                    on December 14, 2017 of the 1.0.4 version. I decided to closely examine Syuzhet
                    1.0.4 to impart the limits and progress of Syuzhet, with the subjects of my
                    experiment being mainly from 19th century British novels, since they are not
                    under copyright, are long enough to produce valid analyses, and are credited for
                    their well-structured plots.</p>
            </div>
            <div>
                <head>2. Lexicons</head>
                <p>The term Syuzhet stems from <quote rend="inline">the Russian Formalists Victor
                        Shklovsky and Vladimir Propp who divided narrative into two components, the
                            <term>fabula</term> and the <term>syuzhet</term></quote><ptr
                        target="#jockers2017c"/> to depict narrative structures of story. Syuzhet
                    intends to provide <quote rend="inline">the latent structure of narrative by
                        means of sentiment analysis</quote> and specifically <quote rend="inline"
                        >the emotional shifts that serve as proxies for the narrative movement
                        between conflict and conflict resolution.</quote>
                    <ptr target="#jockers2017c"/> Jockers’ explanation of Syuzhet describes it as a
                    sentiment analysis tool for the analysis of literary texts. Syuzhet is a
                    dictionary-based package, mainly drawing upon four standard lexicons: Syuzhet,
                    Bing, Afinn, and NRC.</p>
                <table>
                    <head>Number of Sentiment Words in Lexicons Used in the Syuzhet Package</head>
                    <row>
                        <cell/>
                        <cell role="label">Syuzhet</cell>
                        <cell role="label">Bing</cell>
                        <cell role="label">Afinn</cell>
                        <cell role="label">NRC</cell>
                    </row>
                    <row>
                        <cell role="label">No. of Positive Words</cell>
                        <cell role="data">3587</cell>
                        <cell role="data">2006</cell>
                        <cell role="data">878</cell>
                        <cell role="data">2312</cell>
                    </row>
                    <row>
                        <cell role="label"> No. of Negative Words</cell>
                        <cell role="data">7161</cell>
                        <cell role="data">4783</cell>
                        <cell role="data">1598</cell>
                        <cell role="data">3324</cell>
                    </row>
                    <row>
                        <cell role="label">No. of Other Words</cell>
                        <cell role="data">-</cell>
                        <cell role="data">-</cell>
                        <cell role="data">1</cell>
                        <cell role="data">8265</cell>
                    </row>
                    <row>
                        <cell role="label">Total</cell>
                        <cell role="data"> 10748</cell>
                        <cell role="data">6789</cell>
                        <cell role="data">2477</cell>
                        <cell role="data">13901</cell>
                    </row>
                </table>
                <p>The Bing, Afinn, and Syuzhet lexicons provide polarity which sorts words into
                    positive or negative positions with numeric values. The Bing lexicon has a
                    binary categorization, which simply has two values of –1 and 1. The Afinn
                    lexicon grades words between –5 and 5. The Syuzhet lexicon has more specific
                    values for each sentiment word, ranging between –1 and 1, which are –1.0, –0.8
                    –0.75, –0.6, –0.5, –0.4, –0.25, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.8, 1.0. The
                    NRC lexicon sorts sentiment words into categories consisting of positive,
                    negative, anger, anticipation, disgust, fear, joy, sadness, surprise and trust.
                    The other words from the NRC lexicon in Table 1 consist of anger (1247),
                    anticipation (839), disgust (1058), fear (1476), joy (689), sadness (1191),
                    surprise (534), and trust (1231). A number of words from the NRC lexicon are
                    included in different categories at the same time, but the Syuzhet package can
                    only work with positive and negative lexicons from the NRC lexicon. Excluding
                    duplicate words in the different feeling categories of the NRC lexicon, there
                    are 6,468 unique words. Among these, there are 81 words which belong to both
                    positive and negative categories, such as <q>boisterous,</q>
                    <q>endless,</q> and <q>revolution.</q> The Syuzhet package processes those 81
                    words with a score of 0. In addition, if a word was not categorized as positive
                    or negative, it will score 0. For example, <q>confront</q> falls into two
                    categories: anger and anticipation, but scores 0, whereas <q>annoy</q> scores
                    –1, which is categorized as negative, anger, and disgust in the NRC
                    lexicons.</p>
                <figure>
                    <head>Similar results from four different lexicons</head>
                    <graphic url="resources/images/figure01.jpg"/>
                    <figDesc>A set of line graphs showing the emotional valence with respect to
                        narrative time of eight different novels. Each graph features emotional
                        valence as calculated by four different lexicons, and the lines produced by
                        the lexicons are very similar in trajectory.</figDesc>
                </figure>
                <p>Figures 1 and 2 were created through the get_dct_transform function of Syuzhet
                    using four different lexicons, Bing, Afinn, NRC, and Syuzhet, for sixteen
                    novels. In figure 1, the emotional valence of each lexicon is similar over the
                    narrative time from eight novels: Charles Dickens’ <title rend="italic">Oliver
                        Twist</title> and <title rend="italic">Little Dorrit</title>, George Eliot’s
                        <title rend="italic">Adam Bede</title>, <title rend="italic">The Mill on the
                        Floss</title> and <title rend="italic">Middlemarch</title>, Thomas Hardy’s
                        <title rend="italic">The Return of the Native</title>, Elizabeth Gaskell’s
                        <title rend="italic">North and South</title>, and Mary Elizabeth Braddon’s
                        <title rend="italic">Lady Audley’s Secret</title>.</p>
                <figure>
                    <head>Differing results from four different lexicons</head>
                    <graphic url="resources/images/figure02.jpg"/>
                    <figDesc>A set of line graphs showing the emotional valence with respect to
                        narrative time of eight different novels. Each graph features emotional
                        valence as calculated by four different lexicons, and while some of the
                        lines produced by the lexicons are similar in trajectory, others are quite
                        different from each other.</figDesc>
                </figure>
                <p>Figure 2, however, reveals inconsistent emotional valences from four lexicons for
                    eight novels: Charles Dickens’ <title rend="italic">Our Mutual Friend</title>
                    and <title rend="italic">Bleak House</title>, Wilkie Collins’ <title
                        rend="italic">The Woman in White</title>, Jane Austen’s <title rend="italic"
                        >Pride and Prejudice</title>, Emily Brontë’s <title rend="italic">Wuthering
                        Heights</title>, Charlotte Brontë’s <title rend="italic">Jane Eyre</title>
                    and <title rend="italic">Villette</title>, and James Joyce’s <title
                        rend="italic">A Portrait of the Artist as a Young Man</title>. </p>
                <p>What causes different sentiment analysis results to be generated depending on the
                    lexicon? I examined the differences between the four lexicons based on
                    positivity and negativity in order to find the reasons why sentiment
                    trajectories could be different between them. Table 2 reveals that the Bing and
                    Afinn lexicons have the highest similarity of deciding positivity and
                    negativity, whereas the Syuzhet and NRC lexicons have the lowest number between
                    the results, although the number is still high. </p>
                <table>
                    <head>Similarity of deciding positivity and negativity between lexicons used in
                        the Syuzhet package</head>
                    <row>
                        <cell role="label">Lexicons (No. of Words)</cell>
                        <cell role="label">Syuzhet-Bing (5,910)</cell>
                        <cell role="label">Syuzhet-Afinn (2,285)</cell>
                        <cell role="label">Syuzhet-NRC (4,783)</cell>
                        <cell role="label">Bing-Afinn (1,315)</cell>
                        <cell role="label">Bing-NRC (2,396)</cell>
                        <cell role="label">Afinn-NRC (990)</cell>
                    </row>
                    <row>
                        <cell role="label">Similarity of Deciding Positivity and Negativity </cell>
                        <cell role="data">98.26%</cell>
                        <cell role="data">98.47%</cell>
                        <cell role="data">96.59%</cell>
                        <cell role="data">98.71%</cell>
                        <cell role="data">98.33%</cell>
                        <cell role="data">98.18%</cell>
                    </row>
                </table>
                <p>The percent similarity for giving the same words positive or negative values
                    between two different lexicons are the followings: Syuzhet-Bing (98.26%, 5,910
                    words), Syuzhet-Afinn (98.47%, 2,285 words), Syuzhet-NRC (96.59%, 4,783 words),
                    Bing-Afinn (98.71%, 1,315 words), Bing-NRC (98.33%, 2,396 words), and Afinn-NRC
                    (98.18%, 990 words). This means that the Syuzhet and Bing lexicons have 5,910
                    common words that, when given positive and negative scores, conflict 1.74% of
                    the time. For example, the words <q>avenge,</q>
                    <q>enough,</q> and <q>envy</q> are scored 0.25, –0.25, and –0.8 by the Syuzhet
                    lexicon, versus –1, 1, and 1 by the Bing lexicon. Looking into the comparison of
                    the Syuzhet and NRC lexicons, the words <q>absolute,</q>
                    <q>ancient,</q> and <q>blush</q> score –0.25, 0.25, and 0.6 in the Syuzhet
                    lexicon, versus 1, –1, and –1 in the NRC lexicon, respectively. These different
                    decisions whether words will be assigned positive or negative can bring about
                    different results during sentiment analysis, as shown in figure 2.</p>
                <table>
                    <head>Percentage of shared words between lexicons used in the Syuzhet
                        package</head>
                    <row>
                        <cell role="label">Lexicons (No. of Words)</cell>
                        <cell role="label">Syuzhet-Bing (5,910)</cell>
                        <cell role="label">Syuzhet-Afinn (2,285)</cell>
                        <cell role="label">Syuzhet-NRC (4,783)</cell>
                        <cell role="label">Bing-Afinn (1,315)</cell>
                        <cell role="label">Bing-NRC (2,396)</cell>
                        <cell role="label">Afinn-NRC (990)</cell>
                    </row>
                    <row>
                        <cell role="label">Syuzhet</cell>
                        <cell role="data">54.99%</cell>
                        <cell role="data">21.26%</cell>
                        <cell role="data">44.50%</cell>
                        <cell role="data">-</cell>
                        <cell role="data">-</cell>
                        <cell role="data">-</cell>
                    </row>
                    <row>
                        <cell role="label">Bing</cell>
                        <cell role="data">87.05%</cell>
                        <cell role="data">-</cell>
                        <cell role="data">-</cell>
                        <cell role="data">19.37%</cell>
                        <cell role="data">35.29%</cell>
                        <cell role="data">-</cell>
                    </row>
                    <row>
                        <cell role="label">Afinn</cell>
                        <cell role="data">-</cell>
                        <cell role="data">92.25%</cell>
                        <cell role="data">-</cell>
                        <cell role="data">53.09%</cell>
                        <cell role="data">-</cell>
                        <cell role="data">39.97%</cell>
                    </row>
                    <row>
                        <cell role="label">NRC</cell>
                        <cell role="data">-</cell>
                        <cell role="data">-</cell>
                        <cell role="data">73.95%</cell>
                        <cell role="data">-</cell>
                        <cell role="data">37.04%</cell>
                        <cell role="data">15.31%</cell>
                    </row>
                </table>
                <p>Based on table 3, the percentage of words included in the Syuzhet package that
                    are shared with any given lexicon are relatively low across the board. This is
                    most likely due to the fact that the Syuzhet lexicon was created much later with
                    reference to the Bing, Afinn, and NRC lexicons, and therefore includes words
                    from all three. Because of this, Syuzhet has the most words of any lexicon (not
                    including repeated words in the NRC lexicon) at 10,748 words, causing the
                    disproportion between the percentages of shared words for Syuzhet and the
                    lexicons it is being compared with. Similarly, Afinn, with the fewest words of
                    the four lexicons, when compared with them generates higher percentages for
                    itself.</p>
                <p>Despite having the same tool setting conditions, depending on the lexicon,
                    sentiment trajectories could be different due to the subjectivity of the
                    lexicons. The inconsistent sentiment scores of the Syuzhet lexicon result in the
                    discrediting of dictionary-based sentiment analysis. Stephen Ramsay states that
                    literary criticism is not only <quote rend="inline">a qualitative matter</quote>
                    but also <quote rend="inline">an insistently subject manner of
                        engagement.</quote> Likewise, creating lexicons is a <quote rend="inline"
                        >subject manner of engagement</quote>
                    <ptr target="#ramsay2011" loc="8"/> through the subjective interpretation of
                    emotions used in labeling words with scores. Sentiment analysis packages provide
                    customizing functions, either through the customization of dictionaries or the
                    use of dictionaries that are created from scratch, in order to overcome this
                    limit. Nonetheless, it would be challenging to create a dictionary that avoids
                    every critique of subjectivity.</p>
                <p>Syuzhet 1.0.4 has not provided a function to use custom dictionaries yet. Syuzhet
                    2.0.0 is expected to provide the function, but it usually requires a
                    considerable amount of time and effort to create sentiment dictionaries, and
                    customized dictionaries might face the question of reliability and credibility
                    when used in research. Instead of creating a sentiment dictionary from scratch,
                    researchers can use pre-made sentiment dictionaries, such as the psychological
                    Harvard-IV dictionary (DictionaryGI), or customize their sentiment analysis by
                    adding algorithms, but they cannot change the sentiment scores from existing
                    lexicons. </p>
            </div>
            <div>
                <head>3. Syuzhet</head>
                <div>
                    <head>3.1 Parsing</head>
                    <p>The goal of opinion mining is to generate relevant information from texts for
                        analysis. To do so, parsing text is the first step. However, there can be
                        distortions in the process of text mining if raw data are not trimmed.
                        Therefore, well-structured text data need to be inputted for sentiment
                        analysis to generate the correct data. In Syuzhet, there are two different
                        ways to parse text and transform it into vector values: (1) Tokenizing the
                        text into sentences, and then transforming the text into a numeric vector
                        for each sentence. (2) Tokenizing the text into words, and then transforming
                        each word into vector representations. Depending on the purpose of research,
                        the text is tokenized into sentences or words through either the
                        get_sentences function or the get_tokens function. For the sentiment
                        analysis of novels, the first method, which tokenizes the text into
                        sentences, is normally chosen, so I will focus on parsing the text into
                        sentences using the Syuzhet package. The Syuzhet package originally
                        (versions 1.0.1 and earlier) called upon the OpenNLP API, which is an open
                        source, in order to implement the get_sentences and the get_tokens
                        functions. In addition, the Syuzhet package originally required installing
                        Oracle’s Java and two R packages, namely <q>openNLPdata</q> and <q>rJava</q>
                        in order to use the OpenNLP parser, which was not user-friendly. Both the
                        get_sentences function and the get_tokens function parse sentences or
                        tokenize words into numeric vectors of sentiment values. Parsing text is a
                        basic query used to process natural languages, as computers cannot read
                        characters, only numbers. Swafford points out the problems with the OpenNLP
                        parser when grouping sentences <ptr target="#swafford2015"/>, and Jockers
                        responds to her by asserting that the OpenNLP parser and the Stanford
                        CoreNLP parser are <quote rend="inline">good enough</quote>
                        <ptr target="#jockers2015"/>, although he admits that these parsers have
                        problems. In fact, the Stanford parser is a well-constructed tool, which
                        applies a Part-Of-Speech Tagger (POS Tagger). The OpenNLP parser has been
                        improved, but I found that Syuzhet no longer uses the OpenNLP parser for the
                        get_sentences function, despite Jockers mentioning that it does <ptr
                            target="#jockers2017a"/>. Instead, Syuzhet draws upon the Textshape
                        package developed by Tyler Rinker for parsing sentences. It seems the
                        Syuzhet manual has not been updated yet, as this change in the parser by
                        Jockers went undocumented. It is possible that Jockers made the change in
                        order to acknowledge the limits of the OpenNLP parser for literary text.
                        Syuzhet 1.0.2 was updated with the removal of the Java dependency, which
                        means that Syuzhet users do not have to install Oracle’s Java and its
                        dependent packages, <q>openNLPdata</q> and <q>rJava,</q> anymore to utilize
                        the Textshape package, in addition to parallelization of the get_sentiment
                        function by Philip Bulsink on July 28, 2017. </p>
                    <table>
                        <head>Comparison of the parsing results from sixteen novels using Syuzhet
                            0.2.0 and 1.0.4</head>
                        <row>
                            <cell role="label">Author</cell>
                            <cell role="label">Title</cell>
                            <cell role="label"> Syuzhet 0.2.0</cell>
                            <cell role="label">Syuzhet 1.0.4</cell>
                            <cell role="label">Change</cell>
                        </row>
                        <row>
                            <cell role="data">Charles Dickens</cell>
                            <cell role="data"><title rend="italic">Oliver Twist</title></cell>
                            <cell role="data">6,887</cell>
                            <cell role="data">9,128</cell>
                            <cell role="data">+35.24%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell role="data"><title rend="italic">Bleak House</title></cell>
                            <cell role="data">18,171</cell>
                            <cell role="data">20,319</cell>
                            <cell role="data">+11.82%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell role="data"><title rend="italic">Little Dorrit</title></cell>
                            <cell role="data">16,241</cell>
                            <cell role="data">18,110</cell>
                            <cell role="data">+11.51%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell role="data"><title rend="italic">Our Mutual Friend</title></cell>
                            <cell role="data">15,339</cell>
                            <cell role="data">20,261</cell>
                            <cell role="data">+32.09%</cell>
                        </row>
                        <row>
                            <cell role="data">George Eliot</cell>
                            <cell role="data"><title rend="italic">Adam Bede</title></cell>
                            <cell role="data">8,199</cell>
                            <cell role="data">8,909</cell>
                            <cell role="data">+8.66%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell role="data"><title rend="italic">Mill on the Floss</title></cell>
                            <cell role="data">7,597</cell>
                            <cell role="data">8,768</cell>
                            <cell role="data">+10.19%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell role="data"><title rend="italic">Middlemarch</title></cell>
                            <cell role="data">13,540</cell>
                            <cell role="data">14,415</cell>
                            <cell role="data">+6.46%</cell>
                        </row>
                        <row>
                            <cell role="data">Charlotte Brontë</cell>
                            <cell role="data"><title>Jane Eyre</title></cell>
                            <cell role="data">8,605</cell>
                            <cell role="data">9,663</cell>
                            <cell role="data">+12.30%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell role="data"><title rend="italic">Villette</title></cell>
                            <cell role="data">9,172</cell>
                            <cell role="data">10,179</cell>
                            <cell role="data">+10.98%</cell>
                        </row>
                        <row>
                            <cell role="data">Emily Brontë</cell>
                            <cell role="data"><title rend="italic">Wuthering Heights</title></cell>
                            <cell role="data">5,528</cell>
                            <cell role="data">6,755</cell>
                            <cell role="data">+22.20%</cell>
                        </row>
                        <row>
                            <cell role="data">Jane Austen</cell>
                            <cell role="data"><title rend="italic">Pride and
                                Prejudice</title></cell>
                            <cell role="data">5,633</cell>
                            <cell role="data">5,938</cell>
                            <cell role="data">+5.41%</cell>
                        </row>
                        <row>
                            <cell role="data">Wilkie Collins</cell>
                            <cell role="data"><title rend="italic">The Woman in White</title></cell>
                            <cell role="data">12,675</cell>
                            <cell role="data">13,472</cell>
                            <cell role="data">+6.29%</cell>
                        </row>
                        <row>
                            <cell role="data">Elizabeth Gaskell</cell>
                            <cell role="data"><title rend="italic">North and South</title></cell>
                            <cell role="data">8,739</cell>
                            <cell role="data">10,418</cell>
                            <cell role="data">+19.21%</cell>
                        </row>
                        <row>
                            <cell role="data">Mary Elizabeth Braddon</cell>
                            <cell role="data"><title rend="italic">Lady Audley's
                                Secret</title></cell>
                            <cell role="data">6,670</cell>
                            <cell role="data">7,288</cell>
                            <cell role="data">+9.27%</cell>
                        </row>
                        <row>
                            <cell role="data">Thomas Hardy</cell>
                            <cell role="data"><title rend="italic">The Return of the
                                Native</title></cell>
                            <cell role="data">7,888</cell>
                            <cell role="data">8,922</cell>
                            <cell role="data">+13.11%</cell>
                        </row>
                        <row>
                            <cell role="data">James Joyce</cell>
                            <cell role="data"><title rend="italic">A Portrait of the Artist as a
                                    Young Man</title></cell>
                            <cell role="data">5,146</cell>
                            <cell role="data">5,347</cell>
                            <cell role="data">+3.91%</cell>
                        </row>
                        <row>
                            <cell role="data">Total Sentences</cell>
                            <cell role="data">156,390</cell>
                            <cell role="data">177,892</cell>
                            <cell role="data">+13.75%</cell>
                        </row>
                    </table>
                    <p>In table 4, I compared the parsing results from sixteen novels using Syuzhet
                        0.2.0 with the OpenNLP parser and Syuzhet 1.0.4 with the Textshape parser in
                        order to examine the improvements of the parsing function in Syuzhet. Table
                        4 reveals the fact that the parsing function of Syuzhet was improved across
                        the board after Syuzhet deployed the Textshape package for parsing instead
                        of the OpenNLP parser. The parsing results from the sixteen novels between
                        Syuzhet 0.2.0 and 1.0.4 have a 13.75% increase. For example, table 5, which
                        shows the parsing result from Charles Dickens’ <title rend="italic">Our
                            Mutual Friend</title>, informs that the parsing function of Syuzhet
                        1.0.2 was improved by splitting sentences more correctly. The OpenNLP parser
                        often failed to split sentences such as: <quote rend="inline"><said>I’ll
                                take the rest of the spell.</said>
                            <said>No, no, father!</said></quote> In addition, the OpenNLP parser did
                        not split sentences which ended with exclamation and quotation marks. For
                        example, table 5, which is the parsing result from George Eliot’s
                            <title>Middlemarch</title>, is one of examples that proves that the
                        OpenNLP does not process an exclamation mark as a splitter. In other words,
                        the Textshape package parsed the text into sentences more correctly than the
                        OpenNLP parser based on tables 4, 5 and 6. </p>
                    <table>
                        <head>Parsing from George Eliot’s <title rend="italic">Middlemarch</title>
                            (Chapter 1)</head>
                        <row>
                            <cell role="label">Syuzhet ≤ 1.0.1</cell>
                            <cell role="label">Syuzhet ≥ 1.0.2</cell>
                        </row>
                        <row>
                            <cell role="data"><said>Has Mr. Casaubon a great soul?</said> Celia was
                                not without a touch of naive malice.</cell>
                            <cell role="data"><said>Has Mr. Casaubon a great soul?</said></cell>
                        </row>
                        <row>
                            <cell/>
                            <cell role="data">Celia was not without a touch of naive malice.</cell>
                        </row>
                    </table>
                    <table>
                        <head>Parsing from Charles Dickens’ <title rend="italic">Our Mutual
                                Friend</title> (Book 1, Chapter 1)</head>
                        <row>
                            <cell role="label">Syuzhet ≤ 1.0.1</cell>
                            <cell role="label">Syuzhet ≥ 1.0.2</cell>
                        </row>
                        <row>
                            <cell role="data">‘Here! and give me hold of the sculls.</cell>
                            <cell role="data">‘Here!</cell>
                        </row>
                        <row>
                            <cell role="data"/>
                            <cell role="data">and give me hold of the sculls.</cell>
                        </row>
                        <row>
                            <cell role="data">I’ll take the rest of the spell.’ ‘No, no,
                                father!</cell>
                            <cell role="data">I’ll take the rest of the spell.’</cell>
                        </row>
                        <row>
                            <cell role="data"/>
                            <cell role="data">‘No, no, father!</cell>
                        </row>
                        <row>
                            <cell role="data">No! I can’t indeed.</cell>
                            <cell role="data">No!</cell>
                        </row>
                        <row>
                            <cell role="data"/>
                            <cell role="data">I can’t indeed.</cell>
                        </row>
                    </table>
                    <table>
                        <head>Parsing from Charles Dickens’ <title rend="italic">Bleak House</title>
                            (Book 1, Chapter 3)</head>
                        <row>
                            <cell role="label">Syuzhet ≤ 1.0.1</cell>
                            <cell role="label">Syuzhet ≥ 1.0.2</cell>
                        </row>
                        <row>
                            <cell role="data"><said>Mrs. Rachael, I needn’t inform you who were
                                    acquainted with the late Miss Barbary’s affairs, that her means
                                    die with her and that this young lady, now her aunt is
                                    dead--</said>
                                <said>My aunt, sir!</said>
                                <said>It is really of no use carrying on a deception when no object
                                    is to be gained by it,</said> said Mr. Kenge smoothly,
                                    <said>Aunt in fact, though not in law.</said></cell>
                            <cell role="data"><said>Mrs. Rachael, I needn’t inform you who were
                                    acquainted with the late Miss Barbary’s affairs, that her means
                                    die with her and that this young lady, now her aunt is
                                    dead--</said>
                                <said>My aunt, sir!</said></cell>
                        </row>
                        <row>
                            <cell role="data"/>
                            <cell role="data"><said>It is really of no use carrying on a deception
                                    when no object is to be gained by it,</said> said Mr. Kenge
                                smoothly, <said>Aunt in fact, though not in law.</said></cell>
                        </row>
                    </table>
                    <p>Based on the parsing result in table 7, the Textshape parser split sentences
                        after an exclamation mark, but not a dash. Syuzhet 1.0.4 with the Textshape
                        parser sorts sentences better than Syuzhet 1.0.1 with the OpenNLP parser.
                        The Textshape parser, however, still has room for improvement for splitting
                        sentences. For example, the Textshape parser infrequently fails to split
                        sentences based on a period, such as: <quote rend="inline"><said>My dear, I
                                don’t know it,</said> said I. <said>You do,</said> she said very
                            shortly.</quote> (<title rend="italic">Bleak House</title>, Book 1,
                        Chapter 4) in addition to the dash. Based on the parsed result of sixteen
                        novels, I concluded that the Textshape package basically separates sentences
                        based on a period, exclamation mark, or question mark.</p>
                </div>
                <div>
                    <head>3.2 Get_Sentiment</head>
                    <p>Syuzhet allocates different numeric vectors to each word/sentence based on
                        the lexicon chosen. These transitioned numeric vectors are turned into
                        structured data or visualization for further analysis. In Syuzhet, the
                        get_sentiment function transforms texts into accumulative numeric values for
                        sentiment analysis by matching each word with sentiment scores in selected
                        lexicons. Reloading the get_sentiment function, the Syuzhet lexicon and
                        English are set as default. If languages except for English are inputted
                        into Syuzhet, an error or the following message will pop up: <quote
                            rend="inline">Sorry, your language choice is not yet supported.</quote>
                        Jockers revealed that in Syuzhet 2.0, <quote rend="inline">support for
                            sentiment detection in multiple languages was added by using the
                            expanded NRC lexicon from Saif Mohammed</quote>
                        <ptr target="#jockers2017c"/>. In order to use the NRC lexicon, the
                        get_nrc_sentiment function needs to be employed. The get_nrc_sentiment
                        function simply helps perform sentiment analysis with the NRC lexicon by
                        transforming character values into numeric vectors through the
                        get_nrc_values function. The get_nrc_values function calls on the DplyR and
                        TidyR packages in order to execute sentiment analysis with the NRC lexicon.
                        Transformed numeric vectors are allocated into each emotion
                        categorization.</p>
                    <p>Syuzhet does not detect the syntactical and semantic information of each
                        sentence, but simply transforms each word found in the lexicons into
                        numerical sentiment vectors. Using deep neural network (DNN) models, when it
                        comes to approaching NLP, word embeddings, which are <quote rend="inline"
                            >typically pre-trained,</quote> made it possible for the learned word
                        vectors to <quote rend="inline">capture general syntactical and semantic
                            information</quote>
                        <ptr target="#doetal2019" loc="276"/>. I tested this with a variety of
                        different sentences via the get_sentiment function, which uses the Syuzhet
                        lexicon by default (see table 8). The results from both A and B were 0.75.
                        The word, <q>happy</q> was allocated 0.75 points by the Syuzhet lexicon, but
                        the get_sentiment function ignored <q>not</q> in B. I also tested B by
                        replacing <q>not</q> with <q>never,</q> and I got the same result.
                        Furthermore, C produced –0.5 points, and D generated 0.25 points. The word,
                            <q>sad</q> was given –0.5 points. D scored 0.25 points due to the
                        combination of <q>sad</q> (–0.5) and <q>happy</q> (0.75). I also tested the
                        sentences with the Bing, Afinn, and NRC lexicons, using the get_sentiment
                        function.</p>
                    <table>
                        <head>Experiment in Syuzhet with four lexicons</head>
                        <row>
                            <cell/>
                            <cell role="label">Sentences</cell>
                            <cell role="label">Syuzhet</cell>
                            <cell role="label">Bing</cell>
                            <cell role="label">Afinn</cell>
                            <cell role="label">NRC</cell>
                        </row>
                        <row>
                            <cell role="data">A.</cell>
                            <cell role="data">She was happy.</cell>
                            <cell role="data">0.75</cell>
                            <cell role="data">1</cell>
                            <cell role="data">3</cell>
                            <cell role="data">1</cell>
                        </row>
                        <row>
                            <cell role="data">B.</cell>
                            <cell role="data">She was not happy.</cell>
                            <cell role="data">0.75</cell>
                            <cell role="data">1</cell>
                            <cell role="data">3</cell>
                            <cell role="data">1</cell>
                        </row>
                        <row>
                            <cell role="data">C.</cell>
                            <cell role="data">She was sad.</cell>
                            <cell role="data">–0.5</cell>
                            <cell role="data">–1</cell>
                            <cell role="data">–2</cell>
                            <cell role="data">0</cell>
                        </row>
                        <row>
                            <cell role="data">D.</cell>
                            <cell role="data">She was happy but she is sad now.</cell>
                            <cell role="data">0.25</cell>
                            <cell role="data">0</cell>
                            <cell role="data">1</cell>
                            <cell role="data">1</cell>
                        </row>
                        <row>
                            <cell role="data">E.</cell>
                            <cell role="data">She was happy, and she is still happy now.</cell>
                            <cell role="data">0.75</cell>
                            <cell role="data">1</cell>
                            <cell role="data">3</cell>
                            <cell role="data">1</cell>
                        </row>
                        <row>
                            <cell role="data">F.</cell>
                            <cell role="data">She was happy but she is no longer happy.</cell>
                            <cell role="data">0.75</cell>
                            <cell role="data">1</cell>
                            <cell role="data">2</cell>
                            <cell role="data">1</cell>
                        </row>
                        <row>
                            <cell role="data">G.</cell>
                            <cell role="data">She was extremely happy.</cell>
                            <cell role="data">0.75</cell>
                            <cell role="data">1</cell>
                            <cell role="data">3</cell>
                            <cell role="data">1</cell>
                        </row>
                    </table>
                    <p>This result indicates that the Syuzhet package still has issues when
                        semantically detecting sentences, as Swafford has pointed out in the Syuzhet
                        0.2.0 version. The comparison between A and B shows that Syuzhet has no
                        function to detect negators. D and F depict the void of a detector for
                        adversative conjunctions in Syuzhet. In addition, the fact that the
                        sentiment score of A is same with that of G reveals that Syuzhet does not
                        properly detect amplifiers. Table 8 demonstrates how Syuzhet simply reports
                        accumulative sentiment scores based on the words in each sentence.</p>
                </div>
                <div>
                    <head>3.3 Syuzhet Functions for Sentiment Trajectory</head>
                    <p>Jockers mentions that the more sentences you have in a chunk, the less
                        extreme plot trajectories become.<ptr/>
                        <!-- which Jockers citation does this refer to? --> There are four different
                        functions in Syuzhet to show the emotional valence of stories throughout
                        narrative time: the get_sentiment, get_percentage_values,
                        get_transformed_values, and get_dct_transform functions. I used the
                        get_sentiment function to get the sentiment scores above, which provides the
                        sentiment values of each word or sentence. The get_percentage_values
                        function <quote rend="inline">divides a text into an equal number of <quote
                                rend="inline">chunks</quote> and then calculates the mean sentiment
                            valence for each.</quote><ptr/>
                        <!-- which Jockers citation does this refer to? --> The
                        get_transformed_value function uses the Fourier with a low pass filter to
                        make the graph smooth, but Jockers recommends the get_dct_transform function
                        in lieu of the get_transformed_value because the get_transformed_value is
                        only being maintained for legacy purposes. The get_dct_tansform function
                        draws upon <quote rend="inline">the simpler discrete cosine transformation
                            (DCT),</quote> and its strength is to depict <quote rend="inline">edge
                            values in the smoothed version of the sentiment vector</quote>
                        <ptr target="#jockers2017a"/>. The get_percentage_values,
                        get_transformed_value and get_dct_transform functions are percentage-based
                        functions, whereas the get_sentiment function is based on the number of
                        sentences. The four functions are displayed with an X axis for narrative
                        time and a Y axis for emotional valence.</p>
                </div>
                <div>
                    <head>3.4 Comparison between Swafford’s and My Results</head>
                    <p>Swafford points out that the foundation shapes in Syuzhet incorrectly display
                        plot trajectories from James Joyce’s <title rend="italic">The Portrait of
                            the Artist as a Young Man</title><ptr target="#swafford2015"/>. Swafford
                        did not mention which version of the package and lexicons she used, or what
                        lexicon she chose to test the novel with. Assuming that she used Syuzhet
                        0.2.0 and the Bing lexicon to show the sentiment trajectory of the novel,
                        based on the results of her experiment, I tested the same text with Syuzhet
                        1.0.4 and the Bing lexicon to specifically compare my results with hers.
                        Examining the sentiment values and comparing them to each sentence from
                        Joyce’s <title rend="italic">The Portrait of the Artist as a Young
                            Man</title>, with sentiment values given by the Bing lexicon, I found
                        that out of 5347 sentences, the number of positive sentiment sentences is
                        1029 (19%), the number of negative sentiment sentences, 1488 (28%), and the
                        number of neutral sentences, 2830 (53%).</p>
                    <figure>
                        <head>Sentiment trajectory of James Joyce’s <title rend="italic">A Portrait
                                of the Artist as a Young Man</title></head>
                        <graphic url="resources/images/figure03.jpg"/>
                        <figDesc>Bar graph of emotional valence (y-axis) with respect to narrative
                            time (x-axis) of James Joyce’s <title rend="italic">A Portrait of the
                                Artist as a Young Man</title>. the Emotional Valence axis features
                            positive and negative numbers, with 0 at the center of the axis. Bars
                            are logged above and blow zero. The positive/negative range of bars is
                            narrow on average, with a dip into the negative in the middle of the
                            narrative time axis.</figDesc>
                    </figure>
                    <figure>
                        <head>Comparison of two different results from Joyce’s <title rend="italic"
                                >A Portrait of the Artist as a Young Man</title></head>
                        <graphic url="resources/images/figure04.jpg"/>
                        <figDesc>Bar graphs of emotional valence(y-axis) with respect to narrative
                            time (x-axis) of James Joyce’s <title rend="italic">A Portrait of the
                                Artist as a Young Man</title>. The top graph is Swafford's
                            approximate result, and the bottom is the author's result.</figDesc>
                    </figure>
                    <p>Swafford mentions that the foundation shape shows positivity in spite of a
                        strong negative value at x≈1100.<ptr target="#swafford2015"/> I found there
                        were several highly negative sentences with scores of –7, –8, and –7 at
                        x=1177, 1184, and 1185 respectively. This section, which is the ending of
                        chapter 1, makes up 22% of the narrative time for the whole plot. From x≈20
                        in the foundation shape, the plot becomes increasingly negative. However,
                        Swafford’s critique against the foundation graph comes from her incorrect
                        usage of Syuzhet. If scale_vals=TRUE, <quote rend="inline">values will be
                            scaled by subtracting the means and scaled by dividing by their standard
                            deviations</quote>
                        <ptr target="#jockers2017c"/>. In other words, the foundation shape of
                        Syuzhet, if you set scale_vals=TRUE in the get_dct_transform function, will
                        focus on the relativity of positivity and negativity. For instance, if
                        chapter 1 and 2 are –2 and –5 respectively, the foundation shape will draw
                        chapter 1 as a positive shape and chapter 2 as a negative shape, reflecting
                        their relative sentiments. My results in figure 4 are close to those in
                        figure 3, since I adjusted the settings, scale_vals=FALSE. Depending on the
                        research purposes, the settings should be controlled and the reasons for
                        these adjustments explained. Therefore, it is of significance to properly
                        understand and carefully employ alterations to the settings when using
                        digital tools.</p>
                    <p>Stéfan Sinclair, Stan Ruecker, and Milena Radzikowska emphasize the
                        importance of cultivating a sufficient understanding of digital tools since
                            <quote rend="inline">the interpretive work is being guided and biased by
                            the data and software.</quote><ptr target="#sinclairetal2013" loc="54"/>
                        Swafford’s critique of the functions for sentiment trajectory in Syuzhet, in
                        terms of their literary application, reveals the importance of specifically
                        apprehending digital tools to avoid generating biased results, since her
                        criticism is based on observing outputs created by Syuzhet functions without
                        exploring the code and explaining the methods used in her experiment. In
                        response to her criticism, Jockers advocates for the plot trajectory
                        functions in Syuzhet in his blog post, <title rend="quotes">The Rest of the
                            Story.</title><ptr target="#jockers2015"/> Nonetheless, Syuzhet as a
                        sentiment analysis tool seems to have lost credibility and reliability in
                        the DH field after Swafford’s critique of the package made a considerable
                        impact on the opinions of DHers.</p>
                </div>
            </div>
            <div>
                <head>4. Digital Analysis of Charles Dickens’ <title rend="italic">Our Mutual
                        Friend</title>, <title rend="italic">George Eliot’s Middlemarch</title>, and
                    Charlotte Brontë’s <title rend="italic">Jane Eyre</title> through Syuzhet</head>
                <p>I selected the Syuzhet lexicon to test four different functions with Charles
                    Dickens’ <title rend="italic">Our Mutual Friend</title>, George Eliot’s <title
                        rend="italic">Middlemarch</title>, and Charlotte Brontë’s <title
                        rend="italic">Jane Eyre</title> in order to examine the compatibility, as
                    well as the limits, of Syuzhet with literature. In figure 5, each function
                    depicts the emotional valence of <title rend="italic">Our Mutual Friend</title>
                    in different ways. Regarding the settings of the get_transformed_values and
                    get_dct_transform functions, scale_vals=FALSE and scale_range=TRUE. The plot
                    trajectory created by the get_sentiment function is complicated and condensed,
                    showing both positive and negative emotion. Nonetheless, it is a useful function
                    when it comes to meticulously grasping sentiment flow in a story.</p>
                <figure>
                    <head>Comparison of four different functions based on the Syuzhet lexicon from
                        Charles Dickens’ <title rend="italic">Our Mutual Friend</title></head>
                    <graphic url="resources/images/figure05.jpg"/>
                    <figDesc>Four graphs of emotional valence(y-axis) with respect to narrative
                        time(x-axis) of Charles Dickens' <title rend="italic">Our Mutual
                            Friend</title>. The upper left was created using the Get_Sentiment
                        function, and is a bar graph. The upper right was created using the
                        Get_Precentage_Values function, and is a line graph. The bottom two graphs
                        are bar graphs, and were created using the Get_Transformed_Values function
                        and the Get_DCT_Transform function, respectively.</figDesc>
                </figure>
                <p>Looking into the raw file after it was processed by the get_sentiment function
                    using the Syuzhet lexicon, 7,167 sentences out of 20,261 sentences scored 0
                    (neutral), the number of positive sentences was 8,123, and the number of
                    negative sentences was 4,971. The positive average was 0.95, and the negative
                    average was –0.81. Based on the emotion trajectories created by the
                    get_sentiment and get_percentage_values functions, the whole plot of <title
                        rend="italic">Our Mutual Friend</title> is swayed by positive feelings
                    except for eight chapters. The get_sentiment result shows that each chapter
                    entails both positive and negative emotions, and that overall, positive
                    sentiment governs over negative feelings. The get_percentage_values function
                    reveals that there are more negative feelings expressed in books 3 and 4. The
                    highest score (8.7) is found in the last chapter of book 1, x=4907: <quote
                        rend="block">My Dear Sir,–Having consented to preside at the forthcoming
                        Annual Dinner of the Family Party Fund, and feeling deeply impressed with
                        the immense usefulness of that noble Institution and the great importance of
                        its being supported by a List of Stewards that shall prove to the public the
                        interest taken in it by popular and distinguished men, I have undertaken to
                        ask you to become a Steward on that occasion.</quote>
                    <ptr target="#dickens1952"/> The results from the get_dct_transform function
                    reveal that <title rend="italic">Our Mutual Friend</title> begins with slightly
                    positive feelings, then reaches a peak of positivity in book 2, before reversing
                    into negativity from book 3. This makes sense, as in book 2, there are a number
                    of jocund and cheerful events, such as Mr. Headstone’s and Mr. Eugene Wrayburn’s
                    wooing towards Lizzie, Mr. Veneering’s luxurious life, Mr. and Mrs. Lammle’s
                    social life, Fledgeby’s smooth business, Mr. Boffin’s purchase of an old
                    mansion, and Bella’s taste for money. The lowest score (–6.5), on the other
                    hand, is found in book 3 chapter 8, x=12262: <quote rend="block">This boastful
                        handiwork of ours, which fails in its terrors for the professional pauper,
                        the sturdy breaker of windows and the rampant tearer of clothes, strikes
                        with a cruel and a wicked stab at the stricken sufferer, and is a horror to
                        the deserving and unfortunate.</quote>
                    <ptr target="#dickens1952"/> The get_dct_transform function reveals the
                    dominance of negative feelings in the novel from the halfway point, though it
                    becomes positive once more in the ending. Similarly, between x≈10000 and x≈15000
                    (Book 3) from the get_sentiment function, high values of negative sentiment are
                    often found. Emotions fluctuate in book 3, but the negative atmosphere is
                    dominant in book 3 due to an endless string of troubling plots such as Lizzie’s
                    disappearance and return, Mr. Riderhood’s drowning, Bella’s conflicts about
                    money, Silas Wegg’s plot, Headstone’s jealousy, Mr. and Mrs. Lammle’s
                    bankruptcy, and Mr. Boffin’s anger over Rokesmith. Although chapter 4 is filled
                    with a positive ambience surrounding Mr. and Mrs. Wilfer’s wedding anniversary,
                    the emotional flows of the plot shown by the get_dct_transform function are
                    relatively correct. Still, it is impossible to assert that the get_dct_transform
                    function is 100% correct due to its over-simplification of emotion flows, the
                    inconsistent values of lexicons, and the absence of algorithms which detect
                    negators, amplifiers, de-amplifiers, and adversative conjunctions/transitions.
                    For example, at x≈20, sentiment is extremely negative in the
                    get_percentage_values function, whereas both the get_transformed_values and
                    get_dct_transform functions have positive values, which are erroneous results
                    caused by the simplification occurring in their algorithms.</p>
                <p>For the first 8% of narrative time, sentiment values are opposite between the
                    get_percentage_values and get_transformed_values functions, with positive and
                    negative scores respectively (figure 5). Here, the get_transformed_values
                    function does not correctly reveal the sentiment trajectories compared to the
                    other functions. As I mentioned above, Jockers does not recommend use of the
                    get_transformed_values function, which has been preserved for legacy purposes,
                    but it should be referenced since the get_dct_transform function derives from
                    the get_transformed_values function<ptr/>
                    <!-- which Jockers citation does this refer to? -->. The distinctive difference
                    between the two functions is low pass size. The get_transformed_values and the
                    get_dct_transform functions have low pass sizes of 2 and 5 respectively, which
                    denotes that the get_dct_transform function simplifies sentiment trajectory more
                    than the get_transformed values function does. </p>
                <figure>
                    <head>Comparison of four different functions from Book 4, Chapter 15 and 16 of
                            <title rend="italic">Our Mutual Friend</title></head>
                    <graphic url="resources/images/figure06.jpg"/>
                    <figDesc>Four graphs of emotional valence(y-axis) with respect to narrative
                        time(x-axis) of Charles Dickens' <title rend="italic">Our Mutual
                            Friend</title>. The upper left was created using the Get_Sentiment
                        function, and is a bar graph. The upper right was created using the
                        Get_Precentage_Values function, and is a line graph. The bottom two graphs
                        are bar graphs, and were created using the Get_Transformed_Values function
                        and the Get_DCT_Transform function, respectively.</figDesc>
                </figure>
                <p>In order to specifically examine the sentiment aspect from figure 5, I chose
                    chapters 15 and 16, both from book 4, which are from x≈96% (19499) to x≈99%
                    (20116) in figure 5. After parsing, chapters 15 and 16 consist of 336 and 282
                    chunks, respectively. Therefore, in figure 6, chapter 15 is between x=0% and
                    x≈54%, and the rest is chapter 16. Looking into the raw file after it was
                    processed by the get_sentiment function with the Syuzhet lexicon, 154 and 96
                    sentences in chapter 15 and 16, respectively, scored 0 (neutral), 68 and 129
                    sentences had positive values, and 114 and 57 sentences recorded negative
                    values. Although the number of sentences in chapter 15 and 16 combined is less
                    than 1000, which might bring about incorrect results, the four visualizations in
                    figure 6 appear to appropriately demonstrate the two chapters. Chapter 15 is
                    comprised of Riderhood’s blackmail towards Headstone and their subsequent death
                    in the river. The scene which depicts Riderhood staying in Headstone’s classroom
                    is filled with tension, and the result of Syuzhet reflects this with negative
                    sentiment values, the lowest of which is (–3.5): <quote rend="block">But, not to
                        be still further defrauded and overreached–which he would be, if implicated
                        by Riderhood, and punished by the law for his abject failure, as though it
                        had been a success–he kept close in his school during the day, ventured out
                        warily at night, and went no more to the railway station.</quote>
                    <ptr target="#dickens1952"/> In addition, negative feelings are dominant due to
                    Headstone’s attempt to drown Riderhood, which results in both of their deaths,
                    and which occurs in the last twenty sentences in chapter 15. </p>
                <p>Nonetheless, the foundation shapes created by the get_transformed_values and
                    get_dct_transform functions depict positive spikes, whereas the trajectories
                    created by the get_sentiment and get_percentage_values functions at x=317
                    (x≈51%), to x=336 (x≈54%) correctly show negative spikes. The foundation shapes
                    of Syuzhet, due to its smoothing feature, do not properly handle the drastic
                    sentiment changes from the end of chapter 15, which describes drowning – <quote
                        rend="inline">When the two were found, lying under the ooze and scum behind
                        one of the rotting gates, Riderhood’s hold had relaxed, probably in falling,
                        and his eyes were staring upward,</quote>
                    <ptr target="#dickens1952"/> which is given a value of –2.15–to the number of
                    strong positive sentiment values in the beginning of chapter 16. Jockers
                    acknowledges the limits of transforming functions in Syuzhet by noting that
                        <quote rend="inline">when a series of sentence values are combined into a
                        larger chunk using a percentage based measure, extremes of emotional valence
                        tend to get watered down.</quote>
                    <ptr target="#jockers2017a"/> The limit of Syuzhet that Jockers admits to does
                    not seem to be applied in isolation to large data, as it is also seen to affect
                    small data.</p>
                <figure>
                    <head>Comparison of four different functions based on the Syuzhet lexicon from
                        George Eliot’s <title rend="italic">Middlemarch</title></head>
                    <graphic url="resources/images/figure07.jpg"/>
                    <figDesc>Four graphs of emotional valence(y-axis) with respect to narrative
                        time(x-axis) of George Eliot's <title rend="italic">Middlemarch</title>. The
                        upper left was created using the Get_Sentiment function, and is a bar graph.
                        The upper right was created using the Get_Precentage_Values function, and is
                        a line graph. The bottom two graphs are bar graphs, and were created using
                        the Get_Transformed_Values function and the Get_DCT_Transform function,
                        respectively.</figDesc>
                </figure>
                <p>Like Dicken’s <title rend="italic">Our Mutual Friend</title>, George Eliot’s
                        <title rend="italic">Middlemarch</title> is a long Victorian novel, which
                    includes 14,415 sentences after being processed through the get_sentiment
                    function using the Syuzhet lexicon. The number of positive, neutral, and
                    negative sentences from George Eliot’s <title rend="italic">Middlemarch</title>
                    was 7,286, 3,017, and 4,112, respectively. The positive and negative averages
                    were 1.09 and –0.88, respectively. The emotional valence from the get_sentiment
                    and the get_percentage_values reveals the dominance of positive emotion
                    throughout the plots, except for the last part, between x≈85 and x≈95. The
                    emotional trajectories from the get_sentiment and the get_percentage_values
                    precisely depict the ambience of its plots. Although <title rend="italic"
                        >Middlemarch</title> has a number of conflicts during the course of the
                    novel between Dorothea Brooke and Mr. Casaubon and between Rosamond Vincy and
                    Lydgate, the flow of <title rend="italic">Middlemarch</title> is generally
                    filled with positive feelings with the exception of the end. With the sudden
                    death of Mr. Casaubon and Lydgate, the last part of <title rend="italic"
                        >Middlemarch</title> is dominated with negative feelings. However, <title
                        rend="italic">Middlemarch</title> still has a happy ending as Dorothea
                    decides to get married to Will Ladislaw despite the fact that she has to give up
                    her inheritance from Mr. Casaubon when she does so. Rosamond Vincy also
                    remarries another man after losing Lydgate. Mary and Fred live happily together
                    and have children. <!-- Do these references require a citation? --> The happy
                    ending is from x≈98 through 100 (chapter 86 to the finale). The get_sentiment
                    and get_percentage_values functions properly catch the happy ending, whereas the
                    get_transformed_values and get_dct_transform functions do not. In addition,
                    looking into some chapters which have quarrels, there are some parts scored
                    incorrectly by Syuzhet. The highest positive scored sentence is found with a
                    score of 9.05 in chapter 20. Chapter 20 is about the first fight between
                    Dorothea and Mr. Casaubon in Rome after their marriage, which is at x≈25 in
                    figure 7: <quote rend="block">These characteristics, fixed and unchangeable as
                        bone in Mr. Casaubon, might have remained longer unfelt by Dorothea if she
                        had been encouraged to pour forth her girlish and womanly feeling--if he
                        would have held her hands between his and listened with the delight of
                        tenderness and understanding to all the little histories which made up her
                        experience, and would have given her the same sort of intimacy in return, so
                        that the past life of each could be included in their mutual knowledge and
                        affection--or if she could have fed her affection with those childlike
                        caresses which are the bent of every sweet woman, who has begun by showering
                        kisses on the hard pate of her bald doll, creating a happy soul within that
                        woodenness from the wealth of her own love.</quote>
                    <ptr target="#eliot1871" loc="Ch. 20"/>
                    <quote rend="inline">These characteristics</quote> signifies Mr. Casaubon’s
                        <quote rend="inline">tenacity of occupation and … eagerness.</quote>
                    <ptr target="#eliot1871"/> Looking closely into this long sentence, <q>if</q> is
                    the key word. Without <q>if</q> in this sentence, it would be correct to give
                    this sentence positive scores. In this sentence, there are 20 words which have
                    sentiment scores out of 134 words through the get_tokens and the get_sentiment
                    functions: unchangeable (–0.6), encouraged (0.8), womanly (–0.25), feeling
                    (0.25), delight (1), tenderness (0.8), understanding (1), intimacy (0.8),
                    included (0.6), mutual (0.6), knowledge (0.6), affection (1), affection (1),
                    childlike (0.6), bent (–0.4), sweet (0.75), hard (–0.25), happy (0.75), wealth
                    (0.5), and love (0.75). The sum of the tokens is 10.3, but the sentiment score
                    of the sentence level through the get_sentiment function is 9.05. This is due to
                    the conjunction, <q>if,</q> which affects the sentence level by adding –0.25
                    with the get_sentiment function, though it does not have a sentiment score as a
                    word. The word, <q>affection</q> (1) appeared twice, so <q>affection</q> (1) was
                    only added once in the sentence level, which reveals that Syuzhet avoids summing
                    duplicate sentiment words in sentence levels. The algorithms of Syuzhet are
                    meticulous in order to differentiate word and sentence levels. However, Syuzhet
                    failed to semantically detect this sentence and created a faulty sentiment
                    result. This long sentence would have been given negative scores if Syuzhet had
                    a function to semantically detect sentences. In addition, there is another
                    example to examine, which is the second highest scored sentence at 8.1 in
                    chapter 16, which is at x≈21 in figure 7: <quote rend="block">In Rosamond’s
                        romance it was not necessary to imagine much about the inward life of the
                        hero, or of his serious business in the world: of course, he had a
                        profession and was clever, as well as sufficiently handsome; but the piquant
                        fact about Lydgate was his good birth, which distinguished him from all
                        Middlemarch admirers, and presented marriage as a prospect of rising in rank
                        and getting a little nearer to that celestial condition on earth in which
                        she would have nothing to do with vulgar people, and perhaps at last
                        associate with relatives quite equal to the county people who looked down on
                        the Middlemarchers</quote>
                    <ptr target="#eliot1871" loc="Ch. 16"/>.This part basically consists of two
                    sentences. As Syuzhet does not split sentences based on colons, these two
                    sentences were not separated properly. This part reveals Rosamond’s only reason
                    for caring about Lydgate, which is his social rank. It would be more appropriate
                    to consider this part as having neutral emotion since it is based on Rosamond’s
                    criteria in choosing her husband. In this part, there are 14 words which have
                    sentiment scores out of 108 words through the get_tokens and the get_sentiment
                    functions: romance (0.5), hero (0.75), profession (0.25), clever (0.75), well
                    (0.8), sufficiently (1), handsome (1), good (0.75), birth (0.6), distinguished
                    (0.6), marriage (0.6), prospect (0.6), celestial (0.4), and vulgar (–0.5). There
                    is no duplicates or conjunctions which would make a different sum between the
                    bag of tokens and the bag of sentences. In addition, some words in this part
                    which might have been considered <q>negative</q> have not been scored by the
                    Syuzhet lexicon, such as <q>piquant</q> and <q>look down.</q> Syuzhet simply
                    added the sum of sentiment words, and concluded this part to be the second
                    highest positive sentence in <title rend="italic">Middlemarch</title>.</p>
                <figure>
                    <head>Comparison of four different functions based on the Syuzhet lexicon from
                        Charlotte Brontë’s <title rend="italic">Jane Eyre</title></head>
                    <graphic url="resources/images/figure08.jpg"/>
                    <figDesc>Four graphs of emotional valence(y-axis) with respect to narrative
                        time(x-axis) of Charlotte Brontë’s <title rend="italic">Jane Eyre</title>.
                        The upper left was created using the Get_Sentiment function, and is a bar
                        graph. The upper right was created using the Get_Precentage_Values function,
                        and is a line graph. The bottom two graphs are bar graphs, and were created
                        using the Get_Transformed_Values function and the Get_DCT_Transform
                        function, respectively.</figDesc>
                </figure>
                <p>Charlotte Brontë’s <title rend="italic">Jane Eyre</title>, after being processed
                    through the get_sentiment function using the Syuzhet lexicon, included 9,664
                    sentences. Out of these, 2,776 sentences scored 0 (neutral), 4,046 sentences
                    were positive, and 2,824 sentences were negative. The positive average was 1.08,
                    and the negative average was –0.97. Based on the emotion trajectories created by
                    the four functions, emotions from <title rend="italic">Jane Eyre</title>
                    fluctuate between positive and negative feelings throughout the whole plot. The
                    get_dct_transform result depicts the emotional flow of <title rend="italic">Jane
                        Eyre</title> as fluctuating between negative, positive, negative, and
                    finally positive feelings, whereas the get_percentage_values scrupulously
                    delineates each part with binary emotions. Jane Eyre has difficult times when
                    staying at Gateshead and Lowood due to Mrs. Reed, John Reed, and Mr.
                    Broklehurst, in addition to Helen’s death, which occurs from x≈1 to x≈14. Once
                    Jane moves to Thornfield, she has happier days as Adèle’s governess with the
                    slow growth of her feelings for Rochester until her wedding. Based on the
                    get_percentage_values function, the flow of the emotional valence is positive
                    between x≈15 and x≈60 except for at x≈41.
                    <!-- Do these references require a citation? --> Chapter 20 is full of negative
                    feelings due to Bertha Mason’s attack on Richard Mason, which occurs at x≈41 in
                    figure 8. There is a strong negative spike at x≈41: <quote rend="inline">I saw
                        Mr. Rochester shudder: a singularly marked expression of disgust, horror,
                        hatred, warped his countenance almost to distortion; but he only said--
                            <said>Come, be silent, Richard, and never mind her gibberish: don’t
                            repeat it</said></quote>
                    <ptr target="#cbrontë1847"/> which is given a score of –4.5. After the chapter,
                    the flow of the emotional valence is positive until the wedding day. The
                    get_percentage_values function correctly depicts the emotional valence of this
                    part, whereas the get_dct_transform does not. The wedding was canceled with Mr.
                    Mason’s disclosure of the fact that Rochester is already married. Jane reveals
                    her severe feelings when deciding to leave Thornfield: <quote rend="block">I
                        wrestled with my own resolution: I wanted to be weak that I might avoid the
                        awful passage of further suffering I saw laid out for me; and Conscience,
                        turned tyrant, held Passion by the throat, told her tauntingly, she had yet
                        but dipped her dainty foot in the slough, and swore that with that arm of
                        iron he would thrust her down to unsounded depths of agony,</quote>
                    <ptr target="#cbrontë1847"/> which is given a score of –4.65 by Syuzhet at x≈61
                    (Chapter 27). After her marriage is canceled, Jane’s hardships continue as a
                    street beggar until she settles in at Moor House and Morton. Jane moves to a
                    small cottage, and again experiences a positive life as a teacher at x≈76 <ptr
                        target="#cbrontë1847" loc="Ch. 31"/>. When Jane finds Rochester in Ferndean,
                    there are sentences which reveal negative emotions: <quote rend="block">He
                        [Rochester] was taken out from under the ruins, alive, but sadly hurt: a
                        beam had fallen in such a way as to protect him partly; but one eye was
                        knocked out, and one hand so crushed that Mr. Carter, the surgeon, had to
                        amputate it directly</quote> which is given a score of –3.25 by Syuzhet at
                    x≈93 <ptr target="#cbrontë1847" loc="Ch. 36"/>, and which the
                    get_percentage_values function detects precisely. The ending of <title
                        rend="italic">Jane Eyre</title> arouses positive feelings with the
                    successful marriage of Jane and Rochester. </p>
                <p>The most negative sentence from <title rend="italic">Jane Eyre</title> has a
                    score of –7.2 in chapter 27, which occurs at x≈63 in figure 8, where Rochester
                    explains about Bertha Mason after the cancellation of their wedding. <quote
                        rend="block">These were vile discoveries; but except for the treachery of
                        concealment, I should have made them no subject of reproach to my wife, even
                        when I found her nature wholly alien to mine, her tastes obnoxious to me,
                        her cast of mind common, low, narrow, and singularly incapable of being led
                        to anything higher, expanded to anything larger--when I found that I could
                        not pass a single evening, nor even a single hour of the day with her in
                        comfort; that kindly conversation could not be sustained between us, because
                        whatever topic I started, immediately received from her a turn at once
                        coarse and trite, perverse and imbecile--when I perceived that I should
                        never have a quiet or settled household, because no servant would bear the
                        continued outbreaks of her violent and unreasonable temper, or the vexations
                        of her absurd, contradictory, exacting orders--even then I restrained
                        myself: I eschewed upbraiding, I curtailed remonstrance; I tried to devour
                        my repentance and disgust in secret; I repressed the deep antipathy I
                        felt.</quote>
                    <ptr target="#cbrontë1847" loc="Ch. 27"/> This part has several sentences but is
                    considered as one sentence by Syuzhet, since it does not split sentences based
                    on dashes and semicolons. In this part, there are 27 words which have sentiment
                    scores out of 173 words through the get_tokens and the get_sentiment functions:
                    vile (–0.75), treachery (–0.5), concealment (–0.8), reproach (–0.5), found
                    (0.6), alien (–0.6), obnoxious (–0.75), incapable (–0.75), led (0.4), found
                    (0.6), comfort (0.75), kindly (0.5), received (0.6), coarse (–0.6), perverse
                    (–0.5), imbecile (–0.75), quiet (0.25), household (0.6), violent (–0.75),
                    unreasonable (–0.5), temper (–0.5), absurd (–0.75), contradictory (–0.5),
                    exacting (–0.25), devour (–0.4), disgust (–1), and antipathy (–0.5). The sum of
                    the word tokens is –7.35. After excluding the duplicated word, <q>found,</q> the
                    sum should be –7.95, but the Syuzhet score is –7.2. This is because Syuzhet
                    perceives words with dashes as being together. In this part, <q>imbecile</q>
                    should have been counted as –0.75, but <q>imbecile</q> was processed as
                        <q>imbecile--when</q> which is considered null by Syuzhet. Although Syuzhet
                    successfully labeled this part as negative, it shows the limits of the Syuzhet
                    functions. </p>
                <p>The most positive sentence from <title rend="italic">Jane Eyre</title> scored a
                    9.05 in chapter 32, which is at x≈78 in figure 8: <quote rend="block">She was
                        hasty, but good-humoured; vain (she could not help it, when every glance in
                        the glass showed her such a flush of loveliness), but not affected;
                        liberal-handed; innocent of the pride of wealth; ingenuous; sufficiently
                        intelligent; gay, lively, and unthinking: she was very charming, in short,
                        even to a cool observer of her own sex like me; but she was not profoundly
                        interesting or thoroughly impressive</quote>
                    <ptr target="#cbrontë1847" loc="Ch. 32"/>. This is Jane’s positive description
                    of Rosamond Oliver. In this part, there are 19 words which have sentiment scores
                    out of 69 words through the get_tokens and the get_sentiment functions: hasty
                    (–0.5), good (0.75), vain (–1), flush (–0.4), loveliness (1), innocent (0.8),
                    pride (0.25), wealth (0.5), ingenuous (1), sufficiently (1), intelligent (1),
                    lively (0.75), charming (1), cool (0.75), sex (0.1), like (0.5), profoundly
                    (0.8), interesting (0.75), and impressive (0.75). Syuzhet seems to successfully
                    detect this part as positive. The original score should be 9.8 instead of 9.05
                    since <q>good-humoured</q> was not separately detected in the sentence level due
                    to the dash, which means <q>good</q> (0.75) was not counted towards the
                    sentiment score sum in this part. However, in the last sentence, <quote
                        rend="inline">but she was not profoundly interesting or thoroughly
                        impressive,</quote>
                    <ptr target="#cbrontë1847"/> Syuzhet failed to detect the negation <q>not</q>
                    and simply added scores from the words, profoundly (0.8), interesting (0.75),
                    and impressive (0.75) without reversing them, which brought about incorrect
                    results.</p>
                <p>Based on the analysis of the three novels, the get_transformed_values and
                    get_dct_ransform functions do not indicate sophistication of emotion since the
                    purpose of the functions is to grasp the whole emotional flow of plots by
                    simplifying the emotional valence, whereas the get_sentiment and
                    get_percentage_values functions create more detailed results of the emotional
                    valence, which is appropriate for micro sentiment analysis. Syuzhet also reveals
                    its limits through the lack of functions to detect dashes, negators, and
                    adversative conjunctions/transitions, which brings about faulty results.</p>
            </div>
            <div>
                <head>5. Conclusions</head>
                <p>Syuzhet is, in spite of its limits, a promising work in progress with the
                    potential to become an invaluable digital tool for the sentiment analysis of
                    literary text. Jockers asserts that <quote rend="inline">current benchmark
                        studies suggest that [sentiment detection] accuracy</quote> is <quote
                        rend="inline">in the 70-80% range and that depends on genre</quote>
                    <ptr target="#jockers2015"/>. This argument, however, seems to be limited to
                    dictionary-based sentiment analysis tools, such as Syuzhet. The 70-80% range
                    accuracy is not low at all, but could be improved with the application of more
                    advanced algorithms. Sentiment analysis has been developed with a variety of
                    attempts to solve its issues based on machine/deep learning algorithms. Deep
                    learning in natural language process has shown a shining future for sentiment
                    analysis. For example, convolutional neural networks (CNN) which include the
                    convolution stage, detector stage, and pooling stage can improve the accuracy of
                    sentiment analysis by detecting locality and negativity of words. Bing Liu notes
                    that opinion words have different meanings depending on the context <ptr
                        target="#liu2010" loc="16"/>. For example, the sentences, <q>I am not happy
                        to work out</q> and <q>I am happy not to work out,</q> have different
                    meanings. The locality of <q>not</q> can be processed in pooling layers, which
                    are usually applied after the convolutional and detector stages. For example,
                    MALLET (Machine Learning for Language Toolkit), a text mining toolkit, employs
                    conditional random fields (CRF), including the Naïve Bayes classifier and
                    decision trees. CRF is an efficient method of natural language processing that
                    fixes the issues of two previous models, namely HMM [Hidden Markov Model] and
                    MEMM [Maximum Entropy Markov Model]. Deep learning algorithms will help improve
                    the precision of sentiment analysis, but it would be impossible to ever achieve
                    100% accuracy. Stephen Ramsay mentions that <quote rend="inline">the real
                        failure would not be a result that is deemed incorrect</quote> but <quote
                        rend="inline">the decision to banish</quote> computational literary
                    analysis. <ptr target="#ramsay2016" loc="529"/> We should keep using Syuzhet
                    without being afraid of incorrect results, while making efforts to fully
                    understand its limits and abilities.</p>
                <p>It is painstaking to improve algorithms, and the process entails a lot of effort,
                    emotion, time, and money, which is also needed to maintain the tool. Some DHers
                    show disdain and misunderstanding for the funding necessities for DH projects by
                    stating that <quote rend="inline">almost all of the works</quote> can be
                    recreated with only one laptop <ptr target="#da2019" loc="603"/>. As a
                    mobile/web developer, whenever I had meetings with clients interested in making
                    apps without in-depth knowledge in the IT field, there was always a common qualm
                    about costs to develop apps, before they even thought about the cost of future
                    maintenance. To create a simple app that contains only a few functions requires
                    a project manager, iOS/Android developers, back-end developers, and an UI/UX
                    designer. DH projects are no different: Amy Earhart and Toniesha Taylor shared
                    their experiences facing institutional funding issues while collaborating on a
                    DH project <ptr target="#earhart_taylor2016"/>. Due to insufficient funding in
                    the humanities field, it will be challenging to develop new algorithms/functions
                    and maintain Syuzhet. Syuzhet is a great piece of art and will continue to be
                    developed even though, like any other existing computer program, it is not a
                    perfect tool. I believe that the necessary improvements will be made to the
                    algorithms in Syuzhet for semantically and syntactically detecting sentences, in
                    addition to revising sentiment scores in lexicons, so long as DHers support
                    Syuzhet. Improving sentiment analysis as well as digital tools should not remain
                    only as the duty of developers or labs, but as a responsibility of all digital
                    humanists who employ digital tools by participating in improvements through the
                    provision of feedback, such as that in Swafford’s blog post. One comment on
                    sarcasm in sentiment analysis by Tyler Rinker, who developed SentimentR, reveals
                    the difficulties of solving technical issues: <quote rend="inline">Difficult
                        task for 100% accuracy but there may be key features that are highly
                        correlated with a sarcastic comment that would improve sentiment
                        detection.</quote>
                    <ptr target="#rinker2019"/> It is impossible to provide 100% accuracy in
                    sentiment analysis, but we need to keep creating algorithms in order to improve
                    tools for the affluence of sentiment analysis in literature.</p>
            </div>
        </body>
        <back>
            <listBibl>
                <bibl xml:id="austen1813" label="Austen 1813"> Austen, J. <title rend="italic">Pride
                        and Prejudice.</title> Awaiting further bibliographic information from
                    author.</bibl>
                <bibl xml:id="binder2016" label="Binder 2016">Binder, J. M. <title rend="quotes"
                        >Alien Reading: Text Mining, Language Standardization, and the
                        Humanities.</title>
                    <title rend="italic">Debates in the Digital Humanities 2016</title>, pp.
                    201–17.</bibl>
                <bibl xml:id="braddon1862" label="Braddon 1862">Braddon, M. E. <title rend="italic"
                        >Lady Audley's Secret.</title> Awaiting further bibliographic information
                    from author.</bibl>
                <bibl xml:id="cbrontë1847" label="C. Brontë 1847">Brontë, C. <title rend="italic"
                        >Jane Eyre.</title> Awaiting further bibliographic information from
                    author.</bibl>
                <bibl xml:id="cbrontë1853" label="C. Brontë 1853">Brontë, C. <title rend="italic"
                        >Villette.</title> Awaiting further bibliographic information from
                    author.</bibl>
                <bibl xml:id="ebrontë1847" label="E. Brontë 1847">Brontë, E. <title rend="italic"
                        >Wuthering Heights.</title> Awaiting further bibliographic information from
                    author.</bibl>
                <bibl xml:id="clement2016" label="Clement 2016">Clement, T. E. <title rend="quotes"
                        >The Ground Truth of DH Text Mining.</title>
                    <title rend="italic">Debates in the Digital Humanities 2016</title>, pp.
                    534–5.</bibl>
                <bibl xml:id="collins1859" label="Collins 1859">Collins, Wilkie. <title
                        rend="italic">The Woman in White.</title> Awaiting further bibliographic
                    information from author.</bibl>
                <bibl xml:id="da2019" label="Da 2019">Da, N. Z. (2019). <title rend="quotes">The
                        Computational Case against Computational Literary Studies.</title>
                    <title rend="italic">Critical Inquiry</title>, 45(3), pp. 601–39. <ref
                        target="https://doi.org/10.1086/702594">https://doi.org/10.1086/702594</ref>
                    (accessed 19 March 2019).</bibl>
                <bibl xml:id="dickens1853" label="Dickens 1853">Dickens, C. <title rend="italic"
                        >Bleak House.</title> Awaiting further bibliographic information from
                    author.</bibl>
                <bibl xml:id="dickens1857" label="Dickens 1857">Dickens, C. <title rend="italic"
                        >Little Dorrit.</title> Awaiting further bibliographic information from
                    author.</bibl>
                <bibl xml:id="dickens1838" label="Dickens 1838">Dickens, C. <title rend="italic"
                        >Oliver Twist.</title> Awaiting further bibliographic information from
                    author.</bibl>
                <bibl xml:id="dickens1952" label="Dickens 1952">Dickens, C. <title rend="italic">Our
                        Mutual Friend</title>. Introduction by Salter Davies. Oxford: Oxford
                    University Press.</bibl>
                <bibl xml:id="doetal2019" label="Do et al. 2019">Do, H. H., Prasad P. W. C., Maag A.
                    and Alsadoon A. <title rend="quotes">Deep Learning for Aspect-Based Sentiment
                        Analysis: A Comparative Review.</title>
                    <title rend="italic">Expert Systems with Applications</title>, 118: pp. 272–99.
                        <ref target="https://doi.org/10.1016/j.eswa.2018.10.003"
                        >https://doi.org/10.1016/j.eswa.2018.10.003</ref> (accessed 16 March
                    2019).</bibl>
                <bibl xml:id="earhart_taylor2016" label="Earhart and Taylor 2016">Earhart, A. E. and
                    Taylor, T. L. <title rend="quotes">Pedagogies of Race: Digital Humanities in the
                        Age of Ferguson.</title>
                    <title rend="italic">Debates in the Digital Humanities 2016</title>, pp.
                    251–64.</bibl>
                <bibl xml:id="eliot1859" label="Eliot 1859">Eliot, G. <title rend="italic">Adam
                        Bede.</title> Awaiting further bibliographic information from author. </bibl>
                <bibl xml:id="eliot1871" label="Eliot 1871">Eliot, G. <title rend="italic"
                        >Middlemarch.</title> Awaiting further bibliographic information from
                    author. </bibl>
                <bibl xml:id="eliot1860" label="Eliot 1860">Eliot, G. <title rend="italic">The Mill
                        on the Floss.</title> Awaiting further bibliographic information from
                    author. </bibl>
                <bibl xml:id="gaskell1854" label="Gaskell 1854">Gaskell, E. <title rend="italic"
                        >North and South.</title> Awaiting further bibliographic information from
                    author. </bibl>
                <bibl xml:id="hardy1878" label="Hardy 1878">Hardy, T. <title rend="italic">The
                        Return of the Native.</title> Awaiting further bibliographic information
                    from author. </bibl>
                <bibl xml:id="jockers2015" label="Jockers 2015">Jockers, M. L. "The Rest of the
                    Story." Awaiting further bibliographic information from author.
                    <!-- searching Jockers' website reveals that this blog post no longer exists. Maybe author can share functioning link or archived version? --></bibl>
                <bibl xml:id="jockers2017a" label="Jockers 2017a">Jockers, M. L. Introduction to the
                    Syuzhet Package. <ref
                        target="https://cran.r-project.org/web/packages/syuzhet/vignettes/syuzhet-vignette.html"
                        >https://cran.r-project.org/web/packages/syuzhet/vignettes/syuzhet-vignette.html</ref>
                    (accessed 24 February 2019).</bibl>
                <bibl xml:id="jockers2017b" label="Jockers 2017b">Jockers, M. L. Syuzhet: Extract
                    Sentiment and Plot Arcs from Text. <ref
                        target="https://github.com/mjockers/syuzhet"
                        >https://github.com/mjockers/syuzhet</ref> (accessed 24 February
                    2019).</bibl>
                <bibl xml:id="jockers2017c" label="Jockers 2017c">Jockers, M. L. Syuzhet Package
                    v1.0.4 | R Documentation. <ref
                        target="https://www.rdocumentation.org/packages/syuzhet/versions/1.0.4"
                        >https://www.rdocumentation.org/packages/syuzhet/versions/1.0.4</ref>
                    (accessed 24 February 2019).</bibl>
                <bibl xml:id="joyce1916" label="Joyce 1916">joyce, J. <title rend="italic">A
                        Portrait of the Artist as A Young Man.</title> Awaiting further
                    bibliographic information from author. </bibl>
                <bibl xml:id="jungetal2008" label="Jung et al. 2008">Jung, Y., Choi, Y. and Myaeng,
                    S. <title rend="quotes">A Study on Negation Handling and Term Weighting Schemes
                        and Their Effects on Mood-Based Text Classification.</title>
                    <title rend="italic">Korean Journal of Cognitive Science</title>, 19: pp.
                    477–97.</bibl>
                <bibl xml:id="kwartler2017" label="Kwartler 2017">Kwartler, T. <title rend="italic"
                        >Text Mining in Practice with R</title>. John Wiley and Sons.</bibl>
                <bibl xml:id="liu2010" label="Liu 2010">Liu, B. <title rend="quotes">Sentiment
                        Analysis and Subjectivity.</title>
                    <title rend="italic">Handbook of Natural Language Processing</title>, 2: pp.
                    627–66. <ref
                        target="https://www.cs.uic.edu/~liub/FBS/NLP-handbook-sentiment-analysis.pdf"
                        >https://www.cs.uic.edu/~liub/FBS/NLP-handbook-sentiment-analysis.pdf</ref>
                    (accessed 1 April 2019).</bibl>
                <bibl xml:id="medhatetal2014" label="Medhat et al. 2014">Medhat, W., Hassan, A. and
                    Korashy, H. <title rend="quotes">Sentiment Analysis Algorithms and Applications:
                        A Survey.</title>
                    <title rend="italic">Ain Shams Engineering Journal</title> 5(4): pp. 1093–113.
                        <ref target="https://doi.org/10.1016/j.asej.2014.04.011"
                        >https://doi.org/10.1016/j.asej.2014.04.011</ref> (accessed 11 March
                    2019).</bibl>
                <bibl xml:id="ramsay2011" label="Ramsay 2011">Ramsay, S. <title rend="italic"
                        >Reading Machines: Toward an Algorithmic Criticism</title>. Champaign:
                    University of Illinois Press.</bibl>
                <bibl xml:id="ramsay2016" label="Ramsay 2016"> Ramsay, S. Humane Computation. <title
                        rend="italic">Debates in the Digital Humanities 2016</title>, pp.
                    527–9.</bibl>
                <bibl xml:id="rinker2019" label="Rinker 2019">Rinker, T. <title rend="quotes"
                        >Dictionary Based Sentiment Analysis that Considers Valence Shifters:
                        Sentimentr.</title> Available from: <ref
                        target="https://github.com/trinker/sentimentr"
                        >https://github.com/trinker/sentimentr</ref> (accessed 9 March 2019).</bibl>
                <bibl xml:id="rhody2015" label="Rhody 2015">Rhody, L. Awaiting further bibliographic
                    information (accessed 9 April 2019).</bibl>
                <bibl xml:id="sinclairetal2013" label="Sinclair et al. 2013">Sinclair, S., Ruecker,
                    S. and Radzikowska, M. <title rend="quotes">Information Visualization for
                        Humanities Scholars.</title>
                    <title rend="italic">Literary Studies in the Digital Age — An Evolving
                        Anthology</title>. DOI: 10.1632/lsda.2013.6 (accessed 21 March 2019).</bibl>
                <bibl xml:id="swafford2015" label="Swafford 2015">Swafford, A. <title rend="quotes"
                        >Problems with the Syuzhet Package.</title>
                    <title rend="italic">Anglophile in Academia: Annie Swafford’s Blog</title>.
                    Available from: <ref
                        target="https://annieswafford.wordpress.com/2015/03/02/syuzhet/"
                        >https://annieswafford.wordpress.com/2015/03/02/syuzhet/</ref> (accessed 24
                    February 2019).</bibl>
                <bibl xml:id="underwood2014" label="Underwood 2014">Underwood, T. <title
                        rend="quotes">Theorizing Research Practices We Forgot to Theorize Twenty
                        Years Ago.</title>
                    <title rend="italic">Representations</title>, 127(1): 64–72.</bibl>
            </listBibl>

        </back>
    </text>
</TEI>
