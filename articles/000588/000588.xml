<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:dhq="http://www.digitalhumanities.org/ns/dhq"
   xmlns:mml="http://www.w3.org/1998/Math/MathML">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <!--Author should supply the title and personal information-->
            <title type="article" xml:lang="en"><!--article title in English-->Hidden in
               Plain-TeX: Investigating Minimal Computing Workflows</title>
            <!--Add a <title> with appropriate @xml:lang for articles in languages other than English-->
            <dhq:authorInfo>
               <!--Include a separate <dhq:authorInfo> element for each author-->
               <dhq:author_name>Nabeel <dhq:family>Siddiqui</dhq:family>
               </dhq:author_name>
               <idno type="ORCID"
                  ><!--if the author has an ORCID ID, include the full URI, e.g. https://orcid.org/0000-0000-0000-0000-->https://orcid.org/0000-0002-6126-5833</idno>
               <dhq:affiliation>Susquehanna University</dhq:affiliation>
               <email>siddiqui@susqu.edu`</email>
               <dhq:bio>
                  <p>Nabeel Siddiqui is an Assistant Professor of Digital Media at Susquehanna University, where he specializes in data science, the history of information science, new media rhetoric, and science and technology studies. </p>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <!--This information will be completed at publication-->
            <idno type="DHQarticle-id"><!--including leading zeroes: e.g. 000110-->000588</idno>
            <idno type="volume"
               ><!--volume number, with leading zeroes as needed to make 3 digits: e.g. 006-->016</idno>
            <idno type="issue"><!--issue number, without leading zeroes: e.g. 2-->2</idno>
         	<date when="2022-06-25">25 June 2022</date>
            <dhq:articleType>article</dhq:articleType>
            <availability status="CC-BY-ND">
               <!--If using a different license from the default, choose one of the following:
                  CC-BY-ND (DHQ default):        
                  CC-BY:    
                  CC0:  -->
               <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref
                     target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
                     >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref>
               </bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>
         <langUsage>
            <language ident="en" extent="original"/>
            <!--add <language> with appropriate @ident for any additional languages-->
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords">
               <!--Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#authorial_keywords">
               <!--Authors may include one or more keywords of their choice-->
               <list type="simple">
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <!--Each change should include @who and @when as well as a brief note on what was done.-->
         <change when="2022-08-02" who="BRG">fixed malformed xml tags</change>
      </revisionDesc>
   </teiHeader>
   <text xml:lang="en" type="original">
      <front>
         <dhq:abstract>
            <!--Include a brief abstract of the article-->
            <p>Drawing on software studies, data feminism, digital rhetoric studies, information
               science, and the history of computing, this paper foregrounds Markdown as a cultural
               object to analyze the social, cultural, and political pressures surrounding the
               digital humanities. Rather than beginning with contemporary discourse, it draws
               parallels between Markdown and Donald Knuth's TeX. From the 1970s to 1990s, academic
               researchers used TeX to construct plain-text scholarship in mathematics and the hard
               sciences to enhance typography. Most academics saw these concerns as holding marginal
               importance and quickly abandoned the approach for WYSIWYG word processors. Drawing on
               queer theorist Michael Warner, I argue that the community surrounding TeX responded
               reactionarily to these transformations by forming a counterpublic constituted through a
               circulation of texts bemoaning word processors <ptr target="#warner2002"/>. This
               counterpublic persisted well into the 2000s but only made headway amongst niche
               users.</p>
            <p>This plain-text focused counterpublic mutated in response to the neoliberalization of
               higher ed. Rather than viewing plain-text as <soCalled>sustainable
                  scholarship,</soCalled> academic lifehacking and minimal computing embraced what
               David Golumbia calls <soCalled>computationalism,</soCalled> an ideological construct postulating social,
               political, economic, and cultural ills as cybernetic systems to be optimized — or
                  <soCalled>hacked.</soCalled> Minimal computing’s fetishization and casting of
               plain-text as transformative mirrors similar discourses amongst older lifehacking
               enthusiasts. Although plain-text scholarship is not representative of minimal
               computing as a totality, minimal computing's emphasis on workflows leads to few of
               the supposed benefits advocates profess, and in many cases, worsens inequalities.</p>
         </dhq:abstract>
         <dhq:teaser>
            <!--Include a brief teaser, no more than a phrase or a single sentence-->
            <p>Drawing on software studies, data feminism, digital rhetoric studies, information
               science, and the history of computing, this paper foregrounds Markdown as a cultural
               object to analyze the social, cultural, and political pressures surrounding the
               digital humanities.  Rather than beginning with contemporary discourse, it draws
               parallels between Markdown and Donald Knuth's TeX.</p>
         </dhq:teaser>
      </front>
      <body>
         <div>
         <head>Daring Markdown</head>
         <p>In 2004, John Gruber, a user interface designer and blogger, released a new markup
            language, entitled Markdown, featuring what he claimed was simple and self-evident syntax.
            <quote rend="inline">The best way to get a feel for Markdown's formatting syntax,</quote> he asserted, <quote rend="inline">is simply
            to look at a Markdown-formatted document</quote> <ptr target="#gruber2004"/>. Gruber’s language relied on a
            set of simple conventions mimicking those in email correspondence. Users could surround
            words in single and double asterisks to signal italics and bold fonts, respectively, and
            create header levels by preceding header titles with a corresponding number of hashtags
            (i.e., # for H1 and ## for H2). This simplicity was an explicit design goal that
            permeated Markdown's design language and resulted in its quick adoption. </p>
         <p>Markdown's simplicity arises from its composition and plain text file format. <quote rend="inline">The
            overriding design goal of Markdown,</quote> writes Gruber, <quote rend="inline">is the idea that a
            Markdown-formatted document should be publishable as-is, <emph>as plain
               text</emph>, without looking like it's been marked up with tags or formatting
               instructions</quote> <ptr target="#gruber2004" loc="emphasis added"/>. According to the Unicode Standard, plain
            text files are a <quote rend="inline">pure sequence of characters</quote> that <quote rend="inline">contain enough information to
               permit the text to be rendered legibly, and nothing more</quote> <ptr target="#allen2012" loc="18"/>. It
            contrasts plain text with styled or rich text, which is <quote rend="inline">any text representation
            consisting of plain text plus added information such as a language identifier, font
            size, color, hypertext links, and so on</quote> <ptr target="#allen2012" loc="18"/>. Plain text files
            benefit from simplicity, portability across different platforms, and longevity. These
            qualities make it more than just a file type. For Dennis Yi Tenen, plain text is an
            <quote rend="inline">editorial method of text transcription that is both 'faithful to the text of its
               source' and is 'easier to read than the original documents'</quote> <ptr target="#tenen2017" loc="3"/>. In contrast
            to the maximization of <quote rend="inline">system-centric ideals,</quote> he sees plain text as embodying
            minimalism <ptr target="#tenen2017" loc="3"/>.</p>
         <p>Plain text exposes the structure of digital encoding and resists what N. Katherine
            Hayles calls the <soCalled>flickering signifier.</soCalled> In Saussurean semiotics, signifiers are
            unitary, durable, and lack internal structures. In contrast, Hayles argues that
            <soCalled>flickering signifiers</soCalled> infuse computational systems <ptr target="#hayles1999" loc="25–49"/>. These are
            signs embedded in layered informatics where small actions, like the press of a key, can
            cause massive changes in hardware and software. They literally <q>flicker</q> due to computer
            monitors refreshing their presence multiple times per second, resulting in observers
            always witnessing them in a state of flux <ptr target="#gitelman2002"/>. While plain text relies on
            the same computational hardware, it provides a voyeuristic look into what Tenen calls
            the <soCalled>textual lamination</soCalled> of digital materials <ptr target="#tenen2017" loc="145–156"/>. This textual
            lamination refers to the ways that the digital binds text on a screen in a series of
            physical and networked computational infrastructures. </p>
         <p>Markup languages, like Markdown, also allow writers to structure plain-text documents
            without aesthetic differentiations in typography. According to the Unicode Standard,
            markup languages function by <quote rend="inline">interspersing plain text data with sequences of characters
               that represent the additional data structure</quote> <ptr target="#allen2012" loc="19"/>. By preserving
            sequences of characters as plain text, these languages can separate tags from <soCalled>real
            content.</soCalled> For many advocates, this mechanism allows writers to focus on content while
            leaving design issues to others. </p>
         <p>The separation of form and content comes with challenges. Chief amongst these is the
            fragmentation of language protocols as practitioners expand capabilities. Gruber
            designed Markdown to have a limited feature set, but his decisions bumped up against
            practicality as popular websites such as GitHub, Reddit, Stack Exchange, Tumblr, and
            WordPress began permitting users to post in Markdown. New Markdown parsers and
            variations quickly emerged <ptr target="#teamvivaldi2018"/>. For Gruber, these <soCalled>flavors</soCalled> provided
            evidence of open ingenuity rather than chaos. When asked why he did not seek
            standardization, Gruber responded <quote rend="inline">I believe Markdown's success is <emph>due
               to</emph>, not in spite of, its lack of standardization. And its success is not
               disputable</quote> <ptr target="#gruber2014"/>.</p>
         <p>During the flurry of activity to expand Markdown, John MacFarlane, Professor of
            Philosophy at UC Berkeley, released pandoc, a command-line utility that reads various
            Markdown flavors and outputs them to different formats <ptr target="#macfarlene2020"/>. This allowed
            Markdown to serve as a protocol for creating diagrams, slide decks, and even websites.
            Most importantly, pandoc provided a way for Markdown to include citations and footnotes
            that resulted in it gaining popularity amongst a niche group of academics for scholarly
            research. </p>
         <p>Pandoc permitted Markdown to serve as a viable option for various genres of writing, but
            what does Markdown have to do with minimal computing? According to Alex Gil, <quote rend="inline">minimal
            computing is the application of minimalist principles to computing</quote> <ptr target="#gil2015a"/>. He draws
            inspiration from designer and architect Ernesto Oroza’s extemporal ethnography of Cuba’s
            DIY culture. In Havana, Oroza finds a city where participants resist bureaucratic
            intervention and create idiosyncratic habitats. He stresses the <quote rend="inline">moral modulor,</quote> who by
            necessity sees the city through a lens of survival <ptr target="#oroza2020"/>. <quote rend="inline">The moral modulor is
            an individual who has the impulse to rebuild human life, and this is something he does
            for his children or his family,</quote> states Oroza. <quote rend="inline">His condition allows him to discriminate
               against the superfluous or the useless</quote> <ptr target="#oroza2016"/>. Although these practices in Havana
            may seem far from digital humanities research, they provide a paradigm for how digital
            humanities scholars and practitioners should view infrastructure more broadly. Put
            another way, Gil sees in Havana's <quote rend="inline">architecture of necessity</quote> a catalyst for a digital
            humanities community that discards — read: <q>minimizes</q> — the extraneous. He asks us to
            look self-reflexively at our operations and orient them around the question of <quote rend="inline">What do
               we need?</quote> <ptr target="#gil2015a"/>.</p>
         <p>Minimal computing includes a myriad of definitions and practices. According to Jentery
            Sayers, the <q>minimal</q> in minimal computing can refer to design,
            usage, consumption, maintenance, barriers, Internet, externals, space, and technical
            language. Yet, he leaves open the possibility for other forms of minimalism: <quote rend="inline">I did not
               account for all the minimals or their particulars here</quote> <ptr target="#sayers2016"/>. Likewise, Gil
            states, <quote rend="inline">minimal computing is in the eye of the beholder</quote> <ptr target="#gil2015a"/>. </p>
         <p>Due to the often-ambiguous definitions of minimal computing, we must turn to
            self-identified practitioners to understand its relationship with Markdown. As Gregory
            Bateson notes, cultural activities, such as play, serve as meta-communication through
            their self-referential nature <ptr target="#bateson2008"/>. In minimal computing,
            plain-text scholarship in Markdown signals, <q>This is minimal computing.</q> This switch
            from the ontological to the methodological is common when defining the digital
            humanities. As Rafael Alvarado notes, digital humanities, like minimal computing, has no
            real definition, and it is better to see digital humanities as a social field rather than an ontological one:</p>
         <cit><quote rend="block">Instead of a definition, we have a genealogy, a network of family resemblances among
            provisional schools of thought, methodological interests, and preferred tools, a history
            of people who have chosen to call themselves digital humanists and who in the process of
            trying to define the term are creating that definition.</quote> <ptr target="#alvarado2011"/> </cit>
         <p>As we look for a <soCalled>genealogy</soCalled> of minimal computing tools, Markdown emerges as a recurring
            theme. Jentery Sayers and Alex Gil, self-identified minimal computing practitioners,
            frequently tout Markdown-inspired static site generators and plain-text scholarship as
            epitomizing minimal values and assuring sustainability. For example, in an analysis of
            Tenen and Grant Wythoff's workflow for sustainable plain-text scholarship in Markdown,
            Gil praises the workflow’s ability to produce <quote rend="inline">minimal knowledge with the production of
               a minimal artifact, without creating necessary friction for the readers</quote> <ptr target="#gil2015a"/>. He
            laments <q>user-friendly</q> interfaces for their potential to lead to what Matthew
            Kirschenbaum calls a <quote rend="inline">haptic fallacy</quote>: <quote rend="inline">the belief that electronic objects are
            immaterial simply because we cannot reach out and touch them</quote> <ptr target="#kirschenbaum2003"/>.
            Likewise, Sayers asserts that Jekyll, a Markdown reliant static site generator, is
            representative of <quote rend="inline">minimal design</quote> <ptr target="#sayers2016"/>. Jekyll forms the basis for prominent
            minimal computing websites, such as those for the Minimal Computing Working Group, and
            projects, such as Ed. and Wax. We should note that Markdown is, of course, not the
            totality of minimal computing practices. </p>
         <p>Markdown as a digital humanities practice is noticeable for not just its technical
            innovation but the discourses surrounding it. These discourses stress Markdown as a
            force for sustainable scholarship, easing barriers of entry to digital humanities in the
            Global South, and as a means for subverting governmental surveillance. According to
            Bradley Dilger and Jeff Rice, <quote rend="inline">Despite the predominant roles markup plays in online
            writing, and despite the social, cultural, rhetorical, and technological implications of
            these roles, markup is often taken for granted as merely the code behind the text</quote>
            <ptr target="#dilger2010"/>. In response, this article explores the sustainability of
            Markdown as a digital humanities practice by looking back to a key precursor: Donald
            Knuth’s TeX. </p>
         <p>Readers may wonder why I focus on TeX and not other markup languages, such as HTML or
            TEI. Markup languages emerged in the 1960s when users used markups or <q>flags</q> to
            distinguish between lower and upper-case letters. These flags were often proprietary,
            making it difficult for different computational platforms to interact with one another.
            In 1967, Michael Kay implored scholars to create a <quote rend="inline">standard code in which any text
               received from an outside source can be assumed to be</quote> <ptr target="#kay1967"/>. The most influential
            of these markup languages was the Generalized Markup Language (GML) created by Charles
            Goldfarb, Edward Mosher, and Raymond Lorie at IBM in 1969. GML served as a foundation
            for the Standard Generalized Markup Language (SGML) released in 1986, which in turn
            provided a protocol for creating new markup languages like HTML and XML <ptr target="#goldfarb1999"/>.</p>
         <p>TeX and Markdown are notable for their embrace by scholars as computational tools for
            printed text. This is not to say that they do not use other markup languages, such as
            HTML and TEI, to disseminate research. In fact, digital humanities scholars often stress
            alternative publishing platforms, such as online exhibits, blogs, and digital maps as
            meaningful forms of scholarship themselves. However, this is in contrast to TeX and
            Markdown where the goal is to create a more efficient workflow to output digital
            materials in analog formats like academic journals and monographs. </p>
         <p>In this paper, TeX's development and community provide a case study and catalyst for the
            social and cultural development of Markdown as a minimal computing practice. From the
            1970s to the 1990s, academic researchers used TeX to construct plain-text scholarship in
            mathematics and the hard sciences to enhance typographical output. Most academics saw
            these concerns as holding marginal importance and abandoned TeX for What You See Is What
            You Get (WYSIWYG) word processors, especially in the humanities. Drawing on queer
            theorist Michael Warner, I argue that the community surrounding TeX responded
            reactionarily to these transformations by forming a counterpublic constituted through a
            myriad of texts that bemoaned word processors <ptr target="#warner2002"/>. This counterpublic
            persisted well into the 2000s but only made headway amongst a niche scholarly audience.
            After exploring TeX, I conclude by looking at the lessons it provides digital humanities
            scholars about embracing minimal computing practices like Markdown-based scholarship. As
            I make evident, although minimal computing encompasses a range of modalities, discourses
            surrounding Markdown mirroring those of TeX should give pause to those seeking to
            implement it in practice.</p></div>
         <div>
         <head>Taking TeX Seriously</head>
         <p>To understand Markdown-based scholarship in the digital humanities and growing advocacy
            for its use, I turn to the history of computing. The history of computing remains a
            niche field and has had little overlap with the digital humanities. Historians of
            computing have dismissed the latter as narrowly focusing on career development and
            sidelining issues that concern other humanities scholars. As Thomas Haigh — echoing
            Bruno Latour's criticism of modernity concludes — <quote rend="inline">We have never been digital</quote> <ptr target="#haigh2006"/>. 
            Yet, computing's history can provide valuable insights into minimal computing
            practices.</p>
         <p>Given markup's popularity amongst programmers and technical writers, it may be tempting
            to see it as an extension of programming. However, the catalyst for plain-text
            scholarship stems from developments and concerns about digital typography best
            exemplified by Donald Knuth’s TeX. A mathematical prodigy, Knuth won a scholarship to
            Case Western Institute, where he tinkered with the university’s IBM 650, an early
            mainframe computer, in his spare time. After switching concentrations from physics to
            mathematics, Knuth graduated with a Bachelor of Science in mathematics and, by a special
            vote of the faculty, a Master of Science for exceptional work. He went on to earn a
            doctorate in mathematics from the California Institute of Technology and joined its
            faculty as an Assistant Professor of Mathematics in 1963 <ptr target="#walden2019"/>.</p>
         <p>Knuth began writing his magnum opus, <title rend="italic">The Art of Computer
               Programming</title>, originally a comprehensive work about compilers, full time in 1962
            but took a break to investigate the statistical properties of linear probing. This break
            had a profound impact on Knuth who proposed a broader project to his publisher about
            computational algorithms. By the summer of June 1965, he had completed three thousand
            handwritten pages (roughly two thousand pages of printed text), and Addison-Wesley
            agreed to publish the revised work in seven parts. With Knuth’s desire for <title
               rend="italic">The Art of Programming</title> to mirror the totality of computer science
            algorithms, he continued to amend the work throughout his career. While revising the
            second edition of the book in 1976, Knuth received galley proofs from his publisher.
            Addison-Wesley had adopted a new digital-infused workflow, and Knuth became so aghast at
            the typographical quality that he threatened to quit the project altogether <ptr target="#knuth2007"/>.</p>
         <p>Pausing from writing <title rend="italic">The Art of Programming</title>, Knuth sought to
            explore how computer science could enhance typography after seeing a high-resolution
            digital typesetting machine in 1977. By dividing a page into discrete sections (pixels),
            he searched algorithmically for the ideal place for ink (1) or not (0). <quote rend="inline">As a computer
            scientist, I really identify with patterns of 0’s and 1’s; I ought to be able to do
            something about this,</quote> noted Knuth <ptr target="#tex2021"/>. </p>
         <p>Knuth's work on typography formed the basis for TeX, and he dedicated his 1977–1978
            academic sabbatical to the project. Approximately a year later, the American
            Mathematical Society invited Knuth to give a lecture that he used to stress TeX’s
            superiority and mathematical underpinning. For the attending academic audience, TeX
            offered numerous benefits. As the TeX User Group’s official history notes, creating
            academic articles at the time was expensive and relied on proprietary software. A
            document created in one software program often rendered differently on competing
            systems. TeX solved these issues by providing a free markup system that was portable
            across platforms and geared towards academic work <ptr target="#tex2021"/>.</p>
         <p>We should pause to underline that TeX's development had little to do with easing
            composition as later enthusiasts would argue. While the portability of TeX did allow
            researchers to exchange files without vendor lock-in, researchers were more concerned
            about preserving aesthetics rather than stripping away content
            and form. They exchanged TeX files with typographical information and choices affixed in
            document front matter so that others could compose facsimiles rather than leave
            questions of appearance to them.</p>
         <p>Despite TeX’s advantages, it had a steep learning curve. Seeking to assist newcomers,
            computer scientist Leslie Lamport assembled a series of macros for TeX, which he called
            LaTeX, in 1984. LaTeX took cues from Scribe, a markup language Brian Reid created for
            his doctoral dissertation that popularized <q>logical design,</q> a philosophy that separated
            the production of content from appearance. Reid claimed that Scribe allowed writers to
            focus on their writing rather than aesthetics, and by utilizing a small set of
            declarations, they could still output their creations to different formats <ptr target="#reid1981"/>.
            Despite its innovations, many remained apprehensive about what they saw as Scribe’s
            rigidity. Early responses touted LaTeX as <quote rend="inline">Scribe liberated from inflexible formatting
            control</quote> and <quote rend="inline">TeX for the masses</quote> <ptr target="#mittelbach2004"/>. In his original manual <title
               rend="italic">LaTeX: A Document Preparation System</title>, Lamport acknowledges his
            desire for a simpler system. <quote rend="inline">In turning TeX into LaTeX, I have tried to convert a
            highly-tuned racing car into a comfortable family sedan,</quote> writes Lamport, <quote rend="inline">The family
            sedan isn't meant to go as fast as a racing car or be as exciting to drive, but it's
            comfortable and gets you to the grocery store with no fuss</quote> <ptr target="#lamport1986" loc="xiii"/>.</p>
         <p>The rhetoric around LaTeX differed significantly from TeX. Lamport, like Reid, saw
            logical design as a chance to ease composition and to prevent vendor lock-in. This is
            not to say that concerns of typography disappeared, but they had diminished
            considerably. TeX’s typographic benefits originally drew Lamport’s interest, but his
            assemblage of easy-to-use macros shifted how advocates pitched TeX's benefits and would
            serve as a catalyst for later claims by Markdown enthusiasts. Still, most academics
            continued to find markup-oriented scholarship to be unnecessarily difficult to use, and
            with WYSIWYG word processing software more readily available, all but the most diehard
            users defected, especially in the humanities. </p>
         <p>Word processing had emerged during the 1970s as an organizational paradigm for
            centralizing corporate information <ptr target="#haigh2006"/>. Businesses created word processing
            departments that focused on text production in an attempt to ease the burden on other
            departments. Manufacturers, such as IBM and Wang, created standalone systems for this
            new information management paradigm, and by the early 1980s, these machines were
            commonplace in corporate America. Word processing software dedicated solely to text
            editing, on the other hand, was of marginal purpose. As Thomas Haigh notes:</p>
         <p><quote rend="block">It … seemed no more sensible to use a computer to edit than to travel to the shopping
            mall in a supersonic fighter jet. Only the plummeting cost of interactive computing
            could turn an absurd luxury into an expensive tool with economic justifications in
            specialized fields, and eventually into an inexpensive office commonplace. <ptr target="#haigh2006"/></quote> </p>
         <p>As personal computers expanded into business environments during the late 1980s, word
            processing's meaning shifted to refer to standalone software for manipulating text.
            WYSIWYG editors provided real-time rendering of how text would look on paper if the user
            printed it. Various manufacturers created competing programs throughout the decade, but
            Microsoft Word emerged as the market leader by the middle of the 1990s, in turn becoming
            the de facto standard for academic manuscripts.</p>
         <p>If TeX remained a novel typographical system, its impact on the academic community would
            be minimal as many would have abandoned it when WYSIWYG editors became more efficient at
            displaying mathematical formulas. However, discourses about TeX's utility shifted with
            the widespread adoption of personal computing. Rather than emphasizing its technical
            features, advocates posited it as resisting word processing’s dominance as a
            compositional tool. Their discourses focused on two key trends. First, critics asserted
            that word processing software's proprietary formats threatened open access of scholarly
            information. Second, they saw word processors as <q>distracting</q> during intellectual
            labor. Matthew Kirschenbaum notes, <quote rend="inline">Word processing … shapes and informs literary
            subjects — the persons who inhabit the system (and economy) of literature,
            green-screeners or otherwise</quote> <ptr target="#kirschenbaum2016"/>. As writers change their tools, these
            tools shape their composition and orient them into a techno-social framework centered
            around the process of writing. It is in this social milieu that TeX became a social
            force for connecting detractors of word processing, rather than just a typographical
            apparatus.</p>
         <p>By the late 1990s and early 2000s, TeX’s users formed a counterpublic united through
            texts lamenting word processors. As Michael Warner demonstrates, counterpublics shape
            queer identity and challenge Jürgen Habermas' <soCalled>bourgeois</soCalled> public sphere <ptr target="#warner2002"/>.
            Habermas correlates the public sphere's rise in the eighteenth century with the
            emergence of coffeehouses, cafes, salons, and reading clubs in France, England, and
            Germany. In these spaces, the notion of citizenship blended with an abstracted universal
            body <ptr target="#habermas2015"/>. Nancy Fraser criticizes this universalizing impetus of the public
            sphere and draws attention to <soCalled>subaltern counterpublics</soCalled> that emphasized identity and
            power <ptr target="#fraser1990"/>.</p>
         <p>Michael Warner draws on Fraser’s conception to make evident how texts' circulations are
            critical in forming counterpublics. He notes that the <q>public</q> refers to a myriad of
            contradictory definitions. On one hand, <term>the public</term> refers to a
            totality whose members are defined through a set of universalities. <term>A
               public</term>, on the other hand, refers to a subset within this broader public. Warner
            considers a third definition of public. <quote rend="inline">This kind of public,</quote> notes Warner, <quote rend="inline">comes into
            being only in relation to texts and their circulation. It exists <emph>by
               virtue of being addressed</emph></quote> <ptr target="#warner2002" loc="original emphasis"/>. The audience's
            attention to the text creates a set of relationships, and in doing so, formulates a
            distinct <q>poetic</q> worldview <ptr target="#warner2002"/>. </p>
         <p>As corporations embraced word processing during the 1990s, desktop publishing
            constituted a specific public defined through the circulation of texts, advertisements,
            images, and videos addressing a neoliberal workforce. According to Jamie Peck and Adam
            Tickell, neoliberalism has two distinct phases of state mobilization: a <soCalled>roll-back</soCalled> and
            a <soCalled>roll-out.</soCalled> In the roll-back period of the 1980s, political elites mobilized the state
            to create mass deregulation and implemented supply-side economic policies. These
            policies catapulted Margaret Thatcher and Ronald Reagan into political office but
            reached their political limit by the 1990s. This led to neoliberalism's <soCalled>roll-out,</soCalled>
            where policymakers mobilized the state to regulate and discipline the same individuals
            dispossessed by neoliberalization, namely African American and Latino communities <ptr target="#peck2002"/>.
            Eschewing collective political action, neoliberalism imparted ideas
            of self-entrepreneurship, confidence, and prudence onto political subjects.</p>
         <p>Neoliberal market ideology, as Fred Turner shows, intersected with advocacy for
            deregulation by cybercultural entrepreneurs <ptr target="#turner2006" loc="175–206"/>. For neoliberal
            policymakers, computers with WYSIWYG desktop publishing software were essential to
            launching micro-marketing campaigns, assessing the labor force quantitatively, and
            accelerating policy report and white paper creation. In this environment, TeX served as
            a counterpublic against capitalist exploitation of intellectual labor. Although most TeX
            users were white, their outlook on academic publishing pushed them against the
            neoliberalizing trend of efficiency and commercial concerns. As historians have noted
            about the formation of this community:</p>
         <p><quote rend="block">TeX resulted in a worldwide community of users, developers, and user groups evolved,
            largely disconnected from the more conventional desktop publishing world driven by
            commercial concerns of publishers and desktop publishing system vendors (so very
            different than Knuth’s concerns for TeX). This community remains vibrant today, 40 years
            later, and is an important branch in the development of desktop publishing. <ptr target="#beeton2018"/></quote></p>
         <p>The concentrated community backlash to business practices was in part due to Knuth’s
            curation of enthusiasts around his software. On February 22, 1980, a small group of
            enthusiasts bound through Knuth's influence formed the TeX Users Group (TUG). According
            to Beeton, Berry, and Walden, <quote rend="inline">The formation of TUG was an important step in TeX's
            becoming widely popular and in TEX development activity eventually becoming independent
            of Stanford</quote> <ptr target="#beeton2018"/>. From 1982, Knuth also began to hold a
            <q>MetaFont for Lunch Brunch</q> to discuss typography — the name alludes to his
            complementary technology for specifying fonts, which failed to gain traction <ptr target="#beeton2018"/>.
            The group and Knuth’s academic connections ensured that a
            series of graduate researchers, faculty, and outside contributors would continue to
            develop and notably, write about the system. By the decade's end,
            TeX User Groups had close to four thousand members and growing international reach. They
            began publishing a journal entitled <title rend="italic">TUGBoat</title> with support from the
            American Mathematical Society, and the circulation of this new journal helped solidify
            the counterpublic.</p>
         <p>As mentioned earlier, concerns about word processing's growing influence in the academic
            environment and distracting tendencies dominated texts about TeX. For instance, an early
            critique of word processors underlies Lamport's discussion of LaTeX. In his original
            manual, he compares logical design to visual design (another term for <q>what you see is
            what you get</q>). According to Lamport, LaTeX <quote rend="inline">encourages better writing</quote> by causing
            writers to focus on their document's logical structure <ptr target="#lamport1986" loc="8"/>. It also allows
            for better focus on text's composition rather than design: <quote rend="inline">LaTeX was designed to free
            you from formatting concerns, allowing you to concentrate on writing. If, while writing,
            you spend a lot of time worrying about form, you are probably misusing LaTeX</quote> <ptr target="#lamport1986" loc="8"/>.
            This critique became explicit in Lamport's 1994 revised manual. He notes that
            when he wrote LaTeX, there were few facilities for authors to typeset their documents
            whereas they had become commonplace by the mid-1990s. He goes on to explicitly lambast
            the development of <quote rend="inline">WYSIWYG programs [that] replace LaTeX's logical design with visual
               design</quote> <ptr target="#lamport1986" loc="7"/>.</p>
         <p>Later guides for LaTeX — which became the de facto flavor of TeX — would reassert claims
            about word processing’s perceived flaws for academic work. In 1989, for instance, Jon
            Warbrick released a condensed version of Lamport’s manual. In it, he writes, <quote rend="inline">A visual
            system makes it easier to create visual effects rather than a coherent structure;
            logical design encourages you to concentrate on your writing and makes it harder to use
            formatting as a substitute for good writing</quote> <ptr target="#warbrick1988" loc="2"/>. Another widely
            circulated manual by Gavin Maltby in 1992, entitled <title rend="italic">An Introduction to
               TeX and Friends</title>, notes, <quote rend="inline">Essential to the spirit of TeX is that <emph
               >it formats the document whilst you just take care of the content</emph>, making for
                  increased productivity</quote> <ptr target="#maltby1992" loc="3, original emphasis"/>. Another self-described
            <quote rend="inline">polemical rant in favor of TeX as opposed to word processors</quote> by Allin Cottrell,
            Professor of Economics at Wake Forest University, describes Knuth's invention as a
            panacea to WYSIWYG word processors’ faults. <quote rend="inline">The word processor is a stupid and grossly
            inefficient tool for preparing text for communication with others,</quote> contends Cottrell
            <ptr target="#cottrell1999"/>.</p>
         <p>The conflation of TeX with logical design focused on content creation rather than
            typography continues into the present. For example, the website for the LaTeX project
            prominently states the importance of separating content from presentation: <quote rend="inline">LaTeX is not
            a word processor! Instead, LaTeX encourages authors not to worry too much about the
            appearance of their documents but to concentrate on getting the right content </quote> <ptr target="#latexproject"/>.
            It contrasts LaTeX with how an author would format a document by determining
            layout and font. <quote rend="inline">This has two results,</quote> notes the site, <quote rend="inline">authors wasting their time
               with designs; and a lot of badly designed documents!</quote> <ptr target="#latexproject"/></p>
         <p>In short, by the late 1990s and early 2000s, a counterpublic emerged through blogs,
            newspaper articles, and online discussion forums, positioning TeX as an alternative to
            word processing for academic production. As Warner makes evident, <quote rend="inline">texts themselves do
            not create publics [or counterpublics], but the concatenation of texts through time.
            Only when a previously existing discourse can be supposed, and a responding discourse
            can be postulated, can a text address a public</quote> <ptr target="#warner2002"/>.</p>
         <p>Readers in mathematical fields may wonder how TeX can be a counterpublic given its
            popularity in their disciplines. It is important to emphasize that counterpublics often
            gain wide support amongst certain subgroups. <quote rend="inline">A counterpublic maintains at some level,
            conscious or not, an awareness of its subordinate status,</quote> argues Warner. <quote rend="inline">The cultural
            horizon against which it marks itself off is not just a general or wider public but a
            dominant one,</quote> he continues <ptr target="#warner2002"/>. For instance, queer communities may have
            consumer literature challenging heteronormative relationships, but these works remain
            niche amongst mainstream publishers. Likewise, even though TeX has adoption in
            mathematical fields, it has little support in the corporate world, governmental sector,
            or most academic disciplines.</p></div>
         <div>
         <head>The Pitfalls of Markdown</head>
         <p>TeX's origins and subsequent development provide unique insight for scholars of minimal
            computing. As mentioned earlier, minimal computing advocates often stress Markdown and
            Markdown-adjacent tools as representative, although not the totality of, their practice.
            In this brief conclusion, I assess four cautious lessons that TeX provides minimal
            computing practitioners about the adoption of Markdown-based scholarship in the digital
            humanities.</p>
         <p>The first lesson TeX provides is that the adoption of niche tools rarely eases barriers
            of entry and access. With the rise of WYSIWYG word processors, digital composition
            opened up to a wider range of individuals. Works that were in TeX pushed against this
            mainstream adoption. As a result, with growing familiarity of computers throughout the
            1990s, only those that knew what TeX was, found its system easier to manage, and most
            importantly, had the specialized training often gained in graduate school to manipulate
            it were able to contribute. Anne B. McGrail draws attention to a similar issue in
            minimal computing in reference to her community college students:</p>
         <cit><quote rend="block">My students might read Gil’s and Sayer’s pieces but they will likely write about them
            using Google or Word on their laptops and email me using Outlook — transgressing minimal
            computing principles at every keystroke. For these definitions of minimal computing
            themselves point to a set of assumptions for humanistic computing that are worth
            considering in CC students’ digital lives.</quote> <ptr target="#mcgrail2017"/></cit>
         <p>Second, TeX shows that plain-text scholarship, like that written in Markdown, requires a
            large infrastructure to support it and is far from minimal. In fact, criticisms of
            large-scale infrastructures as limiting forces in the digital humanities well precede
            the Minimal Computing Working Group. In a 2012 study of digital humanities projects,
            Joris van Zundert concludes:</p>
         <p><quote rend="block">At least as far as digital humanities research is concerned, there is little benefit to
            be expected from the current large infrastructure projects. Their all-purpose nature
            enforces a generalized strategy aimed at the establishment of standards which is at odds
            with innovative, explorative research. Being standards-driven, institutionally bound,
            and at worst enforcing specific implementations, they are platforms of exclusiveness.
            <ptr target="#vanzundert2012"/></quote></p>
         <p>Echoing Gil's later remark that minimal computing advocates should orient themselves
            around the question of <quote rend="inline">what we need,</quote> Zundert writes that digital humanities
            infrastructures <quote rend="inline">should indeed be the simplest thing that could possibly work</quote> 
         	<ptr target="#vanzundert2012"/>.
            Yet, TeX shows that most supporters, including Knuth, were often only
            able to contribute to the project due to the support of their respective academic
            institutions. Likewise, Markdown-oriented site generators, such as Jekyll, stress the
            <q>free</q> hosting of GitHub, a company Microsoft bought for over $7.5 billion and backs
            with its large corporate infrastructure. The impact of Microsoft’s large server network,
            muddled with bit rot and electrical waste, is rarely taken into account.</p>
         <p>Third, TeX shows that plain-text scholarship is not significantly more future-proof or
            sustainable compared to more proprietary alternatives. In regards to their workflow,
            Tenen and Wythoff argue, <quote rend="inline">Writing in plain text guarantees that your files will remain
            readable ten, fifteen, twenty years from now.</quote> They contrast this with proprietary
            formats, like Word or Google Docs, that <quote rend="inline">may go the way of WordPerfect in the future</quote>
            <ptr target="#tenen2014"/>. While the <quote rend="inline">plain sequence of characters</quote> is likely to be
            readable, the scripts scholars rely on to convert their documents into more acceptable
            publishing standards have limited upkeep. As TeX grew in popularity, support for older
            versions waned leaving many scholars without an easy means of reconverting their
            documents. To turn back Markdown, it’s important to remember that a key reason for its
            growing popularity is its ability to transform into a wide variety of formats through
            pandoc. Although a variety of coders contribute to it, ultimately, it relies on the
            leadership of MacFarlane, and it is unclear how long it would survive without his input.
            In contrast, large organizations and governmental agencies that have adopted proprietary
            software along with the corporations that produce this software have a much greater
            incentive to maintain compatibility.</p>
         <p>Finally, plain-text scholarship provides little security for vulnerable political
            activists as claimed by boosters. Gil notes how sites off-grid can assist political
            revolution. He highlights a project entitled No Connect that he and his colleagues
            developed at Columbia University's Group for Experimental Methods in the Humanities <ptr target="#gil2015b"/>.
            No Connect is a theme for Jekyll meant for users without an internet
            connection. Presumably, this allows political dissidents to distribute subversive and
            sensitive materials through Sneakernets, informal networks for transferring information
            through physical mediums such as CD-ROMs, floppy disks, and USB drives. While such sites
            may circumnavigate traditional computer networks, they come with their challenges. For
            instance, governmental agencies posing as bureaucrats can steal or copy them. These same
            individuals may produce malware and keyloggers that are automatically installed when a
            user places the USB drive in their computer, compromising more elements of the
            Sneakernets. A popular exploit places a large surge of electricity through the USB port
            frying the machine <ptr target="#angelopoulou2019"/>. Later developments of TeX/LaTeX introduced
            security risks due to their reliance on macros <ptr target="#checkoway2010"/>.
            While Markdown does not rely on as many macros, its convoluted conversion structure
            leaves it open to similar vulnerabilities. </p>
         <p>Of course, minimal computing is divergent and growing, and the emphasis on
            plain-text scholarship that this article highlights does not represent the field's
            totality. Many advocates of minimal computing have little focus on markup languages.
            Nonetheless, by historicizing and contextualizing Markdown through my analysis of TeX, I
            have sought to show some of the pitfalls that may occur through widespread adoption. In
            the future, these issues may be solved, but TeX’s lessons should give digital humanities
            scholars a cautionary warning.</p>
         </div>
        
      </body>
      <back>
         <listBibl>
            <bibl xml:id="allen2012" label="Allen et al. 2012"> Allen, Julie D. et al. <title rend="quotes">The Unicode Standard.</title> <title rend="italic"
               >Unicode Consortium,</title> 2012.
               <ref
                  target="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.683.9133&amp;rep=rep1&amp;type=pdf"
                  >http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.683.9133&amp;rep=rep1&amp;type=pdf</ref>.</bibl>
            <bibl xml:id="alvarado2011" label="Alvarado 2011"> Alvarado, Rafael. <title rend="quotes">The Digital Humanities Situation.</title><title
               rend="italic"> The Transducer</title>, May 11, 2011. <ref
                  target="http://transducer.ontoligent.com/?p"
                  >http://transducer.ontoligent.com/?p</ref>.</bibl>
            <bibl xml:id="angelopoulou2019" label="Angelopoulou et al. 2021"> Angelopoulou, Olga, Seyedali Pourmoafi, Andrew Jones and Garauv Sharma. <title rend="quotes">Killing Your Device via Your USB Port,</title> 2020.  <ref target="http://wrap.warwick.ac.uk/137908/1/WRAP-killing-your-device-via-USB-port-Angelopoulou-2020.pdf">http://wrap.warwick.ac.uk/137908/1/WRAP-killing-your-device-via-USB-port-Angelopoulou-2020.pdf</ref>.
             </bibl>
            <bibl xml:id="bateson2008" label="Bateson 2008"> Bateson, Gregory. <title
               rend="italic">Steps to an Ecology of Mind,</title> Chicago; London: University
               of Chicago Press, 2008.</bibl>
            <bibl xml:id="beeton2018" label="Beeton, Berry, and Walden 2018"> Beeton, Barbara, Karl Berry, and David Walden. <title rend="quotes">TEX: A
               Branch in Desktop Publishing Evolution, Part 1.</title> <title rend="italic">IEEE Annals of the
                  History of Computing</title> vol. 40.3 (2018): 78–93.</bibl>
            <bibl xml:id="checkoway2010" label="Checkoway, Shacham, and Rescorla 2010"> Checkoway, Stephen, Hovav Shacham and Eric Rescorla. <title rend="quotes">Are Text-Only Data Formats Safe? Or, Use This LATEX Class File to Pwn Your Computer,</title> 2010. <ref target="https://hovav.net/ucsd/dist/texhack.pdf">https://hovav.net/ucsd/dist/texhack.pdf</ref>.
            </bibl>
            <bibl xml:id="cottrell1999" label="Cottrell 1999"> Cottrell, Allin. <title rend="quotes">Word Processors: Stupid and Inefficient,</title> June 29,
               1999. <ref target="http://ricardo.ecn.wfu.edu/~cottrell/wp.html"
                  >http://ricardo.ecn.wfu.edu/~cottrell/wp.html</ref>.</bibl>
            <bibl xml:id="dilger2010" label="Dilger and Rice 2010"> Dilger, Bradley J. and Jeff Rice. <title rend="quotes">Making a Vocabulary for
               <code>&lt;HTML&gt;</code>.</title> In <title rend="italic">A to <code>&lt;A&gt;</code>: Keywords of Markup,</title> edited by Bradley J. Dilger and Jeff Rice, xi–xxiv. Minneapolis, MN: University of Minnesota Press, 2010.</bibl>
            <bibl xml:id="fraser1990" label="Fraser 1990"> Fraser, Nancy. <title rend="quotes">Rethinking the Public Sphere: A Contribution to the
               Critique of Actually Existing Democracy.</title> <title rend="italic">Social Text</title> 25/26
               (1990): 56–80.</bibl>
            <bibl xml:id="gil2015a" label="Gil 2015"> Gil, Alex. <title rend="quotes">The User, the Learner and the Machines We Make.</title> <title
               rend="italic">Minimal Computing: A Working Group of GO::DH</title>, May 21, 2015.
               <ref target="https://go-dh.github.io/mincomp/thoughts/2015/05/21/user-vs-learner/"
                  >https://go-dh.github.io/mincomp/thoughts/2015/05/21/user-vs-learner/</ref>.</bibl>
            <bibl xml:id="gil2015b" label="Gil and Tenen 2015"> Gil, Alex and Dennis Yi Tenen. <title rend="quotes">No Connect.</title> <title rend="italic"
               >Group for Experimental Methods in the Humanities, </title>July 24, 2015.
               <ref target="https://xpmethod.columbia.edu/knowledge-design-studio/2015-07-24-no-connect.html">https://xpmethod.columbia.edu/knowledge-design-studio/2015-07-24-no-connect.html</ref>.</bibl>
            <bibl xml:id="gitelman2002" label="Gitelman 2002"> Gitelman, Lisa. <title rend="quotes">Materiality Has Always Been in Play: An Interview with
               N. Katherine Hayles.</title> <title rend="italic">Iowa Journal of Cultural Studies</title> vol. 2.1
               (2002): 7–12.</bibl>
            <bibl xml:id="goldfarb1999" label="Goldfarb 1999"> Goldfarb, Charles F. <title rend="quotes">The Roots of SGML: A Personal Recollection.</title> <title
               rend="italic">Technical Communication</title> vol. 46.1 (1999): 75-83.</bibl>
            <bibl xml:id="gruber2004" label="Gruber 2004"> Gruber, John. <title rend="quotes">Markdown.</title> <title rend="italic">Daring Fireball</title>, December
               17, 2004. <ref target="https://daringfireball.net/projects/markdown/"
                  >https://daringfireball.net/projects/markdown/</ref>.</bibl>
            <bibl xml:id="gruber2014" label="Gruber 2014"> Gruber, John. <title rend="quotes">Twitter /@gruber: @comex I believe Markdown’s success is
               *due to*, not in spite of, its lack of standardization. And its success is not
               disputable.</title> September 3, 2014, 11:09 PM.
               <ref target="https://twitter.com/gruber/status/507364924340060160">https://twitter.com/gruber/status/507364924340060160</ref>.</bibl>
            <bibl xml:id="habermas2015" label="Habermas 2015"> Habermas, Jürgen. <title rend="italic">The Structural Transformation of the
               Public Sphere.</title> Cambridge: Polity, 2015. </bibl>
            <bibl xml:id="haigh2006" label="Haigh 2006"> Haigh, Thomas. <title rend="quotes">Remembering the Office of the Future: The Origins of Word
               Processing and Office Automation.</title> <title rend="italic">IEEE Annals of the History of Computing</title> vol. 28. 4
               (October 2006): 6–31. <ref target="https://doi.org/10.1109/MAHC.2006.70"
                  >https://doi.org/10.1109/MAHC.2006.70</ref>.</bibl>
            <bibl xml:id="hayles1999" label="Hayles 1999"> Hayles, Katherine. <title rend="italic">How We Became Posthuman: Virtual Bodies in Cybernetics,
               Literature, and Informatics.</title> Chicago, IL: University of Chicago Press, 1999.</bibl>
            <bibl xml:id="kay1967" label="Kay 1967"> Kay, Martin. <title rend="quotes">Standards for Encoding Data in a Natural Language.</title> <title rend='italic'>Computers
               and the Humanities</title> vol. 1.5 (1967): 170–77.</bibl>
            <bibl xml:id="kirschenbaum2003" label="Kirschenbaum 2003"> Kirschenbaum, Matthew G. <title rend="quotes">Virtuality and VRML: Software Studies
               after Manovich.</title> In <title rend="italic">The Politics of Information.</title>
               Stanford, CA: Alt-X Press, 2003. <ref target="https://electronicbookreview.com/essay/virtuality-and-vrml-software-studies-after-manovich/"
                  >https://electronicbookreview.com/essay/virtuality-and-vrml-software-studies-after-manovich/</ref>.</bibl>
            <bibl xml:id="kirschenbaum2016" label="Kirschenbaum 2016"> Kirschenbaum, Matthew G. <title rend="italic">Track Changes: A Literary History of Word
               Processing</title>. Cambridge, MA: Harvard University Press, 2016. <ref
                  target="https://doi.org/10.4159/9780674969469"
                  >https://doi.org/10.4159/9780674969469</ref>.</bibl>
            <bibl xml:id="knuth2007" label="Knuth 2007"> Knuth, Donald. <title rend="quotes">Oral History.</title> Interview by Edward Feigenbaum. <title rend="italic">Computer
               History Museum</title>, March 14, 2007.
               <ref target="https://www.computerhistory.org/collections/catalog/102658053">https://www.computerhistory.org/collections/catalog/102658053</ref>.</bibl>
            <bibl xml:id="lamport1986" label="Lamport 1986"> Lamport, Leslie. <title rend="italic">LaTeX: A Document Preparation System: User’s Guide and
               Reference Manual.</title> Reading, MA: Addison-Wesley, 1986.</bibl>
            <bibl xml:id="latexproject" label="LaTeX Project 2020"> LaTeX Project. <title rend="quotes">An Introduction to LaTeX.</title> <title rend="italic">LaTeX Project</title>. Accessed
               August 19, 2020. <ref target="https://www.latex-project.org/about/">https://www.latex-project.org/about/</ref>.</bibl>
            <bibl xml:id="macfarlene2020" label="MacFarlane 2020"> MacFarlane, John. <title rend="quotes">About Pandoc.</title> <title rend="italic">Pandoc</title>,
               August 20, 2020. <ref target="https://pandoc.org/">https://pandoc.org/</ref>.</bibl>
            <bibl xml:id="maltby1992" label="Maltby 1992"> Maltby, Gavin. <title rend="italic">An Introduction to Tex and Friends</title>,
               1992. <ref
                  target="http://faculty.washington.edu/stacy/prb/pdf/intro_to_tex_and_friends.pdf"
                  >http://faculty.washington.edu/stacy/prb/pdf/intro_to_tex_and_friends.pdf</ref>.</bibl>
            <bibl xml:id="mcgrail2017" label="McGrail 2017"> McGrail, Anne. <title rend="quotes">Open Source in Open Access Environments: Choices and
               Necessities.</title> <title rend="italic">Minimal Computing: A Working Group of GO::DH</title>, February 17, 2017.
               <ref target="https://go-dh.github.io/mincomp/thoughts/2017/02/17/mcgrail-choices/">https://go-dh.github.io/mincomp/thoughts/2017/02/17/mcgrail-choices/</ref>.</bibl>
            <bibl xml:id="mittelbach2004" label="Mittelbach et al. 2004"> Mittelbach, Frank et al. <title rend="italic">The LaTeX Companion</title>. Boston, MA:
               Addison-Wesley Professional, 2004.</bibl>
            <bibl xml:id="oroza2016" label="Oroza 2016"> Oroza, Ernesto. <title rend="quotes">Interview with Ernesto Oroza.</title> Interview by Alex Gil. In
               <title rend="italic">Debates in the Digital Humanities</title> 2016, edited by Matthew K. Gold and Lauren F. Klein,
               184-93. Minneapolis: University of Minnesota Press, 2016.</bibl>
            <bibl xml:id="oroza2020" label="Oroza 2020"> Oroza, Ernesto. <title rend="quotes">About.</title> <title rend="italic">Architecture of Necessity</title>,
               August 20, 2020. <ref target="http://architectureofnecessity.com/about/"
                  >http://architectureofnecessity.com/about/</ref>.</bibl>
            <bibl xml:id="peck2002" label="Peck and Tickell 2002"> Peck, Jamie and Adam Tickell. <title rend="quotes">Neoliberalizing Space.</title> <title rend="italic">Antipode</title>
               vol. 34.3 (2002): 380–404.</bibl>
            <bibl xml:id="reid1981" label="Reid 1981"> Reid, Brian Keith. <title rend="quotes">Scribe: A Document Specification Language and Its Compiler.</title> Ph.D. thesis. Carnegie Mellon University, 1981. <ref target="https://search.proquest.com/docview/303093737/abstract/BD9D8F366D5D4038PQ/1">https://search.proquest.com/docview/303093737/abstract/BD9D8F366D5D4038PQ/1</ref>.</bibl>
            <bibl xml:id="sayers2016" label="Sayers 2016"> Sayers, Jentery. <title rend="quotes">Minimal Definitions-Minimal Computing.</title> <title
               rend="italic">Minimal Computing: A Working Group of GO::DH</title>, October 2, 2016.
               <ref target="http://go-dh.github.io/mincomp/thoughts/2016/10/02/minimal-definitions/">http://go-dh.github.io/mincomp/thoughts/2016/10/02/minimal-definitions/</ref>.</bibl>
            <bibl xml:id="teamvivaldi2018" label="Team Vivaldi 2018"> Team Vivaldi. <title rend="quotes">What is Markdown and Why Should You Care.</title> <title
               rend="italic">Vivaldi Browser</title>, November 13, 2018.
               <ref target="https://vivaldi.com/blog/markdown-in-vivaldi-notes/">https://vivaldi.com/blog/markdown-in-vivaldi-notes/</ref>.</bibl>
            <bibl xml:id="tenen2014" label="Tenen and Wythoff 2014"> Tenen, Dennis, and Grant Wythoff. <title rend="quotes">Sustainable Authorship in Plain Text Using Pandoc and Markdown.</title> <title rend="italic">Programming Historian</title> 3, March 19, 2014. <ref target="https://programminghistorian.org/en/lessons/sustainable-authorship-in-plain-text-using-pandoc-and-markdown">https://programminghistorian.org/en/lessons/sustainable-authorship-in-plain-text-using-pandoc-and-markdown</ref>.</bibl>
            <bibl xml:id="tenen2017" label="Tenen 2017"> Tenen, Dennis. <title rend="italic">Plain Text: The Poetics of
               Computation</title>. Stanford, CA: Stanford University Press, 2017. </bibl>
            <bibl xml:id="tex2021" label="TeX Users Group 2021"> TeX Users Group. <title rend="quotes">History of TeX - TeX Users Group.</title> <title rend="italic">TeX Users
               Group</title>. Accessed October 22, 2021. <ref target="https://www.tug.org/whatis.html"
                  >https://www.tug.org/whatis.html</ref>.</bibl>
            <bibl xml:id="turner2006" label="Turner 2006"> Turner, Fred. <title rend="italic">From Counterculture to Cyberculture: Stewart Brand, the
               Whole Earth Network, and the Rise of Digital Utopianism</title>. Chicago, IL: University of
               Chicago Press, 2006.</bibl>
            <bibl xml:id="vanzundert2012" label="Van Zundert 2012"> Van Zundert, Joris. <title rend="quotes">If You Build It, Will We Come? Large Scale
               Digital Infrastructures as a Dead End for Digital Humanities.</title> <title rend="italic">Historical Social
               Research/Historische Sozialforschung</title> (2012): 165–86. </bibl>
            <bibl xml:id="walden2019" label="Walden 2019"> Walden, David. <title rend="quotes">Donald E. Knuth - A.M. Turing Award Laureate.</title>
               <title rend="italic">Association for Computing Machinery</title>, 2019.
               <ref target="https://amturing.acm.org/award_winners/knuth_1013846.cfm">https://amturing.acm.org/award_winners/knuth_1013846.cfm</ref>. </bibl>
            <bibl xml:id="warbrick1988" label="Warbrick 1988"> Warbrick, Jon. <title rend="quotes">Essential LaTEX,</title> 1988. Accessed March 22, 2022. <ref target="http://tug.ctan.org/info/latex-essential/ess2e.pdf">http://tug.ctan.org/info/latex-essential/ess2e.pdf</ref>.</bibl>
            <bibl xml:id="warner2002" label="Warner 2002"> Warner, Michael. <title rend="quotes">Publics and Counterpublics.</title> <title rend="italic">Public Culture</title> vol. 14.1 (2002):
               49–90.</bibl>
         </listBibl>
      </back>
   </text>
</TEI>
