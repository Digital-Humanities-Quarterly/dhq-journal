<?xml version="1.0" encoding="UTF-8"?><?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?><?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <!-- Author should supply the title and personal information-->
                <title type="article">Language DNA: Visualizing a Language Decomposition </title>
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Adam James <dhq:family>Bradley</dhq:family></dhq:author_name>
                    <dhq:affiliation>University of Waterloo</dhq:affiliation>
                    <email>adam.bradley@uwaterloo.ca</email>
                    <dhq:bio>
                        <p>Adam Bradley is a PhD candidate in both the department of English
                            Language and Literature and Systems Design Engineering. He is interested
                            in the intersections between technology and traditional literary studies
                            with a focus on early 20th century poetics. His current work focuses on
                            digital tool design for literary criticism and investigations into how
                            philology can still function within a technological context.</p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Travis <dhq:family>Kirton</dhq:family></dhq:author_name>
                    <dhq:affiliation>University of Calgary</dhq:affiliation>
                    <email>tkirton@gmail.com</email>
                    <dhq:bio>
                        <p>Currently director of the interaction design lab Logic&amp;Form, Travis
                            is a creative engineer, designer and researcher. He holds an MA of
                            Interface Culture and a BSc of Interactive Arts, with a specialization
                            in Interaction Design.</p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Mark <dhq:family>Hancock</dhq:family></dhq:author_name>
                    <dhq:affiliation>University of Waterloo</dhq:affiliation>
                    <email>mark.hancock@uwaterloo.ca</email>
                    <dhq:bio>
                        <p>Mark Hancock is an Associate Professor of Management Sciences in the
                            Faculty of Engineering at the University of Waterloo and Associate
                            Director of the Games Institute. His research is in the field of
                            Human-Computer Interaction and includes the design and development of
                            interfaces and interaction techniques for digital surfaces. His research
                            also focuses on the science of games and interaction?using concepts from
                            game design, such as engagement, immersion, and enjoyment, to inform the
                            design of more motivating and compelling novel interfaces.</p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Sheelagh <dhq:family>Carpendale</dhq:family></dhq:author_name>
                    <dhq:affiliation>University of Calgary</dhq:affiliation>
                    <email>sheelagh@ucalgary.ca</email>
                    <dhq:bio>
                        <p>Sheelagh Carpendale is a Professor in the Department of Computer Science
                            at the University of Calgary where she holds a Canada Research Chair in
                            Information Visualization and NSERC/AITF/SMART Technologies Industrial
                            Research Chair in Interactive Technologies. Her research on information
                            visualization, large interactive displays, and new media draws on her
                            background in Computer Science, Art and Design.</p>
                    </dhq:bio>
                </dhq:authorInfo>
            </titleStmt>
            <publicationStmt><publisher>Alliance of Digital Humanities Organizations</publisher><publisher>Association of Computers and the Humanities</publisher>
                <!-- This information will be completed at publication -->
                <idno type="DHQarticle-id">000259</idno>
                <idno type="volume">10</idno>
                <idno type="issue">4</idno>
                <date when="2016-10-04">4 October 2016</date>
                <dhq:articleType>article</dhq:articleType>
                <availability>
                    <cc:License rdf:about="https://creativecommons.org/licenses/by-nd/2.5/"/>
                </availability>
            </publicationStmt>

            <sourceDesc>
                <p>This is the source</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <classDecl>
                <taxonomy xml:id="dhq_keywords">
                    <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
                </taxonomy>
                <taxonomy xml:id="authorial_keywords">
                    <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
                </taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en"/>
            </langUsage>
            <textClass>
                <keywords scheme="#dhq_keywords">
                    <!-- Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors -->
                    <list type="simple">
                        <item/>
                    </list>
                </keywords>
                <keywords scheme="#authorial_keywords">
                    <!-- Authors may include one or more keywords of their choice -->
                    <list type="simple">
                        <item>Text Visualization</item>
                    </list>
                </keywords>
            </textClass>
        </profileDesc>
        <revisionDesc>
            <!-- Each change should include @who and @when as well as a brief note on what was done. -->
            <change who="JDF" when="2016-05-16">Created file</change>
        </revisionDesc>
    </teiHeader>

    <text xml:lang="en">
        <front>
            <dhq:abstract>
                <!-- Include a brief abstract of the article -->
                <p>In the Digital Humanities, there is a fast-growing body of research that uses
                    data visualization to explore the structures of language. While new techniques
                    are proliferating they still fall short of offering whole language
                    experimentation. We provide a mathematical technique that maps words and symbols
                    to ordered unique numerical values, showing that this mapping is one-to-one and
                    onto. We demonstrate this technique through linear, planar, and volumetric
                    visualizations of data sets as large as the Oxford English Dictionary and as
                    small as a single poem. The visualizations of this space have been designed to
                    engage the viewer in the analogic practice of comparison already in use by
                    literary critics but on a scale inaccessible by other means. We studied our
                    visualization with expert participants from many fields including English
                    studies, Information Visualization, Human-Computer Interaction, and Computer
                    Graphics. We present our findings from this study and discuss both the
                    criticisms and validations of our approach.</p>
            </dhq:abstract>
            <dhq:teaser>
                <!-- Include a brief teaser, no more than a phrase or a single sentence -->
                <p>A new, comprehensive technique for mapping language.</p>
            </dhq:teaser>
        </front>
        <body>
            <figure>
                <head>The English language in 1D along the top row. Showing zoom levels to find the
                    word <q>applesauce</q></head>
                <graphic url="resources/images/figure01.png"/>
            </figure>
            <div>
                <head>1 INTRODUCTION</head>
                <p>One of the goals of the literary critic is to analyze language and its embedded
                    complexity. For example, when literary critics examine a poem’s form, they
                    consider many characteristics of the words it contains, including the
                    similarities and differences in orthography, sound, the visible pattern it
                    produces, rhythmic structure, and countless others. Nearly all of this
                    information is available through visual inspection of the poem and contained in
                    what may already be our greatest visualization technique — the written word.
                    However, this same inspection carries with it the biases introduced by the
                    semantic meanings of the words themselves: it is difficult to pay attention to
                    the structural parts of the word “apple” without imagining the fruit it
                    represents.</p>
                <p>One possible method of aiding in the process of literary criticism is to provide
                    an alternate representation <ptr target="#simon1988"/> of the words contained
                    within the text to help separate the meaning from the structure, or to provide a
                    different vantage point with which to examine the work. By providing this
                    alternate view, structural aspects of the poem that may be difficult to
                    recognize when obfuscated by the meaning of the words themselves may be easier
                    to analyze and observe. We caution that this understanding will likely not be
                    valuable unless a connection can be bridged between the alternate representation
                    and the original piece of literature, and we stress that this approach is to be
                    considered an augmentation to existing practices. The goal of the research
                    presented in this paper is to provide an information visualization that provides
                    alternate representations of literature that will allow the critic to recover
                    the original work for analogic purposes.</p>
                <p>There have been a variety of examples in the digital humanities and information
                    visualization disciplines that provide alternate representations of language,
                    such as Word Clouds <ptr target="#viegas2008"/> and Word Trees <ptr target="#wattenberg2008"/>, but the authors are not aware of any examples
                    that have as a priority the ability to discern the text itself from the
                    visualization. Instead, these examples provide a means of examining text with
                    prior knowledge of the contents therein. Nonetheless, it is an open question
                    whether this change in representation would prove useful to the trained literary
                    critic.</p>
                <p>In this paper, we present a design study of an information visualization that is
                    a recoverable representation of language. Specifically, we present the design of
                    a visualization we have named Language DNA (L-DNA) that visually encodes any
                    symbol system, in our case the letters and phonemes of words in the English
                    language, and a qualitative evaluation with several literary critics and
                    designers to investigate the need and use of such a visualization.</p>
            </div>
            <div>
                <head>2 RELATED WORK</head>
                <p>Our study is an examination of how to visualize language in ways that can build
                    ontologies of words based on the needs of the literary critic. Much work has
                    been done in the area of text visualization but none have yet approached a level
                    that can produce whole language interactions. Our work builds on previous text
                    visualization techniques while expanding on the scope of information that can be
                    shown in our system, Language DNA.</p>
                <div>
                    <head>2.1 Text Visualization</head>
                    <p>Many previous text visualizations focused on some form of text. For instance
                        there are visualizations of documents <ptr target="#collins2009a"/>
                        <ptr target="#paley2002"/>, of selected subsets of words <ptr target="#decamp2005"/>
                        <ptr target="#hetzler1998"/>, and repetition in context <ptr target="#hearst1995"/>
                        <ptr target="#vanham2009"/>
                        <ptr target="#wattenberg2008"/>. There are also visualizations for grouping
                        and clustering documents <ptr target="#collins2009b"/>
                        <ptr target="#wise1995"/>. However, they do not approach whole language
                        visualization. Most approaches to text visualization whether coming from the
                        Information Visualization (InfoVis) community or the digital humanities, are
                        often aesthetically pleasing, but have not been demonstrated to have utility
                        for literary criticism or linguistics. This limitation can be seen in text
                        visualization projects such as tag clouds <ptr target="#lee2010"/>
                        <ptr target="#viegas2008"/>
                        <ptr target="#viegas2009"/> word associations <ptr target="#yatani2011"/>
                        <ptr target="#vanham2009"/>, topic modeling <ptr target="#chen2006"/>
                        <ptr target="#gardiner2010"/>
                        <ptr target="#gretarsson2011"/>
                        <ptr target="#hall2008"/>, and text document comparison <ptr target="#collins2009a"/>
                        <ptr target="#lin1992"/>
                        <ptr target="#smalheiser2009"/>
                        <ptr target="#wise1995"/>. There are text visualization projects that fall
                        into the category of linguistics that have had some success. <ptr target="#rohrdantz2012"/> provide a visual analysis of suffixes in
                        English, and the Google N-Gram<note> https://books.google.com/ngrams</note>
                        viewer has given access to historical usage data previously unattainable.
                    </p>
                </div>
                <div>
                    <head>2.2 Visualizing Language in the Digital Humanities</head>
                    <p>Within the domain of digital humanities, there are three main streams of
                        visualization that tend to pervade the literature. All three types are based
                        in text analysis but approach the problem from different directions. The
                        first is the GIS type tools for organizing spatial data in the humanities
                            <ptr target="#jessop2006"/>
                        <ptr target="#jessop2008"/>
                        <ptr target="#wood1992"/>, specific examples of this type of work include
                        Bingenheimer et al.’s visualization of the biographies of Buddhist monks
                            <ptr target="#bingenheimer2009"/>, as well as Valley of the Shadow <ptr target="#valley2015"/>, in which there are examples of multiple types of
                        quantitative and qualitative data presented in a GIS format.</p>
                    <p>The second category involves tools used to augment reading, text analysis
                        tools that highlight relationships in texts, often with visualizations. This
                        category includes work such as Clement’s distant reading of Gertrude Stein
                            <ptr target="#clement2008"/>, and Wattenberg et al.’s work on using tree
                        visualizations for visual concordances <ptr target="#wattenberg2008"/>.
                        Projects such as TAPoR <ptr target="#tapor2015"/> also provide data mining
                        tools for literary and textual analyses. The aim of these projects is to
                        allow for interesting portions of large texts to be marked up and visualized
                        for comparison.</p>
                    <p>The third category of research is the straight visualization projects which
                        are of two types: The first are the projects that use toolkits such as
                        Voyant tools <ptr target="#voyant2015"/> to accomplish their research task
                        and the second are the projects that create bespoke visualizations specific
                        to their research problem. The second type of these includes Moretti’s work
                        on visualizing interactions and character movements in literature <ptr target="#moretti2005"/>, Bingerheimer et al.’s social network
                        visualization from TEI data, which uses text encoded data to produce
                        networked relationships among textual elements <ptr target="#bingenheimer2006"/>, and Gould’s use of network tools for
                        historical data analysis <ptr target="#gould2003"/>. This can also be seen
                        in the TextArc project, which uses radial graphs to show contents and
                        relationships between words in texts <ptr target="#paley2002"/>, and Writing
                        without Words <ptr target="#posavec2015"/>, Posavec’s beautiful graphs of
                        sentence structures and themes in Kerouac’s “On the Road”. Perhaps the most
                        exciting and cognate study is Alexander’s work on the Oxford Historical
                        Thesaurus and mapping sonic relationships in language over time <ptr target="#alexander2012"/>. Also, we find a movement to projects that use
                        art to approach these problems, highlighting that aesthetics may be itself a
                        critical tool. Installations such as TextRain <ptr target="#textrain2015"/>,
                        an interactive art piece where gallery goers interact with falling text, and
                        Word Collider <ptr target="#wordcollider2015"/>, an artistic project modeled
                        after pictures from CERN’s Large Hadron Collider, where parts of words when
                            <q>smashed</q> together produce effects like those seen in images from
                        particle accelerators.</p>
                    <p>The development of our technique was motivated by the fact that existing
                        visualizations and text analysis tools, while usually aesthetic pleasing,
                        cannot easily be used for the types of analyses expected or desirable for
                        literary criticism or linguistics. Our Language DNA is an attempt to build a
                        system that can handle multiple levels of information to display complex
                        structural and content-related relationships within texts. </p>
                </div>
            </div>
            <div>
                <head>3 MOTIVATION — A LITERARY CRITIC’S PERSPECTIVE</head>
                <p>In his book <title rend="italic">Anatomy of Criticism</title>, Northrop Frye asks
                    the question: <cit>
                        <quote rend="inline" source="#frye2000">what if criticism is a science as well as an
                            art?</quote>
                        <ptr target="#frye2000"/>
                    </cit> The development of the visualization technique presented here was driven
                    by this exact question. Our intention is to facilitate a different approach to
                    Frye’s domain-specific question about literary criticism: can we use
                    mathematical and visualization techniques to incorporate science into a literary
                    criticism? These questions have a long history in the humanities and were born
                    out of the general notion that arose in the renaissance when the likes of Locke,
                    Bacon, and Descartes defined a practice that separated and solidified science
                    from the humanities. The 20th century structuralists suggest that this position
                    is reconcilable, that all literature and language is systematic. This idea —
                    that language is systematic — is approachable via visualization.</p>
                <p>The visualization algorithm we present can accommodate as much or as little
                    information that a critic could want, giving the possibility of visualizing as
                    little as a single letter, as much as entire corpora. If we are to imagine a
                    space where the literary critic or linguist can experiment using a
                    language-based mathematics, it must have these three characteristics:</p>
                <div>
                    <head>3.1 Consistency and Reversibility</head>
                    <p>First, a visualization algorithm is needed to encode language such that we
                        can create a space that is both consistent and reversible. In mathematical
                        terms, this would be referred to as one-to-one and onto. The need for
                        consistency and reversibility arises from the requirement in the analysis
                        process of preserving the ability for human interpretation of the words. In
                        order for the visualization to be “readable” by a critic, each word must be
                        consistently mapped and that mapping must be reversible into the original
                        work. Most existing visualization techniques distort the original texts
                        without providing an avenue for reconstituting them. This is problematic
                        when studying things like poetics where the spatial component of the text is
                        integral to its meaning.</p>
                </div>
                <div>
                    <head>3.2 Infinite Plotting Space</head>
                    <p>Second, it is important that the algorithm uses a plotting space that is
                        infinite. Imagine that we were to approach the problem of metaphor. As an
                        example, in theory we do not know if the chain of meaning created by
                        metaphoric relations between words is finite. It stands to reason then, that
                        without an understanding of the full requirements of a system that an
                        infinite space is a safe decision. If we are to start to approach these
                        types of questions our lack of knowledge should not limit the size of
                        possibilities. Specifically, the critic must be able to analyze words and
                        literature that are perhaps not known to the visualization designer. With
                        our technique, we can encode anywhere from one letter to an entire language,
                        to the entire literatures of one language, and even multiple languages, in a
                        space where each point belongs to one individual piece of original
                        information. The infinite space means that in creating <q>experiments</q>
                        the literary critic is not limited to our present understanding of
                        language.</p>
                </div>
                <div>
                    <head>3.3 Layering</head>
                    <p>The third requirement is the need for the ability to layer symbols in order
                        to make comparisons. For instance, it should be possible to overlay a poem
                        within the context of the entire language or other poetry. The need for
                        layering arises from the analogic basis of most types of literary critical
                        and linguistic inquiries. This should extend to any types of symbols, as
                        comparisons are not always rooted in the Latin alphabet. Based on what we
                        recognize as the possible requirements of such a system, we designed our
                        Language DNA visualization with the three characteristics of consistency and
                        reversibility, infinite plotting space, and layering in mind.</p>
                </div>
            </div>
            <div>
                <head>4 DEFINING LANGUAGE DNA</head>
                <p>An important property of our mapping is that the words be recoverable from the
                    visual space. Mathematically, this requires that the mapping be a bijection
                    (i.e., that words both map to a unique place in the visual space, and that each
                    point in the visual space maps back to a word). As an example of the technique
                    we introduce a mathematical translation of words to numbers that relies on the
                    lexicographical ordering of letters. This is essentially a mapping of
                    alphabetical order and is one of possibly infinite ways to group the data. We
                    have chosen this technique as a first demonstration because we are all familiar
                    with the way we order a dictionary, but we must stress that we can map the data
                    many different ways. We define the mapping 𝑔 so that each letter is
                    mapped to its position in the alphabet, as follows:</p>
                <p>𝑔 ∶ 𝐴  →  ℤ</p>

                <!--<graphic url="resources/images/mathfigure01.png"/>-->

                <p>where 𝐴 is the set of alphabetical characters {𝑎, 𝑏 … ,
                    𝑧} and:</p>

                <p>𝑔(𝑎) = 1, 𝑔(𝑏) = 2, … ,
                    𝑔(𝑧) = 26</p>
                <!--<graphic url="resources/images/mathfigure02.png"/>-->


                <p>Note that this mapping is currently written using base 10 numbers for the
                    integers (1 to 26, with an implied 0 for no character), but our mapping requires
                    a base 27 representation (or more generally base N+1, where N is the number of
                    characters in the language), which for convenience we will symbolically
                    represent as follows:</p>

                <p> 1<hi rend="subscript">10</hi> = 𝑎<hi rend="subscript">27</hi> (i.e., 1
                    in base 10 is represented as ‘a’ in base 27) <lb/> 2<hi rend="subscript">10</hi> = 𝑏<hi rend="subscript">27</hi><lb/> ...
                    <lb/> 26<hi rend="subscript">10</hi> = 𝑧<hi rend="subscript">27</hi></p>

                <!--<graphic url="resources/images/mathfigure03.png"/>-->


                <p>Thus, we can define our mapping of words to a one-dimensional number line as
                    follows:</p>
                <p>𝑓: 𝑊 → (0,1)</p>
                <!--<graphic url="resources/images/mathfigure04.png" />-->

                <p>where 𝑊 is the set of alphabetical words (e.g.,<q>apple</q>, <q>dog</q>,
                        <q>the</q>, etc.) such that for each 𝑤 𝜖 𝑊,
                    𝑤 = 𝑥<hi rend="subscript">1</hi> 𝑥<hi rend="subscript">2</hi> ... <hi rend="italic">x</hi><hi rend="subscript">𝑛</hi>,
                    and:</p>

                <p>𝑓 (𝑤) = 0.(𝑥<hi rend="subscript">1</hi>)𝑔(𝑥<hi rend="subscript">2</hi>) ...
                        𝑔(𝑥<hi rend="subscript">𝑛</hi>)</p>
                <!--<graphic url="resources/images/mathfigure05.png"/>-->


                <p>For example, for 𝑤 = “dog”, we have <hi rend="italic">x</hi><hi rend="subscript">1</hi> = ‘d’, 𝑥<hi rend="subscript">2</hi> = ‘o’,
                        𝑥<hi rend="subscript">3</hi> = ‘g’, therefore:</p>

                <p>𝑓 ("dog") = 0.𝑑𝑜𝑔</p>
                <!--<graphic url="resources/images/mathfigure06.png"/>-->


                <p>Note that this is a base 27 number, but could be converted to base 10:</p>


                <p>0.𝑑𝑜𝑔<hi rend="subscript">27</hi> = 4x27<hi rend="superscript">-1</hi> + 15x27<hi rend="superscript">-2</hi> + 7x27<hi rend="superscript">-3</hi> = 0.1690799<hi rend="subscript">10</hi></p>
                <!--<graphic url="resources/images/mathfigure07.png"/>-->


                <figure>
                    <head>All words in the English language visualized along a number line from 0 to
                        1, and the specific word <q>dog</q> (represented as a vertical line in red)
                        would appear 16.9% of the way in.</head>
                    <graphic url="resources/images/figure02.png"/>
                </figure>


                <p>If we relax the restriction that each word needs to end (i.e., we allow words to
                    have an infinite sequence of letters), it becomes clear that 𝑓 is a bijection,
                    since every word generates a unique base 27 representation (one-to-one: the
                    property that if two words map to the same number, they must be the same word)
                    and each number between 0 and 1 can be converted to base 27 to recover the
                    sequence of letters (onto: the property that every number has a word that can
                    map onto it).</p>

                <div>
                    <head>4.2 Using the 2D Visual Space</head>
                    <p>The mapping above describes how an arbitrary word can be mapped onto a number
                        line, which already allows the visual mapping of words onto an axis in 1D
                        space (similar to a lexicographical axis). Here, we describe a method,
                        inspired by Cantor’s Diagonalization to map an individual word onto 2D space
                        directly (and more generally onto n-dimensional space).</p>
                    <p>We can split the word in two by considering every other character, for
                        instance <term>InFoViS</term> would become <term>IFVS</term> and
                            <term>noi</term>. Thus, we can take the base 27 representation of the
                        mapped word and create two dimensions as follows:</p>

                    <p>𝑓<hi rend="subscript">2</hi>:𝑊  →  
                            (0,1)<hi rend="superscript">2</hi><lb/> 𝑓<hi rend="subscript">2</hi>(𝑤) = 𝑓<hi rend="subscript">2</hi>(𝑥<hi rend="subscript">1</hi>𝑥<hi rend="subscript">2</hi> ...
                            𝑥<hi rend="subscript">2𝑛</hi>) = (𝑓(𝑥<hi rend="subscript">1</hi>𝑥<hi rend="subscript">3</hi> ...
                            𝑥<hi rend="subscript">2𝑛-1</hi>) ,
                            (𝑓(𝑥<hi rend="subscript">2</hi>𝑥<hi rend="subscript">4</hi> ... 𝑥<hi rend="subscript">2𝑛</hi>))</p>
                    <!--<graphic url="resources/images/mathfigure08.png"/>-->

                    <p>For example, if our word is <q>applesauce</q> (Fig. 3):</p>

                    <figure>
                        <head>The entire English language can also be visualized in 2D (top-left).
                            The result is what appears as a grid of letter pairs, so that one can
                            zoom into words that begin with AP (top-right), and within that square,
                            words that begin with APPL (bottom).</head>
                        <graphic url="resources/images/figure03.png"/>
                    </figure>

                    <p> 𝑓<hi rend="subscript">2</hi> ("applesauce") =
                        (0.𝑎𝑝𝑒𝑎𝑐,
                        0.𝑝𝑙𝑠𝑢𝑒)</p>
                    <!--<graphic url="resources/images/mathfigure09.png"/>-->

                    <p>which, in base 10 would be:</p>

                    <p>𝑓<hi rend="subscript">2</hi> ("applesauce") =
                        (0.0592410,0.6100587)</p>
                    <!--<graphic url="resources/images/mathfigure10.png"/>-->

                    <p>This mapping can easily be extended to n-dimensions by taking every <hi rend="italic">n</hi><hi rend="superscript">th</hi> character in the base
                        27 representation of (𝑤). <hi rend="italic">f</hi><hi rend="subscript">2</hi> is also clearly a bijection, because every word
                        can be split into alternating characters to generate two base 27
                        representations (one-to-one) and each pair of numbers between 0 and 1 can be
                        converted to base 27 to recover the two parts of the word, which can then be
                        reassembled (onto). Thus, every word in the English language can be mapped
                        onto a 2D space using <hi rend="italic">f</hi><hi rend="subscript">2</hi>,
                        and every 2D point can be mapped to a <q>word</q>, where a word is a
                        sequence of possibly infinite letters which may well not have associated
                        semantics. Note that this mapping does not account for things like homonyms,
                        but with a simple addition to the mapping we could easily differentiate
                        words for any number of their ontological characteristics. </p>
                </div>
                <div>
                    <head>4.3 A Note on Scale</head>
                    <p>Since whole natural languages are immense, it is important to discuss scale,
                        both of what is being visualized and the size of the resulting
                        visualization. We can base a visualization size calculation on the number of
                        words being visualized, and then determine the length of a 1D L-DNA
                        visualization that draws at a density of a single pixel for each word or
                        unit (it is important to remember that these calculations are for
                        orthography, they will change depending on the symbol system used). Two
                        measures are needed to accomplish this: the smallest and the largest
                        distance between two words. Since our algorithm already normalizes words in
                        1D to be between 0 and 1, we can assume that the difference between the
                        largest and smallest words is approximately 1.0 (with the words ‘a’ and
                        ‘zygote’, this is already correct to 1 decimal place). In our analysis of
                        words from the Oxford English Dictionary (OED), the two closest words using
                        our algorithm are “abandoner” and “abandoning”, with the first seven letters
                        in common and the next being very close in the alphabet. The difference in
                        values from our algorithm for these two words is:</p>

                    <p>0.<hi rend="italic">abandoning</hi><hi rend="subscript">27</hi> - 0.<hi rend="italic">abandoner</hi><hi rend="subscript">27</hi> = 1.37 x 10<hi rend="superscript">-11</hi><hi rend="subscript">10</hi></p>
                    <!--<graphic url="resources/images/mathfigure11.png"/>-->

                    <p>Thus, to present a number line from 0 to 1 with numbers only 1.37×10<hi rend="superscript">-11</hi> apart represented as different pixels would
                        require:</p>

                    <p>1.0 ÷ (1.37 x 10<hi rend="superscript">-11</hi>) = 73.1 billion
                        pixels</p>
                    <!--<graphic url="resources/images/mathfigure12.png"/>-->

                    <p>Note that in 2D, our algorithm fairs far better. This same pair of words
                        would be broken down into two pairs of coordinates:</p>

                    <p>(0.<hi rend="italic">aadnn</hi><hi rend="subscript">27</hi>, 0.<hi rend="italic">bnoig</hi><hi rend="subscript">27</hi>) and (0.<hi rend="italic">aadnr</hi><hi rend="subscript">27</hi>, 0.<hi rend="italic">bnoe</hi><hi rend="subscript">27</hi>)</p>
                    <!--<graphic url="resources/images/mathfigure13.png"/>-->

                    <p>which has at most four letters in common for each dimension and would require
                        only:</p>

                    <p>1.0 ÷ (0.<hi rend="italic">aadnr</hi><hi rend="subscript">27</hi> -
                            0.<hi rend="italic">aadnn</hi><hi rend="subscript">27</hi>) = 1.0 ÷
                            (2.79x10<hi rend="superscript">-7</hi>) = 3.6 million pixels</p>
                    <!--<graphic url="resources/images/mathfigure14.png"/>-->

                    <p>To put this into perspective, a 1D visualization using our algorithm would
                        require the width of 38.1 million 1080p screens (1920 × 1080 pixels) placed
                        side-by-side, and a 2D visualization would require 6.2 million 1080p screens
                        arranged to form a rectangle.</p>
                </div>
            </div>
            <div>
                <head>5 ILLUSTRATING L-DNA</head>
                <p>We start with three examples to demonstrate how L-DNA can be used to visualize
                    language. The first is a dictionary mapping for the English language, the second
                    is a view of multiple languages, and the third is a mapping of English phonemes
                    to illustrate the applicability of this approach to any set of symbols<note> We
                        present only three simple possibilities here. It must be stressed that the
                        algorithm works for any symbol system or combination of symbols
                        systems.</note>.</p>
                <div>
                    <head>5.1 Visualizing the Oxford English Dictionary</head>
                    <p>Fig. 4 shows all 370,624 words parsed with criteria that eliminate diacritics
                        and punctuation the Oxford English Dictionary<note>We have removed words
                            with diacritics and punctuation for simplicity of demonstration. The
                            algorithm is fully capable of handling these symbols with slight changes
                            to the function.</note> rendered using the algorithm described above
                        (i.e., using the coordinates provided by <hi rend="italic">f</hi><hi rend="subscript">2</hi>. The result is a mapping that privileges the
                        first two letters of each word. That is, the x-axis can be read as an
                        alphabetical ordering of the first letters of words, and the y-axis can be
                        read as an alphabetical ordering of the second letters. This makes the top
                        left box <q>AA</q>, where you would find words such as <q>Aardvark</q> (note
                        that few words in English begin with two A’s, which is why this box is quite
                        sparse). This property is recursive, so that within each box, the third and
                        fourth letters are similarly privileged. For example, in the <q>BA</q> box,
                        there is an <q>NA</q> box, which has another <q>NA</q> box that contains the
                        word <q>BANANA</q>. This initial visualization shows how we can start to
                        understand where each word belongs within the 2d whole.</p>
                    <figure>
                        <head>The Oxford English Dictionary (OED2) in 2D L-DNA</head>
                        <graphic url="resources/images/figure04.png"/>
                    </figure>
                    <p>Because our algorithm privileges the spelling of words, this 2D
                        representation can be thought of as a form of 2D orthography (specifically
                        spelling rules). It is essentially a two-dimensional layout of alphabetical
                        order. This version of L-DNA reveals a <q>bird’s-eye view</q> of the
                        language that was not previously available to the literary critic, linguist,
                        or lexicographer; a critic could previously flip through a dictionary’s
                        pages or even a list of ordered English words, but this visualization
                        instead provides a new 2d spatial location for each word in this
                        dictionary.</p>
                </div>
                <div>
                    <head>5.2 The Multiple Language L-DNA View</head>
                    <p>Our second example compares multiple languages (English, French, German, and
                        Spanish). Fig. 5 shows these four languages each represented in 1D on the 0
                        to 1 number line using our algorithm, stacked for comparison. Visual
                        inspection reveals a similar sparseness in the ‘Q’ portion of the line for
                        all languages (i.e., few words in any of these languages begin with ‘Q’ and
                        any letter other than ‘U’), but additional sparseness in French, German, and
                        Spanish exists near the end of the alphabet (‘W’, ‘X’, ‘Y’).</p>

                    <figure>
                        <head>Four languages in 1D stacked.</head>
                        <graphic url="resources/images/figure05.png"/>
                    </figure>


                    <p>Fig. 6 also shows a side-by-side comparison of multiple languages in 2D, and
                        Fig. 7 overlays these four languages. Fig. 8 shows a close-up of the AL
                        region of the overlaid image. These side-by-side comparisons or overlays
                        allow for elementary analogic comparisons and can be expanded on with more
                        complex symbol encoding.</p>


                    <figure>
                        <head>2D L-DNA of English (blue), French (red), German (amber), Spanish
                            (aqua)</head>
                        <graphic url="resources/images/figure06.png"/>
                    </figure>

                    <figure>
                        <head>Overlaying the dictionaries of the 4 languages (English, French,
                            German and Spanish) in 2D L-DNA.</head>
                        <graphic url="resources/images/figure07.png"/>
                    </figure>

                    <figure>
                        <head>Close up of the subsection AL from Fig. 7</head>
                        <graphic url="resources/images/figure08.png"/>
                    </figure>


                    <p>The above images were generated with the constraint that we only had access
                        to open source dictionaries <ptr target="#dict2015"/> for languages other
                        than English (for which we have university-wide access to the OED). The
                        French (red) has 197,954 words, the English (blue) has 370,624 words, the
                        German (yellow) 425,501 words, and the Spanish (green) has 160,442
                        words.</p>
                </div>
                <div>
                    <head>5.3 English Phonemes in L-DNA</head>
                    <p>We chose the next example (Fig. 9), English phonemes, to demonstrate the
                        robustness of the technique to arbitrary symbolic representations of
                        language, and to create an analogue between the spellings of words and the
                        sounds of words. The mapping is organized in like sound units: vowels (e.g.,
                            <q>AA, AE</q>), semivowels (e.g., <q>W,Y</q>), stops (e.g.,
                        <q>B,D,K</q>), affricates (e.g., <q>C, H, JH</q>), fricatives (e.g., <q>D,
                            SH, V</q>), aspirates (e.g., <q>HH</q>), liquids (e.g., <q>L, R</q>),
                        and nasals (e.g., <q>M, N, NG</q>).</p>

                    <figure>
                        <head>English Phonemes showing the Phoneme map of 370,624 words used from
                            the OED2 in 2D mapped by sound types (i.e. fricatives, stops,
                            etc.)</head>
                        <graphic url="resources/images/figure09.png"/>
                    </figure>

                    <p>By organizing words into phonemes, some interesting observations can be made.
                        It appears clear that a portion of the phonemes are used primarily for the
                        first syllable and another distinct set is used primarily for the second
                        syllable. This can be observed through the densely populated top and right
                        columns, with the majority of the bottom-left part of the image containing
                        almost no English words. In addition, the top-right corner is mostly empty,
                        with the exception of a few very dense groups, representing the few phonemes
                        that are used for both the first and second syllables.</p>
                </div>
                <div>
                    <head>5.4 Poetry</head>
                    <p>The final example that we created was to insert a single poem into the space
                        that we created for English words and phonemes. This is a first step in
                        being able to use these spaces for analogic comparisons. </p>
                    <p>Some interesting patterns can be observed in the poem through visualizing it
                        in this manner. Firstly, in terms of orthography (Fig. 10) it becomes
                        possible to identify visual rhymes by cluster groups within the image. In
                        Fig. 11, this same phoneme visualization can be used to identify rhyming
                        patterns within a poem. As the phonemes group together it is possible to see
                        the types of sounds being repeated in the piece. Although this is easy to do
                        with a 16 line sonnet, it becomes much more difficult with a poem of any
                        significant length (e.g. Milton’s 10,000 + lines of verse in <title rend="quotes">Paradise Lost</title>) and this technique could help to
                        highlight <q>macro-structures</q> in poetry. Each diagram below is laid out
                        in two dimensions. This is a decision made during the encoding process and
                        can be n-dimensional based on the amount of information you wish to build
                        into the model. In this case we have chosen to show 2d representations for
                        simplicity. In Figure 10 we present what we label our alphabetical order
                        visualization where we represent words by their spellings. A visualization
                        of spelling alone may not lead to many insights, but is useful for simple
                        demonstrations. One area where this simple encoding could be used would be
                        to visually compare irregular spellings in Elizabethan drama. It would
                        provide quick visual access to the places in texts that differed and needed
                        an editor’s attention. The real power in this method comes from being able
                        to encode as many connections as desired. Work has been done in the digital
                        humanities and computer science in the last few years in word embedding
                        models and the consistency of our method could aid in the process of
                        detecting connections in texts by using vectors. In figure 11, we have
                        graphed phonemes in two dimensions. Any highlights that form vertical lines
                        are showing alliteration in the poem. An example is in the line from Donne’s
                        poem: <q>Or like a thiefe, which till deaths doome be
                            read</q>. The words <q>deaths</q> and <q>doom</q> line up vertically
                        to indicate alliteration in this particular encoding. If we wanted to
                        visualize rhymes we would simply encode the phonemes in reverse, privileging
                        the final phoneme and we would generate a similar graph. The n-dimensional
                        nature of the models allows for as much or as little data coding as needed,
                        including relations between words. The only limitations on the questions
                        that can be asked are the imagination of the analyst.</p>


                    <figure>
                        <head>The text of John Donne's "O my black soul" sonnet visualized with the
                            OED.</head>
                        <graphic url="resources/images/figure10.png"/>
                    </figure>

                    <figure>
                        <head>The text of John Donne's "O my black soul" sonnet visualized with
                            English Phonemes.</head>
                        <graphic url="resources/images/figure11.png"/>
                    </figure>


                </div>
            </div>
            <div>
                <head>6.0 QUALITATIVE STUDY</head>
                <p>We wanted to discuss this project with a cross-section of scholars to develop a
                    better understanding of how people understood L-DNA and whether or not they saw
                    potential uses for their research. Our goal was to gain insight into whether
                    this technique could inspire reactions and possibly spark interest in the
                    approach.</p>
                <div>
                    <head>6.1.1 Participants</head>
                    <p>We intentionally sought participants from a variety of disciplines. We had 14
                        participants which included 1 visual artist, 3 literary critics, 1
                        rhetorician, 2 digital media critics, 1 database programmer, 1 business
                        analyst, 1 linguist, 2 interaction designers, 1 graphic designer, and 1
                        marketing specialist.</p>
                </div>
                <div>
                    <head>6.1.2 Procedure</head>
                    <p>Each participant took part in a thirty-minute interview and was first shown
                        L-DNA visualizations that we had intentionally left void of any legends or
                        axis labels, so that we could ask questions about their initial
                        interpretations. After showing the image in Fig. 4, the mapping of the OED
                        in two dimensions, we asked what they thought the image might be. We then
                        showed participants Fig. 7, four languages plotted in the same space, and
                        the interviewer gave a thorough explanation of the how the algorithm works
                        and what they were seeing. We took time to make sure they were comfortable
                        with the explanation and asked about their understanding. We then showed
                        them Fig. 8 to be able to further explain L-DNA and asked questions based on
                        the participants’ understanding. We also asked participants to complete a
                        post-interview questionnaire. Five questions were asked on a 5-point scale,
                        with an opportunity to provide free form answers:</p>

                    <p> Q1. Once explained to what extent is the visualization readable? </p>
                    <p> Q2. Do you think the white space has meaning? </p>
                    <p> Q3. Is the white space necessary? </p>
                    <p> Q4. Does representing languages by colour and words as points work well? </p>
                    <p> Q5. Does this spatial representation of language trigger new ideas?</p>
                    <p>The following three questions asked for free form answers only:</p>
                    <p> Q6. What are your initial interpretations of this visualization? </p>
                    <p> Q7. Can you imagine a more suitable or readable structure? </p>
                    <p> Q8. Please provide any criticism you have about this visualization.</p>
                </div>
            </div>
            <div>
                <head>7.0 RESULTS: SCALE-BASED QUESTIONS</head>
                <p>The scale questions were answered as follows. For Q1, 6 out of 14 participants
                    told us the visualization was clear after the explanation (5 out of 5 on the
                    scale). FOR Q2, 9 out of 14 people said that the white space carried meaning to
                    them (5 out of 5) and 6 participants thought that this white space was
                    completely necessary. For Q4, 7 out of 14 people ranked a 5 out of 5 for the
                    visualization approach. 10 out of 14 participants said that the visualization
                    triggered new ideas for research (5 out of 5). </p>
            </div>
            <div>
                <head>8.0 DISCUSSION: FREE-FORM QUESTIONS &amp; INTERVIEWS</head>
                <p>We have formulated our discussion around the free-form questions. Since our
                    participants were experts from a variety of fields and domains, the similarities
                    in answers in some cases are particularly interesting. In other places it is the
                    difference in answers that encourages us as researchers in terms of the
                    potential of L-DNA as a tool for approaching questions about language. In this
                    discussion we include the questions and a discussion of the general themes that
                    arose in the responses. </p>
                <div>
                    <head>8.1 The Power of Representation</head>
                    <p>Interestingly, when shown the images without any labels, participants tended
                        to engage in metaphoric comparisons of what they were seeing. The omission
                        of a legend led each participant to find something that was cognitively
                        analogous to what they were being shown. For example, some responses were: </p>
                    <p>
                        <said>Is it zoomable? It has a DNA look or sort of ummm a matrix data flow
                            and I feel the urge to zoom it. It looks like I am really far away from
                            an unbound book, like how a book would be printed in sheets. It has that
                            type of aesthetic.</said>
                    </p>
                    <p>
                        <said>Well, it reminds me of DNA, like a screening test, it also looks like
                            a stamp, like someone has stamped something. It is a very tactile image,
                            I want to touch it.</said>
                    </p>
                    <p>
                        <said>It’s kind of like DNA. Like, uh, people show these images that
                            visualize DNA.</said>
                    </p>
                    <p>In response to this process, five out of nineteen (26%) of our participants
                        from varying backgrounds and fields, with no explanation of what they were
                        looking at, described Fig. 4 as appearing like DNA — the inspiration for the
                        name of our technique. This result also demonstrates the power of
                        representation held within L-DNA. Some of the responses received from
                        participants included references to stamped or fading paper, city grids,
                        abstract art, and digital clock faces. Because we were trying to create a
                        space that could handle an ontology of words, the DNA metaphor was highly
                        applicable based on the implications of describing parts of a long chain of
                        information.</p>
                </div>
                <div>
                    <head>8.2 White Space</head>
                    <p>In our interpretation of the study data, the questions about whitespace
                        (Q2-Q3) produced perhaps the most interesting results. It was during this
                        question that most of the participants began to hypothesize about the
                            <q>space</q> in the languages they use every day. Essentially the parts
                        of the visualization with an absence of marks inspired thought, because they
                        were in stark contrast to the actual dots drawn on the screen. This result
                        strongly indicates the analogic or comparative possibilities of this
                        technique — the literary critic can begin to understand what makes a word
                        English by recognizing what is not a word, or by investigating what words
                        poets or writers use that push the boundaries of language. This result is
                        encouraging for the domain-specific problems of literary criticism. One of
                        our requirements is a space for analogues and with the whitespace in this
                        simple mapping there is significant affect. The response of our participants
                        to the relationship between the whitespace and the space occupied by words
                        creates a relationship that gives insight into what sets of symbols we use
                        and which we do not use in our language. The sheer size of the whitespace in
                        comparison forces an understanding of how few of the possible arrangements
                        of letters we actually use. With further work we think it is possible to
                        show that more complex mappings will produce more complex analogues.</p>
                    <p>It was generally agreed upon that it was the relation of the empty space to
                        the marked space that created meaning and inspired insight into what the
                        visualizations were showing and what they could show.</p>
                    <p>
                        <said>the white space gives you a sort of ground against which it makes
                            sense... without it it might be even less evident</said>
                    </p>
                    <p>It was in the white, or the lack of spellings, that our participants saw the
                        potential for growth in the language, or commented on the enormous range of
                        letter combinations that we do not use in English. This is encouraging
                        because as we build “meaning” into these visualizations we expect the
                        response to be comparative, and we expect new interpretations will result
                        from these comparisons. Initial reasons were as follows:</p>
                    <p>
                        <said>Every letter can start a word, but does that mean that there’s
                            combinations of letters that don’t turn into words... you don’t have
                            words that start with trsz is that why there would be space... Maybe it
                            means that language is primitive, not as evolved as it could be.</said>
                    </p>
                    <p>
                        <said>I’m almost more interested in the dots in the white space... if
                            there's one I want to know what that is...the outliers are more
                            interesting.</said>
                    </p>
                    <p>
                        <said>What it does is show what the common letters are and common
                            overlaps.</said>
                    </p>
                    <p>For the researchers this result was surprising, but was explainable. Without
                            <q>meaning</q> being built into this version we were simply showing a
                        part of orthography (spelling) and, in this stripped down version of the
                        possibilities of the space, it was the comparison between what was empty and
                        what was marked that sparked the interest of our participants. This is the
                        exact response we were interested in and we anticipate with more complex
                        representations we will be able to see more complex analogies. Some of the
                        responses to this whitespace analogy are as follows:</p>
                    <p>
                        <said>I think the uniformity of the gaps are startling. It seems oddly
                            uniform and consistent. I think that potentially symbolically the gaps
                            can sort of be a formative quality of language and words will start to
                            fill in those gaps.</said>
                    </p>
                    <p>
                        <said>Well, I guess it kind of goes to show how constrained we are in
                            language, which shows how some things just are not possible with
                            spelling, which is kind of cool. There is so much blank space
                            particularly along certain lines, you get some sense that our alphabet
                            constrains us, which is why we have poets.</said>
                    </p>
                    <p>These responses were typical of all our participants and are very promising
                        for future work.</p>
                </div>
                <div>
                    <head>8.3 Reluctant Inspiration</head>
                    <p>When asked if the images they were seeing inspired any new thought processes,
                        they proved to be exciting to our participants and the answers that follow
                        show the breadth of their thinking:</p>
                    <p>
                        <said>You could map to any narrative, I would like to see this map out, A
                            Tale of Two Cities, it looks like a genetic footprint, like a genetic
                            phonetics, you get to see this formal genetic blueprint, it is more like
                            an autopsy of the text.</said>
                    </p>
                    <p>
                        <said>Yes, from a design and a fine art point of view. I think it is, again,
                            if you look at it as a design issue does it solve any problems, not yet,
                            but then again you are deconstructing something that already has that
                            problem solved so you are raising questions instead of solving problems
                            and you are raising interesting and meaningful questions.</said>
                    </p>
                    <p>
                        <said>Well, I mean my initial instinct is YES (emphasis given by the
                            participant), but I am not sure what that would be yet, I think it could
                            lead to a lot of productive conversations about how language operates or
                            the way someone creatively uses language.</said>
                    </p>
                    <p>
                        <said>These are important questions. Literature departments have always
                            performed as if they were in the shadows of the sciences and…[i]t seems
                            to me that this kind of work, although seemingly scientific, should be
                            the domain of literature department. It would be very important work for
                            us to do.</said>
                    </p>
                    <p>Interestingly the 1 person out of 14 who said no to being inspired (included
                        below) touched directly on the fact that the simplicity of our
                        representation of orthography was limiting but suggested in his negative
                        response that it could be interesting for literary criticism if we could
                        find a way to include meaning, which is fruitful ground for future work and
                        possible with the three criteria we laid out above for the development of
                        the technique:</p>
                    <p>
                        <said>I’m not sure it’s useful for literary theory or criticism because it
                            seems to explicitly set aside the question of meaning in favor of
                            orthography</said>
                    </p>
                    <p>
                        <said>Oh yea, um this is only for spellings well things get really
                            interesting when you get into phrases, rhetorical aspects of language
                            organization, the whole question of nuance which we like to think we are
                            studying as literary scholars. Once you get into these things and away
                            from mere spelling and into points that have meanings you can start to
                            clump together interpretation to different meanings.</said>
                    </p>
                </div>
                <div>
                    <head>8.4 Criticisms from Participants</head>
                    <p>Our participants were in some cases critical of the design of L-DNA. In
                        particular, the most common criticism centered on making the technique
                        interactive, which is a clear (and previously planned) next step in our
                        iterative design process. Another criticism was that the encoding we used
                        was arbitrary, and its meaning was not immediately clear:</p>
                    <p>
                        <said>The mechanism by which you map words to spatial locations, it’s kind
                            of arbitrary (maybe that’s not the right word). Mostly you see the first
                            two letters, and when you zoom in you’re seeing the space of subsequent
                            letters. I guess what this mapping is lacking is the Meaning of words,
                            or the semantics. They end up being distances from one another but … the
                            distance between related concepts, synonyms. I’m not necessarily saying
                            this is a bad visualization because of that. It just doesn’t encode the
                            meaning of words. Which is much harder. But, this is a legitimate way of
                            putting words in a consistent space.</said>
                    </p>
                    <p>
                        <said>The way that it is right now, that it’s static, it’s getting in the
                            way of itself. It demands explanation. It needs to be paired up with
                            something very practical, like reading a word or reading a sentence and
                            how that gets paired up in the system.</said>
                    </p>
                    <p>We see this interactivity as the next steps in developing an application for
                        these types of interactions and it is in that interactivity that the
                        objections to the arbitrariness of the design will be addressed. We
                        hypothesize that being able to investigate the space dynamically, and by
                        defining other symbol systems to encode, the literary critic will be able to
                        explore the types of meaning and associations being looked for by our
                        participants.</p>
                </div>
            </div>
            <div>
                <head>9 STUDY RESPONSE</head>
                <p>From our qualitative study, the overwhelming result was the importance of the
                    white space in our visualizations to the entire group that was interviewed. This
                    reaction has influenced the direction of our future work and demonstrates that
                    this space can be used for the types of comparisons that we are interested in,
                    namely those that lead to interpretive possibilities. We recognize that we have
                    presented a simplified form, but the technique itself allows for infinite
                    complexity. Some of our participants talked about the need to include
                    information that gives meaning to relationships and that is the next step in
                    developing mappings that can solve the original problem of creating a space that
                    can be experimented in with language and literary theory. Our study confirmed
                    the idea that this technique has the potential to answer these much more complex
                    questions as they relate to the domain in question. The sheer breadth of answers
                    to our question in relation to inspiring new ideas is extremely promising and we
                    take it as a success in developing the type of space that can inspire
                    investigation.</p>
                <div>
                    <head>9.1 Prioritizing Whitespace</head>
                    <p>In response to the discussion with participants about the interest in
                        whitespace and the lack of density in certain regions, we produced a density
                        and inverted density map to highlight the white spaces, shown in Fig. 12 and
                        Fig. 13.</p>

                    <figure>
                        <head>Density map of the English language in L-DNA.</head>
                        <graphic url="resources/images/figure12.png"/>
                    </figure>


                    <figure>
                        <head>Inverted density map of the English language in L-DNA.</head>
                        <graphic url="resources/images/figure13.png"/>
                    </figure>


                    <p>This was in direct response to comments from our participants such as:</p>
                    <p>
                        <said>Yeah. But, one thing I was going to say… the UNIFORM inclusion of the
                            whitespace is interesting. But I wonder if there’s a better
                            representation of density and overlap.</said>
                    </p>
                    <p>In this iteration of our design, instead of rendering each word in the
                        language we instead cluster groups of words into the boxes representing
                        pairs of words (<q>AA</q>, <q>AB</q>, etc.), and render the box using
                        transparency that corresponds to the density of words therein. The inverted
                        version of this mapping highlights all of the non-English words, which were
                        clearly of interest to participants.</p>
                </div>
                <div>
                    <head>9.2 ygUDuh</head>
                    <p>We have discussed how the blank spaces are compelling and how the absence of
                        words in these spaces generally seems to intrigue people.</p>
                    <p>It is interesting to note that this space is and has been filled in many
                        interesting ways. For example, E. E. Cummings poem ygUDuh does not contain a
                        single English word, yet it can be read as English, where the <q>words</q>
                        take on the sonic characteristics of English when read aloud. For example,
                        the first few lines of the poem are:</p>
<eg>ygUDuh                   
    
      ydoan
      yunnuhstan</eg>
                    <p>That when read allowed becomes a phonetic map for a type of early 20<hi rend="superscript">th</hi> century urban slang exemplified by the
                        poem:</p>
<eg>you gotta
                        
      you don’t
      you understand</eg>
                    

                    <p>In Fig. 14 we have plotted ygUDuh overlaid on the OED grid. Note how these
                            <q>non words</q> exist largely on the edge of the word spaces and the
                        white spaces. This may be because, while they are not English words — hence
                        the white space proximity — they have similar vowel and consonant structures
                        to English words. By seeing these words overlaid on the whole language, we
                        can see a visual representation of Cummins’ craft, of the attempt to make
                        non English words that sound like English when read aloud. The fact that all
                        of the non-words are situated on the edges of heavily populated space tells
                        us that these arrangements of letters that we try to make into words when
                        reading the poem are <q>closer</q> to English words than we think, at least
                        in terms of spelling.</p>

                    <figure>
                        <head>ygUDuh overlaid on the OED grid.</head>
                        <graphic url="resources/images/figure14.png"/>
                    </figure>


                </div>
                <div>
                    <head>9.3 Instant Messaging</head>
                    <p>Another example where new types of <q>words</q> or at least English
                        communications are evolving is in instant messaging, text messaging, and
                        social media. It seems that for ease and speed, we can give up many letters
                        — chiefly the vowels — in words and still retain meaning. Fig. 15 shows MSN
                            <q>words</q> overlaid on the OED visualization. It is interesting to
                        note that many of the new <q>words</q> (marked with red dots), fall in the
                        spaces where very little or no words exist. This demonstrates that even in a
                        type of shorthand, like the one used in instant messaging (e.g., <q>btw</q>,
                            <q>lol</q>, <q>ttyl</q>, etc.) that many of the newly created words are
                        spelled with letter combinations that simply don’t exist in the language.
                        This is partially a result of the volume of acronyms used in instant
                        messaging but it becomes obvious by <q>reading</q> the image that many of
                        the words used fall on the top line of each row suggesting (such as with row
                        A, and row I) that many of these <q>words</q> and acronyms begin with those
                        letters. In this way our technique produces visuals that allow us to ask
                        further questions about the organization of our data.</p>


                    <figure>
                        <head>MSN ‘words’ overlaid on the OED visualization</head>
                        <graphic url="resources/images/figure15.png"/>
                    </figure>



                </div>
                <div>
                    <head>9.4 Interaction</head>
                    <p>We have also begun to integrate interactive elements into our visualization,
                        some of which were planned prior to our qualitative study, and some of which
                        were inspired by our results. In particular, we have already created a
                        version of L-DNA which incorporates a brushing technique that presents the
                            <q>words beneath the cursor</q>, both when dragging across words and
                        when dragging across the whitespace. We have also created a version of the
                        density map (Section 9.1) that allows zooming into the recursive letter
                        pairs. For example, it is possible to click or tap on the <q>BA</q> square,
                        then the <q>NA</q> square, then another <q>NA</q> square to then see the
                        word <q>BANANA</q> as shown in the static image of figure 3.</p>
                </div>
            </div>
            <div>
                <head>10 CONCLUSION</head>
                <p>In this paper we have introduced L-DNA and presented the findings of a
                    qualitative study of its design. In L-DNA, we have developed a mapping of symbol
                    systems to visual space, which we have demonstrated using language. Our
                    formulation has several properties that are valuable for the analysis of
                    language and are not available in some other common visualizations of language.
                    L-DNA has the following important features:</p>
                <list type="ordered">
                    <item>The L-DNA space is capable of handling any symbol string from a null
                        string to a string of infinite length. L-DNA can be used in 1, 2, or n
                        dimensions.</item>
                    <item>L-DNA space is infinite in that between any two points (words) in the
                        space there exists another word — though it may not have semantic
                        meaning.</item>
                    <item>The L-DNA space is one-to-one and onto (bijective). Every unique coding
                        maps to a unique position and, in reverse, words (or any original
                        information) can be recovered uniquely from the visual space.</item>
                </list>
                <p>We have mathematized language to make exploring and experimenting with language
                    easier, but the results of said experiments need to have the possibility of
                    being reversed out of the space to be able to assign meaning once again to the
                    language. We have also presented a qualitative study, which provided encouraging
                    results that indicate the power of the type of representation provided by L-DNA,
                    the benefit of the whitespace that it generates, and its possibilities to
                    provide inspiration (even if reluctantly), as well as some useful criticisms
                    that led to iterations in our design.</p>
            </div>

        </body>
        <back>
            <listBibl>

                <bibl label="Alexander 2012" xml:id="alexander2012"> Alexander M., “Patchworks and
                    field-boundaries: visualizing the history of English”, Digital Humanities
                    (2012), Hamburg Germany.</bibl>
                <bibl label="Bingenheimer 2006" xml:id="bingenheimer2006"> Bingerheimer M., Xishihu,
                    J. “Social network visualization from tei data”, Lit Linguist Computing 26 (3):
                    271-278 (2006).</bibl>
                <bibl label="Bingenheimer 2009" xml:id="bingenheimer2009"> Bingenheimer, M., Hung,
                    J., and Wiles, S. “Markup meets GIS – Visualizing the ‘Biographies of Eminent
                    Buddhist Monks’”, In Banissi, E. et al. (eds), Proceedings of Information
                    Visualization IV Piscataway/NJ: IEEE Computer Society, pp. 550–4 (2009).</bibl>
                <bibl label="Chen 2006" xml:id="chen2006"> Chen, C. “CiteSpace II: Detecting and
                    visualizing emerging trends and transient patterns in scientific literature”,
                    JIS&amp;T 57, 359–377 (2006).</bibl>
                <bibl label="Chuang 2012" xml:id="chuang2012"> Chuang J., Ramage D., Manning C.,
                    Heer, J. “Interpretation and Trust: Designing Model-Driven Visualizations for
                    Text Analysis” ACM Human Factors in Computing Systems (CHI), 2012.</bibl>
                <bibl label="Clement 2008" xml:id="clement2008"> Clement, T. E. “A thing not
                    beginning and not ending: using digital tools to distant-read Gertrude Stein’s
                    The Making of Americans.”, Literary and Linguistic Computing, 23(3): 361–81
                    (2008).</bibl>
                <bibl label="Collins 2009a" xml:id="collins2009a">Collins, C., Carpendale, S. and
                    Penn, G. "Docuburst: Visualizing document content using language structure."
                    Computer Graphics Forum. Vol. 28. No. 3. Blackwell Publishing Ltd (2009).</bibl>
                <bibl label="Collins 2009b" xml:id="collins2009b">Collins, C. Viegas, F. Wattenberg,
                    M.. "Parallel tag clouds to explore and analyze faceted text corpora." Visual
                    Analytics Science and Technology, 2009. VAST 2009. IEEE Symposium on. IEEE
                    (2009).</bibl>
                <bibl label="Frye 2000" xml:id="frye2000"> Frye, N., The Anatomy of Criticism,
                    Princeton University Press (2000): 7.</bibl>
                <bibl label="Gardiner 2010" xml:id="gardiner2010"> Gardner, M. J., Lutes, J., Lund,
                    J., Hansen, J., Walker, D., Ringger, E., and Seppi, K. “The Topic Browser: An
                    interactive tool for browsing topic models”. In NIPS (Workshop on Challenges of
                    Data Vis), (2010).</bibl>
                <bibl label="Gould 2003" xml:id="gould2003"> Gould, R. V. “Uses of network tools in
                    comparative historical research”, in Mahoney, J. and Rueschemeyer, D. (eds),
                    Comparative Historical Analysis in the Social Sciences. Cambridge: Cambridge
                    University Press, pp. 241–69 (2003).</bibl>
                <bibl label="Gretarsson 2011" xml:id="gretarsson2011"> Gretarsson, B., O’Donovan,
                    J., Bostandjiev, S., Llerer, T. H., Asuncion, A., Newman, D., and Smyth, P.
                    “TopicNets: Visual analysis of large text corpora with topic modeling”, Trans on
                    Intelligent System and Technology 3, 2 (2011).</bibl>
                <bibl label="Hall 2008" xml:id="hall2008"> Hall, D., Jurafsky, D., and Manning, C.
                    D. “Studying the history of ideas using topic models”. In EMNLP, 363–371
                    (2008).</bibl>
                <bibl label="Jessop 2006" xml:id="jessop2006"> Jessop, M. “Dynamic Maps in
                    Humanities Computing”. Human IT, 8.3, 68–82 (2006).</bibl>
                <bibl label="Jessop 2008" xml:id="jessop2008"> Jessop, M. “The Inhibition of
                    Geographical Information in Digital Humanities Scholarship”, Literary and
                    Linguistic Computing, 23(1): 39– 50, (2008).</bibl>
                <bibl label="Lin 1992" xml:id="lin1992"> Lin, X. “Visualization for the document
                    space”. In Vis, 274–281 (1992).</bibl>
                <bibl label="Moretti 2005" xml:id="moretti2005"> Moretti, F, Graphs, Maps, Trees:
                    Abstract Models for a Literary Theory. London: Verso, 2005.</bibl>
                <bibl label="Paley 2002" xml:id="paley2002"> Paley, W. Bradford. "TextArc: Showing
                    word frequency and distribution in text." Poster presented at IEEE Symposium on
                    Information Visualization. (2002). </bibl>
                <bibl label="Smalheiser 2009" xml:id="smalheiser2009"> Smalheiser, N. R., Torvik, V.
                    I., and Zhou, W. “Arrowsmith two-node search interface: a tutorial on finding
                    meaningful links between two disparate sets of articles in MEDLINE” Computer
                    M&amp;P in Biomedicine 94, 2, 190–197 (2009).</bibl>
                <bibl label="van Ham 2009" xml:id="vanham2009"> van Ham, F., Wattenberg, M., and
                    Viegas, F. B. “Mapping text with phrase nets”, in InfoVis, 1169–1176
                    (2009).</bibl>
                <bibl label="Viegas 2008" xml:id="viegas2008"> Viegas, F. B., and Wattenberg, M.
                    “TIMELINES: Tag clouds and the case for vernacular visualization. Interactions”
                    15, 49–52 (2008).</bibl>
                <bibl label="Wattenberg 2008" xml:id="wattenberg2008"> Wattenberg, Martin, and
                    Fernanda B. Viégas. "The word tree, an interactive visual concordance."
                    Visualization and Computer Graphics, IEEE Transactions on 14.6: 1221-1228
                    (2008).</bibl>
                <bibl label="Wise 1995" xml:id="wise1995"> Wise, J., Thomas, J., Pennock, K.,
                    Lantrip, D., Pottier, M., Schur, A., and Crow, V. “Visualizing the non visual:
                    spatial analysis and interaction with information from text documents”, in
                    InfoVis, 51–58,(1995).</bibl>
                <bibl label="Wood 1992" xml:id="wood1992"> Wood, D., The Power of Maps. New York:
                    Guilford Press (1992).</bibl>
                <bibl label="Yatani 2011" xml:id="yatani2011"> Yatani, K., Novati, M., Trusty, A.,
                    &amp; Truong, K. N. “Review spotlight: a user interface for summarizing
                    user-generated reviews using adjective- noun word pairs”. In Proceedings of the
                    2011 annual conference on Human factors in computing systems (pp. 1541-1550).
                    ACM (2011).</bibl>
                <bibl label="Valley 2015" xml:id="valley2015"> Valley of the Shadow
                    http://valley.vcdh.virginia.edu/ (Accessed April 19 2015)</bibl>
                <bibl label="Tapor 2015" xml:id="tapor2015"> portal.tapor.ca (Accessed April 19
                    2015)</bibl>
                <bibl label="TextRain 2015" xml:id="textrain2015">
                    http://camilleutterback.com/projects/text-rain/(Accessed April 19 2015)</bibl>
                <bibl label="WordCollider 2015" xml:id="wordcollider2015">
                    http://www.itsokaytobesmart.com/post/26993944713/word-colliderparticiple-
                    physics (Accessed April 19 2015)</bibl>
                <bibl label="Voyant 2015" xml:id="voyant2015"> http://voyant-tools.org/ (Accessed
                    April 19 2015)</bibl>
                <bibl label="Posavec 2015" xml:id="posavec2015">
                    http://www.stefanieposavec.co.uk/-everything-in-between/#/writing-without-words/
                    (Accessed April 19 2015)</bibl>
                <bibl label="Dict 2015" xml:id="dict2015">http://www.winedt.org/Dict/ (Accessed
                    April 19 2015)</bibl>

                <bibl label="Simon 1988" xml:id="simon1988">Simon, Herbert A. <title rend="quotes">The science of design: creating the artificial.</title>
                    <title rend="italic">Design Issues</title>: 67-82,(1988).</bibl>

                <bibl label="DeCamp 2005" xml:id="decamp2005">DeCamp, P., Frid-Jimenez, A., Guiness,
                    J., &amp; Roy, D. <title rend="quotes">Gist icons: Seeing meaning in large
                        bodies of literature</title>, In <title rend="italic">Proc. of IEEE Symp. on
                        Information Visualization</title> (InfoVis 2005), Poster Session,
                    Minneapolis, USA, October, (2005).</bibl>


                <bibl label="Hetzler 1998" xml:id="hetzler1998">Hetzler, Beth, et al. <title rend="quotes">Multi-faceted insight through interoperable visual information
                        analysis paradigms.</title>
                    <title rend="italic">Information Visualization</title>, 1998. Proceedings. IEEE
                    Symposium on. IEEE, (1998).</bibl>

                <bibl label="Hearst 1995" xml:id="hearst1995">Hearst, Marti A. <title rend="quotes">TileBars: visualization of term distribution information in full text
                        information access.</title>
                    <title rend="italic">Proceedings of the SIGCHI conference on Human factors in
                        computing systems</title>. ACM Press/Addison-Wesley Publishing Co.,
                    (1995).</bibl>

                <bibl label="Lee 2010" xml:id="lee2010">Lee, Bongshin, et al. <title rend="quotes">Sparkclouds: Visualizing trends in tag clouds</title>. <title rend="italic">Visualization and Computer Graphics, IEEE Transactions on 16.6</title>:
                    1182-1189, (2010).</bibl>

                <bibl label="Viegas 2009" xml:id="viegas2009">Viegas, Fernanda B., Martin
                    Wattenberg, and Jonathan Feinberg. <title rend="quotes">Participatory
                        visualization with wordle</title>. <title rend="italic">Visualization and
                        Computer Graphics, IEEE Transactions on 15.6</title>: 1137-1144,
                    (2009).</bibl>

                <bibl label="Rohrdantz 2012" xml:id="rohrdantz2012">Rohrdantz, C., Niekler, A.,
                    Hautil, A., Butt, M., Keim, D. <title rend="quotes">Lexical semantics and
                        distribution of suffixes: a visual analysis</title>. <title rend="italic">EACL 2012 Proceedings of the EACL 2012 Joint Workshop of LINGVIS &amp;
                        UNCLH</title>, pages 7-15. (2012).</bibl>




            </listBibl>

        </back>
    </text>
</TEI>