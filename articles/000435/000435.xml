<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <!-- Author should supply the title and personal information-->
                <title type="article" xml:lang="en">Creating a User Manual for Healthy Crowd
                    Engagement: A Review of Mark Hedges and Stuart Dunn's <title rend="italic"
                        >Academic Crowdsourcing in the Humanities: Crowds, Communities and
                        Co-production</title></title>
                <!-- Add a <title> with appropriate @xml:lang for articles in languages other than English -->
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Samantha <dhq:family>Blickhan</dhq:family></dhq:author_name>
                    <dhq:affiliation>Zooniverse &amp; Adler Planetarium</dhq:affiliation>
                    <email>samantha@zooniverse.org</email>
                    <dhq:bio>
                        <p>Samantha Blickhan is the IMLS Postdoctoral Fellow at the Adler Planetarium, and Humanities Lead for Zooniverse.</p>
                    </dhq:bio>
                </dhq:authorInfo>
            </titleStmt>
            <publicationStmt>
                <publisher>Alliance of Digital Humanities Organizations</publisher>
                <publisher>Association for Computers and the Humanities</publisher>
                <!-- This information will be completed at publication -->
                <idno type="DHQarticle-id">000435</idno>
                <idno type="volume">013</idno>
                <idno type="issue">4</idno>
                <date when="2019-12-14">14 December 2019</date>
                <dhq:articleType>review</dhq:articleType>
                <availability status="CC-BY-ND">
                    <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
                </availability>
            </publicationStmt>

            <sourceDesc>
                <p>This is the source</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <classDecl>
                <taxonomy xml:id="dhq_keywords">
                    <bibl>DHQ classification scheme; full list available at <ref
                            target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
                            >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
                </taxonomy>
                <taxonomy xml:id="authorial_keywords">
                    <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
                </taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en" extent="original"/>
                <!-- add <language> with appropriate @ident for any additional languages -->
            </langUsage>
            <textClass>
                <keywords scheme="#dhq_keywords">
                    <!-- Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors -->
                    <list type="simple">
                        <item/>
                    </list>
                </keywords>
                <keywords scheme="#authorial_keywords">
                    <!-- Authors may include one or more keywords of their choice -->
                    <list type="simple">
                        <item/>
                    </list>
                </keywords>
            </textClass>
        </profileDesc>
        <revisionDesc>
            <!-- Each change should include @who and @when as well as a brief note on what was done. -->
            <change when="2019-10-13" who="murelj">Created file and encoded article</change>
        </revisionDesc>
    </teiHeader>
    <!-- If a translation is added to the original article, add an enclosing <text> and <group> element -->
    <text xml:lang="en" type="original">
        <front>
            <dhq:abstract>
                <p>This piece examines <title rend="italic">Academic Crowdsourcing in the
                        Humanities: Crowds, Communities and Co-production</title>, by Mark Hedges
                    and Stuart Dunn, and considers the role it plays within existing literature
                    about crowdsourcing and digital humanities.</p>
            </dhq:abstract>
            <dhq:teaser>
                <p>Review of <title rend="italic">Academic Crowdsourcing in the Humanities: Crowds,
                        Communities and Co-production</title>, by Mark Hedges and Stuart Dunn.</p>
            </dhq:teaser>
        </front>
        <body>
            <p>In an academic context, <q>crowdsourcing</q> refers to the act of presenting data to
                    members of the public, and inviting them to perform a task, or series of tasks,
                    upon those data. It is a broad definition, but crowdsourcing is a broad
                    methodological concept that can be applied in a number of ways, from academia to
                    business practice. As their title suggests, Mark Hedges and Stuart Dunn narrow
                    the scope considerably with <title rend="italic">Academic Crowdsourcing in the Humanities:
                Crowds, Communities and Co-production</title>, aiming to offer practical guidance,
                    theoretical frameworks, and real-life examples from crowdsourced humanities
                    research projects. Even within this limited scope, there is a wide range of
                    possibility for crowdsourcing when used as a method of academic research, and
                    the authors structure their text accordingly.</p>
            <p>Such breadth of methodological usage is not new territory for authors writing about
                digital projects in the humanities (and it should be said that the focus within this
                text is overwhelmingly on digital methods, though the authors acknowledge
                crowdsourcing’s pre-digital roots), which can be difficult to fit within a single
                framework, particularly due to frequent advances in the technologies that support
                digital projects. The potential audience for this methodological text can include
                everyone from participants in digital humanities projects to practitioners — including
                (but not limited to) researchers, archivists, academics, librarians, institutional
                staff, and students.</p>
            <p>The authors address this breadth of scope in content as well as audience by using
                existing literature from other participatory research fields (most notably the
                adjacent field of <q>citizen science</q>) as a starting point on which to build their
                framework. They note that, under the umbrella of <q>citizen science</q>, projects can
                either focus on data processing (<q>delegative</q> tasks) or on bringing in external
                participants to the process of research (<q>democratizing</q> tasks) <ptr target="#hedges2017" loc="4"/>.
                Using the framework of citizen science allows the authors to present the
                parallel outcomes from humanities-focused projects. These include a distinction
                between <q>academic knowledge</q> and the knowledge production typically associated with
                academic crowdsourcing, as well as frequent outcomes for humanities crowdsourcing,
                such as content transformation and information synthesis. However, this discussion
                also allows the authors to identify where the framework of citizen science does not
                meet the needs of the humanities community, thereby requiring a separate system
                within which this work can take place <ptr target="#hedges2017" loc="8"/>.</p>
            <p>Creating a framework for any digital research method presents a unique challenge. The
                speed with which tools are released, adapted, and discontinued — in conjunction with
                the relatively slow development and practice of the academic research process,
                particularly in regard to traditional methods of publication — means that any sort of
                so-called <q>standard practice</q> can be very difficult to sustain, and research making
                use of digital technologies often becomes commonplace within academic fields before
                any type of structure can be proposed, peer-reviewed, and refined.</p>
            <p>A lack of standardization in the early stages of implementing new academic research
                practice does not necessarily guarantee a negative outcome for the work conducted
                within these nascent technological environments. Such instances of trial and error
                can allow new practices to emerge, free from traditional boundaries, but it often
                means that meta-textual studies must simultaneously function as both historiography
                and theory for these fields: critiquing, reviewing and suggesting best practices for
                their continued use. Hedges and Dunn have set out to provide just such a structure
                with <title rend="italic">Academic Crowdsourcing in the Humanities</title>, a work that
                began as a <quote rend="inline" source="#hedges2017">typology of arts and humanities crowdsourcing methods</quote> <ptr target="#hedges2017" loc="xii"/>,
                but which ultimately functions as a sort of how-to guide for those who
                wish to create, evaluate, or otherwise engage with academic crowdsourcing in the
                humanities. Throughout the book, the authors incorporate interviews with experts,
                practitioners and participants in crowdsourcing projects, gathered from Hedges’ and
                Dunn’s 2012 <title rend="italic">Crowdsourcing Scoping Study</title> and a PARTHENOS
                project-supported <title rend="italic">Foresight Study</title>, which bring an
                    appropriately co-created element to the text.</p>
            <p>Though researchers in the humanities have acknowledged crowdsourcing as a method
                since the early 2010s, the majority of publications on the subject have been
                overviews of how crowdsourcing has been used within specific humanistic disciplines
                or sub-disciplines (examples include <ptr target="#ferriter2016"/> <ptr target="#ridge2014"/>), explorations of
                the effect of public engagement methods in the digital humanities <ptr target="#terras2016"/>, or
                research studies resulting from individual crowdsourcing projects (see for example
                any of the articles produced by the <title rend="italic">Transcribe Bentham</title> team,
                including <ptr target="#causer2012"/> and <ptr target="#causer2014"/>). These early
                publications are thoroughly referenced in <title rend="italic">Academic Crowdsourcing
                    in the Humanities</title>, and their existence essential to the creation of
                    this text, but Hedges’ and Dunn’s work is filling a much-needed gap in the
                    literature by providing a general framework that will be useful for students,
                    research professionals, and members of the public alike.</p>
            <p>The first three chapters of the book are devoted to an overview of crowdsourcing
                    as a method, including an examination of the historical and technological
                    developments that set the stage for a rise in modern academic crowdsourcing
                    (including the World Wide Web, Web 2.0, and business-oriented crowd models); the
                    scientific origins of crowdsourcing as a method, and how they have influenced
                    subsequent humanities-based work; and — perhaps most importantly — the presentation
                    of a typology of crowdsourcing, modeled after Short and McCarty’s
                    <term>methodological commons</term> for digital research methods in the early 2000s <ptr target="#hedges2017" loc="2"/>.
                A number of projects are used as examples to illustrate many
                    of the practices discussed in the early chapters, and actual case studies do not
                    appear until Chapter 4, where they are used mainly to further illustrate
                    examples of the typology presented in Chapter 3. This structure allows Hedges
                    and Dunn to present a useful overview of how academic crowdsourcing projects
                    work, without veering into a prescriptive approach.</p>
            <p>Once the authors have presented the history and methods, and offered a shared
                vocabulary for the actions being taken within digital crowdsourcing projects, they
                turn their attention to the social elements of crowdsourcing, both for individuals
                and communities alike. Topics include roles within projects (Chapter 5), motivations
                for and benefits of participation (Chapter 6), ethical issues like exploitation of
                volunteer labor and questions of data ownership (Chapter 7), and the role
                crowdsourcing can play in the creation of knowledge and memory in regard to cultural
                heritage (Chapter 7). The chapter on ethics is particularly welcome. When digital
                methodologies involve members of the public in academic work, as is the case with
                crowdsourcing, it becomes essential to create a system within which projects can be
                evaluated, as such systems are needed not only for the benefit of the academic
                research output, but to ensure the fair and ethical treatment of the communities
                participating. There has been a fair amount of work published on the ethics of paid
                crowdsourcing, in academia and other platforms like Amazon’s Mechanical Turk (see
                for example <ptr target="#williamson2016"/>), but this is not the case regarding publications on
                unpaid academic crowdsourcing. </p>
            <p>The discussion of labor and exploitation within the chapter on ethical issues
                    presents commonly-asked questions about the ethical grey area that exists around
                    volunteer participation in academic research <ptr target="#hedges2017" loc="108–113"/>. In
                    this section, the interview excerpts are useful for illustrating some of the
                    questions which do not have a definitive answer, especially those which relate
                    to the various justifications presented for why academic crowdsourcing should
                    not be considered unethical. Hedges and Dunn do not shy away from these often
                    difficult topics, and the way they present this information gives a unique
                    insight into the care with which project creators must go about the work of
                    designing, developing and running projects: <cit><quote rend="inline" source="#hedges2017">While participants do not in
                    general regard themselves as exploited, their willingness to volunteer and their
                    professed enjoyment in participating does not in itself imply that humanities
                    crowdsourcing is in ethical terms positive, or even neutral </quote><ptr target="#hedges2017" loc="113"/></cit>.
            </p>
            <p>For all cases involving ethics and crowdsourcing, the authors note that transparency
                and regular communication are requisite elements for projects involving the public,
                as well as acknowledgment of participants and open access to project outcomes in the
                form of data. The suggestion of access to outcomes in the form of data is critical,
                but the authors miss the opportunity to discuss a delicate but important issue: that
                of open access to resulting publications which make use of project data. The authors
                come close to this topic in an earlier discussion of motivations and benefits,
                stating <quote rend="inline" source="#hedges2017">Most humanities crowdsourcing projects, however, do not reward their
                contributors in material or professional ways</quote>, having listed publication as a
                material outcome for researchers in the previous sentence <ptr target="#hedges2017" loc="91"/>,
                but fall short of calling for open access publication as a requirement for
                crowdsourcing project practitioners. In many ways this is part of a larger
                conversation about access to publication within academia and is certainly not
                exclusive to the field of crowdsourcing, but it is particularly relevant to a field
                which invites — and relies upon — public participation. Is it ethical to ask
                participants to volunteer their time for research, and then put a paywall between
                those same people and their access to the resulting publications?</p>
            <p>In the final chapter, <title rend="quotes">Crowds past, present and future</title>, the authors reiterate the
                main arguments from the first eight chapters, and present some suggestions that will
                benefit practitioners of and participants in digital crowdsourcing in the future.
                These include human-computer optimization methods, data literacy initiatives for the
                public, and adoption of open data frameworks (another place where a slight push into
                adjacent issues of open access publication would have been welcome). Hedges and Dunn
                note that many projects and wider initiatives already exist which make use of and
                promote these approaches, but they would certainly benefit from wider adoption.</p>
            <p>In their conclusion, the authors note that <title rend="italic">Academic Crowdsourcing
                    in the Humanities</title> will not be a step-by-step guide for crowdsourcing
                practitioners, but is instead meant to provide a theoretical framework to ensure
                that there is a healthy balance between the quality of project outcomes, and the
                experience of participants. It is indeed a welcome addition to the growing corpus of
                publications related to academic crowdsourcing, and when used in conjunction with
                the existing literature will be a wonderful tool for participants and practitioners
                alike.</p>
        </body>
        <back>
            <listBibl>
                <bibl xml:id="causer2012" label="Causer and Wallace 2012">Causer, T. and Wallace, V. <title rend="quotes">Building a volunteer community: results and findings from
                    <title rend="italic">Transcribe Bentham</title></title>,
                    <title rend="italic">Digital Humanities Quarterly</title>, 6.2 (2012). Available at:
                    <ref target="http://www.digitalhumanities.org/dhq/vol/6/2/000125/000125.html">http://www.digitalhumanities.org/dhq/vol/6/2/000125/000125.html</ref>.
                </bibl>
                <bibl xml:id="causer2014" label="Causer and Terras 2014">Causer, T. and Terras, M. <title rend="quotes">Crowdsourcing Bentham:
                    Beyond the Traditional Boundaries of Academic History</title>,
                    <title rend="italic">International Journal of Humanities and
                        Arts
                        Computing</title> 8.1 (2014): 46-64. DOI: <ref target="https://doi.org/10.3366/ijhac.2014.0119">https://doi.org/10.3366/ijhac.2014.0119</ref>.
                </bibl>
                <bibl xml:id="hedges2012" label="Hedges and Dunn 2012">Hedges, M. &amp; Dunn, S. <title
                        rend="italic">Crowd-Sourcing Scoping Study: Engaging
                        the Crowd with Humanities Research</title>. Arts and
                        Humanities Research Council (2012).</bibl>
                <bibl xml:id="hedges2017" label="Hedges and Dunn 2017">Hedges, M. and Dunn, S., <title
                        rend="italic">Academic Crowdsourcing in the
                        Humanities: Crowds, Communities and Co-production</title>. Elsevier, Inc. (2017).</bibl>
                <bibl xml:id="ferriter2016" label="Ferriter 2016">Ferriter, M. <title rend="quotes">Inviting Engagement, Supporting Success: How to Manage a Transcription Center</title>,
                    <title rend="italic">Collections: A Journal for Museum and
                        Archives Professionals</title>, 12.2 (2016): 97-116.
                    DOI: <ref target="https://doi.org/10.1177%2F155019061601200204">https://doi.org/10.1177%2F155019061601200204</ref>.
                </bibl>
                <bibl xml:id="ridge2014" label="Ridge 2014">Ridge, M. (ed),
                    <title rend="italic">Crowdsourcing Our Cultural
                        Heritage</title>. Ashgate, Surrey (2014).</bibl>
                <bibl xml:id="terras2016" label="Terras 2016">Terras, M. <title rend="quotes">Crowdsourcing in the Digital Humanities</title>.
                    In S. Schreibman, R. Siemens, and J. Unsworth (eds), <title rend="italic">A New Companion to Digital
                        Humanities</title>, Wiley-Blackwell (2016), pp.
                    420-439. DOI: <ref target="https://doi.org/10.1002/9781118680605.ch29">https://doi.org/10.1002/9781118680605.ch29</ref>.
                </bibl>
                <bibl xml:id="williamson2016" label="Williamson 2016">Williamson, V. <title rend="quotes">Can crowdsourcing be ethical?</title>, <title
                        rend="italic">TechTank</title> blog (Feb. 3, 2016),
                    <ref target="https://www.brookings.edu/blog/techtank/2016/02/03/can-crowdsourcing-be-ethical-2/"
                            >https://www.brookings.edu/blog/techtank/2016/02/03/can-crowdsourcing-be-ethical-2/</ref>.
                </bibl>
            </listBibl>
        </back>
    </text>
</TEI>
