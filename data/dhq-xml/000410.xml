<?xml version="1.0" encoding="UTF-8"?><?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?><?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <!-- Author should supply the title and personal information-->
                <title type="article" xml:lang="en">Curating Crowds: A Review of <title
                        rend="italic">Crowdsourcing Our Cultural Heritage</title> (Ashgate,
                    2014)<!-- article title in English --></title>
                <!-- Add a <title> with appropriate @xml:lang for articles in languages other than English -->
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Victoria <dhq:family>Van Hyning</dhq:family></dhq:author_name>
                    <dhq:affiliation>Library of Congress</dhq:affiliation>
                    <email>victoria@zooniverse.org</email>
                    <dhq:bio>
                        <p>Victoria Van Hyning is currently Senior Innovation Specialist at the
                            Library of Congress. She was previously a Digital Humanities
                            Postdoctoral Fellow at Zooniverse.org at the University of Oxford.</p>
                    </dhq:bio>
                </dhq:authorInfo>
            </titleStmt>
            <publicationStmt>
                <publisher>Alliance of Digital Humanities Organizations</publisher>
                <publisher>Association of Computers and the Humanities</publisher>

                <publisher>Association for Computers and the Humanities</publisher>
                <!-- This information will be completed at publication -->
                <idno type="DHQarticle-id">000410</idno>
                <idno type="volume">013</idno>
                <idno type="issue">1</idno>
                <date when="2019-04-26">26 April 2019</date>
                <dhq:articleType>review</dhq:articleType>
                <availability>
                    <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
                </availability>
            </publicationStmt>

            <sourceDesc>
                <p>This is the source</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <classDecl>
                <taxonomy xml:id="dhq_keywords">
                    <bibl>DHQ classification scheme; full list available at <ref
                            target="#http://www.digitalhumanities.org/dhq/taxonomy.xml"
                            >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
                </taxonomy>
                <taxonomy xml:id="authorial_keywords">
                    <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
                </taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en" extent="original"/>
                <!-- add <language> with appropriate @ident for any additional languages -->
            </langUsage>
            <textClass>
                <keywords scheme="#dhq_keywords">
                    <!-- Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors -->
                    <list type="simple">
                        <item/>
                    </list>
                </keywords>
                <keywords scheme="#authorial_keywords">
                    <!-- Authors may include one or more keywords of their choice -->
                    <list type="simple">
                        <item/>
                        <item/>
                        <item/>
                        <item/>
                    </list>
                </keywords>
            </textClass>
        </profileDesc>
        <revisionDesc>
            <!-- Each change should include @who and @when as well as a brief note on what was done. -->
            <change who="BQ" when="2019-05-15">Author approved final revisions</change>
            <change who="BQ" when="2019-02-13">Created file</change>
        </revisionDesc>
    </teiHeader>
    <!-- If a translation is added to the original article, add an enclosing <text> and <group> element -->
    <text xml:lang="en" type="original">
        <front>
            <dhq:abstract>
                <!-- Include a brief abstract of the article -->
                <p>Through case studies and theoretical reflections, Mia Ridge’s edited volume
                        <title rend="italic">Crowdsourcing Our Cultural Heritage</title> makes a
                    comprehensive addition to crowdsourcing research and practice. Authors discuss
                    how issues of project roles, public and volunteer engagement, data use and user
                    choice reshape institutional presence.</p>
            </dhq:abstract>
            <dhq:teaser>
                <!-- Include a brief teaser, no more than a phrase or a single sentence -->
                <p>Review of Mia Ridge's (ed.) <title rend="italic">Crowdsourcing Our Cultural
                        Heritage.</title></p>
            </dhq:teaser>
        </front>
        <body>
            
            <p><title rend="italic">Crowdsourcing Our Cultural Heritage</title> is an important
                collection for anyone working in cultural heritage or academia who is interested in
                the pros and cons of implementing crowdsourcing projects, whether for manuscript
                transcription, image or video tagging or crowd-curated exhibitions. Most essays in
                the collection, starting with the introduction by editor Mia Ridge, offer a
                definition of crowdsourcing, engage with some of the theoretical material pertaining
                to the topic such as James Suroweicki’s <title rend="italic">The Wisdom of
                    Crowds</title>
                <ptr target="#surowiecki2004"/>, and give an overview of the challenges that
                crowdsourcing can help GLAMs and academics overcome. Ridge is one of the most cogent
                advocates for, and careful critics of, crowdsourcing in cultural heritage
                industries, and she gets the volume off to a thought-provoking start with sections
                on <q>Key Trends and Issues</q> and <q>Looking to the Future of Crowdsourcing in
                    Cultural Heritage</q>. While the essays themselves are somewhat repetitive in
                terms of definitions and theoretical ground, almost any one of them could be read on
                its own and provide insight into the broad issues surrounding crowdsourcing. This
                volume would be valuable as a teaching resource for a range of specialists,
                including GLAM practitioners such as archivists and curators, as well as educators,
                audiovisual specialists, art historians, web designers and developers, and
                sociological and history of science theorists interested in crowdsourcing. Most
                articles include robust bibliographies with references to grey and formal
                publications. Although this is a fast-moving area of research and practice, the
                volume is still remarkably up-to-date over four years on from its publication in
                2014.</p>
            <p>Part I contains eight case studies: seven from UK and USA-based GLAMs, and one case
                study of a video tagging project from the Netherlands. The titles of many of the
                former refer to text transcription or metadata extraction projects, in which
                volunteers are invited to transcribe or add tags to digital images of texts held in
                the online catalogues of diverse repositories. And while each case study delivers
                useful insights into the transcription and tagging projects mentioned in their
                titles, each at least touches on a wider range of public engagement and
                crowdsourcing activities undertaken by the authors’ respective GLAMs and/or
                universities or broadcasters. Some of these are in-person events such as
                    <q>roadshows</q>, while the use of surveys by numerous authors helps to surface
                users’ or patrons’ voices. There is a good balance between quantitative and
                qualitative assessment of projects’ successes and failures as well as the reach and
                impact of digital initiatives. Most articles are illustrated with images of the
                web-based tools under discussion, and many include figures and tables communicating
                user participation and engagement.</p>
            <p>Shelley Bernstein’s opening essay <q>Crowdsourcing in Brooklyn</q>, offers insights
                into the Brooklyn Museum’s strategies of digital and in-person engagement over the
                better part of a decade, including the process of curating and displaying an
                exhibition with input from members of the public—<title rend="italic">Click! A
                    Crowd-Curated Exhibition</title> (<ref
                    target="#https://www.brooklynmuseum.org/exhibitions/click"
                    >https://www.brooklynmuseum.org/exhibitions/click</ref>). One of the strengths
                of Bernstein’s piece is her acknowledgement of the design influences and goals of
                Flickr whose founder, Caterina Flake, said <q>You should be able to feel the
                    presence of other people on the Internet</q>, a principle Bernstein and her team
                translated for the GLAM setting: <cit>
                    <quote rend="inline">How could we highlight the visitor’s voice in a meaningful
                        way and utilise technology and the web to foster this exchange?</quote>
                    <ptr target="#ridge2014" loc="18"/>
                </cit>. She also engages with Surowiecki’s idea put forward in <title rend="italic"
                    >The Wisdom of Crowds</title>
                <ptr target="#suroweicki2004"/> that for crowds to be wise they must be diverse and
                their actors independent. Brooklyn attempted to foster both attributes in their open
                call for photographers to submit one image each on the theme of <q>Changing Faces of
                    Brooklyn</q>, to be judged by a crowd for inclusion in a new exhibition. 389
                entries were assessed by 3,344 evaluators in a thoughtfully created interface that
                attempted to minimize outside influence on evaluators. 410,089 evaluations were
                submitted; the top 20% of images were then displayed as the exhibition <title
                    rend="italic">Click!</title>, drawing 20,000 visitors in six weeks. Bernstein
                provides a range of other useful statistics about user engagement with the
                evaluation interface and the exhibition. The remaining case studies include a
                Tinder-style app through which volunteers assess images quickly (<title
                    rend="italic">Split Second: Indian Paintings</title>, <ref
                    target="#http://www.trevorowens.org/2012/03/crowdsourcing-cultural-heritage-the-objectives-are-upside-down/"
                    >https://www.brooklynmuseum.org/exhibitions/splitsecond</ref>), and an
                open-studio tour program spanning 73 square miles and 67 neighbourhoods (Go). The
                article argues persuasively that GLAMs can work with visitors and volunteers to
                transform crowds into communities. Regional museums may be better suited to this
                approach than GLAMs such as the National Library of Wales, which is represented in a
                later chapter of the volume, whose authors remark on how relative regional isolation
                and poor public transportation have made online methods of crowdsourcing
                particularly useful and productive.</p>
            <p>Chapter 2, <q><title rend="italic">Old Weather</title>: Approaching Collections from
                    a Different Angle</q>, by Lucinda Blaser (Royal Museums Greenwich), provides a
                valuable overview of a project in which volunteers transcribe historic ships’ logs
                in an effort to extract climatological data that will improve the British Met
                Office’s weather predication and climate models. As members of the <title
                    rend="italic">Old Weather</title> team have reported previously, volunteers’
                interest in the historic information they encountered along the way has proved an
                unexpected hit, and has been a major reason for sustained engagement with the
                project over time (<ref target="#https://blog.oldweather.org/"
                    >https://blog.oldweather.org/</ref>). The project (<ref
                    target="#https://blog.oldweather.org/">https://www.oldweather.org/</ref>) is a
                collaboration between <title rend="italic">Zooniverse</title> (<ref
                    target="#https://blog.oldweather.org/">www.zooniverse.org</ref>) – an online
                crowdsourcing research group based at the University of Oxford – the Adler
                Planetarium in Chicago, the University of Minnesota, the Met Office, National
                Maritime Museum and Naval-History.net, using original ship log sources held in the
                National Archives, UK (a number of spinoff projects since 2014 have added further
                material accessible through the same site). Blaser remarks that although the source
                material was not held at the National Maritime Museum, the museum held images of the
                ships and other material that <cit>
                    <quote rend="inline">could engage users further with links to historic
                        photographs that would bring these vessels to life, making this project more
                        than just a two-dimensional transcription project</quote>
                    <ptr target="#ridge2014" loc="51"/>
                </cit>. Moreover, she asks if this model could be more widely applied, and poses a
                rhetorical question: <cit>
                    <quote rend="inline">Do we have to be selfish and only think of ourselves in the
                        results of crowdsourcing and citizen science projects, or is the ability to
                        say that as an institution you have helped a large number of users engage
                        with your subject matter in a meaningful way more than enough?</quote>
                    <ptr target="#ridge2014" loc="51"/>
                </cit>. </p>
            <p>Blaser discusses some of the challenges and opportunities inherent in crowdsourcing,
                including the need to foster communities over the long term and incorporate
                crowdsourced results into content management systems. She is admirably attentive to
                the experience of volunteers, quoting a number of contributors in her essay, and
                reflecting on the ways in which volunteers’ engagement can result in new learning
                opportunities and a sense of fulfillment and ownership that can ultimately drive new
                research questions. She briefly mentions instances of crowd-curation’ of exhibitions
                at Royal Museums Greenwich, such as <title rend="italic">Beside the Seaside</title>
                and <title rend="italic">Astronomy Photographer of the Year</title>
                <cit>
                    <quote rend="inline">where crowdsoured images and collection items share the
                        same gallery space</quote>
                    <ptr target="#ridge2014" loc="47"/>
                </cit>. Blaser argues that <cit>
                    <quote rend="inline">crowdsourced displays will become more common</quote>
                    <ptr target="#ridge2014" loc="47"/>
                </cit> thus allowing volunteers to work directly with museum staff and feel greater
                ownership of collections. Her reflections link in well with the previous essay.</p>
            <p>Tim Causer and Melissa Terras of University College London discuss the <title
                    rend="italic">Transcribe Bentham</title> project in chapter 3 of the volume.
                    <title rend="italic">Transcribe Bentham</title> invites members of the public to
                transcribe and apply TEI XML tags to Jeremy Bentham’s voluminous archives, which are
                slowly being edited by a team at UCL. The essay describes the original transcription
                interface—a customized MediaWiki web application—the initial call for engagement,
                updates to the interface, funding, staffing, cost-effectiveness, quality control, as
                well as future collaborations (now underway) to use the vetted Bentham transcripts
                as training data for Handwriting Recognition Technology. Significantly, the authors
                acknowledge that the difficulty of the transcription and marking tasks led to a
                narrowing of participation and reliance on a small cohort of seventeen Super
                Transcribers (the threshold at which one becomes a Super Transcriber is not
                specified). They aver that <title rend="italic">Transcribe Bentham</title> might be
                better described as <q>crowd-sifting</q>, beginning with the traditional open call
                of crowdsourcing but resulting in the retention of a small group of highly dedicated
                individuals. Although the interface was tweaked to ease participation, the authors
                argue that it is worth attempting to attract more Super Transcribers than casual or
                short-term users. Other research teams, including Zooniverse, have attempted to
                lower barriers to participation by developing more granular approaches to text
                transcription. <title rend="italic">Shakespeare’s World</title> and <title
                    rend="italic">AnnoTate</title>, both launched in late 2015, are transcription
                projects built with GLAM partners on the Zooniverse platform, for which I served as
                project lead. These allow participants to transcribe as little as a word or line on
                a page and have resulted in higher levels of participation from a broader base. For
                example, as of May 2017, volunteers who worked on fewer than nine pages contributed
                20% of <title rend="italic">Shakespeare’s World</title> transcriptions overall, a
                significant contribution.</p>
            <p>Case study 4, <title rend="quotes">Build, Analyse and Generalise: Community
                    Transcription of the <title rend="italic">Papers of the War Department</title>
                    and the Development of <title rend="italic">Scripto</title></title> by Sharon M.
                Leon, describes how the creation of a particular project resulted in the release of
                    <title rend="italic">Scripto</title> (<ref target="#www.scripto.org"
                    >www.scripto.org</ref>) <cit>
                    <quote rend="inline">a customisable software library [built on WikiMedia]
                        connecting a repository to an editing interface, and as extensions for three
                        popular web-based content management systems</quote>
                    <ptr target="#ridge2014" loc="97"/>
                </cit> including Omeka, Drupal, and WordPress. <title rend="italic">Papers of the
                    War Department</title> (PWD) digitally assembles nearly 45,000 documents from
                archives in the US, Canada, Britain and France pertaining to the period 1784–1800.
                The papers had long been believed to be lost due to a fire in the War Office in
                1800, which destroyed the central repository. Through the efforts of scholar Ted
                Crackel in the 1980s and 1990s, the whereabouts of copies and examples of the
                original correspondence were located and imaged, originally for the purposes of a
                printed edition, then a CD-ROM, and finally, in 2008, for <title rend="italic"
                    >PWD</title>, which invites members of the public to transcribe the sources. The
                sources were lightly catalogued by experts by 2010, but as Leon points out this only
                opened the corpus to researchers who knew precisely what they were looking for,
                while those <cit>
                    <quote rend="inline">with less concrete demands</quote>
                    <ptr target="#ridge2014" loc="92"/>
                </cit> found the early index less useful. Project funding was used to add more
                detailed metadata to a third of the collection, but could not stretch far enough to
                cover the whole. At this point, in 2013, <title rend="italic">PWD</title> staff
                analyzed their site traffic and concluded they had a ready-made group of users who
                might be willing to contribute their own transcriptions and expertise back into the
                collection.</p>
            <p>Before describing <title rend="italic">Scripto</title> Leon gives an overview of some
                of the theoretical work and existing transcription tools and crowdsourcing platforms
                that inspired staff at the Roy Rosenzweig Center of History and New Media (RRCHNM)
                to engage with the public. She cites Max Evans’s <cit>
                    <quote rend="inline">2007 call for commons-based peer production as a way to
                        create <q>Archives of the People, by the People, for the People</q></quote>
                    <ptr target="#ridge2014" loc="92"/>
                </cit>: Wikipedia, Flickr Commons, Zooniverse and <title rend="italic">Transcribe
                    Bentham</title>. Like many organisations that have harnessed crowdsourced
                transcription, RRCHNM realized that <cit>
                    <quote rend="inline">public contributions [could] provide transcriptions where
                        there once were none, and where there likely would be none in the
                        future</quote>
                    <ptr target="#ridge2014" loc="96"/>
                </cit> due to budgetary constraints and the sheer scale of the job. Moreover
                    <q>public contributions</q> where volunteers choose what to transcribe <cit>
                    <quote rend="inline">can serve as a barometer of the most interesting materials
                        within a particular collection</quote>
                    <ptr target="#ridge2014" loc="96"/>
                </cit> and perhaps have a bearing on editorial choices for print or digital editions
                in the future. Surely many publishers would be swayed by concrete evidence of this
                kind.</p>
            <p>User testing of the early site led the team to implement a series of innovations to
                the standard MediaWiki transcription interface, for example showing the manuscript
                document at the top of the page and the transcription pane beneath. Login accounts
                are required and new users can wait a business day to be approved. I tested this on
                a working day, and was confirmed for a new account in less than twenty-four hours.
                The project team felt approved login was necessary to reduce vandalism and spam, but
                I would argue it probably acts as a deterrent to users who might feel motivated to
                engage, but are unwilling or unable to return to the project in future. The
                remainder of the case study traces the support, development, and editorial time
                devoted to DWP and the release and uptake of <title rend="italic">Scripto</title>,
                which has been particularly popular amongst university libraries <ptr
                    target="#ridge2014" loc="108"/>.</p>
            <p>Case study 5 returns us to New York, with an engaging piece titled <title
                    rend="quotes"><title rend="italic">What’s on the Menu?</title>: Crowdsourcing at
                    the New York Public Library</title>, by Michael Lascarides and Ben Vershbow. The
                authors combine a detailed case study of a menus transcription and metadata
                extraction project launched in 2011 with up-to-date (and still relevant) analysis
                and insight into user motivation, usability, sustainability, and data ownership.
                Lascarides and Vershbow argue that <q>it needs to be made very clear at the outset
                    that your library entirely owns the newly created data to do with whatever it
                    wants, and that the participant willingly relinquishes any ability to restrict
                    those rights</q> and that <cit>
                    <quote rend="inline">usually, you will want to share the [resulting] content
                        that results from their labours as broadly as you can</quote>
                    <ptr target="#ridge2014" loc="122"/>
                </cit>. NYPL have perhaps been more explicit than others about the status of the
                data they collect. While most GLAMs want their data to be reusable and searchable
                through a web interface, and clearly state this in their mission statement and other
                materials geared towards potential volunteers, project owners could do more to
                highlight that any data produced through their interface will become the property of
                the institution.</p>
            <p>After providing a clear overview of the site functionality, supported by images of
                the interface, the authors also highlight the depth of user engagement with <title
                    rend="italic">What’s on the Menu</title> (<ref target="#http://menus.nypl.org/"
                    >http://menus.nypl.org/</ref>) during its first sixteen months: 163,690 visits,
                four million page views, and an average of 6.36 minutes on the site, compared to
                just 2.38 on nypl.org <ptr target="#ridge2014" loc="126"/>, suggesting that
                transcription and other crowdsourcing interfaces offer patrons ways of engaging with
                and exploring collections that more traditional GLAM interfaces do not. In a
                    <q>What’s Next?</q> section the authors advocate for <q>crowdsourcing at
                    scale</q> in which <q>a new generation of reusable tools that require less
                    maintenance and serve a wider variety of purposes</q> are deployed across most
                if not all NYPL domains, as opposed to building and attempting to maintain single
                stand-alone apps. Lascarides and Vershbow conclude with reflections on the
                gamification debate, arguing persuasively that participants are often motivated by
                the collections themselves and do not need an additional layer of play to become or
                remained involved in crowdsourcing. They cite a range of authorities including
                Trevor Owens (Library of Congress): <cit>
                    <quote rend="block">When done well, crowdsourcing offers us an opportunity to
                        provide meaningful ways for individuals to engage with and contribute to
                        public memory. Far from being an instrument which enables us to ultimately
                        better deliver content to end users, crowdsourcing is the best way to
                        actually engage our users in the fundamental reason that these digital
                        collections exist in the first place. [Owens, 2012, cited <ptr
                            target="#ridge2014"/>, 131]</quote>
                    <ptr target="#owens2012"/>
                </cit> Like a number of other contributors to the volume, Lascarides and Vershbow
                emphasize the experimental and iterative nature of crowdsourcing projects at their
                institution (including others beyond <title rend="italic">What’s on the
                    Menu?</title>, such as <title rend="italic">GeoTagger</title>, a geo-referencing
                project). They write about paying down their <q>technical debt</q> after a
                successful beta test of <title rend="italic">What’s on the Menu</title>, by
                overhauling the original application code, implementing new visual design and
                elements of the user interface, with better search and browsing features, and
                perhaps most significantly, a new public API <cit>
                    <quote rend="inline">to provide other application developers or digital
                        researchers real-time data from the project</quote>
                    <ptr target="#ridge2014" loc="126"/>
                </cit>.</p>
            <p>Chapter 6, <title rend="quotes">What’s Welsh for <q>Crowdsourcing</q>? Citizen
                    Science and Community Engagement at the National Library of Wales</title>, by
                Lyn Lewis Dafis, Lorna M. Hughes and Rhian James, reports on two crowdsourcing
                projects undertaken at the National Library of Wales (NLW): <title rend="italic">The
                    Welsh Experience of the First World War</title> (<ref
                    target="#http://cymru1914.org/">http://cymru1914.org/</ref>) collecting project
                and <title rend="italic">Cymru1900Wales</title> (<ref
                    target="#http://cymru1914.org/">http://www.cymru1900wales.org/</ref>), a place
                name gathering project in partnership between NLW, the University of Wales, People’s
                Collections Wales, the Royal Commission on the Ancient and Historical Monuments
                Wales and Zooniverse. They also describe the digitized collection of <title
                    rend="italic">Welsh Wills Online</title>, a project with potential for adding
                crowdsourced transcription. The authors remark that the relatively remote location
                of the library has led the institution to focus on <cit>
                    <quote rend="inline">mass digitisation of core collections to support access,
                        preservation, research and education</quote>
                    <ptr target="#ridge2014" loc="139"/>
                </cit>, as well as the provision of all tools and web services in both Welsh and
                English. Moreover, they argue that crowdsourcing <cit>
                    <quote rend="inline">can [...] be seen as the logical development of a long
                        tradition of research and engagement based on the Library’s
                        collections</quote>
                    <ptr target="#ridge2014" loc="144"/>
                </cit>.</p>
            <p>Like others in the volume, the authors have recourse to the theoretical frameworks
                put forward by Jeff Howe of Wired magazine in regards to crowdsourcing and business
                practice. They conclude that crowdsourcing in the cultural heritage domain <q>seeks
                    to utilise the multiple perspectives of the crowd</q>, a statement most clearly
                borne out in <title rend="italic">The Welsh Experience of the First World
                    War</title> which collected and digitized primary material provided by the
                public in a series of five <q>roadshows</q> held in geographically diverse parts of
                Wales. The roadshow format is not new, as the authors point out, citing the
                Oxford-based <title rend="italic">Great War Archive</title> project, <title
                    rend="italic">Europeana 1914–1918</title> and the JISC-funded <title
                    rend="italic">Welsh Voices of the Great War Online</title>. But the project is
                different in that it aimed to digitize materials that would fill particular gaps in
                existing collections. The authors provide a list of those organizations they
                contacted and the advertising deployed to recruit participants, and reveal that
                while the 350 items that were digitized were diverse, they did not succeed in
                gathering non-documentary or text-based items. They conclude that future marketing
                of roadshows would need to be much more targeted in order to capture other kinds of
                media.</p>
            <p><title rend="italic">Cymru1900Wales</title>, the library’s first crowdsourcing
                project, launched in September 2012 and asks volunteers to add local place name
                information to digitized Ordnance Survey maps from 1900. A number of research goals
                are referred to in broad strokes by the authors, for example the hope that the
                dataset will unlock social and linguistic history. Unlike the roadshows, this
                project was conducted entirely remotely, with academics and participants
                communicating via email, project blog, FaceBook and Twitter. This is particularly
                important for GLAMs that are remote from their patron base. <title rend="italic"
                    >Welsh Wills Online</title> consists of 800,000 pages of wills and other legal
                documents collected in the Welsh ecclesiastical courts between the late-sixteenth
                century and 1858. Like so many of the text-based collections discussed throughout
                the volume, the materials here are not yet machine-readable, making manuscript
                transcription necessary if the contents of the images and original documents are to
                become word-searchable. At the time of writing, NLW had not yet embarked upon such a
                project and one does not appear to be under development at present.</p>
            <p>The authors acknowledge that while crowdsourcing may have great promise, many GLAM
                and academic end-users, including those they surveyed, are anxious that projects be
                cost-effective. This manifests in two distinct but related anxieties: 1) that time
                spent setting up and maintaining projects should not exceed the amount of time it
                would take staff to do the core tasks associated with the project themselves, i.e.
                transcription and 2) that end-users, i.e. researchers, be able to make use of the
                results. Quality control and vetting, the authors argue, should not create a heavier
                burden than any work offset by the use of crowdsourcing. Like Causer and Terras
                above (<title rend="italic">Transcribe Bentham</title>), the NLW team concludes that
                it might be best to attract and retain specialists or, to put it another way, a
                cohort of Super Transcribers. Again, drawing on my experience of <title
                    rend="italic">Shakespeare’s World</title> in which volunteers transcribe a range
                of early modern English manuscripts that share some of the difficulties of the Welsh
                wills corpus, a significant proportion of volunteers are able to make meaningful
                contributions to transcription when given some guidance in the form of handbooks,
                tutorials, shortcut keys for common abbreviations, and so on. But however much we
                lower barriers to participation, GLAMs and academics still need time, money and
                support to deal with both the process and the products of crowdsourcing. In this
                regard, the authors’ emphasis on the potential for crowdsourcing to save money is
                perhaps misleading, though even within the context of the present volume, it is a
                widely expressed view; one that may have its roots in crowdsourcing for business
                purposes. As Trevor Owens argues at the close of the volume, and as Blaser argues in
                chapter 2, crowdsourcing in GLAM and academic environments may save time on tasks
                such as transcription and metadata extraction, but ideally should create new roles
                dedicated to public engagement with collections and tweak existing roles and the
                ways in which GLAMs conceptualize their duties and interactions to patrons. GLAMs
                might, for example, spend more time nurturing public engagement projects and
                ingesting the products of crowdsourcing and other kinds of engagement projects into
                CMSs (content management systems), rather than having specialists add deeper
                metadata to a lightly catalogued collection.</p>
            <p>In <title rend="quotes"><title rend="italic">Waisda?</title>: Making Videos Findable
                    Through Crowdsourced Annotations</title> (chapter 7), Johan Oomen, Riste
                Gligorov and Michiel Hildebrand describe two pilot projects that resulted in the
                contribution of over one million tags to a corpus of video clips in the Netherlands
                Institute for Sound and Vision, which holds over 750,000 hours of audiovisual
                material as of 2014. The primary audience for the archive is not the equivalent of
                library patrons or museum-goers, but broadcasters and journalists who seek out
                reusable content. Secondary and tertiary audiences are comprised of researchers and
                students who use materials in a broad range of disciplines, and <q>home users</q>
                who access the materials for <cit>
                    <quote rend="inline">personal entertainment or a learning experience</quote>
                    <ptr target="#ridge2014" loc="169"/>
                </cit>. The opening pages of the article give an overview of the challenges of
                making non-machine readable datasets accessible through crowdsourcing, and describe
                various approaches to crowdsourcing and motivational factors for both GLAMs and
                    <q>end-users</q> or participants. Many of these, such as <cit>
                    <quote rend="inline">increasing connectedness between audiences and the
                        archive</quote>
                    <ptr target="#ridge2014" loc="166"/>
                </cit> are echoed in contributions throughout this volume.</p>
            <p>Unlike most of the other projects here, <title rend="italic">Waisda?</title> deploys
                gamification strategies to engage users, and the authors report successful outcomes
                from what they call <q>serious game</q> play <ptr target="#ridge2014" loc="171"/>.
                As in the ESP Game, players of <title rend="italic">Waisda?</title> accrue points if
                their tags match those of other players. <title rend="italic">Waisda?</title>
                players can see their score relevant to other players and scorekeeping is split into
                a number of categories including <cit>
                    <quote rend="inline">fastest typers</quote>
                    <ptr target="#ridge2014" loc="173"/>
                </cit>. Evaluation of the results is provided for the first and second pilot
                studies, focusing on the overall usefulness of the tags created. As the authors
                indicate, some of these findings have been published at an earlier date, but an
                overview is offered here. Ultimately, they conclude that <cit>
                    <quote rend="inline">using only verified user tags (i.e. where there was mutual
                        agreement) for search gives poorer performance than search based on all user
                        tags</quote>
                    <ptr target="#ridge2014" loc="179"/>
                </cit> and that search functionality improves with the addition of more tags. Like
                the <title rend="italic">Transcribe Bentham</title> and <title rend="italic"
                    >PWD</title> teams, the authors advocate for finding <q>super-taggers</q> rather
                than creating broad appeal, but they do acknowledge that Zooniverse offers an
                    <q>alternative model</q>, which they describe as relying on a <cit>
                    <quote rend="inline">sustainable <q>army</q> of users</quote>
                    <ptr target="#ridge2014" loc="180"/>
                </cit>. That said, they do not elaborate how that army might have been engaged in
                the first place nor how <title rend="italic">Waisda?</title> might emulate
                Zooniverse to create broader engagement. However, the research team have reuse and
                sustainability on their agenda, having published their code on GitHub, and connected
                with the European Film Gateway and <title rend="italic">Europeana</title>
                <ptr target="#ridge2014" loc="180"/>. As Lascarides and Vershbow argue in chapter 5,
                reusability of apps is necessary for long-term sustainability.</p>
            <p>Chapter 8, <title rend="quotes"><title rend="italic">Your Paintings Tagger</title>:
                    Crowdsourcing Descriptive Metadata for a National Virtual Collection</title> by
                Kathryn Eccles and Andrew Greg, describes the <title rend="italic">Your
                    Paintings</title> site hosted by the British Broadcasting Corporation (BBC),
                containing over 200,000 images of paintings in The Public Catalogue Foundation, and
                a metadata extraction project called <title rend="italic">Your Paintings
                    Tagger</title> (<ref target="#www.tagger.thepcf.org.uk"
                    >www.tagger.thepcf.org.uk</ref> formerly). While many articles in <title
                    rend="italic">Crowdsourcing our Cultural Heritage</title> directly invoke
                Zooniverse’s Galaxy Zoo and other scientific projects, <title rend="italic">Your
                    Paintings Tagger</title> (YPT) was built in partnership with Zooniverse, and
                    <title rend="italic">Galaxy Zoo</title> user motivations have been compared
                directly with those of YPT participants by researchers at Oxford and the University
                of Glasgow (the current chapter builds on previous work undertaken by Greg and
                Eccles). Not all Zooniverse components were deployed in the YPT, for example this
                project does not have a social forum or other mechanism whereby volunteers and
                experts can interact. It was only through surveys that the project team learned of
                volunteers’ desire for a social space. Like Causer and Terras of <title
                    rend="italic">Transcribe Bentham</title>, Greg and Eccles conclude that because
                most tags are contributed by a small cohort of volunteers, more should be done to
                engage and retain additional ‘super-taggers’, though the authors do gesture to the
                prospect that the threshold for agreement among taggers could be lowered and that
                paintings shown by some logic such as artist or time period might be more engaging
                than the default Zooniverse mechanism for presenting images, which is random.</p>
            <p>The authors spend some early pages of the chapter discussing the complex negotiations
                between experts at the BBC, participating GLAMs and the University of Glasgow, who
                tried to pin down a suitable metadata format for <title rend="italic">Your
                    Paintings</title>, before the introduction of a crowdsourced dimension. Other
                GLAM practitioners may find this account useful when considering the institutional
                barriers they may need to overcome when trying to make collections more
                discoverable. It is notable however, that while Greg and Eccles, like others in this
                volume, suggest that crowdsourcing is more cost effective than traditional metadata
                improvement projects, time and money are still needed to support communities.
                Indeed, even without a social forum feature, which generally entails more staff time
                to maintain than projects without a social dimension, YPT is currently unavailable
                due to a funding shortage. The project owners are keen to implement changes to the
                platform and a call for donations (a form of crowdfunding) is prominent on the home
                page. Rather than conceiving of crowdsourcing as a cheap alternative to metadata
                extraction, we should focus on other benefits, for example the prospect of engaging
                people in new ways with collections they might not otherwise encounter; and in the
                case of tagging developing alternative languages for searching that enable broader
                access to online collections. Greg and Eccles do in fact report on these benefits
                throughout their piece, and acknowledge that at the rate of tagging reported in 2013
                it would take a long time for the project to come to completion. Project owners will
                continue to experience the same disappointments over cost effectiveness and speed so
                long as the (narrow) messaging around the value of crowdsourcing remains the
                same.</p>
            <p>Part II, <title rend="quotes">Challenges and Opportunities of Cultural Heritage
                    Crowdsourcing</title>, contains four essays that address different aspects of
                the relationships between GLAMs and volunteers. Alexandra Eveleigh’s thoughtful and
                carefully balanced piece, <title rend="quotes">Crowding Out the Archivist? Locating
                    Crowdsourcing within the Broader Landscape of Participatory Archives</title>,
                acknowledges some of the common concerns of archivists and domain specialists in
                engaging with the crowd—notably concerns about authority and accuracy—while also
                advocating for careful engagement with online communities. Eveleigh examines the <cit>
                    <quote rend="inline">tension inherent between a custodial instinct to control
                        context and authenticity, and a desire to share access and promote
                        usage</quote>
                    <ptr target="#ridge2014" loc="212"/>
                </cit> of collections, and suggests that the reality of participatory archival
                practices will cause neither the demise of the archivist specialist nor the complete
                revolution of their role, but rather that the ever-changing landscape of
                participatory technologies and projects will enable the curator/gatekeeper role to
                evolve and to place greater emphasis on the perspective of the user/volunteer.
                Eveleigh’s piece brings many of the bubbling concerns from the case studies to the
                fore, and serves as a strong yet encouraging critique of GLAM practice with regards
                to crowdsourcing.</p>
            <p>Stuart Dunn and Mark Hedges’ <title rend="quotes">How the Crowd Can Surprise Us:
                    Humanities Crowdsourcing and the Creation of Knowledge</title> is a follow on
                from their <title rend="quotes">Crowd-Sourcing Scoping Study: Engaging the Crowd
                    with Humanities Research</title>
                <ptr target="#hedges2012"/>. In the present essay they offer a series of definitions
                and typologies of crowdsourcing activities, which may be helpful for researchers
                interested in terminology and theories of crowdsourcing. They explore distinctions
                between crowdsourcing for business versus epistemic purposes, arguing that
                humanities crowdsourcing, while it may draw on <q>mechanical</q> micro-tasking
                approaches common in business crowdsourcing projects, can also provide the
                circumstances for knowledge co-creation, interpretation, creative responses,
                editing, investigation, and new research. They conclude that because a small number
                of people undertake the bulk of tasks in any given crowdsourcing project, <cit>
                    <quote rend="inline">successful uptake of contributor effort in humanities
                        crowdsourcing will be dependent on finding pockets of enthusiasm and
                        expertise for specific areas</quote>
                    <ptr target="#ridge2014" loc="244"/>
                </cit>.</p>
            <p>The penultimate chapter is <title rend="quotes">The Role of Open Authority in a
                    Collaborative Web</title> by Lori Byrd Phillips, which begins by quoting Jane
                McGonigal’s <title rend="quotes">Gaming the Future of Museums</title> lecture <ptr
                    target="#mcgonigal2008"/>, and striking a note common to almost all of the other
                pieces: that there is <q>pent-up knowledge in museums</q> and <q>pent-up
                    expertise</q> in the public that can be married up for the benefit of all
                involved. Perhaps more clearly than the other authors in the volume, Byrd Phillips
                argues that the increase in user-generated content created a <cit>
                    <quote rend="inline">renewed need for authoritative expertise in museums</quote>
                    <ptr target="#ridge2014" loc="247"/>
                </cit>. This argument essentially turns the more familiar paradigm—that there are
                collections that cannot be unlocked without volunteer effort—inside out. The piece
                echoes ideas put forward by Eveleigh and draws on additional theoretical
                perspectives, including the Reggio Emilia approach to learning, a child-led
                educational model that emerged in post-WWII Italy. Byrd Phillips argues that this
                model may be particularly useful for museums wishing to create <cit>
                    <quote rend="inline">opportunities for community learning and
                        collaboration</quote>
                    <ptr target="#ridge2014" loc="259"/>
                </cit>.</p>
            <p>The final essay, Trevor Owens’s <title rend="quotes">Making Crowdsourcing Compatible
                    with the Missions and Values of Cultural Heritage Organisations</title> closes
                the volume on a confident and even utopian note, declaring that crowdsourcing should
                be a core function of the way in which GLAMs serve the public: <cit>
                    <quote rend="inline">crowdsourcing is one of the most valuable experiences we
                        can offer our users</quote>
                    <ptr target="#ridge2014" loc="279"/>
                </cit>. He argues that crowdsourcing, when done well, can engage users with content
                in active and meaningful ways – not as mechanical transcribers for instance but as
                ‘authors of our historical record’, who contribute their passion and time to tasks
                that on the one hand open up collections for new kinds of investigation, and which
                also enable users to encounter primary material more deeply than if they were simply
                browsing an online catalogue.</p>
            <p>Owens is a rhetorically skillful proponent of what he calls <q>ethical
                    crowdsourcing</q> which is as much focused on the experience of patrons or
                volunteers as on cultural heritage outcomes. He touches on the work of Surowiecki,
                the examples of <title rend="italic">ReCaptcha</title>, <title rend="italic"
                    >BabelZilla</title> – <q>an online community for developers and translators of
                    extensions for Firefox web browser</q> – and <title rend="italic">Galaxy
                    Zoo</title>. Of the latter he argues: <cit>
                    <quote rend="inline">all the work of the scientists and engineers that went into
                        those systems are part of one big scaffold that puts users in a position to
                        contribute to the frontiers of science through their actions on a website,
                        without needing the skills and background of a professional
                        scientist</quote>
                    <ptr target="#ridge2014" loc="276"/>
                </cit>. His concept of scaffolding is particularly relevant in light of two new
                platforms, which enable anyone to create their own free project: <ref
                    target="#www.zooniverse.org/lab">www.zooniverse.org/lab</ref> (<title
                    rend="italic">Zooniverse Project Builder</title>) and <ref
                    target="#https://crowdcrafting.org/">https://crowdcrafting.org/</ref> (<title
                    rend="italic">crowdcrafting</title>), both launched after the publication of
                Ridge’s volume. Finally, as if in answer to some of the contradictory statements
                about cost-effectiveness and emerging modes of engaging with the public that have
                been put forward by various case study authors in Part I, Owens argues that <cit>
                    <quote rend="inline">in the process of developing [...] crowdsourcing projects
                        we have stumbled onto something far more exciting than speeding up or
                        lowering the costs of document transcription</quote>
                    <ptr target="#ridge2014" loc="277"/>
                </cit>. He closes with an example of transcription of Civil War diaries from the
                University of Iowa Libraries’ DIY history site http://diyhistory.lib.uiowa.edu/,
                whose former head of Digital Library Services, Nicole Saylor, sees transcription as
                a <q>wonderful by-product</q> of a process of engaging the public with history. This
                model is a more realistic image of what GLAMs can hope to achieve by deploying
                crowdsourcing.</p>
            <p><title rend="italic">Crowdsourcing our Cultural Heritage</title> has much to offer a
                range of researchers and GLAM practitioners both in terms of particular examples of
                projects focused on a diverse range of media, and in terms of the evolving and
                complex debates about the role of crowdsourcing and public engagement in GLAMs and
                academia. This is an excellent starting place for anyone interested in studying
                crowdsourcing or embarking upon or improving existing projects.</p>
            <div>
                <head>Acknowledgements</head>
                <p>This review was written while I was a British Academy Postdoctoral Fellow at the University of Oxford and Pembroke College, and the Zooniverse Humanities Principal Investigator in 2017, prior to my relocation to the Library of Congress, Washington DC, where I serve as Senior Innovation Specialist and Community Manager for By the People, a new crowdsourcing initiative (crowd.loc.gov).</p>
            </div>
        </body>
        <back>
            <listBibl>
                <bibl xml:id="hedges2012" label="Hedges and Dunne 2012">Hedges, Mark and Stuart
                    Dunne. <title rend="quotes">Crowd-Sourcing Scoping Study: Engaging the Crowd
                        with Humanities Research.</title>
                    <ref
                        target="#https://kclpure.kcl.ac.uk/portal/en/publications/crowdsourcing-scoping-study(abf40e6d-7ece-4d76-94d2-36f91b5707ff).html"
                        >https://kclpure.kcl.ac.uk/portal/en/publications/crowdsourcing-scoping-study(abf40e6d-7ece-4d76-94d2-36f91b5707ff).html</ref>
                    (2012).</bibl>
                <bibl xml:id="mcgonigal2008" label="McGonigal 2008">McGonigal, Jane. <title
                        rend="quotes">Gaming the Future Museums.</title> Lecture presented at
                    Newseum, Washington, D.C., hosted by American Alliance of Museums (AAM), <ref
                        target="#https://www.youtube.com/watch?v=zJ9j7kIZuoQ"
                        >https://www.youtube.com/watch?v=zJ9j7kIZuoQ</ref> (2008, published
                    2012.)</bibl>
                <bibl xml:id="owens2012" label="Owens 2012">Owens, Trevor. <title rend="quotes"
                        >Crowdsourcing Cultural Heritage: The Objectives are Upside Down.</title>
                    <ref
                        target="#http://www.trevorowens.org/2012/03/crowdsourcing-cultural-heritage-the-objectives-are-upside-down/"
                        >http://www.trevorowens.org/2012/03/crowdsourcing-cultural-heritage-the-objectives-are-upside-down/</ref>
                    (2012).</bibl>
                <bibl xml:id="ridge2014" label="Ridge 2014">Ridge, Mia (ed). <title rend="italic"
                        >Crowdsourcing Our Cultural Heritage</title> Ashgate, Farnham (2014).</bibl>
                <bibl xml:id="surowiecki2004" label="Surowiecki 2004">Surowiecki, James. <title
                        rend="italic">The Wisdom of Crowds: Why the Many are Smarter than the Few
                        and How Collective Wisdom Shapes Business, Economies, Societies, and
                        Nations.</title> Doubleyday and Co., New York (2004).</bibl>
            </listBibl>
        </back>
    </text>
</TEI>
