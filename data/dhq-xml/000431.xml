<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?>
<?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <!-- Author should supply the title and personal information-->
                <title type="article" xml:lang="en">Manual Annotation of Unsupervised Models: Close
                    and Distant Reading of Politics on Reddit</title>
                <!-- Add a <title> with appropriate @xml:lang for articles in languages other than English -->
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Christoph <dhq:family>Aurnhammer</dhq:family></dhq:author_name>
                    <dhq:affiliation>Department of Language Sciene and Technology, Saarland
                        University</dhq:affiliation>
                    <email>aurnhammer@coli.uni-saarland.de</email>
                    <dhq:bio>
                        <p>Christoph Aurnhammer is a doctoral researcher in psycholinguistics at the
                            special research group Information Density and Linguistic Encoding at
                            the Department of Language Science and Technology, Saarland University,
                            Germany. He received undergraduate education in the humanities and
                            social sciences from the University of Passau and studied linguistics at
                            Tilburg University and Radboud University, the Netherlands. His research
                            applies computational approaches to text with questions on human
                            communication and the human mind.</p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Iris <dhq:family>Cuppen</dhq:family></dhq:author_name>
                    <dhq:affiliation/>
                    <email>iriscuppen@gmail.com</email>
                    <dhq:bio>
                        <p>Iris Cuppen holds an MA degree in Culture Studies from Tilburg
                            University, the Netherlands, and works as a writer at Bakken &amp; Bæck,
                            a digital studio based in Amsterdam. Before, she worked as a graphic
                            designer and as an art teacher at St. Joost‘s - Hertogenbosch, where she
                            also studied graphic design.</p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Inge <dhq:family>van de Ven</dhq:family></dhq:author_name>
                    <dhq:affiliation/>
                    <email>i.g.m.vdven@uvt.nl</email>
                    <dhq:bio>
                        <p>Inge van de Ven is Assistant Professor of Online Culture in the
                            Department of Culture Studies at Tilburg School of Humanities and
                            Digital Sciences, the Netherlands. She holds a PhD from Utrecht
                            University, where she also completed postdoctoral research on creativity
                            in education, funded by Education for Learning Societies. She held a
                            Core Fellowship at the Institute for Advanced Study of the Central
                            European University in Budapest, as well as visiting scholarships at
                            Harvard University, the Shanghai International Studies University, and
                            The University of Copenhagen. Her articles appeared in journals such as
                                <title rend="italic">European Journal of English Studies</title>,
                                <title rend="italic">Image &amp; Narrative</title>, <title
                                rend="italic">Narrative</title>, and <title rend="italic">Journal
                                for Creative Behavior</title>. Her monograph <title rend="italic"
                                >Big Books in times of Big Data</title> will be published in
                            November 2019 with Leiden University Press.</p>
                    </dhq:bio>
                </dhq:authorInfo>
                <dhq:authorInfo>
                    <!-- Include a separate <dhq:authorInfo> element for each author -->
                    <dhq:author_name>Menno <dhq:family>van Zaanen</dhq:family></dhq:author_name>
                    <dhq:affiliation>South African Centre for Digital Language Resources, North-West
                        University, Potchefstroom, South Africa</dhq:affiliation>
                    <email>menno.vanzaanen@nwu.ac.za</email>
                    <dhq:bio>
                        <p>As a professor in Digital Humanities, Menno is particularly interested in
                            incorporating the use of computational techniques in the field of
                            Humanities. His PhD in the area of computer science dealt with building
                            systems that learn (linguistic) grammars from plain sequences
                            (sentences). These empirical grammatical inference systems result in
                            patterns that can be used for further analysis of the data, for
                            instance, in applied machine learning, computational linguistics, or
                            computational musicology. During his MA (computational linguistics) and
                            MSc (computer science) studies, Menno used techniques from the one field
                            and applied it to situations in the other, such as proofing tools and
                            error correction, machine translation, and multi-modal information
                            retrieval. Such techniques can be applied to Humanities data, but for
                            them to be fully successful, the results still need to be interpreted in
                            the context of Humanities.</p>
                    </dhq:bio>
                </dhq:authorInfo>
            </titleStmt>
            <publicationStmt>
                <publisher>Alliance of Digital Humanities Organizations</publisher>
                <publisher>Association of Computers and the Humanities</publisher>

                <publisher>Association for Computers and the Humanities</publisher>
                <!-- This information will be completed at publication -->
                <idno type="DHQarticle-id">000431</idno>
                <idno type="volume"
                    >013</idno>
                <idno type="issue">3</idno>
                <date when="2019-10-21">10 October 2019</date>
                <dhq:articleType>article</dhq:articleType>
                <availability>
                    <cc:License rdf:about="http://creativecommons.org/licenses/by-nd/2.5/"/>
                </availability>
            </publicationStmt>

            <sourceDesc>
                <p>This is the source</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <classDecl>
                <taxonomy xml:id="dhq_keywords">
                    <bibl>DHQ classification scheme; full list available at <ref
                            target="http://www.digitalhumanities.org/dhq/taxonomy.xml"
                            >http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
                </taxonomy>
                <taxonomy xml:id="authorial_keywords">
                    <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
                </taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en" extent="original"/>
                <!-- add <language> with appropriate @ident for any additional languages -->
            </langUsage>
            <textClass>
                <keywords scheme="#dhq_keywords">
                    <!-- Authors may suggest one or more keywords from the DHQ keyword list, visible at http://www.digitalhumanities.org/dhq/taxonomy.xml; these may be supplemented or modified by DHQ editors -->
                    <list type="simple">
                        <item/>
                    </list>
                </keywords>
                <keywords scheme="#authorial_keywords">
                    <!-- Authors may include one or more keywords of their choice -->
                    <list type="simple">
                        <item/>
                    </list>
                </keywords>
            </textClass>
        </profileDesc>
        <revisionDesc>
            <!-- Each change should include @who and @when as well as a brief note on what was done. -->
            <change when="2019-10-18" who="murelj">finished encoding per author revisions</change>
        </revisionDesc>
    </teiHeader>
    <!-- If a translation is added to the original article, add an enclosing <text> and <group> element -->
    <text xml:lang="en" type="original">
        <front>
            <dhq:abstract>
                <!-- Include a brief abstract of the article -->
                <p>This article offers a methodological contribution to manually-assisted topic
                    modeling. With the availability of vast amounts of (online) texts, performing
                    full scale literary analysis using a close reading approach is not practically
                    feasible. The set of alternatives proposed by Franco Moretti (2000) under the
                    umbrella term of <q>distant reading</q> aims to show broad patterns that can be
                    found throughout the entire text collection. After a survey of literary-critical
                    practices that combine close and distant reading methods, we use manual
                    annotations of a thread on Reddit, both to evaluate an LDA model, and to provide
                    information that topic modeling lacks. We also make a case for applying these
                    reading techniques that originate in literary reading more broadly to online,
                    non-literary contexts. Given a large collection of posts from a Reddit thread,
                    we compare a manual, close reading analysis against an automatic, computational
                    distant reading approach based on topic modeling using LDA. For each text in the
                    collection, we label the contents, effectively clustering related texts. Next,
                    we evaluate the similarity of the respective outcomes of the two approaches. Our
                    results show that the computational content/topic-based labeling partially
                    overlaps with the manual annotation. However, the close reading approach not
                    only identifies texts with similar content, but also those with similar
                    function. The differences in annotation approaches require rethinking the
                    purpose of computational techniques in reading analysis. Thus, we present a
                    model that could be valuable for scholars who have a small amount of manual
                    annotation that could be used to tune an unsupervised model of a larger
                    dataset.</p>
            </dhq:abstract>
            <dhq:teaser>
                <!-- Include a brief teaser, no more than a phrase or a single sentence -->
                <p>Presents a model that could be valuable for scholars who have a small amount of
                    manual annotation that could be used to tune an unsupervised model of a larger
                    dataset.</p>
            </dhq:teaser>
        </front>
        <body>
            <head/>
            <div>
                <head>Introduction</head>
                <p>The management of ever-vaster amounts of information that bombard us daily is one
                    of the most important challenges we have been facing since the broad
                    availability of the Internet. Technological developments during this time have
                    drastically changed our abilities to access, process, and transfer information.
                    In particular, the popularity of Web 2.0, which places human interaction and
                    collaboration at its center, has led to massive amounts of available data.
                    Additionally, other types of data are made available, including the contents of
                    individual books that are integrated into bigger and bigger networks of texts,
                    usurped by the continuously expanding structures of online databases. Google, as
                    well as non-profit organizations such as Project Gutenberg, the Million Book
                    Project and the Internet Archive, carry out large-scale projects to scan and
                    upload the contents of whole libraries at a time. Kevin Kelly, co-founder of
                        <title rend="italic">Wired</title> magazine rejoices: <cit>
                        <quote rend="inline" source="#kelly2012">[o]nce books are digital, books
                            seep out of their bindings and weave themselves together. The collective
                            intelligence of a library allows us to see things we can’t see in a
                            single, isolated book</quote>
                        <ptr target="#kelly2012"/>
                    </cit>. So far, Google has scanned and made available over 30 million books. It
                    would take a human an estimated twenty thousand years to read such a vast
                    collection at the reasonable pace of two hundred words per minute, without
                    interruptions for food or sleep <ptr target="#aiden2013" loc="47"/>.</p>
                <p>Projects that make available great amounts of data, however, pose what Matthew
                    Wilkens calls a <quote rend="inline" source="#wilkens2012">problem of
                        abundance</quote>: <cit>
                        <quote rend="block" source="#wilkens2011">We don’t read any faster than we
                            ever did, even as the quantity of text produced grows larger by the
                            year. If we need to read books in order to extract information from them
                            and if we need to have read things in common in order to talk about
                            them, we’re going to spend most of our time dealing with a relatively
                            small set of texts. … each of us reads only a truly minuscule fraction
                            of contemporary fiction (on the order of 0.1 percent, often much less).
                            … we need to decide what to ignore.</quote>
                        <ptr target="#wilkens2011" loc="250"/>
                    </cit></p>
                <p>The field of Digital Humanities (DH) aims to offer methodological innovations to
                    solve this problem of abundance. Since 2000, many have followed Franco Moretti's
                    provocative call for distant reading. Moretti deemed close reading <quote
                        rend="inline" source="#moretti2000">a theological exercise</quote> and urged
                    humanists to <quote source="#moretti2000" rend="inline">read less</quote>.
                    According to some big data theorists, the act of sampling is <cit>
                        <quote rend="inline" source="#mayerschonberger2013">an artifact of a period
                            of information scarcity, a product of the natural constraints on
                            interacting with information in an analog era</quote>
                        <ptr target="#mayerschonberger2013" loc="16–17"/>
                    </cit>. With rich metadata and computational pattern matching, difficult texts
                    like <title rend="italic">The Making of Americans</title>, are now
                        <emph>not-readable</emph> in important new ways <ptr target="#don2007"/>
                    (see also <ptr target="#kirschenbaum2007"/>).</p>
                <p>Els Stronks has opined we should make the gap between close and distant as wide
                    as possible by further developing distant reading techniques, and at the same
                    time making our close readings more precise and skillful in order to interpret
                    the results gained by computational analysis <ptr target="#stronks2013"
                        loc="207"/>. Juxtaposition of the two, however, is mostly a polemical issue
                    or rhetorical strategy. According to Jeremy Rosen (2011), Wilkens makes it seem
                    like we have to choose between methods. Distant reading is not a replacement but
                    a supplement or alternative to traditional close reading practices. On the
                    contrary, <cit>
                        <quote rend="inline" source="#rosen2011">[t]he availability of voluminous
                            electronic data, one might conclude, makes it even more necessary to
                            cultivate the faculty of analyzing data closely and critically</quote>
                        <ptr target="#rosen2011"/>
                    </cit>. Indeed, in his study (2013) of changes in the geographic imagination of
                    American fiction around the Civil War, Wilkens exclusively makes use of distant
                    reading techniques. Yet, close and distant reading are by no means antithetical
                        <ptr target="#moretti2009"/>
                    <ptr target="#earhart2015"/>.</p>
                <p>Moretti's argument in <title rend="quotes">Slaughterhouse of Literature</title>
                    (2000) for instance, as one of the first applications of his distant reading
                    methods, relies entirely on manual annotation of 108 detective stories, read by
                    human beings in a graduate seminar (if not exactly <soCalled>close
                        reading,</soCalled> reading for clues involves at least skimming the text).
                    Many other works that are usually taken as representative of distant reading
                    rely extensively on manual annotation or close readings of illustrative literary
                    passages. So contrary to Moretti’s somewhat provocative proposition of distant
                    reading as alternative to close reading, his work typifies the importance of
                    human reading and tabulation. Yohei Igarashi <ptr target="#igarashi2015"/> has
                    shown how the interrelatedness between close and non-close reading predates the
                    digital humanities, as it occurs at least since educational word lists of the
                    early twentieth century.</p>
                <p>A brief survey of how different scales of analyses are connected in actual
                    literary-critical practice will show us that indeed, close and distant reading
                    were never mutually exclusive. In DH, this work has mostly been carried out in
                    literary history — see, for instance, a recent study on race, religion, and the
                    US novel <ptr target="#so2019"/>. Stephen Ramsay, in his book <title
                        rend="italic">Reading Machines</title> (2011), offers different methods to
                    engage in what he calls <cit>
                        <quote rend="inline" source="#ramsay2011">algorithmic criticism,</quote>
                        <ptr target="#ramsay2011"/>
                    </cit> criticism derived from algorithmic manipulation of text. Ramsay holds
                    that we should not take close reading to be diametrically opposed to
                    computational, data-driven approaches, since there are important similarities
                    between the two. Both methods are interpretive, in the sense that they transform
                    the original text into something else. <cit>
                        <quote rend="inline" source="#ramsay2011">The critic who endeavors to put
                            forth a <soCalled>reading,</soCalled> puts forth not the text, but a new
                            text in which the data has been paraphrased, elaborated, selected,
                            truncated, and transduced</quote>
                        <ptr target="#ramsay2011" loc="16"/>
                    </cit>. But the same is true for a computer-driven distant reading where the
                    original text is converted to information by an algorithm. In a recent issue of
                        <title rend="italic">PMLA</title>, moreover, several scholars reflect on
                    ways to nuance Moretti’s statements on <soCalled>not reading,</soCalled>
                    effectively reducing the distance between the two textual approaches <ptr
                        target="#booth2017"/>
                    <ptr target="#drucker2017"/>
                    <ptr target="#piper2017"/>.</p>
                <p>For a good overview of papers combining close and distant reading from 2005-2015,
                    see <ptr target="#janicke2015"/>. They argue that most papers that combine the
                    two usually follow the <title rend="quotes">Information Seeking Mantra</title>: <cit>
                        <quote rend="inline" source="#shneidermann1996">Overview first, zoom &amp;
                            filter, details on demand</quote>
                        <ptr target="#shneiderman1996"/>
                    </cit>. The output of a distant reading is then an overview of the data that
                    highlights potentially interesting patterns for close reading. They call this
                    most common form of connecting scales of analysis <q>top-down</q>: first, a
                    distant view on the textual data is shown, and later the details come into view.
                    One can think of the reading of Christina Rossetti in Ted Underwood’s <title
                        rend="quotes">The Longue Durée of Literary Prestige</title> (2016).
                    Underwood collected two samples of English-language poetry from 1820–1919: one
                    from volumes reviewed in prominent periodicals, and one of an obscure author,
                    randomly chosen from a large digital library. Looking at 360 reviewed and 360
                    random volumes, his study assessed the strength of the relationship between
                    poetic language and reception. The approach taken was to first look at broad
                    patterns, and then zoom in and read a few revealing passages. Likewise, in a
                    recent study of novelty in modernist texts <ptr target="#mcgrath2018"/>,
                    scholars first measure intratextual novelty and then use close reading of a
                    sample to test the measurements, scores, and graphs. Another <ptr
                        target="#lee2018"/> analyzes textual scale as a structuring principle of
                    geographical, spatial scale in studying the pre-modern world, by not-reading
                    tens of thousands of Renaissance books.</p>
                <p>Stanford Lit Lab pamphlet 4 <ptr target="#heuser2012"/> traces macroscopic
                    changes in the British novel during the nineteenth century. It signals two
                    interrelated transformations in novelistic language during this period: a
                    systemic concretization of language and a change in the social spaces of the
                    novel. The authors research quantifiable features such as word usage, adopting a <cit>
                        <quote rend="inline" source="#heuser2012">dialogic approach that oscillates
                            between the historical and the semantic, between empirical word
                            frequencies that reveal the historical trends of words and semantic
                            taxonomies that help us identify the meaning and content of those
                            trends</quote>
                        <ptr target="#heuser2012" loc="9"/>
                    </cit>. Through their <cit>
                        <quote rend="inline" source="#heuser2012">hypothesis-testing mode of
                            interpretation</quote>
                        <ptr target="#heuser2012" loc="49"/>
                    </cit>, they make sure their results are semantically and culturally
                    interpretable. This way, they offer a possible answer to what Alan Liu has
                    called the <quote rend="inline" source="#liu2013">meaning problem</quote> at the
                    heart of the digital humanities: to determine the relation between <cit>
                        <quote rend="inline" source="#liu2013">quantitative interpretation and
                            humanly meaningful qualitative interpretation</quote>
                        <ptr target="#liu2013" loc="414"/>
                    </cit>. As a certain measure of sampling when researching literary history is
                    unavoidable, the issue of canon vesus archive is of import here <ptr
                        target="#algeehewitt2016"/>. In digital research, a researcher often works
                    according to a process that Jo Guldi <ptr target="#guldi2018"/> calls winnowing:
                    careful culling and fine-tuning of the algorithm to get rid of false positives
                    or messy data, towards cleaner data and clearer results. In that respect, it is
                    in fact not so far removed from more traditional approaches such as close
                    reading the single text.</p>
                <p>Therefore, we follow this trend in mixing qualitative and quantitative methods
                    and using them to analyze corpora that solicit readings that zoom in and out
                    between part and whole. But rather than following the top-down approach or the
                        <title rend="quotes">Information Seeking Mantra,</title> in our mixed
                    method, manual annotation is not of a sample that follows from the overview
                    produced by the distant reading, but a method that comes before the LDA
                    analyses, to evaluate its workings and to reflect on its strengths and
                    weaknesses. </p>
                <p>We believe that this mostly literary-historical body of work since Moretti,
                    especially concerning the <cit>
                        <quote rend="inline" source="#moretti2000a">great unread</quote>
                        <ptr target="#moretti2000a" loc="227"/>
                    </cit> has value when it comes to the current <soCalled>information
                        overload</soCalled> that we exemplify here using a case study from web
                    platform Reddit. Here, we propose a transfer from the literary to non-literary
                    informational contexts. What is interesting for our purpose here is not some
                    presumed binary between close and distant reading. It is, rather, the collective
                    recognition, since Moretti, that literary history is not a clearly demarcated,
                    well-mapped, and exhaustible field, but an <cit>
                        <quote rend="inline" source="#moretti2000">uncharted expanse</quote>
                        <ptr target="#moretti2000"/>
                    </cit> whose macroscopic shape we cannot fully know. This is true, albeit in a
                    different, non-historical sense, for online web forums. By using a mixed method
                    of manual annotation and LDA, we propose a means to confront this other,
                    contemporary version of the <cit>
                        <quote rend="inline" source="#cohen1999">great unread</quote>
                        <ptr target="#cohen1999" loc="23"/>
                    </cit>. Other studies <ptr target="#jockers2016"/> rely and build on the
                    readings and value judgments of other professional readers to select their
                    corpus. In <soCalled>testing</soCalled> and <soCalled>correcting</soCalled>
                    previous gender and genre classifications of their peers, such studies have a
                    strong sense of tradition that studies of a contemporary phenomenon such as
                    Reddit threads obviously lack. </p>
                <p>As announced, we propose a strategy for using manual annotation to evaluate and
                    supplement an LDA model. Our analysis incorporates local annotation in a distant
                    reading. The investigation requires the development of computational tools
                    (e.g., topic identification, summarization) that deal with large amounts of
                    documents. This should provide large patterns in the dataset that enable a
                    fine-grained analysis of interesting parts of the data. Additionally, in-depth,
                    qualitative inspection of the performance of the computational analyses is
                    essential, in order to evaluate the computational approach. </p>
                <p>In this article, we investigate whether we can analyze a large document
                    collection from a distant reading perspective, indicating the different
                    semantics of the texts within the entire collection. This analysis is compared
                    against a manual, close reading analysis, to be able to evaluate the performance
                    of the computational approach. If the computational technique behaves similarly
                    to the manual approach, we can effectively use a distant reading technique to
                    complement the close reading analysis. Summarizing, our approach entails a
                    comparative analysis of the two reading methodologies: a close reading with
                    manual annotation on the one hand, and a distant reading with topic modeling on
                    the other. In order to explore both close and distant reading methods, we begin
                    by annotating the data both manually and computationally. This way, we can
                    reflect on and distillate the most valuable properties from both approaches. At
                    the same time we can evaluate the suitability of generic computational
                    techniques to high-quality manual analysis.</p>
                <p>In order to explore the possible strategies that are located between the extremes
                    of distant and close reading, we focus on a selected discussion thread of the
                    popular online forum Reddit. Applying reading strategies from a literary studies
                    context to this non-literary environment provides us a valuable insight into the
                    merits of these strategies in an age of digital information. Furthermore, the
                    Reddit thread is large enough to identify higher level patterns and manageable
                    enough for manual analysis. Additionally, the posts within the thread, which
                    pose suitable units of information, are expected to have different semantic
                    content.</p>
                <p>We will first give an overview of the close and distant reading methods employed
                    on a conceptual level, and then outline how we operationalized them in this
                    research. Following this, results of the comparison between the results found
                    using the two methods are presented and discussed in the context of efficiently
                    combining close and distant reading. This shows in how far we can use
                    computational techniques as a pre-processing phase to relieve us from a large
                    part of the labor-intensive work, enabling close reading of the interesting
                    parts of huge data collections, an informed choice based on the results of the
                    computational analysis. Lastly, we summarise the results and propose next
                    steps.</p>
            </div>
            <div>
                <head>Background</head>
                <div>
                    <head>Close Reading</head>
                    <p>Close reading is an umbrella term for an assortment of reading strategies
                        characterized by devout and detailed attention to the meaning and
                        composition of art works. The approach was made famous by the New Critics, a
                        group of Anglo-American literary scholars including Cleanth Brooks, William
                        K. Wimsatt, and Monroe C. Beardsley. Inspired by I.A. Richards (author of
                            <title rend="italic">Practical Criticism</title>, 1929), Matthew Arnold,
                        and T.S. Eliot, these scholars experienced their heyday of academic fame in
                        the forties and fifties of the last century. Going against contemporary
                        practices that, in their view, overvalued historical context and
                        biographical information, the New Critics suggested that literary scholars
                        should investigate the text itself. They wrote extensively on certain
                        contemporary fallacies of literary analysis, for instance, letting your own
                        emotions factor into the interpretation (the <cit>
                            <quote rend="inline" source="#wimsatt1949">affective fallacy</quote>
                            <ptr target="#wimsatt1949"/>
                        </cit>) or writing about authorial intentions (the <cit>
                            <quote rend="inline" source="#wimsatt1946">intentional fallacy</quote>
                            <ptr target="#wimsatt1946"/>
                        </cit>). Another practice they attacked was the paraphrasing of the contents
                        or message of a work (the <cit>
                            <quote rend="inline" source="#brooks1947">heresy of paraphrase</quote>
                            <ptr target="#brooks1947"/>
                        </cit>).<note>
                            <ptr target="#jockers2013" loc="6"/> Other seminal works to mention in
                            this respect are Cleanth Brooks and Robert Penn Warren’s <title
                                rend="italic">Understanding Poetry</title> (1938) and Laurence
                            Perrine’s <title rend="italic">Sound and Sense</title> (1956), which
                            together come close to <cit>
                                <quote rend="inline" source="#culler2010">an orthodoxy of close
                                    reading</quote>
                                <ptr target="#culler2010" loc="22"/>
                            </cit>.</note> Instead, this school propagated the careful examination
                        of evidence offered by the text itself: images, symbols, and metaphors as
                        part of a larger structure that gives the text its unity and meaning. Of
                        particular interest to the close reader were devices that create
                        ambiguities, paradoxes, irony, and other forms of tension within the text.
                        Moving from close to distant reading, the level of analysis shifts from
                        details within single texts to categories of many texts.</p>
                </div>
                <div>
                    <head>Distant Reading</head>
                    <p>Distant reading is the practice of aggregating and processing information
                        about, or content in, large bodies of texts without the necessity of a human
                        reader to read these texts <ptr target="#drucker2013"/>. Distant reading
                        corresponds to quantifying, computational reading methods and was introduced
                        by Franco Moretti with the intention to identify the bigger picture in large
                        collections of textual data that close reading cannot uncover.
                            <soCalled>Reading</soCalled> is outsourced to a computer: it is in fact
                        a form of data mining that allows information in (e.g., subjects, places,
                        actors) or about (e.g., author, title, date, number of pages) the text to be
                        processed and analyzed. The latter are called metadata: data about the data.
                        Natural language processing can analyze the contents of
                            <soCalled>practically unreadably</soCalled> large corpora of texts,
                        while with data mining we can expose patterns or summarize on a scale that
                        is beyond human capacity. </p>
                    <p>In his book <title rend="italic">Distant Reading</title> (2013) Franco
                        Moretti introduces the term polemically in explicit opposition to close
                        reading, which, to his mind, fails to uncover the true scope of literature.
                        Moretti is founder of the Stanford Literary Lab that seeks to confront
                        literary <soCalled>problems</soCalled> by scientific means – computational
                        modeling, hypothesis-testing, automatic text processing, algorithmic
                        criticism, and quantitative analysis. The Lab’s first pamphlet suggested
                        that literary genres <quote rend="inline" source="#allison2014">possess
                            distinctive features at every possible scale of analysis</quote> and
                        that there are formal aspects of literature that people, unaided, cannot
                        detect <ptr target="#allison2014" loc="8"/>. The second pamphlet used
                        network theory to re-envision plots <ptr target="#moretti2011"/>. Since
                        then, Jockers (2013) has further developed distant reading in what he has
                        called <quote rend="inline" source="#jockers2013">macroanalysis</quote>, a
                        new approach to the literary reading and study designed for exploring
                        digital texts in large quantities. Using computational tools to retrieve
                        keywords, key phrases, and linguistic patterns across thousands of digital
                        texts in databases allows researchers to attain quantifiable evidence on how
                        literary trends have evolved over time and geographically. It can also
                        determine what social, cultural, and historical connections exist between
                        individual authors, texts, and genres <ptr target="#jockers2013"/>. In this
                        article, we seek to combine such a macro-scaled method with close reading
                        and manual annotation, and apply it to a non-literary dataset.</p>
                </div>
            </div>
            <div>
                <head>Methodology</head>
                <div>
                    <head>Dataset</head>
                    <p>The text corpus used in the research described in this article comes from
                        Reddit, a social content aggregation website and the self-styled <q>front
                            page of the internet</q>. Functioning as <cit>
                            <quote rend="inline" source="#duggan2013">a bulletin of user-submitted
                                text, links, photos, and videos </quote>
                            <ptr target="#duggan2013" loc="2"/>
                        </cit>, it is a message board wherein users submit content and discuss this
                        content in different communities. The website is further referred to as a <cit>
                            <quote rend="inline" source="#gilbert2013">social voting site</quote>
                            <ptr target="#gilbert2013"/>
                        </cit> as users (often referred to as redditors) vote submitted content up
                        or down, sending the submissions with most upvotes to the Front page, i.e.,
                        the home page of reddit.com. Content on Reddit is organized in communities,
                        so called subreddits. The nearly 900,000 communities of Reddit are organized
                        around different topics like Technology, WorldNews, Music, Gaming, or
                        PoliticalDiscussion. A single subreddit can be reached via, for example, <hi
                            rend="italic">reddit.com/r/PoliticalDiscussion</hi>. The single posts in
                        one community are referred to as submissions. A submission usually contains
                        a link, embedded images, gifs, or videos and may also contain a text written
                        by the posting redditor. It is of special interest for textual analysis that
                        other redditors can comment on a submission and reply to other comments. The
                        comments are organized in a thread, a tree-like structure that allows for
                        following the discussion chronologically and with regard to content. From
                        any comment (every branch of the tree) further comments can emerge that yet
                        again may receive comments (as more branches sprouting from the prior
                        branch). Furthermore, redditors can make use of basic text formatting
                        functions, such as quoting text of prior comments or highlighting. The text
                        of the original submission and the comments on this submission are the
                        primary source of information of this research.</p>
                    <p>The thread that formed the basis of our dataset was submitted on January 19th
                        of 2017, and posed the following question: <hi rend="italic">Should the
                            Democrats nominate a celebrity in 2020? What would be the pros and
                            cons?</hi><note>
                            <ref target="https://redd.it/5oy1sz">https://redd.it/5oy1sz</ref></note>
                        Furthermore, the users added certain sub-questions, like: <hi rend="italic"
                            >Would celebrity power help or hurt a presidential nominee in the next
                            election?</hi> and <hi rend="italic">If this plan actually goes forward,
                            who would be the best choice?</hi>. Our dataset consists of 449 (461
                        including deleted comments) responses to these questions. Since the thread
                        is still open, comments have been added after we collected and investigated
                        our dataset. These new comments are not included in our research. </p>
                    <p>While investigations using Reddit data often aim at uncovering trends across
                        single discussions and even across discussion forums (subreddits) (cf. <ptr
                            target="#zhang2017"/>), the highest level of distant reading analysis in
                        this research is on the level of a single discussion thread. This restricts
                        the dataset to a size that can still be analysed by means of close reading
                        and also constrains the comments to relate, even if only peripherally, to
                        the one question or topic that initiated the discussion thread.</p>
                    <p>A common phenomenon in discussions in general is that the sub-questions
                        emerge and that the focus of the topics shifts to new content. This
                        illustrates that a technique is needed that can zoom in from the
                        whole-thread level to prevalent topics that group the single posts into
                        content categories. These single posts, on the other hand, can not only be
                        members of topical (content) groups, but also point towards groups related
                        to discourse function in Reddit discussions <ptr target="#zhang2017"/>. </p>
                    <p>The hierarchical structure of Reddit discussions, ranging from single
                        comments to a whole thread, matches our goal to contrast low-level close
                        reading with high-level distant reading. For a scholarly reading of a
                        discussion forum, neither isolated comments nor a high level view on the
                        discussion thread as a whole are sufficient. Scholars need to know about
                        topical groupings that provide a frame of reference for single comments.
                        While grouping of comments can be achieved by manual labeling, a distant
                        reading approach is promising as a method that is faster, that in principle
                        scales up to larger discussion threads, and that may remove some human
                        biases during the annotation process.</p>
                    <p>Yet, the role of irony, emotion, and humor in this thread warrants a close
                        reading approach. The pervasiveness of irony and ironic detachment in
                        contemporary (online) culture has been described by Ian Bogost as the <cit>
                            <quote rend="inline" source="#bogost2016">escape from having to choose
                                between earnestness and disdain,</quote>
                            <ptr target="#bogost2016" loc="59"/>
                        </cit>. Poe’s Law, an adage of Internet culture, states that online, it’s
                        impossible to know who’s joking and who’s being serious. In <title
                            rend="italic">The Ambivalent Internet</title> (2017), Whitney Phillips
                        and Ryan Milner show how digital communications, e.g., through GIFs, memes,
                        and videos, are operationalized to fundamentally destabilize the worldviews
                        of others. It is almost impossible to determine when an ironic posture is
                        adopted. Humor, irony, and role playing are central to the behaviors in
                        online environments and communities like those on reddit. A manual
                        annotation is to be expected to detect more of this humor and irony than a
                        topic model. Therefore, we have chosen to call the level of human annotation
                            <q>close reading</q>, which traditionally attends to tone and style as
                        well as content of the message. </p>
                </div>
                <div>
                    <head>Close reading</head>
                    <p>While the initial question of the Reddit thread regards viewpoints on the
                        pros and cons of a future celebrity president and the names of potential
                        Democrat candidates, the thread soon developed into a more complex
                        conversation in which different <soCalled>new</soCalled> questions were
                        discussed as well. In order to grasp these associative developments inside
                        the discussion and the mechanics of a forum like Reddit, we choose to employ
                        a hypothesis-free form of close reading, which means we first started
                        looking for patterns in the material of the discussion in a rather
                        open-ended way, without explicitly framing our horizon of expectation, or
                        what we were expecting to find, beforehand. We chose this approach since our
                        aim was first and foremost to comparatively analyze methodologies, and only
                        secondarily, to find an answer to the question posed in the thread,
                        regarding celebrities in politics. </p>
                    <p>This process took place in a bottom-up fashion: two human annotators analyzed
                        the posts in the thread, and chose a word or phrase to summarize each post.
                        During this process, they developed a collection of labels that were
                        assigned to the posts. Based on this reading, fifteen classes of posts were
                        identified and color-coded based on the classes. Ten of them turned out to
                        be related to three different underlying questions that we formulated based
                        on the classes. We describe these at more length under <title rend="quotes"
                            >report of the close reading analysis</title>. After manually annotating
                        the 449 posts separately, we compared the lists of the outcome and slightly
                        modified the categories to accommodate both our findings. Upon comparison,
                        we discovered there was a high degree of congruence between the categories
                        assigned to the posts in both annotations. </p>
                </div>
                <div>
                    <head>Distant reading</head>
                    <p>Parallel to the close reading based, manual annotations, we approach the
                        Reddit thread from a distant reading perspective. Specifically, we adopt a
                        data-driven ideal of distant reading, i.e. we want to start analysing
                        without any human insight into the textual dataset. This results in two
                        requirements on a distant reading method: First, the approach needs to be
                        unsupervised, i.e. not relying on any prior labeling of the data. Second,
                        the fact that Reddit threads are open-ended in the topics they comprise, the
                        number of topics in the shape of clusters resulting from the distant reading
                        algorithm needs to be variable. At least, there needs to be a possibility to
                        model a range of clusters in a computationally feasible manner. These two
                        requirements can be understood as equivalent to the hypothesis-free aspects
                        (of the close reading approach) in our distant reading method. </p>
                    <p>One technique that fulfills both requirements is Latent Dirichlet Allocation
                        (LDA) topic modeling <ptr target="#blei2003"/>. This method allows for the
                        automatic grouping of text documents according to latent content categories.
                        These topics underlying a text corpus are modelled in a completely
                        unsupervised manner, meaning that the algorithm does not know which texts
                        belong together (for example, according to some human labeling) beforehand.
                        This aspect of unsupervised LDA thus serves a data-driven ideal of distant
                        reading. For each topic, LDA creates a different language model, as the
                        underlying assumption is that different topics require different words and
                        constructions. In our research, we expect that LDA is suitable as texts with
                        different topics are expected to use a different
                            <soCalled>language</soCalled>.</p>
                    <p>Importantly, the number of topics resulting from LDA is a parameter that is
                        set manually by the user. While determining an adequate number of topics for
                        a dataset is often a problematic challenge for which no definite solutions
                        are agreed on, the variability of the resulting number of cluster matches
                        the second requirement to our desired distant reading technique. Because it
                        is unknown how many topics are to be expected from a discussion thread, a
                        pass through a range of numbers of LDA topics is necessary. Investigating a
                        whole range of numbers of topics may additionally reveal several different
                        levels of topical granularity that can be captured using LDA.</p>
                    <p>LDA has already been used for text analysis in the area of Digital
                        Humanities. For example, Emmery and van Zaanen (2015) investigated the
                        application of LDA to identify changes in the number of comments on news
                        articles on the topic of online security before and after the Snowden
                        revelation in 2013.</p>
                    <p>Lastly, we choose LDA as counterpart to close reading, since both approaches
                        focus on content of the texts (posts within the Reddit thread). We
                        strengthen this perspective by removing stop words (which are mostly
                        function words) from the textual data, before modeling topics with LDA.</p>
                    <p>As mentioned above, deciding on the optimal number of topics to be modeled is
                        problematic. In the case of a Reddit thread, new topics unfold as the
                        discussion proceeds, which means that the number of topics depends on the
                        size of the Reddit thread. It is therefore difficult to make an informed
                        decision about the number of topics for an LDA model, based on manual
                        inspection of comments alone. To resolve this problem, we propose a
                        possibility to determine an adequate number of topics for a set of already
                        present manual annotations. </p>
                    <p>During the annotation process, each post (the original thread submission
                        question or a comment on it) in the Reddit thread is treated as a separate
                        document (<ref target="#figure01">Figure 1</ref>, left). For each document,
                        the LDA topic with the highest probability is selected. This is certainly a
                        limiting decision, but we find that the per-document probability
                        distributions usually strongly favor one single topic with a very high
                        probability, while the probabilities for the other topics are close to
                        zero.</p>
                </div>
                <div>
                    <head>Comparison of the approaches</head>
                    <p>After analyzing the documents, they are thus represented by two labels, one
                        from two distinct sets of annotations each: a close reading annotation and a
                        (single) LDA topic. Based on this information, we now aim to identify LDA
                        topics and manual annotations that express similar concepts. Going through
                        the list of documents, co-occurrences of the two annotations are counted in
                        a matrix (<ref target="#figure01">Figure 1</ref>, right, LDA topics in
                        columns, manual annotation classes in rows).</p>
                    <figure xml:id="figure01">
                        <head>Co-occurrences of manual annotation classes and LDA classes are
                            counted in a matrix. Only the most probable LDA class per document is
                            taken into account.</head>
                        <graphic url="resources/images/figure01.png"/>
                        <figDesc/>
                    </figure>
                    <p>Given the co-occurrence matrix, the aim is to find, for each LDA topic, the
                        manual annotation class that is best represented by the topic. In order to
                        do so, the matrix is passed columnwise, and the manual annotation class in
                        the row with the highest count is selected as corresponding best to the LDA
                        class of that column. At this point we introduce an optional step of
                        normalisation, applied on the co-occurrence matrix (<ref target="#figure02"
                            >Figure 2</ref>). Collecting absolute counts in the matrix may give an
                        unfair advantage to annotation tags with high class support. During
                        normalisation, the counts are divided by the class support of the manual
                        annotation class of this row, resulting in fractions instead of absolute
                        numbers. The steps described in the rest of this article always make use of
                        both the absolute counts and the normalised counts matrix separately.</p>
                    <figure xml:id="figure02">
                        <head>Normalising co-occurrence counts, by dividing by manual class
                            support.</head>
                        <graphic url="resources/images/figure02.png"/>
                        <figDesc/>
                    </figure>
                    <p>For each manual/LDA pair of classes with highest co-occurrence, we generate a
                        mapping from LDA classes to manual annotation classes (<ref
                            target="#figure03">Figure 3</ref>). The mapping expresses classes of
                        annotations that, from now on, we regard as corresponding to each other.
                        Note that, as in the example of <ref target="#figure03">Figure 3</ref>, not
                        necessarily all manual annotation classes are covered by the mapping.</p>
                    <figure xml:id="figure03">
                        <head>Using the highest value per column in the co-occurrence matrix
                            (absolute counts shown), a mapping from LDA class to close reading class
                            is created.</head>
                        <graphic url="resources/images/figure03.png"/>
                        <figDesc/>
                    </figure>
                    <p>Using the mapping, the LDA classes are translated into manual annotation
                        classes (<ref target="#figure04">Figure 4</ref>). These can be regarded as
                        the computer’s <soCalled>guess</soCalled> of the manual class that was
                        assigned by a human. In the original list of documents, each document is now
                        represented by two annotations that are drawn from one <emph>common</emph>
                        pool of possible annotations. In machine learning terms, the manual
                        annotations are treated as gold standard (or true labels) and the mapped LDA
                        classes are regarded as predictions. To measure the extent to which the
                        predictions and the gold standard overlap, we calculate the accuracy.</p>
                    <figure xml:id="figure04">
                        <head>Using the mapping, the per document LDA annotation is transformed to
                            manual classes.</head>
                        <graphic url="resources/images/figure04.png"/>
                        <figDesc/>
                    </figure>
                    <p>For a single topic model, we have now obtained a measure of overlap between
                        close reading based, manual annotations and distant reading LDA topics. In
                        order to find the optimal topic model, several topic models with varying
                        numbers of topics can be computed and the overlap accuracy can be compared.
                        For the present study, we produced topic models with a number of topics
                        ranging from 1 topic to <hi rend="italic">N</hi> topics, with an <hi
                            rend="italic">N</hi> equal to the number of documents in the collection.
                        We expect a topic model with as many topics as are documents in the corpus
                        to be of low expressive power. Similarly, a topic model with only one LDA
                        class cannot adequately express several manual annotation classes. </p>
                    <p>For the Reddit thread on the question <hi rend="italic">Should the Democrats
                            nominate a celebrity in 2020? What would be the pros and cons?</hi>,
                        overlap accuracy is calculated for LDA models with 1 to 461 topics. The
                        topic model with the best fit to the manual annotations is defined as the
                        topic model corresponding to the highest accuracy value.</p>
                    <p>Note that increasing the number of LDA topics leads to a higher likelihood of
                        high accuracy. Imagine the situation in which each document receives a
                        unique LDA class. This allows for a perfect accuracy, but the predictive
                        power is extremely low as no document is comparable according to the LDA
                        classes. To resolve this issue, a second possibility to determine the
                        optimal number of topics is also investigated. Here, we reverse the mapping
                        step and transform manual classes to LDA classes. The steps described above
                        stay the same, except the co-occurrence matrix is passed row-wise instead of
                            column-wise<note> It is equally possible to simply transpose the input
                            matrix and leave all other steps the same.</note>. </p>
                    <p>As seen in the results, both the forward mapping and the reverse mapping
                        result in a perfect solution: Mapping LDA classes to manual classes leads to
                        increasingly high accuracy with an increasing number of topics. Mapping
                        manual classes to LDA classes, in turn, leads to complete overlap for a
                        single LDA class, because all manual classes are correctly mapped to that
                        single LDA class. The maximum accuracy values in the two scenarios are
                        misleading because neither having a single LDA topic nor having hundreds is
                        useful for the purpose of distant reading. In our approach we exploit this
                        phenomenon by aiming for the right balance between the two perfect
                        solutions. We do so by calculating the absolute difference between forward
                        and reverse accuracy for each number of topics. Subsequently, we select the
                        number of topics with the lowest absolute difference in the accuracies from
                        the forward and reverse mapping.</p>
                </div>
            </div>
            <div>
                <head>Results</head>
                <div>
                    <head>Report of the close reading analysis</head>
                    <p>Based on the close reading strategy described above, we identify fifteen
                        classes of posts (<ref target="#table01">Table 1</ref>). Ten of them are
                        related to three different underlying questions that we formulate based on
                        the classes: <hi rend="italic">What characteristics should a president have
                            in order to be a good leader?</hi> (Red, class 1-3), <hi rend="italic"
                            >Which parties could influence the likeability of a potential
                            president?</hi> (Green, class 4-5), <hi rend="italic">In which political
                            climate and context is the question discussed?</hi> (Blue, class 6-10).
                        The other five are classified as <q>actions</q> that are divided over two
                        groups, hyperlinks to other sources (Yellow, class 11-12) and
                        (self-)referential comments/responses (Purple, class 13-15). </p>
                    <table xml:id="table01">
                        <head>Close reading annotation classes.</head>
                        <row>
                            <cell><graphic url="resources/images/table01.png"/></cell>
                        </row>
                    </table>
                    <figure xml:id="figure05">
                        <head>Linear data-visualization of the Reddit thread.</head>
                        <graphic url="resources/images/figure05.png"/>
                        <figDesc/>
                    </figure>
                    <p>By assigning colors to the classes that relate to the same question or
                        action, we can distinguish the variety of discussions inside one subreddit
                        and see how these discussions develop throughout the thread (<ref
                            target="#figure05">Figure 5</ref>). From left to right, the first 130
                        comments mostly discuss the political climate (Blue) (e.g., <hi
                            rend="italic"><q>Democrats didn’t show up. Republican turnout fairly
                                steady.</q></hi> (post 63)). These comments seem to create a context
                        for the discussion as a whole. Thereafter, the characteristics of an ideal
                        president are discussed (Red) (e.g., <hi rend="italic"><q>I say charisma
                                goes a long way, part of being president is to inspire people. Dems
                                should go young and the candidate should be well spoken (Obama) and
                                inspiring. Leave the dynasties, get someone younger, inspire people
                                to come out and vote for them.</q></hi> (post 120)). Near the end,
                        the influence of media and celebrity culture are set against the former
                        discussions (Green) (e.g., <hi rend="italic"><q>Do you think he would’ve won
                                the popular vote if not for that video</q></hi> (post 17)). The
                            <soCalled>actions</soCalled> of hyperlinking (Yellow), joking (e.g., <hi
                            rend="italic"><q>We’ll get him a box. Worked for Napoleon.</q></hi>
                        (post 239)) and (emotional) responding (e.g., <hi rend="italic"><q>I’ll
                                concede that that’s an excellent point.</q></hi> (post 57)) (Purple)
                        occur equally frequent throughout the whole subreddit. The variety of
                        questions discussed in the subreddit does not seem to occur randomly, but in
                        clusters: We can see a certain development in how the colors follow each
                        other up.</p>
                </div>
                <div>
                    <head>Report of the distant reading analysis</head>
                    <p>Following application of the LDA topic modeling technique and the process to
                        assign LDA topics to manual topics, we measure the overlap between manual
                        and computational annotation. Accuracy measures are obtained for a varying
                        number of topics in the LDA model. <ref target="#figure06">Figure 6</ref>
                        plots the overlap accuracy over the number of topics. It can be observed
                        that the accuracy keeps increasing with higher numbers of topics in the LDA
                        models. The reason for this is, that with more LDA topics, more and more
                        topics get assigned to only one document. During the mapping, the single
                        occurrence of an LDA class is necessarily converted to the correct manual
                        annotation class. This creates the aforementioned perfect solution to the
                        mapping problem. However, the model with the highest overlap accuracy has
                        low generalising power. Such a detailed topic model moves away from the
                        desired distant reading perspective, which would group the comments into a
                        limited set of categories. </p>
                    <figure xml:id="figure06">
                        <head>Evolution of overlap accuracy over the number of topics used in the
                            LDA model.</head>
                        <graphic url="resources/images/figure06.png"/>
                        <figDesc/>
                    </figure>
                    <p>In order to resolve the problem of overspecification, we look at a
                        combination of the forward and reverse accuracy. As outlined above, we
                        balance the two LDA to manual assignment and manual to LDA assignment scores
                        and inspect where the two curves intersect. The intersection is defined as
                        the number of topics with the lowest absolute difference in accuracy. <ref
                            target="#figure07">Figures 7</ref> and <ref target="#figure08">8</ref>
                        depicts forward and reverse accuracies over number of topics based on
                        absolute and normalised co-occurrence counts.</p>
                    <figure xml:id="figure07">
                        <graphic url="resources/images/figure07.png"/>
                        <figDesc/>
                    </figure>
                    <figure xml:id="figure08">
                        <head>Evolution of the forward (LDA to manual class) and reverse mapping
                            accuracies.</head>
                        <graphic url="resources/images/figure08.png"/>
                        <figDesc/>
                    </figure>
                    <p>To evaluate how well the LDA model overlaps with the manual annotations it is
                        of fundamental importance to compare the performance against a baseline. As
                        baseline we use a random assignment of the manual annotations to the
                        documents. We explicitly decide not to make use of another common baseline,
                        the majority class baseline. The reason for this is that we aim to cover all
                        classes instead of just a single one and random assignment better reflects
                        this goal. The random assignment labels are then compared to the actual
                        manual assignment. This process is bootstrapped and averaged over 1000
                        trials. The accuracy measures derived from the random assignment and the LDA
                        topic models are presented in <ref target="#table02">Table 2</ref>.
                        Regardless of whether the co-occurrence matrix is normalised for class
                        support the LDA classes lead to a higher overlap with the manual annotations
                        than the random assignment. The overlap between the LDA classes and the
                        manual annotations is thus above chance level. Comparing the non-normalised
                        model to the normalised model it can be observed that normalisation
                        increases recall by covering relatively many manual classes to the mapping
                        even when a small number of topics is modeled. </p>
                    <p>For the Reddit thread case study, the described process results in a topic
                        model with 6 topics that has the highest overlap with the gold standard
                        annotations. However, the measures based on absolute counts are still
                        strongly biased towards the majority class. Since we intend to cover all
                        classes as well as possible, the accuracy based on absolute counts is too
                        optimistic for our purpose. The corresponding model using normalised counts
                        may better generalise to all classes. According to the model normalised for
                        class support, 23 topics best represent the manual annotation.</p>
                    <table xml:id="table02">
                        <head>Baseline accuracy (random assignment) and maximum accuracies based on
                            the proposed overlap measures with their corresponding number of
                            topics.</head>
                        <row>
                            <cell/>
                            <cell>Accuracy</cell>
                            <cell>Number of Topics</cell>
                        </row>
                        <row>
                            <cell>Baseline <lb/> (Random Assignment)</cell>
                            <cell>6.03%</cell>
                            <cell>-</cell>
                        </row>
                        <row>
                            <cell>Forward + Reverse<lb/> (absolute counts matrix)</cell>
                            <cell>29.17%</cell>
                            <cell>6</cell>
                        </row>
                        <row>
                            <cell>Forward + Reverse<lb/> (normalised counts matrix)</cell>
                            <cell>13.01%</cell>
                            <cell>23</cell>
                        </row>
                    </table>
                </div>
            </div>
            <div>
                <head>Discussion</head>
                <p>The manual annotation revealed that we did not only identify several opinions or
                    find information that regards the question that the thread set out from; in
                    addition, we found another class of posts that we choose to describe along the
                    lines of <hi rend="italic">discourse function</hi>: for instance, humor,
                    hyperlinks, or direct responses (e.g., <q>yes</q>, <q>no</q>, <q>indeed</q>).
                    These are elements that fulfill a certain function within the larger collective
                    discourse, without being reducible to an answer to the main question, an opinion
                    or a piece of information. The posts that fall within the function classes do
                    not correspond to specific topics, so it is likely that these elements can only
                    be identified by close reading. In particular, posts that deal with humor and
                    irony are hard to identify computationally, which underlines the importance of
                    human annotation. The bottom-up process of manual annotation and our
                    hypothesis-free form of close reading unraveled underlying questions and
                    contexts that we can use to aid computational strategy.</p>
                <p>The manual annotation (close reading), as made visible by the color coding, seems
                    to point to an associative structure between the comments. So far, our close
                    reading approach regards the posts in a linear (chronological) order, while our
                    distant reading methodology regards the posts without any order or structure.
                    However, Reddit also organizes posts in hierarchical structure. What further
                    differentiates Reddit from a real-time information network like Twitter is that
                    the community curates the stream of content themselves. Items that they consider
                    to be of value are <soCalled>upvoted</soCalled>, and those deemed unworthy are
                        <soCalled>downvoted</soCalled>. This way the position of root comments
                    within one single thread, i.e., comments that directly reply to the original
                    submission, is determined by Reddit’s voting system. We did not investigate this
                    in the current research, but it will certainly influence the required reading
                    strategy for this specific environment. Note that the current distant reading
                    approach cannot easily incorporate the inherent hierarchical information of the
                    dataset.</p>
                <p>By supplementing our close reading with a distant reading methodology, we can
                    give the reader an overview of the relations between the discussions. The idea
                    of studying the hierarchical structure, which with the present method remains
                    un(der)explored, will be the next step in our research. Examining this
                    hierarchical structure as an extra dimension is necessary in order to come to a
                    more comprehensive take on the information we encounter on this online platform. </p>
                <p>Second, there is a problem with the hypothesis-free approach, as employed in our
                    study. A predetermined research question aids in keeping the set of close
                    reading annotation types controlled, i.e., a small number of unique topics as
                    well as topics that stay within concise conceptual borders. Still, there are
                    many questions on the close reading side, leading to different collections of
                    close reading classes and we need to determine which of those correspond to the
                    identified distant reading classes. In other words, it is as of yet unclear how
                    generalizable this approach is.</p>
                <p>We have proposed a way to find a mapping from LDA to manually assigned classes.
                    The analysis of the close and distant reading demonstrates that LDA is indeed a
                    possibility to generate a computational model of close reading annotations.
                    However it needs to be clearly stated that the overlap between the two sets of
                    labels, as measured by accuracy, is relatively low. This may, first, be due to
                    the rather high number of 15 classes of comments on a relatively small dataset
                    (461 comments). Second, some of the close reading based classes describe
                    function rather than content. LDA topic modeling is designed to primarily
                    capture content information and may thus not be able to accurately capture
                    functional classes. </p>
                <p>Still, the proposed approach leads to an overlap above chance level and future
                    work should try to further increase the overlap. If we can find an LDA model
                    that overlaps well with a set of annotations it is possible to generalise from
                    the LDA model to new, unseen data. From this point on, less manual annotation
                    would be needed, which would benefit the literary analysis by extending the size
                    of the data. Conclusions can then be drawn on the grounds of a larger
                    dataset.</p>
                <p>Finally, the research was carried out by a diverse group of researchers, both
                    from a computational and a cultural studies background. The interdisciplinary
                    character of the research group is essential for this type of research, but also
                    introduces challenges. The terminology used in the two fields is not exactly the
                    same, which leads to a confusion of tongues. For example, clustering texts is
                    not the same as close reading, even though the resulting information may be used
                    as the basis for close reading. Furthermore, close reading entails much more
                    than human annotation of text samples. We believe that for a successful
                    application of distant reading approaches in a close reading context, this
                    language or terminology boundary between the disciplines needs to be
                    crossed.</p>
            </div>
            <div>
                <head>Conclusion</head>
                <p>We have argued that close and distant reading, from the beginning of the latter,
                    have gone hand in hand, other than Moretti’s polemic introduction to the topic
                    would suggest. Studies that use distant reading methods and combine it with
                    close reading most often follow the information seeking mantra or top down
                    approach (overview first, zoom &amp; filter, details on demand). As an
                    alternative, we presented a study in which we used manual annotation not as a
                    sample that follows from the overview produced by the distant reading, but a
                    method that comes before, or runs parallel to, the LDA analyses, to evaluate its
                    workings and to reflect on its strengths and weaknesses. We used close reading
                    of posts and manual annotation to fill in the gaps, to evaluate and to reflect
                    upon the LDA distant reading.</p>
                <p>We see that close reading may reveal interesting detailed knowledge that distant
                    reading may not find, while distant reading allows for the identification of
                    large-scale patterns by analyzing vast collections of text that cannot be seen
                    when only analyzing small amounts. Reading the same corpora at different scales
                    using differently tuned digital instruments can then be more illuminating than
                    either close or distant reading of their own accord.</p>
                <p>Close reading digs for complexity, opacity, irony, and ambiguity: values that
                    stand to be reappraised in a time when we encounter vast bodies of information
                    through multiple platforms, and when, moreover, we tend to overemphasize
                    transparency and immediacy when processing this information. Even though we live
                    in a time that tends to privilege the <soCalled>full picture</soCalled> and
                    distrust sampling, we contend with Johanna Drucker that meaning-making is
                    precisely based on editing, focus, and finitude: <cit>
                        <quote rend="inline" source="#drucker1997">Editing towards meaning is a
                            fundamental skill of human survival, through the selection of pertinent
                            information, which accumulates in a significant pattern</quote>
                        <ptr target="#drucker1997" loc="109"/>
                    </cit>. Yet, another indispensable skill in a time of information overload is
                    the ability to skim, to filter out, and to ignore the inessential. </p>
                <p>Therefore, we undertook a first, explorative step in this paper towards a mixed
                    methodology where the input of a close reading drives the analysis of the
                    distant reading: an analysis that incorporates local annotation in a
                        <soCalled>distant</soCalled> analysis. We have investigated and evaluated
                    the use of the content-oriented LDA technique to identify clusters of texts in a
                    way that simulates a close reading approach. Automatic analysis allows for a
                    motivated selection of documents that should be considered for a deeper close
                    reading analysis. Regarding distant reading methodologies, we find that our
                    current approach that relies on LDA topic modeling cannot fully replace manual
                    annotations altogether. Still, it may be valuable to extend from already present
                    manual annotations. Future work will focus on human-in-the-loop approaches, such
                    as labeled LDA <ptr target="#ramage2009"/>, which can steer the clustering
                    method based on prior human-proposed knowledge. LDA topic modeling could then be
                    used to find content-based clusters with a higher density of keywords,
                    questions, and topics. Once clustered, the groups can be submitted to a closer
                    (close reading) analysis. Our further research will explore and evaluate this
                    possibility for Reddit discussions.</p>
            </div>
            <div type="acknowledgements">
                <p>This work was supported by the Institute for Advanced Study in Budapest.</p>
            </div>
        </body>
        <back>
            <listBibl>
                <bibl xml:id="aiden2013" label="Aiden and Michel 2013">Aiden, E., and J. Michel.
                        <title rend="italic">Uncharted: Big Data as a Lens on Human Culture</title>.
                    New York: Penguin, 2013. </bibl>
                <bibl xml:id="algeehewitt2016" label="Algee-Hewitt et al. 2016">Algee-Hewitt, M., S.
                    Allison, M. Gemma, R. Heuser, F. Moretti, and H. Walser. <title rend="quotes"
                        >Canon/Archive. Large-scale Dynamics in the Literary Field.</title>
                    <title rend="italic">Literary Lab Pamphlet 11</title>, 2016.</bibl>
                <bibl xml:id="allington2016" label="Allington et al. 2016">Allington, D.,
                    Brouillette, S., and D. Golumbia. <title rend="quotes">Neoliberal Tools (and
                        Archives): A Political History of Digital Humanities.</title>
                    <title rend="italic">LA Review of Books</title>, May 1, 2016, pp. 1-5.</bibl>
                <bibl xml:id="allison2014" label="Allison et al. 2014">Allison, S., et al. <title
                        rend="quotes">Quantitative Formalism: An Experiment.</title>
                    <title rend="italic">Stanford Literary Lab, Pamphlet 1</title>, 15 Jan. 2011.
                    Web. 16 April 2014.</bibl>
                <bibl xml:id="blei2003" label="Blei et al. 2003"> Blei, D.M., Ng, A.Y., and M.I.
                    Jordan. <title rend="quotes">Latent dirichlet allocation.</title>
                    <title rend="italic">Journal of machine Learning research</title> , vol. 3, no.
                    Jan., 2003, pp. 993-1022. </bibl>
                <bibl xml:id="bogost2016" label="Bogost 2016">Bogost, I., 2016. <title rend="italic"
                        >Play Anything. The Pleasure of Limits, the Uses of Boredom, and the Secret
                        of Games</title>. New York: Basic Books, 2016.</bibl>
                <bibl xml:id="booth2017" label="Booth 2017"> Booth, A. <title rend="quotes"
                        >Mid-range Reading: Not a Manifesto.</title>
                    <title rend="italic">PMLA</title> 132.2, 2017. 620–627. </bibl>
                <bibl xml:id="brooks1947" label="Brooks 1947">Brooks, C. <title rend="italic">The
                        Well-wrought Urn: Studies in the Structure of Poetry</title>. San Diego:
                    Harcourt, 1947.</bibl>
                <bibl xml:id="cohen1999" label="Cohen 1999">Cohen, M. <title rend="italic">The
                        Sentimental Education of the Novel</title>. Princeton: Princeton University
                    Press, 1999.</bibl>
                <bibl xml:id="compagnon2014" label="Compagnon 2014">Compagnon, A. The Resistance to
                    Interpretation. <title rend="italic">New Literary History,</title> vol. 45, no.
                    2,2014, pp. 271- 80.</bibl>
                <bibl xml:id="culler2010" label="Culler 2010">Culler, J. <title rend="quotes">The
                        Closeness of Close Reading.</title>
                    <title rend="italic">ADE Bulletin</title> vol. 149, no. -, 2010, pp.
                    20-25.</bibl>
                <bibl xml:id="don2007" label="Don et al. 2007-08">Don, A., Zheleva, E., Gregory, M.,
                    Tarkan, S., Auvil, L., Clement, T., Shneiderman, B., Plaisant, C. <title
                        rend="quotes">Discovering interesting usage patterns in text collections:
                        integrating text mining with visualization.</title> HCIL Technical Report,
                    2007-08. </bibl>
                <bibl xml:id="duggan2013" label="Duggan and Smith 2013">Duggan, M., and A. Smith.
                        <title rend="quotes">6% of online adults are reddit users.</title>
                    <title rend="italic">Pew Internet &amp; American Life Project</title>, vol. 3,
                    no. Jul., 2013, pp. 1-10.</bibl>
                <bibl xml:id="drucker2013" label="Drucker 2013">Drucker, J. <title rend="italic"
                        >Intro to Digital Humanities</title>, Sept. 2013. Web. 10 Aug. 2015.</bibl>
                <bibl xml:id="drucker1997" label="Drucker 1997">Drucker, J. <title rend="quotes">The
                        Self-Conscious Codex: Artists’ Books and Electronic Media.</title>
                    <title rend="italic">SubStance</title>, vol. 26, no. 1, 1997, pp. 93-112.</bibl>
                <bibl xml:id="drucker2017" label="Drucker 2017"> Drucker, J. <title rend="quotes"
                        >Why Distant Reading Isn’t.</title>
                    <title rend="italic">PMLA</title> 132.3, 2017. 628–35. </bibl>
                <bibl xml:id="earhart2015" label="Earhart 2015">Earhart, A. <title rend="italic"
                        >Traces of the Old, Uses of the New: The Emergence of Digital Literary
                        Studies</title>. Ann Arbor: University of Michigan Press, 2015.</bibl>
                <bibl xml:id="emmery2015" label="Emmery and van Zaanen 2015">Emmery, C., and M. van
                    Zaanen. <title rend="quotes">Modelling Discussion Topics to Improve News Article
                        Tagging</title>. Presented at the 2nd Digital Humanities Benelux Conference
                    (DHBenelux 2015), Antwerp, Belgium. 9 June 2015.</bibl>
                <bibl xml:id="gilbert2013" label="Gilbert 2013">Gilbert, E. <title rend="quotes"
                        >Widespread underprovision on Reddit.</title>
                    <title rend="italic">Proceedings of the 2013 conference on Computer supported
                        cooperative work</title>. ACM, 2013.</bibl>
                <bibl xml:id="guldi2018" label="Guldi 2018">Guldi, J. <title rend="quotes">Critical
                        Search: A Procedure for Guided Reading in Large-Scale Textual
                        Corpora,</title> <title rend="italic">Journal of Cultural
                    Analytics</title>. December 20, 2018.</bibl>
                <bibl xml:id="heyman2015" label="Heyman 2015">Heyman, S. <title rend="quotes">Google Books: A complex and
                    controversial experiment</title>. <title rend="italic">New York Times</title>, <title
                        rend="italic">28</title>, 2015. </bibl>
                <bibl xml:id="igarashi2015" label="Igarashi 2015">Igarashi, Y. <title rend="quotes"
                        >Statistical Analysis at the Birth of Close Reading.</title>
                    <title rend="italic">New Literary History</title>, Vol. 46, no. 3, 2015. pp.
                    485-504.</bibl>
                <bibl xml:id="janicke2015" label="Jänicke et al. 2015">Jänicke, S., G. Franzini, M.
                    F. Cheema, and G. Scheuermann. <title rend="quotes">On close and distant reading
                        in digital humanities: A survey and future challenges.</title>
                    <title rend="italic">Eurographics Conference on Visualization (EuroVis)-STARs.
                        The Eurographics Association</title>, 2015.</bibl>
                <bibl xml:id="jockers2013" label="Jockers 2013">Jockers, M. <title rend="italic"
                        >Macroanalysis: Digital Methods and Literary History</title>. Urbana:
                    University of Illinois Press, 2013.</bibl>
                <bibl xml:id="kelly2012" label="Kelly 2012">Kelly, K. <title rend="quotes">Scan This
                        Book!</title>
                    <title rend="italic">The New York Times Magazine</title>, 14 May 2006. Web. 25
                    April 2012.</bibl>
                <bibl xml:id="kirschenbaum2007" label="Kirschenbaum 2007">Kirschenbaum. M. <title
                        rend="quotes">The Remaking of Reading: Data Mining and the Digital
                        Humanities.</title> NF Symposium on Next Generaion of Data Mining and
                    Cyber-Enabled Discovery for Innovation. 11 October 2007.</bibl>
                <bibl xml:id="lee2018" label="Lee et al. 2018">Lee, J.J., B. Greteman, J. Lee, and
                    D. Eichmann, <title rend="quotes">Linked Reading: Digital Historicism and Early
                        Modern Discourses of Race around Shakespeare's Othello,</title>
                    <title rend="italic">Journal of Cultural Analytics</title>. Jan. 25,
                    2018.</bibl>
                <bibl xml:id="liu2013" label="Liu 2013">Liu, A. <title rend="quotes">The Meaning of
                        the Digital Humanities,</title>
                    <title rend="italic">PMLA</title> vol. 128, no. 2, 2013. pp. 409-23.</bibl>
                <bibl xml:id="manderino2015" label="Manderino 2015">Manderino, M., <title
                        rend="quotes">Reading and Understanding in the Digital Age. A look at the
                        critical need for close reading of digital and multimodal texts.</title>
                    <title rend="italic">Reading Today</title>, Jan/Feb. 2015, pp. 22-23.</bibl>
                <bibl xml:id="mayerschonberger2013" label="Mayer-Schönberger and Cukier 2013"
                    >Mayer-Schönberger, V., and K. Cukier. <title rend="italic">Big Data: A
                        revolution That Will Transform How We Live, Work, and Think</title>. New
                    York: Houghton Mifflin Harcourt, 2013.</bibl>
                <bibl xml:id="mcgrath2018" label="McGrath 2018">McGrath, L., D. Higgins, &amp; A.
                    Hintze, <title rend="quotes">Measuring Modernist Novelty,</title> <title
                        rend="italic">Journal of Cultural Analytics</title>. November 9, 2018.<title
                        rend="italic"> </title></bibl>
                <bibl xml:id="moretti2000" label="Moretti 2000">Moretti, F. <title rend="quotes"
                        >Conjectures on World Literature.</title>
                    <title rend="italic">New Left Review</title>, vol. 1 no.-, 2000, pp.
                    54-68.</bibl>
                <bibl xml:id="moretti2009" label="Moretti 2009">Moretti, F. <title rend="quotes"
                        >Critical Response: II. <q>Relatively Blunt</q>.</title>
                    <title rend="italic">Critical Inquiry</title> vol 36, no. 1, 2009, pp.
                    159-71.</bibl>
                <bibl xml:id="moretti2013" label="Moretti 2013">Moretti, F. <title rend="italic"
                        >Distant Reading</title>. London: Verso, 2013.</bibl>
                <bibl xml:id="moretti2000a" label="Moretti 2000a">Moretti, F. <title rend="quotes"
                        >The Slaughterhouse of Literature.</title>
                    <title rend="italic">MLQ: Modern Language Quarterly</title>, vol. 61 no. 1,
                    2000a. pp. 207-227.</bibl>
                <bibl xml:id="phillips2017" label="Phillips and Milner 2017">Phillips, W., and R.
                    Milner. <title rend="italic">The Ambivalent Internet: Mischief, Oddity and
                        Antagonism Online. </title>Cambridge: Polity, 2017.</bibl>
                <bibl xml:id="piper2017" label="Piper 2017">Piper. A. <title rend="quotes">Think
                        Small: On Literary Modelling.</title> PMLA 132.2, 2017, 613-619.</bibl>
                <bibl xml:id="ramage2009" label="Ramage et al. 2009">Ramage, D., Hall, D.,
                    Nallapati, R., &amp; Manning, C. D. (2009, August). Labeled LDA: a supervised
                    topic model for credit attribution in multi-labeled corpora. In <title
                        rend="italic">Proceedings of the 2009 Conference on Empirical Methods in
                        Natural Language Processing, vol. 1</title>, no. -, pp. 248-256. Association
                    for Computational Linguistics.</bibl>
                <bibl xml:id="ramsay2011" label="Ramsay 2011">Ramsay, S. <title rend="italic"
                        >Reading Machines: Toward an Algorithmic Criticism</title>. U of Illinois P,
                    2011.</bibl>
                <bibl xml:id="richards1929" label="Richards 1929">Richards, I.A. 1929. <title
                        rend="italic">Practical Criticism: A Study of Literary Judgment</title>.
                    London: Routledge, 2014.</bibl>
                <bibl xml:id="rosen2011" label="Rosen 2011">Rosen, J. <title rend="quotes">Combining
                        Close and Distant, or the Utility of Genre Analysis: A Response to Matthew
                        Wilkens’s <title rend="quotes">Contemporary Fiction by the
                        Numbers</title>,</title> in <title rend="italic">Post45</title>, December 3,
                    2011.</bibl>
                <bibl xml:id="shneiderman1996" label="Shneiderman 1996">Shneiderman, B. <title
                        rend="quotes">The Eyes Have It: A Task by Data Type Taxonomy for Information
                        Visualizations In Visual Languages</title>, <title rend="italic"
                        >Proceedings</title>, 1996, pp. 336–343.</bibl>
                <bibl xml:id="so2019" label="So 2019">So, R.J., H. Long, and Y. Zhu, <title
                        rend="quotes">Race, Writing, and Computation: Racial Difference and the US
                        Novel, 1880–2000,</title> <title rend="italic">Journal of Cultural
                        Analytics</title>. January 11, 2019. </bibl>
                <bibl xml:id="stronks2013" label="Stronks 2013">Stronks, E. <title rend="quotes">De
                        afstand tussen <hi rend="italic">close</hi> en <hi rend="italic"
                            >distant</hi>. Methoden en vraagstellingen in computationeel
                        letterkundig onderzoek.</title>
                    <title rend="italic">Tijdschrift voor Nederlandse Taal- en Letterkunde</title>,
                    vol. 129, no. 4, 2013, pp. 205-14.</bibl>
                <bibl xml:id="underwood2016" label="Underwood 2016">Underwood, T. <title
                        rend="quotes">The Longue Durée of Literary Prestige</title>. <title
                        rend="italic">Modern Language Quarterly</title> vol 77, no. 3, 2016. pp.
                    321-44.</bibl>
                <bibl xml:id="vaidhyanathan2011" label="Vaidhyanathan 2011">Vaidhyanathan, S. <title
                        rend="italic">The Googlization of Everything</title>. Berkeley and Los
                    Angeles: University of California Press, 2011.</bibl>
                <bibl xml:id="wilkens2011" label="Wilkens 2011">Wilkens, M. <title rend="quotes"
                        >Canons, Close Reading, and the Evolution of Method.</title> Debates in the
                    Digital Humanities. Ed. Matthew K. Gold. Minneapolis: University of Minnesota
                    Press, 2011, pp. 249-58.</bibl>
                <bibl xml:id="wilkens2013" label="Wilkens 2013">Wilkens, M. <title rend="quotes">The
                        Geographic Imagination of Civil War-Era American Fiction,</title> in <title
                        rend="italic">American Literary History</title> vol 25, no. 4, 2013. pp.
                    803-840.</bibl>
                <bibl xml:id="wimsatt1946" label="Wimsatt and Beardsley 1946">Wimsatt, W.K., &amp;
                    M. Beardsley. <title rend="quotes">The intentional fallacy.</title>
                    <title rend="italic">Sewanee Review</title>, vol. 54, no. -, 1946, pp.
                    468-88.</bibl>
                <bibl xml:id="wimsatt1949" label="Wimsatt and Beardsley 1949">Wimsatt, W.K., &amp;
                    M. Beardsley. <title rend="quotes">The affective fallacy.</title>
                    <title rend="italic">Sewanee Review</title>, vol. 57, no. 1, 1949, pp.
                    31-55.</bibl>
                <bibl xml:id="zhang2017" label="Zhang 2017">Zhang, A.X., B. Culbertson, and P.
                    Paritosh. <title rend="quotes">Characterizing online discussion using coarse
                        discourse sequences.</title>
                    <title rend="italic">Proceedings of the Eleventh International Conference on Web
                        and Social Media. AAAI Press</title>. 2017.</bibl>
            </listBibl>

        </back>
    </text>
</TEI>
