<?xml version="1.0" encoding="UTF-8"?><?oxygen RNGSchema="../../common/schema/DHQauthor-TEI.rng" type="xml"?><?oxygen SCHSchema="../../common/schema/dhqTEI-ready.sch"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cc="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dhq="http://www.digitalhumanities.org/ns/dhq">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="article" xml:lang="fr">Le texte numérique : enjeux herméneutiques</title>
            <title type="article" xml:lang="en">Digital text: hermeneutic issues </title>
            <dhq:authorInfo xml:id="jean_meunier">
               <!-- Include a separate <dhq:authorInfo> element for each author.
                         The value of xml:id should be first_last without diacritics, all lower case.
                    -->
               <dhq:author_name>Jean Guy <dhq:family>Meunier</dhq:family></dhq:author_name>
               <dhq:affiliation> Université du Québec à Montréal</dhq:affiliation>
               <email>meunier.jean-guy@uqam.ca</email>
               <dhq:bio>
                  <p>Jean Guy Meunier, PhD (Montréal), est professeur-chercheur à l’Université du
                     Québec à Montréal, co-directeur du Laboratoire d’analyse cognitive de
                     l’information (LANCI), membre de l’Institut des sciences cognitives de l’UQAM,
                     membre du Centre de recherches dans les humanités numériques (CRHN) et membre
                     titulaire de l’Académie internationale de philosophie des sciences (Bruxelles).
                     Il effectue de la recherche dans le domaine des humanités numériques depuis les
                     années 1970. La SEMI/SDH, principale association canadienne de chercheurs dans
                     le domaine des humanités numériques, lui a décerné un prix pour sa contribution
                     à ce domaine.</p>
               </dhq:bio>
            </dhq:authorInfo>
         </titleStmt>
         <publicationStmt>
            <!-- This information will be completed at publication -->
            <publisher>Alliance of Digital Humanities Organizations</publisher>
            <publisher>Association for Computers and the Humanities</publisher>
            <idno type="DHQarticle-id">000362</idno>
            <idno type="volume">012</idno>
            <idno type="issue">1</idno>
            <date when="2018-04-06">6 April 2018</date>
            <dhq:articleType>article</dhq:articleType>
            <availability>
               <cc:License rdf:about="https://creativecommons.org/licenses/by-nd/2.5/"/>
            </availability>
         </publicationStmt>

         <sourceDesc>
            <p>This is the source</p>
         </sourceDesc>
      </fileDesc>
      <encodingDesc>
         <classDecl>
            <taxonomy xml:id="dhq_keywords">
               <bibl>DHQ classification scheme; full list available at <ref target="http://www.digitalhumanities.org/dhq/taxonomy.xml">http://www.digitalhumanities.org/dhq/taxonomy.xml</ref></bibl>
            </taxonomy>
            <taxonomy xml:id="authorial_keywords">
               <bibl>Keywords supplied by author; no controlled vocabulary</bibl>
            </taxonomy>
         </classDecl>
      </encodingDesc>
      <profileDesc>

         <langUsage>
            <language ident="en" extent="translation_stub"/>
            <language ident="fr" extent="original"/>
         </langUsage>
         <textClass>
            <keywords scheme="#dhq_keywords">
               <list>
                  <!-- fill in a separate <item> for each keyword or keyword phrase -->
                  <item/>
               </list>
            </keywords>
            <keywords scheme="#authorial_keywords">
               <list>
                  <!-- fill in a separate <item> for each keyword or keyword phrase -->
                  <item/>
               </list>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <change when="2018-07-03" who="DD">Validation Check</change>
      </revisionDesc>
   </teiHeader>

   <text>
      <group>

         <!-- Original language -->

         <text xml:lang="fr" type="original" resp="#jean_meunier">
            <!-- @resp for the original article is a pointer to xml:id of <dhq:authorInfo>, e.g. "#john_doe" -->
            <front>
               <dhq:abstract>
                  <p>La numérisation des textes est omniprésente dans les humanités numériques. Elle
                     semble se présenter uniquement comme une modification du support matériel : du
                     texte sur papier au texte numérique. Mais elle fait plus que cela. La
                     numérisation touche aussi le texte en tant qu’objet sémiotique. Or, les
                     multiples opérations de cette technologie mettent en œuvre des décisions
                     interprétatives qui ne sont pas sans affecter le texte sémiotique, c’est-à-dire
                     celui qui se donne à lire et à analyser. En ce sens, la numérisation des textes
                     n’est pas neutre. Elle est un moment important d’une herméneutique matérielle.
                  </p>
               </dhq:abstract>
               <dhq:teaser>
                  <p>Cet article considère les problèmes herméneutiques des textes numériques.</p>
               </dhq:teaser>
            </front>
            <body>
               <head>Le texte numérique : enjeux herméneutiques</head>
               <div>
                  <head>1. Introduction </head>
                  <p>La numérisation des documents est une des nombreuses technologies informatiques
                     qui transforment la culture et la science. Tous les supports matériels
                     classiques de l’image au film, de la musique à la sculpture peuvent être
                     transformés et déposés sur un support dit numérique. Mais plus que tout autre,
                     le texte, dans son format traditionnel – manuscrit, codex, livre, revue,
                     rapports, magazine, etc. –, est, depuis une vingtaine d’années, soumis à une
                     numérisation massive. Et à cette masse de textes numérisés s’est ajoutée celle
                     issue de la production directe de textes via des logiciels de traitement de
                     textes. De nos jours, peu de textes échappent ainsi à la technologie de la
                        numérisation<note> Les statistiques portant sur la totalité historique du
                        matériel publié dans le monde varient. On parle d’environ 30 MK de livres,
                        750 MK d’articles, 25 MK de chansons, 500 MK images, 3 MK de vidéos ou
                        programmes et 100 MK de pages internet. Dans une étude de 2011 <ptr target="#thielens2011"/>, on comptait environ 285 exabits de données non
                        structurées de divers types (images, son, textes, etc.). Pour un état de
                        l’accroissement des données textuelles, voir : <ptr target="#xiao2008"/>Xiao, 2008.</note>.</p>
                  <p>Si certains projets de ce <soCalled> virage numérique </soCalled> sont
                     modestes, qu’ils soient créés ou gérés par des groupes de recherche, des
                     institutions académiques, ou par des initiatives sociales ou commerciales
                     locales, d’autres sont au contraire ambitieuses et de dimensions titanesques.
                     Reprenant et prolongeant d’une certaine manière l’objectif premier et originel
                     de la bibliothèque d’Alexandrie, dont le patrimoine textuel comptait plus de
                     500 000 rouleaux manuscrits, ces projets aspirent à la construction d’une
                     bibliothèque numérique universelle, rendant accessible à tous, en tout temps et
                     partout, une grande partie du patrimoine textuel<note> Voir les sites web de la
                        Bibliothèque numérique mondiale (<ref target="https://www.wdl.org/fr/">https://www.wdl.org/fr/</ref>) ainsi que du projet Gutenberg (<ref target="https://www.wdl.org/fr/">http://www.gutenberg.org/</ref>) et de
                        l’énoncé de sa mission par Michael Hart (<ref target="http://www.gutenberg.org/wiki/Gutenberg:Project_Gutenberg_Mission_Statement_by_Michael_Hart">http://www.gutenberg.org/wiki/Gutenberg:Project_Gutenberg_Mission_Statement_by_Michael_Hart</ref>).</note>.</p>
                  <figure xml:id="figure01">
                     <head>Évocation de la librairie d’Alexandrie, par O. von Corben (Tolzmann,
                        Hessel et Peiss, 2001)</head>
                     <graphic url="resources/images/figure01.jpg"/>
                  </figure>
                  <p>Grâce à de tels projets ainsi qu’aux nouvelles possibilités offertes par les
                     technologies informatiques actuelles, tant d’archivage, de traitement que de
                     télécommunications, on espère que des villages reculés auront désormais la
                     possibilité de bonifier leur mince bibliothèque locale de plusieurs millions de
                     copies de livres numériques. </p>
                  <p>Cette numérisation massive de documents textuels, par l’importance de son
                     impact présent et futur sur la culture et la science, change radicalement le
                     rapport au savoir et à sa communication<note> Ce qui n’est pas sans soulever de
                        nombreuses questions politiques et juridiques. Sur cette question, voir <ptr target="#jeanneney2005"/>.</note>. La présente recherche veut analyser
                     cette technologie de numérisation des textes afin d’identifier les opérations
                     importantes qui y sont effectuées ainsi que les produits textuels qui en sont
                     issus. Elle s’intéressera à certains des enjeux herméneutiques de la lecture et
                     de l’analyse des textes numérisés.</p>
               </div>
               <div>
                  <head>2. La numérisation comme technologie et comme herméneutique</head>
                  <p>La technologie de numérisation des textes met en relation deux termes : la
                        <term>numérisation</term> et le <term>texte</term>. Avant d’entamer notre
                     analyse, nous devons préciser certains points de la sémantique de ces termes
                     afin d’éviter toute ambiguïté.</p>
                  <p>Le terme <term>numérisation</term>, dans un contexte informatique, revêt
                     d’abord une double signification. Dans une première acception, il renvoie à une
                     technologie qui convertit un signal physique (sonore, lumineux, mécanique,
                     etc.) en un signal dit numérique qu’un ordinateur peut traiter. De multiples
                     technologies effectuent de la numérisation : par exemple, les systèmes
                     d’alarme, les ouvertures automatiques de portes, l’imagerie médicale, etc.
                     Lorsque cette technologie est appliquée à des documents textuels, la
                     numérisation fait référence aux divers processus physiques (optiques,
                     mécaniques, électroniques, etc.) que réalise un périphérique informatique
                     appelé un <term>numériseur</term> ou un <term>scanneur</term>.</p>
                  <p>Dans une seconde acception, la <term>numérisation</term> renvoie plutôt au
                     traitement formel, c’est-à-dire aux processus algorithmiques qui opèrent dans
                     un numériseur ou scanneur. En ce sens, la numérisation est un ensemble
                     d’opérations de transformations qui, appliquées à des symboles ou signes
                     linguistiques déposés sur un support physique (papier, microfiches, etc.), le
                     transforment en un autre type de symboles ou signes qu’un programme peut
                     traiter. Comprise ainsi, la numérisation produit un texte dit
                        <term>numérisé</term>. Par exemple, si les symboles choisis sont des
                     chiffres 0 et 1 (un encodage binaire,) alors le texte numérisé est un texte
                     numérique à proprement parler (en anglais, <foreign xml:lang="en">digital</foreign>), mais dans certains cas, les symboles choisis peuvent
                     être des images formant des mots : comme dans le texte affiché sur un écran.
                     Autrement dit, tout texte numérisé n’est pas nécessairement uniquement un texte
                     numérique.</p>
                  <p>Cette double signification a son utilité. Elle permet au discours sur la
                     numérisation d’être métonymique. De fait, ce terme naviguera souvent entre ces
                     deux significations ; ce qui permettra de masquer la complexité tant du
                     processus physique que du processus algorithmique mis en œuvre. Par exemple :
                     si on dit qu’un service d’archives mène un projet de <term>numérisation</term>,
                     on peut aussi bien penser que le projet mettra en place une technologie
                     complexe de numérisation (les numériseurs) ou encore qu’il en appellera à des
                     stratégies et processus algorithmiques pour réaliser la numérisation.</p>
                  <p>Un même type d’ambiguïté accompagne le terme <term>texte</term>. En effet, ce
                     mot, selon les contextes, peut faire référence à un objet servant de support
                     physique (papier, électronique) ou à un objet sémiotique, c’est-à-dire une
                     entité linguistique complexe signifiante. Dans la première acception, le texte
                     désigne le substrat physique d’un contenu sémiotique écrit<note> Les analyses
                        philologiques du terme <q> texte </q> renvoient d’ailleurs en tout premier
                        lieu au tissu et au tissage : <cit>
                           <quote rend="inline" source="cerquiglini1989"> <title rend="italic">Textus</title>, du participe
                              passé de <term>textere</term>, est ce qui a été tissé, tressé,
                              entrelacé, construit ; c’est une trame. </quote>
                           <ptr target="#cerquiligni1989" loc="59"/>
                        </cit>.</note>, lequel se résume habituellement aux matériaux (papier,
                     toile, carton, etc.) servant de support aux inscriptions scripturales
                     (effectuées au moyen de crayons, d’encre, etc.), et constituant, une fois
                     relié, un document textuel à part entière (qu’il s’agisse d’un codex, d’un livre<note>
                        <title rend="italic">Wikipédia</title> le définit directement de cette
                        manière : <quote rend="inline" source="#vandendorpe2009"> Un livre (sens le plus courant) est un
                           ensemble de pages reliées entre elles et contenant des signes destinés à
                           être lus. </quote> (<ref target="https://fr.wikipedia.org/wiki/Livre">https://fr.wikipedia.org/wiki/Livre</ref>)</note>, d’une brochure, d’un
                     manuscrit, etc. (voir <ptr target="#vandendorpe2009"/>). Le texte constitue
                     ainsi un objet physique dénombrable, rendant possibles et intelligibles des
                     expressions telles que <quote rend="inline" source="#vandendorpe2009"> <term>mettre un texte dans une
                        </term>enveloppe </quote> ou <quote rend="inline" source="#vandendorpe2009"> <term>empiler dix textes
                           sur un bureau</term> </quote>. Dans le cadre informatique, le texte
                     demeure aussi un objet physique, à ceci près toutefois, que le support physique
                     change de nature et devient électromagnétique (disque dur, clef USB, etc.) ou
                     lumineux d’un écran. Par ces transformations, la notion de texte se voit
                     intégrée à de nouvelles pratiques discursives : on parle désormais de textes
                     copiés par des imprimantes, reproduits par des scanneurs, traités par des
                     logiciels, diffusés sur internet ou envoyés par des téléphones intelligents.
                     Pour désigner le dernier cas, un nouveau synonyme, le <q> texto </q>, est même
                     apparu ; dans l’industrie, on dira dès lors que les messages <q> textes </q>
                     sont plus économiques que les messages oraux. Dans tous ces cas d’énonciation
                     et indépendamment de la forme matérielle qui lui est associée, du papier
                     jusqu’au format électronique<note> Ces propriétés matérielles du texte sont
                        importantes. De nombreux historiens et théoriciens ont montré comment, à
                        travers les siècles, la lente transformation du support physique du texte a
                        été déterminante sur sa lecture et son analyse. Un texte inscrit sur la
                        pierre ne pouvait être lu qu’oralement. Un manuscrit de copiste exigeait un
                        lecteur spécialisé. Le codex ouvrait à un public plus large. L’insertion
                        d’une gravure et d’une image orientait l’interprétation. La forme
                           <term>livre</term> impose une lecture solitaire, séquentielle, un rythme
                        spécifique. Elle contraint aussi l’analyse qui entre autres permet le
                        soulignement, le commentaire, l’annotation (<foreign xml:lang="la">marginalia</foreign>), etc. Chacun de ces types de supports physiques
                        touchait de manière propre l’accès, le contenu signifiant du texte. Et
                        aujourd’hui, le support électronique n’est pas sans offrir aussi une
                        diversité de manipulations originales et spécifiques (déroulement,
                        hyperliens, gigogne, archivage, transmission, affichages multiples, etc.)
                        qui à leur tour ne sont pas sans affecter la lecture et l’analyse.</note>,
                     le terme <term>texte</term> réfère au <term>support physique</term> d’un
                     contenu signifiant écrit. </p>
                  <p>Parallèlement à cette conception du texte comme <q> contenant </q>, une seconde
                     acception, beaucoup plus classique, riche et complexe, renvoie au contenu
                     proprement dit, c’est-à-dire à un ensemble organisé de signes linguistiques.
                     Pris en ce sens, le texte est un objet sémiotique qui transcende sa
                     matérialisation dans un support physique, ou du moins, il qui ne saurait s’y
                     réduire. Conformément à cette acception, mille textes matériels imprimés
                     peuvent tous être à propos d’un même texte sémiotique. Par exemple, une
                     imprimante peut produire mille textes matériels du même texte de la
                     constitution américaine.</p>
                  <p>Bien que dans certains cas, ces considérations sur les supports physiques
                     soient importantes, c’est sur ce contenu du texte sémiotique que portent
                     principalement les grands projets de numérisation. Pour ces derniers, le
                     contenu de textes comme la Bible ou le Coran est en effet plus important que
                     les supports physiques qui les ont portés au fil des siècles, de la peau de
                     mouton au papyrus, en passant par le papier, le microfilm et, finalement, le
                     support électromagnétique. </p>
                  <p>À la lumière de l’ambiguïté de ces deux notions de <q> numérisation </q> et de
                        <q> texte </q>, la problématique de la <q> numérisation de textes </q>
                     s’avère beaucoup plus complexe qu’il n’y paraît de prime abord. En effet, par
                     numérisation de textes, on peut autant renvoyer au processus physique qu’au
                     processus algorithmique et à la manipulation des signes textuels. En
                     conséquence, la compréhension de cette technologie de numérisation des textes
                     sera constamment confrontée à cette ambiguïté. Aussi, pour explorer avec plus
                     de précision ce qu’est cette technologie de numérisation des textes, nous
                     aurons à répondre à deux questions épineuses : 1) Quelles sont les grands types
                     d’opérations physiques et algorithmiques que la numérisation des textes met en
                     œuvre ? 2) Quels effets ces opérations ont-elles sur la lecture et l’analyse
                     des textes ?</p>
                  <p>Les réponses à ces questions sont tout sauf simples. Et elles s’avèrent
                     déterminantes pour la compréhension des pratiques d’une herméneutique
                        matérielle<note> Voir notamment : <ptr target="#foucault1969"/> ; <ptr target="#rastier2011"/>.</note> pour de la lecture et de l’analyse de
                     textes. Il nous faut donc décrire plus en détail ces différentes opérations
                     impliquées dans le processus de numérisation et présenter les impacts sur la
                     dynamique herméneutique interprétative du texte numérisé. Nous espérons que les
                     concepts mis en place éclaireront aussi les débats sur la lecture à l’ère
                     numérique <ptr target="#eberle-sinatra2014"/> ou sur la lecture <cit>
                        <quote rend="inline" source="#moretti2013"> distante </quote>
                        <ptr target="#moretti2013"/>
                     </cit> et la lecture <cit>
                        <quote rend="inline" source="#baccino2004"> électronique </quote>
                        <ptr target="#baccino2004"/>
                     </cit>. </p>
               </div>
               <div>
                  <head>3. Les opérations et produits de la numérisation</head>
                  <p>À première vue, le processus de numérisation de texte semble très simple.
                     Quelques secondes suffisent pour qu’un document textuel sur papier s’affiche
                     sur un écran. La majorité des opérations physiques et algorithmiques mises en
                     œuvre échappent à l’attention. Pourtant, le processus est complexe. En fait, il
                     peut être décomposé en plusieurs phases, chacune constituée de plusieurs
                     sous-opérations dont le produit est toujours un document constitué de signes
                     qui se doivent d’être fidèles au texte source. En cela, la numérisation produit
                     un document que nous appellerons un texte <emph>numérisé</emph>. Mais comme
                     nous le découvrirons dans l’analyse qui suit, il existera plusieurs types de
                     textes numérisés, chacun étant le résultat d’un type spécifique
                     d’opération.</p>
                  <p>Dans notre description du processus de numérisation, nous symboliserons par une
                     lettre indicée T<hi rend="subscript"><hi rend="italic">i</hi></hi> le type de
                     document textuel produit par chaque type d’opération. Ainsi, nous distinguerons
                     (voir figure suivante) : 1) les textes sources <hi rend="italic">T</hi><hi rend="italic"><hi rend="subscript">c</hi></hi> issus d’une opération de
                        <emph>collection</emph>, 2) les textes <hi rend="italic">T</hi><hi rend="italic"><hi rend="subscript">p</hi></hi>
                     <emph>sélectionnés</emph> pour un <foreign xml:lang="la">corpus</foreign>. Ces
                     deux derniers de types de textes seront ceux qui seront soumis à la
                     numérisation et qui produiront 3) les textes <hi rend="italic">électroniques
                        T</hi><hi rend="italic"><hi rend="subscript">e</hi></hi>, résultant d’une
                        <foreign xml:lang="en">transduction</foreign>, 4) les textes <hi rend="italic">proprement dits <q> numériques </q> T</hi><hi rend="italic"><hi rend="subscript">n</hi></hi>, résultant d’un <term>encodage,</term>
                     5) les textes dynamiques T<hi rend="italic"><hi rend="subscript">d</hi>
                     </hi>résultant d’une <term>reconnaissance optique de caractères</term>, 6) les
                     textes <hi rend="italic">annotés T</hi><hi rend="italic"><hi rend="subscript">a</hi></hi>, produit par une annotation, 7) les textes édités T<hi rend="italic"><hi rend="subscript">d</hi></hi>, issus d’un travail
                        d’<term>édition</term>. S’ajouteront à ces textes 8) des textes images Ti et
                     9) les textes à interpréter T<hi rend="subscript">i. </hi>Voici une
                     représentation schématique de ces opérations et produits textuels. Nous
                     expliciterons la spécificité de chaque type d’opérations et textes TiT<hi rend="subscript">i</hi> produit.</p>
                  <p>
                     <figure xml:id="figure02">
                        <graphic url="resources/images/figure02.png"/>
                     </figure>
                  </p>
                  <p>Vu la multiplicité des objectifs et complexité des opérations en jeu dans les
                     divers projets de numérisation de texte, cette liste n’est aucunement
                     exhaustive. Il serait possible d’identifier de nombreux autres types
                     d’opération et documents textuels, mais ceux retenus ici seront suffisamment
                     pertinents pour révéler, ou à tout le moins illustrer, les enjeux
                     herméneutiques de la numérisation des documents textuels sur leur lecture et
                     leur analyse. </p>
                  <div>
                     <head>3.1 La collection des textes T<hi rend="subscript">c</hi> et le corpus
                        textuel T­­<hi rend="subscript">p</hi>
                     </head>
                     <p>Le premier moment de ce processus de numérisation peut lui sembler externe.
                        Pourtant, il s’agit d’une étape qui lui est tout aussi essentielle
                        qu’intrinsèque. En effet, dès le point de départ, un projet de numérisation
                        doit distinguer au moins deux ensembles de documents textuels. </p>
                     <p>Un premier ensemble est constitué des documents textuels T(c) c’est-à-dire
                        de documents qui forment une <term>collection</term> de textes sources
                        pertinents et disponibles, que le projet vise à soumettre à la numérisation.
                        Dans certains projets, on peut vouloir soumettre le plus grand ensemble
                        possible de textes. Mieux vaut plus que moins, dira-t-on. Après, on pourra
                        toujours revenir et choisir parmi les textes numérisés ceux qui intéressent
                        des projets particuliers. On numérise alors à la chaîne tout ce qui semble
                        pertinent. Par exemple, des bibliothèques pourraient décider de convertir en
                        version électronique tous leurs documents, sans exception ou discrimination.
                        Des revues scientifiques autrefois sur format papier pourraient envisager de
                        convertir en format électronique la collection entière de leurs anciens
                        volumes.</p>
                     <p>Mais dans plusieurs cas, surtout dans des projets de recherche, un choix
                        sera effectué. Car il peut s’avérer impossible ou encore non pertinent de
                        tout numériser. Ainsi, un deuxième ensemble de documents textuels T<hi rend="subscript">p</hi> sera construit et il constituera le corpus. Par
                        exemple, la collection T<hi rend="subscript">c</hi> des œuvres écrites de
                        Jean -Paul Sartre pourrait contenir uniquement les œuvres publiées,
                        délaissant la correspondance, les manuscrits, les cahiers de notes, etc. Et
                        un projet de recherche pourrait ne retenir comme corpus T<hi rend="subscript">p</hi> que les textes qui sont de nature
                        philosophique.</p>
                     <p>On définit habituellement un corpus de textes T<hi rend="subscript">p</hi>
                        comme un sous-ensemble de la collection de textes à numériser ou déjà
                        numérisés qui sont réunis en regard des objectifs d’une recherche (<ptr target="#habert1997"/> ; <ptr target="#rastier2001"/> ; <ptr target="#mayaffre2002"/>). Dans certains domaines, le corpus peut
                        s’avérer coextensif à la collection des textes T<hi rend="subscript">c</hi>.
                        Cependant, dans la grande majorité des cas, il n’en constitue qu’un
                        sous-ensemble.</p>
                     <p>Pour construire tant une collection qu’un corpus, deux critères particuliers
                        peuvent être considérés, l’un interne, l’autre externe. Le critère interne
                        est lié aux hypothèses d’utilisation du corpus ou des manipulations qui lui
                        seront appliquées. Aucun corpus n’est neutre et toute sélection de textes
                        est déterminée ou normée par une pratique ou une théorie. Par exemple, des
                        bibliothèques auront souvent à choisir des documents textuels à numériser
                        pour construire leur propre collection électronique. Cette collection sera
                        formée, entre autres, en regard d’une politique d’archivage ou encore des
                        besoins supposés de leur clientèle. Pour constituer leur corpus, les
                        littéraires pourront privilégier les textes qui sont susceptibles de
                        susciter une critique ou une analyse ; les archivistes choisiront ceux qui
                        peuvent constituer un témoignage prototypique d’un événement institutionnel
                        ou social ; les linguistes sélectionneront ceux qui présentent des
                        régularités d’une langue, tandis que les philosophes retiendront les textes
                        les plus pertinents sur le plan théorique ou conceptuel. Bref, tout projet
                        de numérisation débute par la sélection de textes et donc de la
                        constitution, soit d’une collection, soit d’un corpus en regard des
                        objectifs poursuivis. Ces collections et corpus ne sont pas sans liens avec
                        ce que <ptr target="#genette1979"/>, <ptr target="#rastier2001"/>, <ptr target="#jeanneret2014"/>, <ptr target="#souchier1999"/>, entre autres,
                        appellent un ensemble architextuel, c’est-à-dire un ensemble de textes qui
                        présentent une certaine unité sémantique (par genre, thème, etc.) et qui
                        influencent le sens des autres textes avec lesquels ils sont réunis.</p>
                     <p>Un critère externe, de nature matérielle ou sociale, entre également en jeu.
                        Sur le plan matériel, la constitution d’une collection ou d’un corpus peut
                        demander une attention particulière à l’état physique des textes. Par
                        exemple, la numérisation de textes anciens nécessite une analyse préalable
                        de leur état de conservation, de leur dégradation ou de leur capacité à
                        subir des manutentions mécaniques. De même, la numérisation de journaux et
                        des revues ne peut se faire sans prendre préalablement en considération leur
                        format, leur quantité, leur qualité d’impression, etc. La structure même des
                        documents demande également à être analysée, et ce pour plusieurs raisons.
                        Tout d’abord, les variantes structurelles entre les différents types de
                        textes (articles de revue, lettres, pièces de théâtre, manuscrits, etc.),
                        qu’ils soient inclus dans un même corpus ou non, nécessitent l’utilisation
                        de procédés de numérisation adaptés pour chacun d’eux. Aussi, pour chacun,
                        différentes transformations structurelles sont possibles. Par exemple, au
                        sein d’un même document, on trouvera souvent des variantes dans la
                        pagination, la mise en page, dans les types de polices, dans la
                        justification, dans la disposition des notes. Autant d’éléments dont un
                        processus sérieux de numérisation devra éventuellement s’occuper. Par
                        exemple, si un texte contient des <foreign xml:lang="la">marginalia</foreign> ou des commentaires, on devra se demander si
                        ceux-ci doivent être conservés dans une version électronique.</p>
                     <p>Sur le plan social, certains projets auront peut-être à considérer les
                        autres projets avec lesquels ils pourraient entrer en relation. Par exemple,
                        un projet de numérisation des œuvres d’un auteur peut s’inscrire dans le
                        cadre ou répondre aux objectifs de diverses politiques et activités
                        organisationnelles, des centres de recherche aux bibliothèques et libraires.
                        Dans de tels cas, les projets de numérisation peuvent avoir avantage à se
                        conformer à différents standards industriels (XML, SGML) ou académiques
                        (TEI). Par exemple, un projet de numérisation de la correspondance d’un
                        écrivain français lauréat d’un prix Nobel de littérature aura peut-être à se
                        conformer aux divers paramètres du corpus numérisé du <title rend="italic">Trésor de la langue française</title> (TLF) dans lequel il pourrait se
                        retrouver éventuellement.</p>
                     <p>Bref, tous ces critères matériels et ceux propres à un projet particulier
                        jouent un rôle déterminant dans la construction d’un corpus. En tant qu’ils
                        construisent une classe particulière de textes, ils établissent des
                        relations entre les textes. Relations qui ne sont pas sans faire émerger du
                        sens nouveau dans chacun d’eux. Une collection et un corpus ont donc un
                        effet direct sur la lecture et l’analyse de textes. L’interprétation qui
                        s’ensuivra sera différente de celle qui serait proposée d’un texte isolé
                        sans lien avec une collection ou un corpus. On peut imaginer comment un
                        corpus contenant <title rend="italic">Le Capital</title> de Marx et <title rend="italic">La Doctrine sociale de l’Église catholique</title>
                        influencerait la lecture et l’analyse de l’autre. Dans cette perspective,
                        une collection et un corpus instancient l’interdiscursif dont parlait
                        Foucault. </p>
                  </div>
                  <div>
                     <head>3. 2 La transduction : le texte électronique (T<hi rend="subscript">e</hi>)</head>
                     <p>Habituellement réalisé au moyen d’un dispositif appelé
                           <term>numériseur</term> ou <foreign xml:lang="en">scanner</foreign>, le
                        processus de la seconde phase de numérisation consiste à modifier le
                        document textuel issu de la collection ou du corpus habituellement déposé
                        sur un support matériel papier, quelquefois encore sur microfiches ou même
                        sur photos (textes anciens sumériens, grecs romains, arabes, cunéiformes sur
                        divers supports physiques papyrus, pierre, etc.<note> Voir le travail requis
                           pour numériser les documents textuels et mis en ligne par l’Oriental
                           Institute Open Access Publications : <ref target="https://oi.uchicago.edu/research/catalog-publications.">https://oi.uchicago.edu/research/catalog-publications.</ref></note>),
                        pour le convertir et le déposer sur un support <term>électronique</term>.
                        Parce que réfléchissant la lumière, ces divers supports émettent des flux de
                        photons, que des capteurs électroniques transforment (par transduction) en
                        des signaux électriques discrets. Cette technologie matérielle est complexe.
                        Elle repose sur un ensemble de sous-technologies aussi complexes, qu’ils
                        soient physiques (rouleau, vitre, etc.), optiques (lentilles, filtres,
                        miroir, etc.), mécaniques (roues, rubans, etc.), électriques (ampoules,
                        moteurs, etc. ou électroniques (puces, semi-conducteurs, transistors,
                        condensateurs, etc.). Prises conjointement, toutes ces technologies forment
                        une <q> machine </q>, c’est-à-dire un mécanisme physique intégré dont le
                        produit final est une configuration de variations normées de voltage
                        électrique. Ces configurations représentent le document source sous une
                        forme électronique que nous appellerons ici, le document textuel
                        électronique T<hi rend="subscript">e</hi>. Il est un texte numérisé. Il faut
                        bien noter cependant, que ce document textuel T<hi rend="subscript">e</hi>
                        n’est pas encore transformé en document textuel encodé par des chiffres 0 et
                        1, il n’est qu’une suite d’engrammes physiques (des
                           <soCalled> bits </soCalled> physiques) à voltage varié, alternant et
                        inscrit sur un support électronique (semi-conducteur) souvent miniaturisé
                        (disque dur, mémoire, clef USB, etc.). Ces suites d’inscriptions
                        électroniques ne sont pas directement <q> lisibles </q> par un humain<note>
                           Sur ce plan, une image peut aussi être numérisée et devenir une suite
                           d’inscriptions électroniques. Aucun humain ne peut, du moins normalement,
                           y reconnaitre une image comme telle.</note>.</p>
                     <p>À cette étape, le support électronique d’un document textuel n’est toutefois
                        pas toujours isomorphe au document textuel source. Très souvent, la copie
                        électronique ne retient pas tout ce qui se trouvait sur l’original.
                        Plusieurs propriétés physiques informationnelles du document d’origine ne
                        sont pas intégralement captées et reproduites. Ces pertes et bruits produits
                        dans l’opération de transduction peuvent avoir plusieurs causes. Par
                        exemple, la nature incandescente de la source lumineuse peut contribuer à
                        restreindre le spectre lumineux. Relativement à ce même spectre, celui-ci
                        peut n’être qu’imparfaitement capté ou converti par les capteurs, voire
                        déformé par la lentille du numériseur. La vibration mécanique (<foreign xml:lang="en">aliasing</foreign><note> Cependant, selon la qualité de la
                           conversion, il est possible formellement et matériellement de reproduire
                           de manière fidèle le signal analogique original. Certaines techniques de
                           filtrage du bruit permettent de stabiliser, de nettoyer et de rendre plus
                           précis le signal entrant (cf. l’effet Dither : effet de réverbération du
                           bruit de la mécanique du moteur sur la numérisation).</note>) du scanneur
                        peut également interférer au niveau de l’enregistrement du voltage. Un
                        échantillonnage statistique peut avoir été appliqué pour permettre une
                        compression des informations. Ainsi, dans cette conversion d’un signal
                        physique analogique et continu en un signal électronique atomique et
                        discret, une perte non négligeable d’informations est susceptible de se
                        produire.</p>
                     <p>En raison de cette complexité de l’opération physique, certaines précautions
                        doivent être prises afin de s’assurer de la conformité du processus de
                        numérisation aux objectifs initiaux : par exemple, on devra être attentif à
                        la manutention physique des documents originaux<note> La manutention de
                           certains documents anciens peut exiger des technologies plus fines, qui
                           éviteront de les fragiliser davantage : par exemple, éviter de forcer la
                           reliure, la délicatesse du changement de page, etc. L’ampleur et la
                           finalité de la numérisation exigent des scanneurs appropriés : manuels ou
                           automatiques. Dans les grands projets, la saisie est confiée à des
                           entreprises spécialisées via des sous-traitances (<foreign xml:lang="en">outsourcing</foreign>). Les plus simples sont à couverts plats ou en
                           V, les plus sophistiqués sont à angles, ou même robotiques. Le choix d’un
                           type particulier de scanneur dépendra des fins poursuivies. Il ne sera
                           pas le même pour copies dactylographiées à archiver et à envoyer, à
                           mettre sur Internet, ou pour ceux à inclure dans une collection de
                           bibliothèques patrimoniales ou à conserver pour la postérité.</note>, à
                        la qualité et à la complexité du numériseur<note> Par exemple, la qualité
                           des lentilles et la stabilité physique de l’appareil. Il existe divers
                           types de scanneurs, les uns plus sophistiqués que les autres, et leur
                           coût est évidemment lié à leur performance potentielle.</note>, à la
                        couleur de numérisation à privilégier<note> Le noir et blanc doivent être
                           limités à des copies de travail. Il y a trop de perte d’informations.
                           Mieux vaut la couleur et avec la plus haute résolution et finesse
                           possible pour des fins de conservation. Il est toujours possible alors de
                           revenir à des copies de travail plus économiques en espace
                           mémoire.</note> ainsi qu’aux logiciels d’assistance, formats
                        d’enregistrement, à l’espace disque et au support matériel à utiliser<note>
                           On ne peut négliger les multiples sous-opérations impliquées dans une
                           numérisation. De nombreuses fonctionnalités logicielles peuvent assister
                           la numérisation et la rendre ergonomiquement plus facile. Par exemple, le
                           choix des types de pages, des sections de pages, des copies multiples, de
                           l’automatisation des fonctions, des outils d’édition, de l’ajustement des
                           couleurs, etc.</note>.</p>
                     <p>Dans tout ce processus de conversion du document textuel source en document
                        textuel électronique TeT<hi rend="subscript">e</hi>, certaines propriétés ou
                        caractéristiques des signaux originaux sont omises ou laissées pour compte.
                        Ou encore, certains ajouts peuvent produire du bruit. D’un point de vue
                        herméneutique, si cet ajout ou cette perte d’information est négligeable
                        pour des documents textuels simples ou d’utilisation courante (par exemple
                        dans le cas d’un texte dactylographié), il en va tout autrement lorsque les
                        textes originaux sont anciens et dégradés. Une numérisation de papyrus ou de
                        vieux codex est particulièrement sensible à ce type de traitement : qu’il
                        s’agisse d’un manuscrit médiéval ou d’un parchemin retrouvé dans une
                        ancienne mosquée, l’omission d’une marque ou d’un signe particulier peut
                        donner lieu à des interprétations radicalement différentes. Pour cette
                        raison et afin d’éviter que des informations cruciales du texte original
                        échappent ou soient ajoutées à la transduction du texte matériel en texte
                        électronique, il est coutume de solliciter l’aide et l’expertise d’exégètes,
                        de philologues et de paléographes à cette étape du processus de
                        numérisation. À la lumière de ces différentes considérations, à mi-chemin
                        entre la transduction électronique et l’interprétation textuelle, force est
                        de convenir que le concept d’<q> herméneutique matérielle </q> prend ici un
                        tout nouveau sens. La production d’un document textuel électronique T<hi rend="subscript">e</hi> implique toujours des décisions herméneutiques
                        relatives à la représentativité de texte électronique. Elle en appelle à une
                        multitude d’actes interprétatifs.</p>
                  </div>
                  <div>
                     <head>3. 3 L’encodage : le texte numérique (T<hi rend="subscript">n</hi>) </head>
                     <p>Le document textuel électronique T<hi rend="subscript">e</hi> n’est
                        cependant pas encore un texte numérique au sens propre du terme. Pour le
                        devenir, chaque variation électrique du document textuel électronique doit
                        être encodée en une suite de symboles appartenant à un code numérique
                           binaire<note> La sémantique de ce code : il réfère aux deux grandes
                           classes de variations électriques de l’inscription électronique du
                           signal, soit le positif ou le négatif.</note>, c’est-à-dire composé
                        uniquement des symboles 0 et 1. Seule cette forme de texte encodé est, à
                        proprement parler, le texte <emph>numérique</emph> (T<hi rend="subscript">n</hi>) ou en anglais le <foreign xml:lang="en">digital text</foreign>. </p>
                     <figure xml:id="figure03">
                        <head>Un texte numérique</head>
                        <graphic url="resources/images/figure03.jpg"/>
                     </figure>
                     <p>Enregistré sur des supports électroniques auxquels on peut ajouter de
                        l’annotation de formatage tels JPEG (<title rend="italic">Joint Photographic
                           Expert Group</title>) ou TIFF (<title rend="italic">Tagged Image File
                           Format</title>)<note> Les autres formats classiques de sortie de l’image
                           sont le GIF (<title rend="italic">Graphics Interchange Format</title>) et
                           le PDF (<title rend="italic">Portable Document Format</title>). Pour la
                           numérisation académique, on utilisera surtout les formats TIFF, JPEG et
                           PDF. En fait, une combinaison des trois sera souvent utile selon la
                           multiplicité des usages faite des documents numérisés. Le format TIFF est
                           le format le plus compatible avec les multiples plateformes logicielles
                           et celui qui conserve le plus d’informations. Évidemment, il coûte cher
                           en espace mémoire, mais il assure une stabilité dans la conservation et
                           l’interchangeabilité logicielle. Le format JPEG est un format de
                           compression. Il est le plus populaire pour des documents à mettre sur
                           Internet et pour échanger. L’œil ne saisira pas la différence, mais pour
                           l’archivage, ou des agrandissements et des manipulations plus fines, ce
                           format sera problématique.</note>, cet encodage binaire sert surtout à
                        des fins de traitements algorithmiques ultérieurs, d’analyse, mais surtout
                        de distribution et d’archivage. Par ailleurs, ce statut de texte numérique
                        est fondamental pour une manipulation informatique. En effet, il s’agit du
                        seul format qui peut être pris en charge par un ordinateur. Certains des
                        documents textuels inscrits dans l’ordinateur et que nous présenterons
                        ci-après auront ce format.</p>
                     <p>Il existe donc une différence importante entre le document textuel
                        électronique (T<hi rend="subscript">e</hi>), inscrit sur les supports
                        électroniques et le document textuel numérique (T<hi rend="subscript">n</hi>). Le document textuel numérique est en effet issu d’une technologie
                        où des algorithmes complexes (la compilation) transforment les signaux
                        physiques en une suite (et même de couches) de symboles 1 et 0. Cette suite
                        de symboles est le langage natif d’un ordinateur. Comme <ptr target="#desclés1996" loc="103–145"/> l’a souvent montré, le processus de
                        compilation qui produit ces couches de symboles est une sémiose formelle qui
                        à partir d’une configuration originelle proche du texte électronique lui
                        applique une série de transformations pour l’amener à format final qui sera
                        ultimement celui que l’ordinateur manipulera à diverses fins : mise en
                        mémoire, archivage, distribution, reconnaissance optique de caractères,
                        affichage, annotation, édition, etc. Dans ces transformations, il peut
                        s’insérer survenir encore un fois des ajouts et des pertes d’information qui
                        ultimement peuvent produire un document textuel numérique présentant des
                        différences avec le document textuel électronique et avec le document
                        textuel source. Et donc, un texte numérique altéré en viendra à affecter la
                        lecture et l’analyse. Ce n’est pas sans raison que les exégètes voudront le
                        plus souvent consulter le texte source.</p>
                  </div>
                  <div>
                     <head>3. 4 L’affichage : le texte image (T<hi rend="subscript">i</hi>)</head>
                     <p>Ce dernier document textuel numérique n’est normalement pas
                           <soCalled> lisible </soCalled> (en tant que chiffres) par des humains. Il
                        est constitué uniquement de séquence de symboles propre au langage machine
                        de base. En effet, il est possible pour un humain de reconnaître des suites
                        de symboles 1 et 0, mais il sera exceptionnellement rare que des
                           humains<note> Von Neumann <soCalled> lisait </soCalled> directement le
                           code binaire : <ref target="http://w3.salemstate.edu/~tevans/VonNeuma.htm">http://w3.salemstate.edu/~tevans/VonNeuma.htm</ref>.</note> puissent
                        traduire rapidement de telles suites de ces symboles numériques dans des
                        symboles appartenant à une langue naturelle ou mathématique. Pour que
                        l’interprétation devienne possible, une autre transformation est
                        nécessaire : il faut convertir le document textuel numérique de T<hi rend="subscript">n</hi> en un format qui fait apparaître des symboles
                        directement interprétables par des humains.</p>
                     <p>Une manière simple de procéder consistera à traduire des configurations de
                        symboles binaires par l’activation d’une imprimante ou de par l’activation
                        de point lumineux (pixels) sur un écran électronique (moniteur) ou par
                        l’activation d’un projecteur sur une toile réfléchissante. Ainsi, est
                        produit un document textuel image T<hi rend="subscript">i</hi>. Ce document
                        textuel est évidemment <soCalled> lisible </soCalled> c’est-à-dire qu’il
                        peut être parcouru sur le plan de son contenu sémiotique. Il permet la
                        lecture au sens cognitif de ce terme.</p>
                     <p>Ce document textuel image T<hi rend="subscript">i</hi> est en un sens comme
                        une photographie du document textuel original. De fait, il contient le texte
                        original. En effet, apparaissent aussi toutes les autres marques que le
                        document source présentait (ratures, corrections, tache, trous, etc.).
                        Certains sont importants mais d’autres sont du bruit.</p>
                     <figure xml:id="figure04">
                        <head>Texte image du manuscrit de <title rend="italic">l’Alchimie</title> de
                              Newton<note> Extrait de la collection Dibner : <ref target="http://webapp1.dlib.indiana.edu/newton/project/about.do">http://webapp1.dlib.indiana.edu/newton/project/about.do</ref>.</note></head>
                        <graphic url="resources/images/figure04.jpg"/>
                     </figure>
                     <p>Malgré son contenu hybride, ce texte-image est précieux ; dans plusieurs
                        domaines de recherche, il devra être conservé et facilement accessible et
                        disponible pour les chercheurs. Faute d’avoir accès au document matériel
                        originel, le chercheur pourra s’en servir comme socle de validation. Reste
                        que ce document image n’est pas le document source. Dans un projet
                        paléographique, un petit trou dans le manuscrit original peut apparaitre
                        comme une marque sémio-linguistique importante (exemple : dans les documents
                        textes anciens). </p>
                     <p>Encore une fois, comme dans les transformations précédentes, il existera
                        divers types d’interventions qui toucheront ce texte-image ; par exemple :
                        la compression, la résolution en pixels, le filtrage, etc.<note> Plus la
                           résolution est fine, meilleure est la précision de la copie électronique.
                           La résolution doit être haute si la finalité est la constitution
                           d’archives professionnelles ; elle peut être moins haute si la
                           numérisation n’est qu’une étape vers la production d’un texte vivant
                           (soumis au ROC). Le choix de la résolution sera préférablement haut
                           (autour de 1000 dpi) pour de l’archivage patrimonial, mais pour une
                           reconnaissance optique de caractères, quelque 400 dpi suffisent.</note>.
                        Ceci peut modifier substantiellement le contenu des différents types de
                        textes impliqués. À chacune de ces diverses opérations des décisions
                        affecteront l’interprétation du texte.</p>
                     <p>Par ailleurs, le texte-image pose des problèmes particuliers à la lecture,
                        surtout si celle-ci porte sur le texte image-écran. Le parcours du texte
                        impose des contraintes perceptuelles et cognitives qui ont été mises en
                        évidence par les recherches. Le texte-image sur écran perd de nombreuses
                        balises qu’offrait le codex. Des repaires physiques disparaissent. Il
                        surcharge la mémoire. L’annotation, le commentaire, le marquage ne sont pas
                        toujours accessibles. Ce sont autant d’éléments qui affectent la lecture,
                        l’interprétation et la compréhension du contenu sémiotique. Cela dit, il est
                        important de noter que le texte-image n’épuise pas toutes les variantes des
                        textes numérisés.</p>
                     <p>Bref, si nous résumons ces premières étapes, nous devons constater qu’il y a
                        des enjeux herméneutiques distincts, mais importants. Chacune des étapes
                        peut comporter de décisions qui modifient le document textuel, soit en
                        ajoutant soit en éliminant quelque chose. Toutes ces décisions qui touchent
                        la matérialité du texte peuvent ultimement affecter l’interprétation des
                        textes. On imagine ce que toutes ces modifications pourraient signifier si
                        le document textuel source était issu de la collection biblique des rouleaux
                        manuscrits de Qumran ! Et qu’il faut lire ceux-ci sur en format PDF sur
                        l’écran d’un téléphone intelligent !</p>
                  </div>
                  <div>
                     <head> 3. 5 La reconnaissance <emph>linguistique</emph> : le texte dynamique
                           (T<hi rend="subscript">d</hi>)</head>
                     <p>À ce stade de la chaîne de traitement, le texte-image (T<hi rend="subscript">­i</hi>) n’est qu’un ensemble de transcriptions de configurations de
                        taches d’encre sur un support papier ou d’activation de pixels lumineux sur
                        un écran. Certaines des configurations de tâches d’encre ou de pixels sont
                        reconnues par les humains comme des symboles linguistiques, mais un
                        ordinateur ne peut manipuler ces symboles comme des signes linguistiques. Le
                        texte-image est figé, statique. Or, pour de nombreuses finalités de lecture,
                        et surtout d’analyse et d’édition, de diffusion, l’ordinateur doit manipuler
                        de manière dynamique ces symboles comme des signes linguistiques. Le
                        texte-image doit donc être transformé en texte <emph>dynamique</emph> (T<hi rend="subscript">d</hi>)<hi rend="subscript">.</hi> Il y a deux manières
                        de procéder pour ce faire : l’une manuelle, l’autre automatique.</p>
                     <p>En ce qui a trait à l’approche manuelle, il arrive que certains
                        textes-images soient si complexes, bruités et idiosyncrasiques qu’aucun
                        algorithme ne peut réussir à reconnaître des configurations de signes
                        linguistiques. On peut penser ici aux manuscrits écrits à la main, en langue
                        ancienne ou ceux contenant des symboles particuliers, comme les notes
                        sténographiées de Husserl ou les textes de <title rend="italic">l’Alchimie</title> de Newton. Dans de tels cas, il faut alors recopier
                        au clavier<note> Il est intéressant de noter que l’expression
                              <q> numérique </q> associée à <q> clavier </q> renvoie habituellement
                           au pavé numérique, c’est-à-dire le clavier avec des chiffres. Le clavier
                           ordinaire d’un ordinateur est une technologie mécanique qui transforme
                           une pression effectuée sur une touche en un signal électrique qui, à son
                           tour, est transformé en un code numérique. Lorsque les textes à copier
                           sont complexes, la saisie passe souvent par l’intermédiaire de plusieurs
                           personnes. Elles encoderont manuellement, en parallèle et de manière
                           comparée, le texte-image (ou le texte source lui-même) pour assurer la
                           plus grande fidélité du texte vivant avec l’original.</note>, signe par
                        signe, le texte-image. Cette procédure manuelle permet d’assigner
                        directement un code numérique standardisé spécifique<note> Il faut
                           distinguer le jeu de caractères codés avec leur représentation en bits.
                           Par exemple, le code ASCII est lui-même encodé en 8 bits dans la norme
                           ISO 8859.</note> (code ASCII : <title rend="italic">American Standard
                           Code for Information Interchange</title>) à chacun des signes
                        linguistiques. L’ordinateur, par l’intermédiaire de logiciels de traitement
                        de texte, peut ainsi manipuler directement des suites de codes 0, 1 comme
                        des signes linguistiques et afficher des configurations de pixels ou d’encre
                        correspondant à ces signes linguistiques<note> Et dans ce cas, il faudra des
                           stratégies complexes de vérification et de correction : par exemple,
                           faire des copies parallèles qui sont comparées et co-corriger.</note>. </p>
                     <p>La procédure automatique repose quant à elle sur la reconnaissance optique
                        de caractères (ROC)<note> Les logiciels de ROC ne travaillent jamais sur le
                           document papier d’origine ; ils en font toujours, mais de manière
                           transparente, une copie image, et c’est cette image via la représentation
                           numérique des configurations lumineuses qui est soumise au logiciel de
                           reconnaissance.</note>. Celle-ci identifie dans la multitude des
                        configurations de codes binaires (0, 1), du texte <emph>numérique</emph>
                           T­­<hi rend="subscript">n</hi> ou même du <term>texte-image</term> T<hi rend="subscript">i </hi>– celles qui forment des signes linguistiques
                        dynamiques : des lettres, ponctuation chiffres, espaces, etc.) et filtrant,
                        si nécessaire des marques résultant de la texture du papier, des taches ou
                        de tout autre source non pertinente du point de vue linguistique. Ces
                        algorithmes complexes, basés sur des modèles mathématiques de reconnaissance
                        ou de classification de formes, permettent dans les configurations de pixels
                        des textes-images, notamment par le truchement de différentes opérations de
                        translation, de rotation, de compression et de réduction ou d’agrandissement
                        d’échelle, d’identifier des signes linguistiques et d’éliminer les effets
                        dus au bruit ou aux imperfections. Ces opérations de reconnaissance
                        utilisent parfois des dictionnaires ou des outils linguistiques. Il est
                        évident que le document textuel dynamique T<hi rend="subscript">d</hi> est
                        distinct du texte-image, tout comme du texte numérique avec lequel il est
                        souvent confondu. </p>
                     <p>Les signes linguistiques reconnus et affichés sur écran ou imprimés sur
                        papier correspondent à des standards, par exemple, ASCII. Le texte peut
                        alors être enregistré sous un format manipulable par des logiciels
                        spécialisés dans le traitement de signes linguistiques. Les formats
                        d’enregistrement les plus connus et utilisés sont TXT<note> Le format TXT
                           élimine tous les marqueurs et ne garde que les espaces entre les mots
                           alors que le RTF en conserve quelques marqueurs importants (comme les
                           paragraphes et les italiques).</note>, RTF, ou ceux utilisés par des
                        logiciels de traitement de textes<note> Il est intéressant de noter la
                           métonymie sous-jacente à cette nomination de <q> logiciel de traitement
                              de textes </q>. <title rend="italic">Word</title><hi rend="superscript">TM</hi>, par exemple, ne traite pas du texte
                           sémiotique, mais des signes linguistiques encodés de manière standard.
                           Pour ce logiciel, il n’y a pas de différence informatique entre <q> la
                              klr ok kf prp oi klr </q> et <q> Il lit ce livre au lit </q>. Les deux
                           sont des suites de signes linguistiques même si la première suite n’a
                           aucun sens.</note> comme <title rend="italic">Word</title> et <title rend="italic">OpenOffice.</title> En général, le choix d’un format
                        particulier dépend essentiellement des objectifs poursuivis. Mais il est
                        évident que ce choix doit prendre en considération la durabilité, de ces
                        standards pour l’archivage, et leur a compatibilité avec les divers outils
                        informatiques de lecture et d’analyse. </p>
                     <p>Ainsi, à ce stade du processus le texte numérique dynamique<note> Le texte
                           est quelques fois appelé <q> vivant </q> ou en anglais <q> living </q>
                           par les entreprises informatiques spécialisées en logiciels ROC. Mais le
                           terme dynamique semble utilisé le plus souvent.</note> (T<hi rend="subscript">d</hi>) peut certes être lu comme le texte-image, mais
                        surtout il peut être, corrigé, souligné, commenté et ultimement traité par
                        une variété d’algorithmes. Il reste cependant que ce texte dynamique est
                        lui-même présent dans l’ordinateur comme un texte électronique manipulable
                        dans sa version numérique par des programmes. </p>
                     <p>Ici encore, cette phase de la chaîne de traitement présente ses propres
                        enjeux herméneutiques. En effet, la transformation manuelle ou automatique à
                        l’origine de la création du texte dynamique influencera la lecture et
                        l’analyse. Tout comme dans le cas des textes sources électroniques,
                        numériques, images celui-ci subira des transformations importantes. Par
                        exemple, de multiples informations textuelles, tels le soulignement, le
                        surlignage, les polices de caractères, la mise en italique, en gras ou en
                        page, la pagination, les notes et commentaires peuvent être conservées ou
                        éliminées. Des erreurs de reconnaissance dues notamment au bruit (une tache,
                        une ombre, une interférence) peuvent s’y glisser<note> Un nettoyage et un
                           filtrage sont souvent par la suite nécessaires. Mais ces tâches peuvent
                           être assistées par des outils informatiques. Par exemple, un extracteur
                           de lexique peut fournir la liste des chaînes de caractères formant les
                              <q> mots </q> mal identifiés.</note>. </p>
                     <p>De telles modifications affecteront éventuellement l’analyse du texte. C’est
                        surtout d’ailleurs ce type de texte qui servira comme point de départ des
                        multiples stratégies d’analyse du contenu textuel : annotations,
                        lexicométrie, classification, visualisation, édition, etc. Ces opérations
                        d’analyse exigent un texte dynamique. Encore ici, la différence entre une
                        herméneutique classique et matérielle prend tout son sens. </p>
                  </div>
                  <div>
                     <head>3. 6 L’annotation : le texte annoté (T<hi rend="subscript">a</hi>)</head>
                     <p>Dans sa forme la plus élémentaire, un texte numérisé dynamique n’est qu’une
                        suite de caractères séparés par des espaces. Mais au sens sémiotique, un
                        texte est plus qu’une suite de symboles. En effet, comme le soulignent
                        régulièrement plusieurs linguistiques et sémioticiens (<ptr target="#halliday1976"/> ; <ptr target="#rastier2001"/> ; <ptr target="#adam1999"/>) un texte est un objet sémiotique complexe. Il est
                        un ensemble structuré de plusieurs niveaux de signes qui, conjointement,
                        sont créateurs de sens. L’organisation de ces signes est complexe, car
                        ceux-ci sont de divers types. Certains par exemple, appartiennent à
                        l’organisation éditoriale du texte (la ligne, le paragraphe, le titre, le
                        sous-titre, la note de bas de page et les numéros de page), alors que
                        d’autres sont de nature linguistique (les mots, les phrases, les formes
                        morphologiques ou grammaticales). Si les marques d’édition sont évidentes
                        dans les textes numérisés, les marqueurs liés aux formes et aux contenus
                        linguistiques y sont toutefois beaucoup plus discrets. Aucun texte numérique
                        dynamique ne montre la différence grammaticale du mot <q> lit </q> dans la
                        séquence alphabétique : <q> Il lit ce livre au lit. </q></p>
                     <p>Aussi, si le projet de numérisation implique certaines manipulations
                        sémiotiques du texte dynamique (T<hi rend="subscript">d</hi>), il peut
                        devenir nécessaire d’ajouter des informations spécifiques aux multiples
                        types ou formes de signes présents dans le texte dynamique. Cela sera
                        effectué par le biais d’annotations qui représentent sur le plan
                        informatique des métadonnées, c’est-à-dire des étiquettes ou des marqueurs
                        qui nomment la catégorie de l’information et qui sont ajoutés au texte
                        dynamique. </p>
                     <p>Les types d’annotations varient selon les objectifs du projet de
                        numérisation, qu’il s’agisse de production d’une édition papier ou
                        électronique, d’archivage, d’aide à la recherche sur Internet, de
                        construction d’un Web sémantique, de fouille ou d’analyse de données
                        textuelles spécialisées. Plusieurs stratégies (manuelles ou automatiques) et
                        classes d’annotations ont été proposées par le passé. Si certaines formes
                        d’annotation portent sur le traitement informatique de type documentaire
                        (indexation, archivage, notamment)<note> Voir <ptr target="#goldfarb1981"/> ; <ptr target="#reid1980"/> ; <ptr target="#renear1996"/> ; <ptr target="#derose1999"/>DeRose, 1999.</note>, d’autres portent plutôt
                        sur les formes linguistiques et textuelles ou relèvent de la sémioticité du
                           texte<note> Voir <ptr target="#marshall1998"/> ; <ptr target="#bird2001"/>.</note>. En ce qui a trait à la lecture et à l’analyse, finalités
                        premières des projets de numérisation de textes scientifiques et
                        académiques, les formes sémiotiques d’annotation semblent être les plus
                        pertinentes. Malheureusement, compte tenu de leur complexité et des
                        difficultés qu’elles impliquent, la traduction informatique adéquate de ces
                        formes d’annotations reste à faire. Nous nous contenterons ici d’en décrire
                        quelques-unes. </p>
                     <p>Un premier type d’annotation relève de ce que <ptr target="#genette1987"/>
                        appelle le péritexte. Ce terme renvoie à l’ensemble des signes qui, sous la
                        responsabilité de l’auteur jouent un rôle externe, mais immédiat
                        relativement au contenu du texte. Par exemple, sont dits membres du
                        péritexte tous les mots ou passages référant à l’un des éléments ou
                        dimensions textuels suivants : le titre, l’auteur, la date de publication,
                        la référence, la pagination,les chapitres et sections, les épigraphes, la
                        dédicace, la table des matières, les index et la couverture. Ce type
                        d’annotations s’avère essentiel à la manipulation informatique du texte
                        numérique. Par exemple, les marqueurs indiquant le numéro des pages ou des
                        sections et des titres seront d’une importance cruciale pour le rappel, le
                        résumé, la classification comme d’un point de vue rhétorique ou
                        argumentatif. </p>
                     <p>Les annotations intratextuelles portent quant à elles sur le contenu interne
                        du texte. Celles-ci peuvent toucher différentes dimensions textuelles.
                        Ainsi, on pourra vouloir indiquer le statut linguistique des signes –
                        notamment  : leur catégorie syntaxique (p. ex., <q> porte </q> comme
                           <term>verbe</term> ou comme <term>nom</term>), leur catégorie sémantique
                        (p. ex., <q> porte </q> comme <term>objet physique</term>, comme
                           <term>action</term>, etc.) leur catégorie pragmatique, logique,
                        rhétorique, discursive, etc. Certains voudront marquer le genre du texte,
                        les attitudes, les sentiments, les jugements de valeur, les citations, etc.
                        Certains voudront peut-être ajouter de l’information contextuelle, sociale,
                        etc. </p>
                     <p>De plus, l’annotation peut avoir pour but de distinguer les signes non
                        linguistiques présents dans le texte, mais qui participent de manière
                        importante au contenu du texte sans pour autant constituer du
                        <q> texte </q>, par exemple les tableaux, les schémas, les cartes, les
                        photos, les images et ainsi de suite. Finalement, on inclura aussi les
                        commentaires, variantes, remarques, précisions, etc. – c’est-à-dire, les
                           <foreign xml:lang="la">marginalia</foreign> qui participent à leur
                        manière au contenu sémiotique du texte. En vérité, la liste des types
                        d’annotations intratextuelles est presque infinie.</p>
                     <figure xml:id="figure05">
                        <head>Exemple d’annotation de <title rend="quotes"> Marie lit une pièce de
                              théâtre de Molière </title><note> Voir <ptr target="#ma2009"/>.</note></head>
                        <graphic url="resources/images/figure05.jpg"/>
                     </figure>
                     <p>Une troisième catégorie d’annotation, relevant de ce que Genette appelle
                           <quote rend="inline" source="#genette1979"> épitexte </quote> et que Foucault et Kristeva
                        désignent par <quote rend="inline" source="#genette1979"> intertexte </quote>, renvoie à des
                        textes externes, liés de manière intermédiaire au contenu textuel principal.
                        Certains éléments <quote rend="inline" source="#genette1979"> épitextuels </quote> peuvent être
                        produits par l’auteur du texte principal, par exemple la correspondance, le
                        journal intime et les interviews, alors que d’autres portent spécifiquement
                        sur lui, par exemple les critiques et les analyses. Certains seront privés
                        d’autres publiques. Enfin, d’autres formes d’annotations relevant du même
                           <quote rend="inline" source="#genette1979"> cadre discursif </quote> que le texte annoté
                        peuvent jouer un rôle important dans la compréhension de son contenu
                        sémiotique, par exemple les textes historiques ou techniques. Bien que ces
                        différents textes n’aient pas de rapport direct avec le texte principal, une
                        analyse textuelle rigoureuse se doit toutefois de les prendre en compte. </p>
                     <p>Plusieurs projets de numérisation ont recours à ces divers types
                        d’annotations, bien qu’à des degrés divers. Les pratiques peuvent faire
                        preuve d’une grande variabilité de détail et de complexité. Compte tenu de
                        cette diversité et des complications qu’elle est susceptible d’entraîner,
                        une normalisation des marquages s’est imposée pour de nombreux projets de
                        numérisation, normalisation permettant d’assurer à la fois une certaine
                        cohésion interprétative et une communicabilité informatique. </p>
                     <p>Au niveau proprement informatique, cette normalisation des pratiques
                        d’annotations s’est traduite par le développement de plusieurs standards,
                        certains étant plus utilisés que d’autres. Le SGML (<title rend="italic">Standard Generalized Markup Language</title>), fortement utilisé dans
                        les projets de numérisation antérieurs aux années 2000, représente l’un des
                        formats les plus connus. Sommairement, ce format est basé sur la distinction
                        entre la structure dite <soCalled> logique </soCalled> du document et son
                        contenu (titre, chapitre, sections, paragraphe, etc.). Utilisé par plusieurs
                        industries documentaires, le SGML a toutefois été relativement boudé par la
                        communauté académique, notamment en raison de sa lourdeur, de son coût
                        d’exécution élevé et de son manque de précision pour plusieurs types de
                        tâches. </p>
                     <p>Un second type de marquage plus simple, XML (<title rend="italic">Extensible
                           Markup Language</title>), a rapidement remplacé SGML dans le monde
                        industriel et académique. Permettant une plus grande variété d’annotations
                        que ce dernier, il a notamment contribué au développement de plusieurs
                        formes de marquage secondaire. Ainsi, l’émergence du Web a mené au
                        développement des balises structurantes HTML, et de balises de forme CSS,
                        lesquelles permettent non seulement la mise en forme de documents à des fins
                        de publication en ligne, mais aussi l’insertion de liens
                           <term>hypertextuels</term> entre le texte original et des textes
                           connexes<note> Une modification de XML a donné lieu (en 2007) à XHTML,
                           mais ce dernier a été ensuite abandonné.</note>. Les variantes RDFS
                           (<title rend="italic">Resource Description Framework Schema</title>) et
                        OWL (<title rend="italic">Ontology Web Language</title>) permettent pour
                        leur part d’organiser l’information sémantique d’un texte par
                        l’intermédiaire d’ontologies<note> Une ontologie est une spécification
                           explicite et formelle d’une conceptualisation partagée d’un domaine
                           d’intérêt. Les concepts y sont traditionnellement organisés en un graphe
                           dont les relations peuvent être soit des relations sémantico-logiques,
                           soit des relations de composition et d’héritage (conformément au
                           paradigme objet). L’interprétation des ontologies est souvent de nature
                           épistémique, dans la mesure où elles représentent des
                           connaissances.</note>. </p>
                     <p>En tant qu’ensembles terminologiques et conceptuels structurés, recouvrant
                        la dimension sémantique d’un champ de connaissances, les ontologies peuvent
                        servir à organiser les informations sémantiques contenues dans des textes,
                        notamment en vue de faciliter leur intégration web. Dans la perspective où
                        une bonne partie des textes numérisés est susceptible d’être affichée dans
                        des sites internet, plusieurs spécialistes du domaine proposent d’intégrer
                        de ces ontologies aux pratiques d’annotation habituelles<note> Voir <ptr target="#buitelaar2005"/> ; <ptr target="#ma2009"/>.</note>. </p>
                     <p>Dans l’ensemble, les différentes normes décrites ci-dessus ont certes
                        contribué à uniformiser la mise en ligne des collections textuelles.
                        Désormais, les formats XML et HTML ainsi que leurs variantes sont essentiels
                        à tout projet de numérisation et de mise en ligne. Toutefois, ce type de
                        balises ne saurait entièrement convenir aux projets académiques, dans la
                        mesure où ceux-ci nécessitent bien souvent des formats de balisage plus
                        fins.</p>
                     <p>Le format proposé par le consortium international de la <title rend="italic">Text Encoding Initiative</title> (TEI), sorte de compromis entre les
                        formats généraux SGML et celui des ontologies, semble mieux à même de
                        répondre aux demandes du monde académique. Permettant une annotation
                        textuelle sophistiquée, il est adaptable et n’empêche aucunement son
                        insertion sur le Web. Parallèlement au développement et à la popularisation
                        de la TEI, des types de plus en plus complexes d’annotations ont été conçus
                        et introduits. Tout en permettant une plus grande précision, ces types
                        d’annotations bénéficient également d’un certain statut consensuel,
                        facilitant la collaboration et les échanges au sein de la communauté
                        académique. Toutefois, ces formats tendent trop souvent à être lourds et de
                        réalisation coûteuse. </p>
                     <p>Par le truchement de ces différents formats et techniques d’annotation,
                        cette dernière phase du processus de numérisation produit ainsi un nouveau
                        texte : le texte annoté (T<hi rend="subscript">a</hi>). De plus comme il
                        faut préciser le type d’annotations, il faut indexer ce texte : soit T<hi rend="subscript">a</hi><hi rend="italic"><hi rend="subscript">i</hi></hi>
                        où <hi rend="italic">i</hi> indique le type d’annotation effectuée. </p>
                     <p>Sur le plan interprétatif, les techniques d’annotation soulèvent leurs
                        propres enjeux herméneutiques. Encore plus que pour les autres phases du
                        processus de numérisation, ces opérations peuvent orienter profondément
                        l’interprétation du contenu sémiotique du texte. Et dans ce contexte
                        transformationnel, l’herméneutique matérielle est directement interpellée. </p>
                     <p>Un premier enjeu est la multiplicité des perspectives possibles. À l’inverse
                        des autres opérations qui peuvent occasionner une réduction du texte, les
                        annotations lui ajoutent au contraire une quantité non négligeable
                        d’informations. En outre, ces nouvelles informations reposent souvent sur
                        une diversité de cadres théoriques qui ne sont pas universellement
                           partagés<note> Il y a toujours une théorie latente qui opère dans la
                           préparation du balisage. Comme le dit M. Sperberg-McQueen, <cit>
                              <quote rend="inline" source="#sperberg-mcqueen1991"> <foreign xml:lang="en">Markup reflects a theory
                                    of text</foreign> </quote>
                              <ptr target="#sperberg-mcqueen1991" loc="34"/>
                           </cit>.</note> : s’il est facile de s’entendre sur le fait qu’une suite
                        linguistique particulière est un <emph>verbe</emph> ou un
                        <emph>titre</emph>. Il n’en va pas de même lorsque différentes
                        interprétations linguistiques, discursives, énonciatives ou
                        socio-psychologiques sont sollicitées. En conséquence, il est difficile de
                        proposer des types universels ou tout au moins généraux d’annotations, d’où
                        le caractère fortement subjectif de tout projet d’annotation : à chaque
                        utilisateur ou groupe d’utilisateur son système d’annotation. Face à cette
                        situation, certains projets ont rejeté toute standardisation des
                           annotations<note> Les multiples projets d’annotation linguistique
                           constituent à ce titre de bons exemples.</note>, lui préférant plutôt des
                        marquages hybrides ou <foreign xml:lang="la">ad hoc</foreign>. Ce type
                        d’approche semble par ailleurs celle qui est devenue la plus acceptable et
                        la plus pratiquée. </p>
                     <p>Malgré ces difficultés et la tendance générale qui en découle, la
                        possibilité de découvrir et d’établir des normes d’annotation minimales,
                        applicables aux textes présentant certaines similarités (par exemple,
                        d’ordre littéraire, philosophique ou technique), demeure néanmoins réaliste.
                        Par exemple, un poème pourrait permettre une annotation sensible au vers, au
                        verset, à la métrique, aux lignes ou aux strophes, sans pour autant que ces
                        différentes annotations soient liées entre elles. Également, une annotation
                        littéraire pourrait se résumer à identifier les personnages d’une pièce de
                        théâtre ou à préciser certains types d’actes de langage. Une annotation
                        sémiologique ou linguistique pourrait se contenter de distinctions entre
                        actants, actions ou épreuve, de même qu’une annotation philologique pourrait
                        se limiter à préciser des variantes dans des manuscrits. En ce sens, il
                        semblerait donc possible d’effectuer certaines annotations générales
                        communes, malgré le caractère <quote rend="inline" source="#undocumented"> spécifique au
                           domaine </quote> d’un bon nombre d’entre elles. En fait, le cœur du
                        problème de l’annotation est que celle-ci constitue une forme déguisée
                        d’interprétation ou, pour reprendre l’expression de <ptr target="#pincemin2007" loc="12"/>, l’expression technique, mais
                        déterminante de plusieurs choix théoriques participant de l’interprétation
                        d’un texte. </p>
                     <p>Un deuxième enjeu herméneutique est la multiplication des documents textuels
                        annotés T<hi rend="subscript">a</hi>. En effet, contrairement à une démarche
                        herméneutique classique qui ne porte que sur un texte source canonique et
                        ses diverses transcriptions ou éditions, l’annotation multiplie les types de
                        textes presque à l’infini. De plus, ces annotations sont souvent
                        transparentes au lecteur et à l’analyste : alors que dans le texte papier,
                        auquel l’interprète peut ajouter des <foreign xml:lang="la">marginalia</foreign>, les annotations demeurent visibles, il en va tout
                        autrement dans le cadre numérique. En effet, même si les catégories
                        d’annotations sont diversifiées ou précises, elles ne sont pas toujours
                        visibles à la lecture immédiate (écran ou imprimé). Dans certains cas, leur
                        origine peut même être inconnue, ce qui complique d’autant plus la tâche des
                        interprètes. </p>
                     <p>Ainsi, dans le cadre numérique, l’annotation informatique multiplie les
                        types de textes. Un texte annoté syntaxiquement est différent d’un texte non
                        marqué sémantiquement. Ainsi, presque chaque texte numérique T<hi rend="subscript">a</hi> se multiplie en n textes différents par l’ajout
                        divers types d’annotations, complexifiant d’autant la démarche
                        herméneutique. </p>
                  </div>
                  <div>
                     <head>3. 7 L’édition : le texte édité (T<hi rend="italic"><hi rend="subscript">s</hi></hi>)</head>
                     <p>Les deux derniers textes, le texte-image et le texte dynamique, peuvent
                        donner accès au contenu sémiotique textuel ; ils sont lisibles. Mais seuls
                        les textes dynamiques et annotés permettent une manipulation
                        computationnelle et analytique. Par contre, ces derniers documents ne sont
                        habituellement pas la forme ultime que visent les projets de numérisation.
                        On désire offrir aux différents lecteurs un document textuel édité T­<hi rend="subscript">d</hi> qui contiendra les multiples qualités résultant
                        d’un travail éditorial propre à un document numérisé affichable sur écran ou
                        ultimement imprimable sous une forme ou une autre. L’édition dite
                           <q> électronique </q> pourra se plier à diverses normes ou pratiques
                        selon les usages qu’on en fera (par exemple : les livres, les revues,
                        l’accès libre, l’interopérabilité, le catalogage, la, pérennisation, les
                        tablettes – liseuses, le multimodal, etc.). Bref, ces éditions électroniques
                        ne contiennent plus uniquement des ensembles de <q> lignes de textes </q>.
                        Elles créent des <q> textes en ligne </q>. </p>
                     <p>Ce travail d’édition permettra divers types d’accès au contenu textuel.
                        Comme <ptr target="#virbel1993"/> l’avait bien vu, l’édition électronique
                        permet une créativité importante dans les formes de présentation d’un texte
                        et par conséquent au contenu sémiotique du texte. Nous n’en présentons ici
                        que des échantillons. </p>
                     <p>Un premier est de type décompositionnel ; le texte édité déconstruit les
                        formes classiques de la présentation du codex ou du livre connu. Par
                        exemple, si dans textes édités pour des sites web (voir les sites web
                        consacrés à Shakespeare<note> Voir <ptr target="#mueller2008"/>.</note>,
                           Kierkegaard<note> Sur Wikipédia, l’accès aux textes de Kierkegaard (<ref target="https://en.wikipedia.org/wiki/Søren_Kierkegaard">https://en.wikipedia.org/wiki/Søren_Kierkegaard</ref>) se fait par
                           plusieurs sites interreliés où textes, paratextes et péritextes sont mis
                           en interrelation par des commentateurs annotateurs et fort probablement
                           revisés par la fondation Kierkegaard.</note>, Russell<note> Hébergé par
                              <title rend="italic">The Bertrand Russell Society</title> (<ref target="https://users.drew.edu/~jlenz/brtexts.html">https://users.drew.edu/~jlenz/brtexts.html</ref>).</note>,
                           Wittgenstein<note> Hébergé par <title rend="italic">The British
                              Wittgenstein Society</title> (<ref target="http://www.britishwittgensteinsociety.org">http://www.britishwittgensteinsociety.org</ref>) et <hi rend="italic">The Cambridge Wittgenstein Archive</hi> (<ref target="http://www.wittgen-cam.ac.uk/">http://www.wittgen-cam.ac.uk/</ref>).</note>, Claude Bernard<note>
                           Voir le site web Claude Bernard (<ref target="http://www.claude-bernard.co.uk">http://www.claude-bernard.co.uk</ref>).</note>, etc.), on retrouve
                        des lignes de textes similaires (mais flexibles) à celles trouvées dans
                        l’édition papier, on trouve aussi des textes décomposés en de multiples
                        sous-textes qui deviennent tabulaires, réticulaires, empilés, gigognes,
                        juxtaposés, hypertextualisés, navigables, etc. Dans ses formes fragmentées,
                        le parcours du texte n’est plus uniquement linéaire, mais
                        multidirectionnel ; il invite à parcours intra-, péri-, para- et
                        architextuel. Ainsi, le texte édité ouvre à un contenu sémiotique hybride. </p>
                     <p>Un autre type est compositionnel. Ici le texte édité devient agrégation de
                        segments de textes autonomes, qui, par exemple dans <title rend="italic">Wikipédia</title>, peuvent provenir d’auteurs et de sources diverses et
                        être l’objet de changement constant. Comme le dit <ptr target="#gabler2010" loc="50"/>, le texte édité est <emph>supersegmenté. </emph>Ces segments,
                        que les programmeurs appellent des <q> <foreign xml:lang="en">snippets</foreign> </q>, permettent des recompositions infinies de
                        nouveaux textes qui à leur tour peuvent être ajustés afin de répondre aux
                        divers types de lecteurs. Ces <foreign xml:lang="en">snippets</foreign>
                        peuvent même être convertis en <q> textos </q> pour être diffusés dans les
                        réseaux sociaux par l’intermédiaire de téléphones intelligents. Cela invite
                        évidemment à une multitude de parcours de lecture. Il va sans dire le
                        contenu sémiotique des textes devient alors de plus en plus hybride. </p>
                     <p>Une des dimensions importantes du travail éditorial classique plus
                        particulièrement de l’édition experte, académique et critique est le sceau
                        d’autorité et de validité qu’il appose un texte sémiotique. En effet, les
                        éditeurs jouent un rôle de garant de la qualité d’un texte par la
                        correction, l’évaluation, la disposition, l’ajout d’appareillage critique,
                        etc. Or, l’édition électronique des textes, ce travail ne se retrouve pas
                        toujours de manière évidente. Certes, on le voit dans l’édition de l’<title rend="italic">Index Thomisticus</title> dont l’éditeur est un
                        spécialiste : le jésuite Busa. La confiance, cependant, n’est pas la même
                        pour les textes en libre accès, ou encore ceux de Wikipédia. </p>
                     <p>Bref, comme, le texte numérique édité (Td) modifie à sa manière la dynamique
                        herméneutique. Les nouvelles formes d’édition comme le dit Gabler, elle
                        invite au dépassement des frontières qui délimitaient l’édition classique : <cit>
                           <quote rend="block" source="#gabler2010"> The digital medium has the potential to develop into
                              an environment suitable to reintegrate textual criticism into
                              criticism – and, just a importantly: to ground criticism again in
                              textual criticism. </quote>
                           <ptr target="#gabler2010" loc="46"/>
                        </cit></p>
                     <p>De ce fait, le texte édité n’est pas innocent sur le plan herméneutique. Il
                        instaure une nouvelle forme de médiation structurelle, critique et
                        évaluative entre le format du texte et son contenu. La lecture, l’analyse et
                        la compréhension des textes en sont modifiées. Si dans certains cas, elles
                        sont balisées par une édition classique et qu’elle invite à une
                        compréhension proche de l’horizon connu du lecteur et de l’analyste, dans
                        d’autres cas, elles plongent le lecteur dans une boite de Pandore dont
                        l’issu peut être autant une impasse ou un cul-de-sac qu’un nouvel horizon à
                        explorer et découvrir. </p>
                  </div>
                  <div>
                     <head>3. 8 La lecture et l’analyse : le texte à lire analyser et interpréter
                           (T<hi rend="italic"><hi rend="subscript">l</hi></hi>)</head>
                     <p>Dans la variété des types des textes identifiés jusqu’à maintenant nous
                        pouvons distinguer deux ensembles de textes selon qu’ils donnent ou ne
                        donnent pas accès immédiat au contenu textuel comme objet de lecture et
                        d’analyse. </p>
                     <p>Le premier ensemble contient les textes électroniques et les textes
                        numériques qui, bien que porteurs de marques ou de symboles, ne sont pas
                        comme des textes lisibles et analysables par des humains ; ils ne peuvent
                        ancrer la compréhension. Le deuxième contient les textes-images, les textes
                        annotés, les textes dynamiques, les textes édités. Ceux-ci sont
                        véritablement <hi rend="italic">les textes à lire, à analyser et à
                           interpréter</hi> (T<hi rend="italic"><hi rend="subscript">l</hi></hi>)
                        c’est-à-dire dire ils sont des textes signifiants, objets de sémiose et
                        ultimement de compréhension. </p>
                     <p>Sur le plan de la lecture, l’expérience perceptuelle de la lecture est
                        modifiée par l’introduction de tout nouveaux facteurs physiques susceptibles
                        d’influencer le parcours visuel. Du nombre, citons notamment la grandeur de
                        l’écran, le lieu, la luminosité, l’angle, le format de l’écran, la polarité,
                        le lissage des caractères, le mode d’affichage de déroulement, le fenêtrage
                        et le mouvement des yeux. À la lumière de la quantité et de l’importance de
                        ces paramètres d’affichage, la lecture d’un même texte sur le moniteur d’un
                        ordinateur de bureau, une tablette ou un portable est susceptible de
                        produire des expériences textuelles différentes. </p>
                     <p>Comme l’ont montré de nombreuses recherches, la lecture papier, en raison
                        notamment de la portabilité, durabilité, maniabilité et facilité
                        d’annotation des livres, continue d’être préférée à la lecture-écran<note>
                           Les premières recherches menées par Dillon ont démontré d’importantes
                           différences dans les deux types d’expérience textuelle, notamment en ce
                           qui a trait à la rapidité, à la précision, à la fatigue visuelle ainsi
                           qu’à la compréhension <ptr target="#dillon1992"/>.</note>. Elle semble
                        donner plus facilement des lectures critiques, profondes et expertes du
                        contenu textuel. Mais, le texte numérisé gagne aussi en importance, surtout
                        en l’absence d’équivalents papier. Tout comme le texte papier, le texte
                        numérisé permet aussi des lectures critiques, profondes et expertes.
                        L’hypersegmentation et l’hypertextualisation permises par les formes
                        éditoriales variées créent une nouvelle structuration de signes par lesquels
                        le texte est exprimé. Le texte numérisé acquiert ainsi une flexibilité sans
                        précédent. Tout peut en effet être transformé, du titre aux commentaires, de
                        la préface à la postface, de la légende à la note et de l’argumentation à la
                        rhétorique. Par ailleurs, cette flexibilité peut ouvrir à un lecture
                        gigogne, où chaque un segment s’ouvre à d’autres segments engouffrant le
                        lecteur dans des cybersémioticités. Une telle sorte de lecture impose au
                        lecteur de nouvelles charges cognitives au lecteur (<ptr target="#destefano2007"/> ; <ptr target="#ackerman2011"/> ; <ptr target="#baccino2004"/>). En augmentant considérablement la quantité de
                        matériel textuel disponible, ce nouveau monde textuel contraint
                        nécessairement le développement et l’adoption de différentes stratégies de
                        lecture, par exemple la fouille, l’écrémage ou le marquage. </p>
                     <p>Si la lecture classique séquentielle convient fort bien aux romans
                        policiers, rien toutefois ne permet de croire que cette forme traditionnelle
                        de lecture textuelle continuera également de prévaloir pour d’autres types
                        de textes. Selon le contexte et les objectifs de lecture, le format textuel
                        numérisé, annoté de liens hypertextuels renvoyant à des définitions, à des
                        explications ainsi qu’à des critiques et commentaires de spécialistes, sera
                        peut-être préféré au format papier traditionnel, ouvrant ainsi la lecture a
                        un parcours textuel plus éclaté. L’impact de ce changement de mode de
                        lecture est bien évident dans le cas d’un ouvrage comme l’<title rend="italic">Origine des espèces</title> de Darwin. Par les annotations
                        et surtout l’hypertextualisation, le lecteur peut accéder tout au long de sa
                        lecture à un corpus paratextuel et épitextuel formé de plus de 63 éditions
                        différentes de l’ouvrage et de plus de 1500 sources secondaires. La lecture
                        classique est ainsi rompue au profit de parcours de textes multiples,
                        diversifiés et participant à interconnexion textuelle véritablement
                           révolutionnaire<note> Pour <ptr target="#kelly2006"/>, les liens
                           hypertextes et les marqueurs représentent deux des plus importantes
                           inventions des cinquante dernières années.</note>. </p>
                     <p>Outre la lecture, l’analyse technique est aussi profondément modifiée par la
                        numérisation de textes. En effet, le texte à analyser, parce que dynamique,
                        annoté, édité permet une plus grande diversité d’approches analytiques
                        assistées par ordinateur que le permettaient celles réalisées
                        traditionnellement <soCalled> à la main </soCalled>. Elles étaient souvent
                        laborieuses. Et certaines, bien qu’imaginables, étaient cependant souvent
                        impossibles. Un texte numérisé, dynamisé, annoté, édité, etc., peut faire
                        l’objet de nouveaux processus de classification, de catégorisation, de
                        comparaison ou de fouille, etc. Également, de nouvelles formes d’analyse
                        stylistique, linguistique, discursive, thématique, conceptuelle, narrative
                        et rhétorique apparaissent ; l’impact sur le processus interprétatif est
                        considérable. </p>
                     <p>Enfin, il va sans dire que la numérisation des textes affecte aussi
                        grandement leur diffusion et leur partage. Certes, l’analyse de l’impact
                           <soCalled> distributionnel </soCalled> des projets de numérisation
                        massive, par exemple celui initié par Google pour les textes importants de
                        l’humanité, reste à faire. Cependant, il n’en demeure pas moins que la
                        numérisation des textes a profondément modifié les pratiques de partage du
                        savoir, notamment au niveau du mode de fonctionnement d’organismes tels que
                        les maisons d’édition, les librairies, les journaux, les bibliothèques et
                        les universités. Enfin, sur le plan sémiotique, la numérisation favorise non
                        seulement la diffusion et la distribution des textes, notamment dans de
                        nouvelles communautés, mais également elle les intègre aux autres médias
                        technologiques que ce soit à titre visuel ou sonore, avec l’image, le film
                        et la musique.</p>
                     <p>Jusqu’alors limitée, sous sa forme classique, à l’interprétation des textes
                        dans un horizon du sujet, de la culture et du savoir, l’herméneutique doit
                        désormais s’ajuster au contexte numérique, tant à la nouvelle matérialité du
                        texte qu’aux outils d’assistance et à la nouvelle pratique interprétative
                        qui lui est liée. De nos jours, l’herméneutique classique ne peut donc se
                        faire indépendamment d’une herméneutique matérielle. En dépit de cette
                        nouvelle contrainte, toute démarche de ce genre aboutira néanmoins et
                        toujours à la création d’un nouveau texte à lire (T<hi rend="subscript">l</hi>) et, partant, à l’ajout d’un nouvel élément à la
                           <soCalled> galaxie </soCalled> de textes liés au texte source. </p>
                  </div>
               </div>
               <div>
                  <head>4. Conclusion</head>
                  <p>Au fil de cette analyse, nous avons voulu mieux préciser la nature du texte non
                     pas <emph>numérique</emph>, mais du texte <emph>numérisé</emph>. Le texte
                     numérique n’est qu’une des formes d’encodage particulier qu’un texte peut
                     recevoir au sein du processus de numérisation. Celle-ci , en effet, est un
                     processus complexe qui permet de multiples transformations d’un texte. Elle
                     produit le texte numérisé. Chaque opération de ce processus en est une de
                     transformation d’un document textuel vers une autre forme de document textuel.
                     Au départ, le texte source est transformé en un texte matériel : le texte
                     encodé de manière <emph>électronique</emph>. Ensuite, celui-ci est transformé
                     en divers types de textes sémiotiques : un premier, le texte <q> numérique </q>
                     à proprement parler encode le texte par des symboles 0 et 1. Celui-ci, comme
                     texte, est normalement illisible par des humains ; un second, dit <q> texte
                        image </q>, peut être affiché sur écran ou imprimé sur papier et lu en tant
                     que tel, mais l’analyse y est surtout <q> manuelle </q> ; viennent ensuite le
                     texte <emph>dynamique</emph>, le texte annoté et le texte <emph>édité</emph>.
                     Enfin apparaît le texte <hi rend="italic">à lire et à analyser</hi>. Ainsi,
                     partant d’un texte source sélectionné parmi une collection de textes, la
                     numérisation produit non pas une copie unique dite <q> numérique </q> du texte,
                     mais bien une véritable galaxie de textes numérisés. Interreliés et organisés
                     hiérarchiquement, les textes numérisés formant cette galaxie ouvrent ainsi à
                     des parcours nouveaux de lecture et d’analyse. </p>
                  <p>Dans une telle perspective, une critique ou une valorisation de la textualité
                     numérisée doit être prudente. Les défauts et les qualités, les solutions et les
                     problèmes, les avantages et les désavantages du texte numérisé ne s’appliquent
                     pas à tous et de la même manière. Chaque format ou type de texte présente sa
                     signature. Et il faut en saisir la forme, l’usage, la portée, la pertinence,
                     pour en souligner les problèmes ou la valeur. </p>
                  <p>Enfin, la lecture et l’analyse des textes numérisés, quelle qu’en soit la
                     richesse ou la finesse, ne peuvent jamais se faire de manière totalement
                     automatisée, l’ordinateur ne pouvant ici jouer qu’un rôle d’assistance. Même à
                     l’ère numérique, la lecture et l’analyse des textes demeureront une activité
                     humaine. Elles ne peuvent être réduites à un processus intégralement
                     algorithmique. Tout dans le monde n’est pas un modèle complètement
                     computationnel.</p>
                  <p>
                     <figure xml:id="figure07">
                        <head>Galaxie numérique textuelle</head>
                        <graphic url="resources/images/figure06.png"/>
                     </figure>
                  </p>
                  <p>Qu’elle soit classique ou matérielle, la pratique herméneutique est
                     nécessairement interpelée par ces transformations, dans la mesure où elle ne
                     porte plus sur un texte unique, mais sur une galaxie de textes. Par ailleurs,
                     l’analyse et l’interprétation textuelles vont même jusqu’à jouer un rôle actif
                     dans le processus de numérisation en soi, que ce soit au niveau de la mise en
                     corpus, de la saisie électronique, de l’encodage numérique et l’annotation. À
                     la lumière de ces transformations, l’activité interprétative se trouve du coup
                     plongée dans un contexte dynamique radicalement différent du cadre
                     herméneutique classique, que les thèses sémiotiques de Peirce et discursives de
                     Foucault permettent de mieux comprendre et modéliser. L’interprétation porte
                     toujours sur un système de signes canoniquement inscrits dans des puces,
                     affichés ou imprimés, et elle navigue dans une galaxie de <hi rend="italic">systèmes de signes. </hi></p>
                  <p>Évidemment, ce nouveau paysage herméneutique n’est pas sans affecter le monde
                     scientifique et culturel. Cette connectivité numérique, intertextuelle, hybride
                     influenceront grandement le savoir des lecteurs et des analystes, leurs
                     connaissances et désirs ainsi que leur langage. En ce sens, la numérisation des
                     textes modifie profondément les fonctions sémiotiques classiques des textes ;
                     elle les enrichit de pratiques rhétoriques originales, informées de nouvelles
                     formes d’affirmation, de conviction, d’organisation et d’argumentation. Cela
                     dit, malgré toutes ces transformations, Hermès veillera au grain.</p>
               </div>
            </body>
         </text>

         <!-- Translated language -->

         <text xml:lang="en" type="translation_stub" resp="julia_flanders">
            <!-- Use "translation_stub" if only the abstract and possibly a short summary is translated. Use "translation" if the entire article has been translated. -->
            <!-- @resp for the translation is a pointer to xml:id of <dhq:translatorInfo> -->
            <front>
               <dhq:abstract>
                  <p>The digitization of texts is omnipresent in the digital humanities. It seems to
                     present itself only as a modification of the material medium: from text on
                     paper to digital text. But it does more than that. Digitization also affects
                     the text as a semiotic object. The multiple operations of this technology
                     implement interpretative decisions that are not without their effects on the
                     semiotic text; that is to say, the text that offers itself for reading and
                     analysis. In this sense, the digitization of texts is not neutral. It is an
                     important moment of material hermeneutics. </p>
               </dhq:abstract>
               <dhq:teaser>
                  <p>Considering the hermeneutic issues of digital texts.</p>
               </dhq:teaser>
            </front>
            <body>
                  <div>
                     <head>Note on Translation</head>
                     <!-- This boilerplate paragraph describes DHQ's translation practices. If there is no full translation, this paragraph should be left in place. If the article is fully translated, this paragraph can be deleted (it is essentially a stand-in in cases where no full translation is provided). -->
                  <p>For articles in languages other than English, DHQ provides an English-language
                     abstract to support searching and discovery, and to enable those not fluent in
                     the article's original language to get a basic understanding of its contents.
                     In many cases, machine translation may be helpful for those seeking more
                     detailed access. While DHQ does not typically have the resources to translate
                     articles in full, we welcome contributions of effort from readers. If you are
                     interested in translating any article into another language, please contact us
                     at editors@digitalhumanities.org and we will be happy to work with you.</p>
                  </div>
            </body>
         </text>


      </group>

      <back>
         <listBibl>
            <!-- The bibliography should follow DHQ's standard practices. -->
            <bibl xml:id="ackerman2011" label="Ackerman et Goldsmith 2011">Ackerman, Rafaket,
               Goldsmith, Morris (2011). <title rend="quotes">Metacognitive regulation of text
                  learning: On screen versus on paper</title>. <title rend="italic">Journal of
                  Experimental Psychology: Applied</title>, 17-1 (2011): 18-32.</bibl>
            <bibl xml:id="adam1999" label="Adam 1999">Adam, Jean-Michel. <title rend="italic">Linguistique textuelle: des genres de discours aux textes</title>. Paris, Nathan
               (1999).</bibl>
            <bibl xml:id="baccino2004" label="Baccino 2004">Baccino, Thierry. <title rend="italic">La lecture électronique: De la vision à la compréhension</title>. Grenoble,
               Presses Universitaires de Grenoble (2004).</bibl>
            <bibl xml:id="bird2001" label="Bird et Liberman 2001">Bird, Steven, Liberman, Mark.
                  <title rend="quotes">A Formal Framework for Linguistic Annotation (revised
                  version)</title>. <title rend="italic">Speech Communication</title>, 33, 1-2
               (2001): 23-60. </bibl>
            <bibl xml:id="buitelaar2005" label="Buitelaar, Cimiano et Magnini 2005">Buitelaar, Paul,
               Cimiano, Philipp, Magnini, Bernardo, <title rend="quotes"> Ontology Learning from
                  text: An Overview </title>. In Buitelaar, Paul, Cimiano, Philipp, Magnini,
               Bernardo Magnini (dir.). <title rend="italic">Ontology Learning from Text: Methods,
                  Evaluation and Applications</title>. Amsterdam, IOS Press (coll. <title rend="quotes">Frontiers in Artificial Intelligence and Applications</title>): 3-12
               (2005). </bibl>
            <bibl xml:id="cerquiligni1989" label="Cerquiligni 1989">Cerquiligni, Bernard. <title rend="italic">Éloge de la variance : histoire critique de la philologie</title>.
               Paris, Éditions du Seuil (1989). </bibl>
            <bibl xml:id="destefano2007" label="DeStefano et LeFevre 2007">De Stefano Diana, Lefevre
               Jo-Anne. <title rend="quotes">Cognitive load in hypertext reading: A review</title>.
                  <title rend="italic">Computers in Human Behavior</title>. 23-3 : 1616-1641 (2007). </bibl>
            <bibl xml:id="derose1999" label="DeRose 1999">DeRose, Steven J., van Dam, Andries,
                  <title rend="quotes">Document structure and markup in the FRESS Hypertext
                  System.</title>
               <title rend="italic">Markup Languages </title>1(1), Winter 1999: 7-32.</bibl>
            <bibl xml:id="desclés1996" label="Desclés 1996">Desclés, Jean-Pierre. <title rend="quotes">Cognition, compilation, langage</title>. In Chazal, Gérard,
               Terrasse, Marie-Noëlle (dir.). <title rend="italic">Philosophie du langage et
                  informatique</title>. Paris, Hermès: 103-145 (1996).</bibl>
            <bibl xml:id="dillon1992" label="Dillon 1992">Dillon, Andrew. <title rend="quotes">Reading from Paper Versus Screens: a Critical Review of the Empirical
                  Literature</title>. <title rend="italic">Ergonomics</title>, 35-10 (1992):
               1297-1326. </bibl>
            <bibl xml:id="eberle-sinatra2016" label="Eberle Sinatra et Forest 2016">Eberle Sinatra,
               Michael, Forest, Dominic. <title rend="quotes">Lire à l’ère du numérique: <title rend="italic">Le nénuphar et l’araignée</title> de Claire Legendre</title>.
                  <title rend="quotes">Sens public</title>. 22 décembre 2016 : <ref target="http://www.sens-public.org/article1230.html">http://www.sens-public.org/article1230.html</ref>.</bibl>
            <bibl xml:id="eberle-sinatra2014" label="Eberle Sinatra et Vitali-Rosati 2014">Eberle
               Sinatra, Michael, Vitali-Rosai, Marcello (dir.). <title rend="italic">Pratiques de
                  l’édition numérique</title>. Montréal, Presses de l’Université de Montréal, coll.
                  <title rend="quotes"> Parcours numérique </title> (2014). </bibl>
            <bibl xml:id="foucault1969" label="Foucault 1969">Foucault, Michel. <title rend="italic">Archéologie du savoir</title>. Paris, Gallimard (1969). </bibl>
            <bibl xml:id="gabler2010" label="Gabler 2010">Gabler, Hans W. <title rend="quotes">Theorizing the Digital Scholarly Edition</title>. <title rend="italic">Literature
                  Compass</title>. 7-2 (2010): 43-56. </bibl>
            <bibl xml:id="genette1979" label="Genette 1979">Genette, Gérard. <title rend="italic">Introduction à l’architexte</title>. Paris, Seuil (2001).</bibl>
            <bibl xml:id="genette1987" label="Genette 1987">Genette, Gérard. <title rend="italic">Seuils</title>. Paris, Le Seuil (1987).</bibl>
            <bibl xml:id="goldfarb1981" label="Goldfarb 1981">Goldfarb, Charles F. <title rend="quotes">A Generalized Approach to Document Markup</title>. In <title rend="italic">Proceedings of the ACM SIGPLAN-SIGOA Symposium on Text
                  Manipulation</title>. New York, ACM (1981). </bibl>
            <bibl xml:id="habert1997" label="Habert et al. 1997">Habert, Benoît, Nazarenko, Adeline,
               Salem, André, <foreign xml:lang="la">et al. </foreign><title rend="italic">Les
                  linguistiques de corpus</title>. Paris, Armand Colin (1997).</bibl>
            <bibl xml:id="halliday1976" label="Halliday et Hasan 1976">Halliday Michael, Hasan,
               Ruqaiya. <title rend="italic">Cohesion in English.</title> Londres, Longman
               (1976).</bibl>
            <bibl xml:id="jeanneney2005" label="Jeanneney 2005">Jeanneney, Jean-Noël. <title rend="quotes">Quand Google défie l’Europe</title>. <title rend="italic">Le
                  Monde</title>. 22 janvier 2005.</bibl>
            <bibl xml:id="jeanneney2010" label="Jeanneney 2010">Jeanneney, Jean-Noël. <title rend="quotes">Quand Google défie l’Europe</title>. <title rend="italic">Plaidoyer
                  pour un sursaut</title>. Fayard, Mille et une nuits, Paris (2010).</bibl>
            <bibl xml:id="jeanneret2014" label="Jeanneret 2014">Jeanneret, Yves. <title rend="italic">Critique de la trivialité. Les médiations de la communication, enjeu
                  de pouvoir</title>. Paris, Éd. Non Standard (2014). </bibl>
            <bibl xml:id="kelly2006" label="Kelly 2006">Kelly, Kevin. <title rend="quotes">Scan this
                  book!</title>. <title rend="italic">New York Times</title>. 14 mai 2006: <ref target="http://www.nytimes.com/2006/05/14/magazine/14publishing.html">http://www.nytimes.com/2006/05/14/magazine/14publishing.html</ref>. </bibl>
            <bibl xml:id="kulkarni2014" label="Kulkarni et Rokade 2014">Kulkarni, Kiran C., Rokade,
               Shashikant. <title rend="quotes">Review on Automatic Annotation Search From Web
                  Database International Journal of Emerging Technology and Advanced Engineering
                  Website</title>: <ref target="https://www.ijetae.com">www.ijetae.com</ref>, 4-1
               (2014). </bibl>
            <bibl xml:id="ma2009" label="Ma, Audibert et Nazarenko 2009">Ma, Yue, Audibert, Laurent,
               Nazarenko, Adeline. <title rend="quotes">Ontologies étendues pour l’annotation
                  sémantique</title>. In Gandon, Fabien L. <title rend="italic">IC2009: Actes des
                  20</title><hi rend="italic"><hi rend="superscript">e</hi></hi><title rend="italic"> Journées francophones d’ingénierie des connaissances</title>. Hammamet, Tunisie,
               Mai 25-29. Grenoble, Presses universitaires de Grenoble (2009). </bibl>
            <bibl xml:id="mangen2013" label="Mangen, Walgermo et Bronnick 2013">Mangen, Anne,
               Walgermo, Bente R., Bronnick, Kolbjørn. (2013) <title rend="quotes">Reading linear
                  texts on paper versus computer screen: Effects on reading comprehension</title>.
                  <title rend="italic">International Journal of Educational Research</title>, 58
               (2013): 61-68.</bibl>
            <bibl xml:id="marshall1998" label="Marshall 1998">Marshall, Catherine. <title rend="quotes">The Future of Annotation in a Digital (Paper) World.</title>
               presented at the 35th Annual SGLIS Clinic: Successes and Failures of Digital
               Libraries, University of Illinois at Urbana-Champaign (1998).</bibl>
            <bibl xml:id="mayaffre2002" label="Mayaffre 2002">Mayaffre, Damon. <title rend="italic">Les corpus réflexifs: entre architextualité et hypertextualité</title>. <title rend="italic">Corpus</title>, 1 (2002) : <ref target="https://corpus.revues.org/11">https://corpus.revues.org/11</ref>.</bibl>
            <bibl xml:id="meyers2005" label="Meyers 2005">Meyers, Adam. <title rend="quotes">Introduction to Frontiers in Corpus Annotation II Pie</title>. In <title rend="italic">The Sky Proceedings of the Workshop on Frontiers in Corpus
                  Annotation II: Pie in the Sky</title>: 1-4 (2005).</bibl>
            <bibl xml:id="moretti2013" label="Moretti 2013">Moretti, Franco. <title rend="italic">Distant Reading. </title>Londres et New York, Verso (2013).</bibl>
            <bibl xml:id="morrison2013" label="Morrison, Popham et Wikander 2013">Morrison, Alan,
               Popham, Michael, Wikander, Karen. <title rend="quotes">Creating and Documenting
                  Electronic Texts</title>. <title rend="italic">AHDS Guides to Good
                  Practice.</title>
               <title rend="italic">Oxford Text Archive</title> (2013): <ref target="http://ota.ox.ac.uk/documents/creating/cdet/">http://ota.ox.ac.uk/documents/creating/cdet/</ref>.</bibl>
            <bibl xml:id="mueller2008" label="Mueller 2008">Mueller, Martin. <title rend="quotes">Digital Shakespeare, or Toward a Literary Informatics</title>. <title rend="italic">Shakespeare</title>, 4-3: 284-301 (2008). </bibl>
            <bibl xml:id="newton1665" label="Newton v.1665">Newton, Isaac. <title rend="italic">Trinity College Notebook</title>. Cambridge University Digital Library
               (1661-1665): <ref target="http://cudl.lib.cam.ac.uk/view/MS-ADD-03996/1">http://cudl.lib.cam.ac.uk/view/MS-ADD-03996/1</ref>.</bibl>
            <bibl xml:id="noyes2008" label="Noyes et Garland 2008">Noyes, Jan, Garland, Kate. <title rend="quotes">Computer- vs. Paper-based Tasks: Are They Equivalent?</title>.
                  <title rend="italic">Ergonomics</title>. 51-9 (2008): 1352-1375. </bibl>
            <bibl xml:id="pincemin2007" label="Pincemin 2007">Pincemin, Bénédicte. <title rend="quotes">Introduction</title>. <title rend="italic">Corpus.</title>
               <title rend="quotes">Interprétation, contextes, codage</title>. 6 (2007): 5-15. </bibl>
            <bibl xml:id="rastier2001" label="Rastier 2001">Rastier, François. <title rend="italic">Arts et sciences du texte</title>. Paris, Presses universitaires de France
               (2001).</bibl>
            <bibl xml:id="rastier2011" label="Rastier 2011">Rastier, François. <title rend="italic">La mesure et le grain: sémantique de corpus</title>. Paris, Honoré Champion
               (2011).</bibl>
            <bibl xml:id="reid1980" label="Reid 1980">Reid, Brian. <title rend="quotes">A High-Level
                  Approach to Computer Document Formatting</title>. In <title rend="italic">Proceedings of the 7<hi rend="italic"><hi rend="superscript">th</hi></hi> Annual
                  ACM Symposium on Programming Languages</title>. New York, ACM (1980).</bibl>
            <bibl xml:id="renear1996" label="Renear, Mylonas et Durand 1996">Renear, Allen H.,
               Mylonas, Elli, Durand, David. <title rend="quotes">Refining our Notion of What Text
                  Really Is: The Problem of Overlapping Hierarchies</title>. In Ide, Nancy, Hockey,
               Susan (dir.). <title rend="italic">Research in Humanities Computing</title>. Londres,
               Oxford University Press (1996).</bibl>
            <bibl xml:id="smith1987" label="Smith 1987">Smith, Joan M. <title rend="quotes">The
                  Standard Generalized Markup Language (SGML) for Humanities Publishing</title>.
                  <title rend="italic">Literary and Linguistic Computing</title>. 2-3: 171-75
               (1987). </bibl>
            <bibl xml:id="souchier1999" label="Souchier et Jeanneret 1999">Souchier, Emmanuel,
               Jeanneret, Yves. <title rend="quotes">Pour une pratique de <q>l’écrit
                  d’écran</q></title>. <title rend="italic">Xoana</title>. 6: 98-99 (1999).</bibl>
            <bibl xml:id="sperberg-mcqueen1991" label="Sperberg-McQueen 1991">Sperberg-McQueen,
               Michael. <title rend="quotes">Text in the Electronic Age: Textual Study and Text
                  Encoding, with Examples from Medieval Texts</title>. <title rend="italic">Literary
                  and Linguistic Computing</title>. 6-1: 34-46 (1991).</bibl>
            <bibl xml:id="thielens2011" label="Thielens 2011">Thielens, John. <title rend="quotes">Big Data Wizardry: Pay Attention To What's Behind The Curtain</title> (2011):
                  <ref target="https://www. forbes.                   com/sites/ciocentral/2012/02/23/big-data-wizardry-pay-attention-to-whats-behind-the-curtain/#384aca06752d">https://www. forbes.
                  com/sites/ciocentral/2012/02/23/big-data-wizardry-pay-attention-to-whats-behind-the-curtain/#384aca06752d</ref>.</bibl>
            <bibl xml:id="tolzmann2001" label="Tolzmann, Hessel et Peiss 2001">Tolzmann, Don
               Heinrich, Hessel, Alfred, Peiss, Reuben. <title rend="italic">The Memo of
                  Manki</title>. New Castle, Oak Knoll Press (2001). </bibl>
            <bibl xml:id="vandendorpe2009" label="Vandendorpe 2009">Vandendorpe, Christian. <title rend="italic">From Papyrus to Hypertext. </title>Urbana-Champaign, Illinois
               University Press (2009). </bibl>
            <bibl xml:id="veronis2000" label="Veronis 2000">Veronis Jean. <title rend="quotes">Annotation automatique de corpus: état de la technique</title>. <title rend="italic">Ingénierie des langues</title>. <title rend="italic">Hermes</title>,
               111-118 (2000): 1-52.</bibl>
            <bibl xml:id="virbel1993" label="Virbel 1993">Virbel, Jacques. <title rend="quotes">Reading and Managing Texts on the Bibliothèque de France Station</title>. In
               Delany, Paul, Landow, George P. (éd.). <title rend="italic">The Digital Word: Text
                  Based Computing in the Humanities. </title>Cambridge, MIT Press (1993).</bibl>
            <bibl xml:id="wästlund2005" label="Wästlund, Reinikka, Norlander et Acher 2005">Wästlund, Erik, Reinikka, Henrik, Norlander, Torsten, Acher, Trevor. <title rend="quotes">Effects of VDT and Paper Presentation on Consumption and Production
                  of Information: Psychological and Physiological Factors</title>. <title rend="italic">Computers in Human Behavior</title>. 21 (2005): 377 <title rend="italic">sq</title>. </bibl>
            <bibl xml:id="weinnreich1972" label="Weinnreich 1972">Weinnreich, Uriel. <title rend="italic">Explorations in Semantic Theory.</title> Berlin, De Gruyter Mouton
               (1972).</bibl>
            <bibl xml:id="xiao2008" label="Xiao 2008">Xiao, Richard Z. <title rend="quotes">Well-known and influential corpora</title>. In Lüdeling, Anke, Merja, Kyto
               (dir.). <title rend="italic">Corpus Linguistics: An International Handbook</title>,
               vol. 1. Berlin, De Gruyter Mouton (2008): 383-457.</bibl>
         </listBibl>

      </back>
   </text>
</TEI>